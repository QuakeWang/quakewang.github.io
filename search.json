[{"categories":null,"content":"写在 2023 立冬之后，不想再谈 Web 3.0 和我走的比较近的朋友都知道，我最近对于 Rust 比较感兴趣，关于这门系统级编程语言有哪些优点这里不想多说，但其中最关键的一点是安全，这也就造就了她独有的魅力。\n八月底参加了 GTR@Hangzhou 也是第一次参与 Rust 技术相关的 meetup，以及九月下旬去上海看了 GOSIM，其中会有不少开发者都是做 Web 3.0 这一块的。我第一次听 Web 3.0 是在 20 年年底的时候，当时大概的印象就是去中心化。只会觉得很有发展前景，但却很难普及。\n最近立冬，天变冷了，闲着无聊，不如开始重新认识一下 Web 3.0。\n互联网的诞生 如果想要弄清楚 Web 3.0 的诞生，先来纵向梳理一下互联网的发展历程和现状。\n不言而喻的是，互联网的发展是人类发展步入到信息社会的前提，一方面，大量信息可以被低成本的记录和传播，因为随着硬件技术的发展，存储成本是不断下降的；另一方面，当这些信息内容的总量达到一定量级之后，会对社会和经济活动产生巨大的影响。人们常说的大数据，就是在这种情况下发展的产物，数据变成资源，哪家公司掌握的用户数据越多，可操作的空间就越大。\n在上个世纪 90 年代，互联网的诞生可以说是在纸质媒体之外创造了一个全新的传播渠道，诞生了一批专业的内容生产平台 PGC，此时的互联网是一个只读网络，所有网站的内容都由运营者提供，用户只能观看，是静态互联网。其中代表性的企业包括雅虎、新浪、搜索等门户网站，各网媒雇佣大批编辑，将图文并茂的内容发布为网页。对于读者来说，能做的只有访问网站，浏览数字内容，但读者不能写，无法参与内容的操作。这一时期的互联网是单向的，互联网产生的数据和用户的关系不大。这就是 Web 1.0 时代。\n接着，随着时间的推移，用户开始不满足“只有输入没有输出”的状态了，于是在用户渴望表达自己想法的诉求下，催生出了一大批可以为用户提供创作和表达的平台，比如 Twitter、微博 等。除此之外，还有就是需要用户参与的电商平台、视频网站，以及为这些服务提供终端可基础设施的科技公司，比如微软和苹果，也纷纷涌现。这个阶段，我们在这过渡到 Web 2.0 时代。\n数据资源 在这一时期，用户的各种行为产生了大量数据，但这些数据的特点是存储即拥有，而不是谁创造谁拥有。这样一来，就会导致如下问题：互联网公司凭借收集的数据和掌握数据资源的优势，可以随便操纵分析用户的数据，为企业谋取利益最大化，也就有了所展示出来的私人立场和公共利益的冲突日益变大。\n我们可以看一下 Meta 这家公司（也就是 Facebook），截止 2021 年末最高市值达到 1 万亿美元，如果按照这个数值参与当年各国 GDP 排名的话，大概可以排进全球前十五的位置。就其背后原因，是 19 亿日活用户和 29 亿月活用户，月活用户在全球人口中占比高达 36%。但在 Facebook 主导的互联网里面，你就必须得遵守它所设定的规则，方面的例子就是当年追求连任的川建国同志一样，被“社交性死亡”。\n由此及彼，现如今的互联网服务差不多都是这个样子，其他领域也是同理。比如，在国内我们常用的沟通工具就是微信，随着网络技术的普及，无线网的覆盖面积越来越大，运营商的流量相较以往也在降价，所以作为用户，是以极低的代价使用这些工具。而作为公司来说，肯定是想盈利的。他们为用户提供了沟通的服务，也随之掌握了用户的信息。通过信息变现，会向用户投送广告，作为用户，是不太愿意看见这些广告的。\n这就是事情的关键，你在互联网上获得了很多服务，但你在互联网上的每一步，其实都离不开某一个互联网巨头的“陪伴”。每个互联网巨头又都为他们的产品设计了一整套的制度，在这套制度面前，用户就像一个孩子在面对家长或者老师，几乎没有任何讨价还价的能力和空间。这一时期互联网功能可谓非常强大，但用户离开互联网公司，可谓是“寸步难行”。\n这个时期，我们感受到了互联网服务的强大，但也深陷离开互联网公司就“寸步难行”的困境！互联网公司利用用户对自己产品的依赖，正在像“灰犀牛”一样，把私人机构的价值诉求，变成某种社会规则。\nWeb 3.0：互联网的革命？ 那么有的人可能会说，如果数据归用户自己所有，不就可以了嘛。这也就是 Web 3.0 要做的事情！把互联网打开，从技术层面让互联网实现一种开放性，再通过技术逻辑的再造去改变它的“精神气质”。\n不过，关于 Web 3.0 还没有形成一个大家公认的定义。比如以太坊的前 CTO，Polkadot 创始人加文·伍德（Gavin Wood）就提出，Web 3.0 是一组包容性协议，可为应用程序构建模块；这些模块取代了传统的 Web 技术，如 HTTP 和 MySQL 等，同时可以提供一种全新的创建应用程序的方式。再比如著名硅谷风投机构 A16Z，将 Web 3.0 定义为“一组包含区块链、加密协议、数字资产、去中心化金融和社交平台的技术”。\n简单来说可以这样理解，Web 3.0 即是互联网功能的协议化，协议仅按照代码体现的有限规则运行，既没有更多的利益诉求，也没有更多地投射到社会层面的价值主张；协议之间可以通过相互组合实现功能的叠加，并体现出一种开放和协作的精神。\n举个例子，支付宝的诞生对于电商的兴起来说，是发挥了基础性的作用的，因为在没有支付宝的情况下，买家和卖家互不相识且互不信任，卖家担心发货之后收不到货款，买家担心付款之后收不到货，交易几乎无法完成。而支付宝就在买家和卖家之间，发挥了一种“担保交易”的功能，来组织资金结算，进而促进了贸易的达成。但支付宝的想法并没有到此为止，而是在支付的基础上继续绑定借贷业务，通过推出交易金额越大，信用额度也就越大的激励政策，推荐自己的借贷业务，这就是 Web 2.0 的典型模式。但我们要注意一点，支付业务和借贷业务的绑定，其实会对借贷市场的其他金融机构形成一种排斥效果，这明显对于金融市场扩大供给、促进市场竞争是不利的。\n那么，在 Web 3.0 网络中，支付宝的作用就不再由某一家机构承担了，而是由一个协议来承担，这样就算没有第三方机构作为中介，不信任的双方仍可以安全地进行交易结算，这种协议就叫 HTLC，全名叫哈希时间锁协议，它还可以为其他金融机构创造一种更加公平的竞争环境。\n功能的协议化仅仅是 Web3.0 建设的第一步，在这些协议的背后，还需要一个作为“硬件系统”的支撑协议运行的分布式计算网络，和一个作为“软件系统”的通用的、围绕用户的身份验证、数据记录以及如何使用授权和激励的经济系统。\n硬件系统 “硬件系统”为协议执行提供技术支撑，从底层到应用层分别实现通信、计算、存储和交互等功能，并且在每个环节中都体现出一种“可替代性”，也就是说这些功能并不是依赖于某个特定的机构或者组织才能实现的，但是功能的逻辑是准确而可信的，这种特性又被称为是“去信任的信任”，即 Trustless Trust。\n比如，在目前互联网中，我们所有的程序在执行计算任务的时候，都要自行解决输入的可用性、可靠性以及相互之间的授权问题，还需要因此花费额外的资源，去解决各种不兼容和安全风险等问题。而定位于“互联网计算机”的 IC 协议，就提供了一种 Web 3.0 的解决方案。\nIC 协议是基于区块链共识机制，在 TCP/IP 协议和应用层之间构建了一个包括多个物理节点的虚拟子网；子网内部的节点对输入输出达成共识，可以相互验证计算结果；多个子网之间可以通信，并且可以通过相互组合，实现计算能力的大幅提升。\n其实，类似于 IC 的设计理念，在通信、计算、存储等领域也有类似的探索，这些协议通过相互组合为数据的产生、存储、调用以及隐私保护创造了一个不依赖于任何特定机构的，且功能完整的链条，从而使得互联网具备了一种克服“单点故障”的基本架构。\n经济系统 而在“硬件系统”之外，围绕用户还需要一套针对身份认证、数据记录以及使用授权和激励的经济系统。这套系统需要内嵌到协议的执行过程，协议的实施无需任何第三方机构的参与和帮助。基于这套经济系统，不同的协议就可以相互叠加和组合，并实现经济利益的协调。\n那么，从“硬件和软件”系统的功能来看，区块链就是 Web 3.0 发展高度依赖的一项技术，区块链不仅可以不依赖任何第三方机构实现去信任的协作，还可以通过代币系统对系统成员进行激励。但是，区块链并不是 Web 3.0 的全部，因为区块链的主要作用是建立一套可信共享账本，而不能为 Web 3.0 需要解决的全部问题提供解决方案；Web 3.0 还将通过区块链、隐私计算，人工智能甚至物联网技术的结合获得更大的发展空间。\n但需要注意的是，虽然前面讲了很多“硬件和软件”的组合，但从用户使用的角度看，Web 3.0 与 Web 2.0 可能没有什么太大的区别。Web 3.0 通过分布式技术架构和经济系统的打造，将创造一个全新的商业模式，一个高度联系、无国界的数字经济体，并产生大量的自下而上的创新机会。\nWeb 3.0 的出现反映了一种底层技术的变革在产业链层面带来的新的职能分工，而新的职能分工往往就意味着新的业务模式和新的产业机会。所以，Web 3.0 就是基于技术的方式，对现有互联网进行的一次“破坏性创新”。\n写在之后 Web 3.0 从技术的角度赋予了互联网开放的精神气质，通过分布式技术架构和经济系统的打造，将创造一个全新的商业模式，一个高度联系、无国界的数字经济体。\n但基于目前的环境，我想说 Web 3.0 只能说是一个美好的愿景，实现起来很难很难，触及到的利益链条太多了。但朝这个方向发展是大势所趋，只不过会比较漫长。\n有的时候很喜欢从技术的角度，去解读现如今的世界，倒不如说技术是为了更好地服务。比如说，在 Web 3.0 的概念中，计算将会变成一种通用服务，这一点我是认可的，毕竟让数据回归到创造数据的人手里才是终点，从而就能摆脱数据垄断。这也就提出“公链”这个概念，大家常说的以太坊就是这样一种提供通用计算服务的基础设施。\n所以如果可以的话，我想回归重新去做 infra。还是拿以太坊来继续往下写一点吧。以太坊是在比特币的基础上，实现了图灵完备的智能合约，它理论上可以支持任何形式的去中心化应用，但毕竟是理论上。事实上，以太坊只能支持有限数量的去中心化应用。就其主要原因就是著名的 CAP 不可能三角定理。也就是说，一个分布式系统中，在一致性、可用性和分区容错性三项特征中，最多只能存在其中两个。\n好好好。打住！，啰里八嗦的写了一堆。整理这些资料的时候，也让自己对于技术的发展有了一个重新的认识，也算是一个科普向的文章，并未涉及到了技术方面的知识，毕竟现如今这个社会上，懂不懂技术都可以好好生活，不是嘛。\n写得比较片面，也比较主观。。\n","description":"","tags":null,"title":"不想再谈 Web3","uri":"/tech/web3/web3-001_introduce/"},{"categories":null,"content":"聊聊分布式互斥 前言 在之前的两篇博客中，完成了分布式的基础入门，也就是知道了什么是分布式，以及分布式有哪些指标。下面一个篇章，将会聚焦于分布式协调与同步的内容。简单来说就是，如何让程序通过协作共同去达成一个业务目标。\n什么是分布式互斥？ 假设如下的场景，你正在吃自选餐，刚刚寻找到你想吃的菜品，突然在这时有一个抠脚大汉过来，把你挤到一边。看着他那体型，你只好耐着性子等他打完菜，再继续打自己的菜。结果你夹菜到一半他又回来中断了你的过程。如果这样反复来几次，你肯定会想，这老几就是来找茬的，马上就会来一场“有你没我，有我没你”的格斗了。\n上述的场景，也同样存在于分布式集群环境。就像我们在选菜过程中不希望被打断一样，对于同一共享资源，一个程序正在使用的时候也不希望被其它程序进程所打扰。这就要求在同一时刻只能有一个程序能够访问这种资源。\n在分布式系统里，这种排他性的资源访问形式，叫作分布式互斥，而这种被互斥访问的共享资源叫作临界资源。\n接下来，一起看看如何才能让分布式系统中的程序互斥地访问临界资源。\n集中式算法 对于前文提到的打菜问题，是不是可以增加一个“协调者”来约束大家文明就餐，从而避免强行插入打断别人进程的问题。\n那么，按照这种方式，我们可以在分布式集群中，引入一个协调者程序，得到一个分布式互斥算法。每个程序在需要访问临界资源时，先给协调者发送一个请求。如果当前这个资源处于空闲状态，也就是没有程序正在使用，协调者直接授权请求程序访问；否则，可以按照先来后到的顺序为请求程序“排一个号”。如果有程序使用完资源，则通知协调者，协调者从“排号”的队列里面取出排在最前面的请求，并给它发送授权消息。拿到授权消息的程序，可以直接去访问临界资源。\n这就是 FIFO 的模式，这个互斥算法，就是我们常说的集中式算法。之所以这么称呼，是因为协调者代表着集中程序，如下图所示：\n程序 1、2、3、4 为普通运行的程序，另一个程序为协调者。当程序 2 和 程序 4 需要使用临界资源时，会先向协调者发送申请，请求协调者授权。\n不巧的是，程序 3 正在使用临界资源。这时，协调者会根据程序 2 和 4 的申请顺序，依次将它们放入等待队列。比如当前的案例是，程序 4 的申请时间早于程序 2，因此排在程序 2 的前面。\n程序 3 使用完临界资源后，通知协调者释放授权。此时，协调者从等待队列中通知程序 4，并给它发放授权。这时，程序 4 就可以使用临界资源了。依次类推，直到所有申请结束。\n基于上述流程可以看出，一个程序完成一次临界资源访问，需要如下几个流程和信息交互：\n向协调者发送请求授权信息，1 次消息交互； 协调者向程序发放授权信息，1 次消息交互； 程序使用完临界资源后，向协调者发送释放授权，1 次信息交互。 因此，每个程序完成一次临界资源访问，至少需要进行 3 次信息交互。\n集中式算法的优点在于直观、简单、信息交互量少、易于实现，并且所有程序只需和协调者通信，程序之间无需通信。但缺点也很明显，就是在协调者自身，原因如下：\n一方面，协调者会成为系统的性能瓶颈。假设如果有 200 个程序要访问临界资源，那么协调者要处理 200*3=600 条消息。也就是说，协调者处理的消息数量会随着需要访问临界资源的程序数量线性增加； 另一方面，容易引发单点故障。当协调者的受到的请求访问量过大，如果某一进程特别重，可能会引发协调者故障，就会导致所有程序都无法访问临界资源，可能会进一步造成系统处于不可用状态。 因此，在使用集中算法的时候，一定要选择性能好、可靠性高的服务器来运行协调者。\n分布式算法 既然引入协调者会带来一些问题，那不用协调者是否可以实现对临界资源的互斥访问呢？比如试试看，能不能协商着来。在访问某块资源之前，先征求其他人的意见，在确认其他人都没有意向使用的时候，就属于来到自己的主场了。\n同理，我们可以把这种方式用于分布式系统。当一个程序要访问临界资源时，先向系统中的其他程序发送一条请求信息，在接受到所有程序返回的同意消息后，才可以访问临界资源。其中请求消息需要包含请求的资源、请求者的 ID，以及发送请求的时间。这就是民主协商法。\n如图所示，程序 1、2、3 需要访问资源 A。在时间戳为 8 的时刻，程序 1 想要使用资源 A，于是向程序 2 和 3 发起使用资源 A 的申请，希望得到它们的同意。在时间戳为 12 的时刻，程序 3 想要使用资源 A，于是向程序 1 和 2 发起访问资源 A 的请求。\n如果此时程序 2 暂时不访问资源 A，因此同意了程序 1 和 3 的资源访问请求。对于程序 3 来说，由于程序 1 提出请求的实践更早，因此同意程序 1 先使用资源，并等待程序 1 返回用以消息。\n程序 1接收到其他所有程序的同意消息之后，开始用资源 A。当程序 1 使用完资源 A 后，释放使用权限，向请求队列中需要使用资源 A 的程序 3 发送同意使用资源的消息，并将程序 3 从请求队列中删除。此时，程序 3 收到了其他所有程序的同意消息，获得了使用资源 A 的权限，开始用临界资源 A。\n从上述流程可以看出，一个程序完成一次临界资源的访问，需要进行如下的信息交互：\n向其他 n-1 个程序发送访问临界资源的请求，总共需要 n-1 次消息交互； 需要接收到其他 n-1 个程序回复的同意消息，方可访问资源，总共需要 n-1 次消息交互。 可以得出以下结论，一个程序要成功访问临界资源，至少需要 2*(n-1) 次消息交互。假设，现在系统中的 n 个程序都要访问临界资源，则会同时产生 2(n-1) *n 条消息。总结来说，在大型系统中使用分布式算法，消息数量会随着需要访问临界资源的程序数量呈指数级增加，容易导致高昂的“沟通成本”。\n从上述分析不难看出，分布式算法根据“先到先得”以及“投票全票通过”的机制，让每个程序按时间顺序公平地访问资源，简单粗暴、易于实现。但，这种算法可用性很低，主要包括以下两个方面：\n当系统内需要访问临界资源的程序增多时，容易产生“信令风暴”，也就是程序收到的请求完全超过了自己的处理能力，从而导致自己正常的业务无法继续开展； 一旦某一程序发生故障，无法发送同意消息，那么其他程序均除以等待回复的状态中，使得整个系统处于停滞状态，导致整个系统不可用。所以，相对于集中算法的协调者故障，分布式算法的可用性更低。 针对可用性低的一种改进办法是，如果检测到一个程序故障，则直接忽略这个程序，比如网络阻塞，长时间接收不到返回的消息，既然等不到那么就无需再等咯。\n这就好比在自助餐厅，一个人离开了餐厅，你想选某个菜品也就无需再征求他的建议。但这样的话，每个程序都需要对其他程序进行故障检测，这无疑带来了更大的复杂性。\n因此，分布式算法适合节点数目少且变动不频繁的系统，且由于每个程序均需通信交互，因此适合 P2P 结构的系统。比如，运行在局域网中的分布式文件系统。\n令牌环算法 既然集中式算法、分布式算法都存在一定的缺陷，那么还有什么方法可以实现分布式互斥嘛？答案是肯定的。比较方法总比问题多。轮值 CEO 其实就给了我们一个很好的启示：在轮值 CEO 体系里，CEO 就是临界资源，同时只能有一个人担任，由多名高管轮流出任 CEO。\n类似的，程序访问临界资源问题也可以按照轮值 CEO 的思路实现，如下图所示，所有程序构建一个环结构，令牌按照指定的顺序（顺时针或逆时针）方向在程序之间传递，收到令牌的程序有权访问临界资源，访问完成后将令牌传送给下一个程序；若该程序不需要访问临界资源，则直接把令牌传送给下一个程序。\n在分布式领域，通常将这个算法叫作令牌环算法。为了便于理解记忆，可以形象地称之为轮值 CEO 算法。\n因为在使用临界资源前，不需要像分布式算法那样挨个征求其他程序的意见了，所以相对而言，在令牌环算法里单个程序具有更高的通信效率。同时，在一个周期内，每个程序都能访问到临界资源，因此令牌环算法的公平性很好。\n但是，不管环中的程序是否想要访问资源，都需要接收并传递令牌，所以也会带来一些无效通信。假设系统中有 100 个程序，那么程序 1 访问完资源后，即使其它 99 个程序不需要访问，也必须要等令牌在其他 99 个程序传递完后，才能重新访问资源，这就降低了系统的实时性。\n综上，令牌环算法的公平性高，在改进单点故障后，稳定性也很高，适用于系统规模较小，并且系统中每个程序使用临界资源的频率高且使用时间比较短的场景。\n总结 在这篇博客中，我们介绍了分布式互斥的概念和几种实现方法，包括集中式算法，分布式算法和令牌环算法。\n集中式算法引入了一个协调者程序，每个程序在需要访问临界资源时，先给协调者发送一个请求。协调者根据请求的顺序，决定哪个程序可以访问资源。集中式算法的优点是简单和易于实现，但是协调者可能会成为系统的性能瓶颈，或者引发单点故障。\n分布式算法的思路是，一个程序在访问临界资源时，先向其他程序发送请求。只有当所有程序都同意之后，该程序才可以访问资源。这种方式可以避免单点故障的问题，但是可能会产生大量的消息交互，导致“信令风暴”。此外，如果某个程序发生故障，那么整个系统可能会处于停滞状态。\n令牌环算法则是所有程序构成一个环，令牌按照一定的顺序在程序之间传递。只有拿到令牌的程序才能访问资源。这种方法避免了无效的通信，提高了通信效率。同时，由于在一个周期内，每个程序都能访问到资源，因此令牌环算法的公平性很好。但是，不论程序是否需要访问资源，都需要接收并传递令牌，这可能会降低系统的实时性。\n总的来说，每种算法都有其适用的场景和局限性。在实际使用中，需要根据系统的规模，程序的数量，以及临界资源的使用频率和使用时间等因素，选择最合适的算法。同时，也可以考虑使用混合的方式，结合多种算法的优点，以满足不同的需求。\n","description":"","tags":null,"title":"分布式 003——互斥","uri":"/tech/distributedsystem/ds003_mutex/"},{"categories":null,"content":"分布式系统有哪些指标？？ 前言 经过上一篇博客，我们简单了解了分布式的起源，对于分布式技术有了一个整体的印象。这篇内容将会回归理性，一起来看看可以用哪些指标来具体地衡量一个分布式系统。\n从分布式技术的起源可以看出，分布式系统的出现就是为了用廉价的、普通的机器解决单个服务器处理复杂、大规模数据和任务所存在的性能问题、资源瓶颈问题，以及可用性和可扩展性问题。因为我们知道如果要想使得一台机器能兼顾所有的性能，成本是非常昂贵的。简单来说，分布式的目的就是用尽可能低的成本，处理更多的数据和更复杂的任务。\n由此可以看出，性能、资源、可用性和可扩展性是分布式系统的重要指标。接下来，就详细来逐个来了解一下。\n性能（Performance） 谈起性能指标，主要是用于衡量一个系统处理各种任务的能力，无论是分布式系统还是单机系统，都会对性能有所要求。\n不同的系统、服务要达成的目的不同，所以各自对于性能的要求也就会有所区别，甚至是相互矛盾的。这里我们来看几个常见的性能指标，分别是吞吐量、响应时间和完成时间。\n吞吐量指的是，单位时间内系统能够处理的请求或事务，能够表示系统的处理能力和效率。\n吞吐量的衡量可以根据具体应用场景而有所不同。例如，在网络通信中，吞吐量可以表示单位时间内传输的数据量；在数据库系统中，吞吐量可以表示每秒钟执行的查询数量；在并发用户访问网站时，吞吐量则可以表示每秒钟处理的请求数量。\n常见的吞吐量指标有 QPS（Queries Per Second）、TPS（Transaction Per Second）和 BPS（Bits Per Second）。\nQPS，即查询数每秒，用于衡量一个系统每秒处理的查询数，需要注意的是离开响应时间的要求是无法衡量 QPS 的。这个指标通用用于读操作，越高说明对读操作的支持越好。比如刚才我们所举的数据库的查询操作，就会用这个指标来表示。所以，我们在设计一个分布式系统的时候，如果主要都是偏向于读的操作，那么就需要重点考虑如何提高 QPS，来支持高频的读操作。 TPS，即事务数每秒，用于衡量一个系统每秒处理的事务数。这个指标通常对应于写操作，越高说明对写操作支持越好。那么如果需要设计一个以写请求的分布式系统，对于 TPS 的支持是需要关心的，从而达到支持高频的写操作； BPS，即比特数每秒，用于衡量一个系统每秒处理的数据量。对于一些网络系统、数据管理系统，我们不能简单的按照请求数或事务数来衡量其性能。因为请求与请求、事务与事务之间也存在着很大的差异，比如说，有的事务因为要写入更多的数据，所以比较大。那么在这种情况下，BPS 更能客观地反映系统的吞吐量。 响应时间指的是，系统响应一个请求或输入需要花费的时间。响应时间直接影响到用户体验，对于时延敏感的业务非常重要。比如我们出门时都会用到导航，如果响应时间过长，很容易带错路。\n完成时间指的是，系统真正完成一个请求或处理需要花费的时间。任务并行模式出现的其中一个目的，就是缩短整个任务的完成时间。特别是需要计算海量数据或处理大规模任务时，系统对完成时间的感受非常明显。\n资源占用（Resource Usage） 资源占用指的是，一个系统在正常运行时需要占用的硬件资源，比如 CPU、内存和硬盘等。\n一个系统在没有任何负载时的资源占用，叫作空载资源占用，体现了这个系统自身的资源占用情况。比如，我们手机上在安装一款新的 APP 的时候，在软件的详情页面都会标注出软件的大小，比如多少 KB。这就是该 APP 的空载硬盘资源占用。对于同样的功能，空载资源占用越少，说明系统设计的越整洁，往往也会更容易被用户所接受。\n一个系统满额负载时的资源占用，叫作满载资源占用，体现了这个系统全力运行时占用资源的情况，也体现了系统的处理能力。同样的硬件配置上，运行的业务越多，资源占用越少，说明这个系统设计的越好。\n可用性（Availability） 可用性，通常来说是指系统在面对各种异常时可以正确提供服务的能力。可用性是分布式系统的一项重要指标，衡量了系统的 Robustness，是系统容错能力的体现。\nRobustness 也就是中文翻译的“鲁棒性”，我是不太喜欢这个翻译的，让人不知所以然。主要指的是系统在面对异常、错误或不符合预期输入时的稳健性和能力。\n我们经常会在分布式系统中看见高可用这个词，也就是 7*24 不间断连续工作。那么系统的可用性可以用系统停止服务的时间与总的时间之比衡量。假设一个网站总的运行时间是 24 小时，在 24 小时内，如果网站故障导致不可用的时间是 6 个小时，那么系统的可用性就是 6/24=0.25，也就是有四分之一的时间处于不可用阶段。\n除此之外，系统的可用性还可以用某功能的失败次数与总的请求次数之比来衡量，比如给网站发送 1000 次请求，其中有 10 次请求失败，那么可用性就是 99%。\n提到了可用性，有的同学可能会疑惑，诶 这个和可靠性（Reliability）有何区别呢？\n可靠性通常用来表示一个系统完全不出故障的概率，更多地用在硬件领域。而可用性则更多的是指在允许部分组件失效的情况下，一个系统对外仍能正常提供服务的概率。\nJeff Dean 曾在 Google I/O 大会上透露：谷歌一个基于 1000 台通用计算机的集群，一年之内就有 1000+ 硬盘会出现故障。由于现在比较常见的分布式系统基本上都是基于通用计算机的，这就意味着在这些系统中无法实现真正的可靠，所以我们也会在一些场合见到可靠性和可用性交换使用的情况。\n可扩展性（Scalability） 可扩展性，指的是分布式系统通过扩展集群机器规模提供系统性能（吞吐量、响应时间、完成时间）、存储容量、计算能力的特征，是分布式系统的特有性质。\n分布式系统的设计初衷，就是利用集群多机的能力处理单机无法解决的问题。然而，完成某一具体任务所需要的集群规模，取决于单个机器的性能和任务的要求。\n当任务的需求随着具体业务不断提高时，除了升级系统的性能做垂直 / 纵向扩展外，另一个做法就是通过增加机器的方式去水平 / 横向扩展系统规模。\n这里垂直 / 纵向扩展指的是，增加单机的硬件能力，比如 CPU 增强、内存增大等；水平 / 横向扩展指的就是，增加计算机数量。好的分布式系统总是在追求“线性扩展性”，也就是说系统的某一指标可以随着集群中的机器数量呈线性增长。\n衡量系统可扩展性的常见指标是加速比（Speedup），也就是一个系统进行扩展后相对扩展前的性能提升。\n如果扩展的目标是为了提高系统吞吐量，则可以用扩展后和扩展前的系统吞吐量之比进行衡量。 如果目标是为了缩短完成时间，则可以用扩展前和扩展后的完成时间之比进行衡量。 总结 这篇内容读起来可能比较无聊，更偏向于科普类的介绍了一些常用的专业术语。需要注意的是，使用这些指标衡量一个分布式系统不能教条化。\n按照不同维度，分布式系统的指标可以分为性能、资源占用、可用性、可扩展性这四大类。我们当然也希望自己开发或者使用的系统，是高性能、高可用、可扩展和低资源同时占用的，但考虑到硬件成本、开发效率等因素，对于不同的系统和业务，必须在设计时做出取舍。\n","description":"","tags":null,"title":"分布式 002——分布式系统的指标","uri":"/tech/distributedsystem/ds002_norm/"},{"categories":null,"content":"分布式该从何谈起？？ 前言 现如今做开发，写代码出门和人聊天，动不动就会提起分布式，而且很多使用的框架、中间件都会采用分布式的设计。所以开阔自己的眼界，别做个 API Boy(Girl)。想了想开始试水写点相关的文章，一来梳理一下自己的学习心得，再者编写博客的过程中，也是对知识加强的一种途径。BTW 如果能帮助有些人就再好不过啦～～\n作为第一篇文章，先来看看分布式到底是什么。抛去那些抽象的的技术名词，该如何阐述这个概念呢？？\n注：为了更好地理解分布式的发展过程，默认每个计算机或服务器都是单核、单处理器的。\n分布式起源 从第一台计算机开始聊聊 世界上第一台通用计算机是在 1946 年情人节发布的 ENIAC，由于当时硬件水平的限制，就如大家所说的那样，占地面积大，还显得特别笨重，但在那个时候已经做到了每秒可进行 5000 次加法或者 400 次乘法运算，标志着单机模式的开始。\n从这方面来看，电脑的出现就是为了计算，其实现如今也不例外，如果有时间可以简单来谈谈计算，试着从莱布尼茨开始说起 哈哈。回归正题，所谓单机模式简单来说是指，所有应用程序和数据均部署在一台电脑或服务器上，由一台设备完成所有的处理。\n最近“双十一”，就以电商网站系统为例，删繁就简，只关注以下几个模块，分别是：用户管理、商品管理和订单管理。数据也就包括用户数据、商品数据和订单数据等。如果使用单机模式，那么所有的模块和数据均会部署在同一台计算机上，也就是说数据存储、请求处理均有同一个服务器来完成。这种模式的好处是功能、代码和数据更加集中，便于维护、管理和执行。\n单机模式的示意图，如下所示：\nEvery coin has two sides. 那么单机部署的缺点是什么呢？？单个计算机的处理能力取决于 CPU 和内存等，但硬件的发展速度和性能是有限的（可以看看摩尔定律），而且升级硬件的成本也比较高，可以说硬件的性能是单机模式的瓶颈。还有就是如果当前将所有的任务都交给一台服务器，可能会承受较大的负载压力，或者受到攻击挂了的话，所有的服务也就不能正常运行了，这也就将所有鸡蛋放到一个篮子里的风险，也就是单点失效问题。\n顺着这个思路往下走，既然单机模式存在性能的瓶颈，也就会导致会存在可用性的问题，有没有更好的解决办法呢？\n数据并行 为解决单机模式的问题，并行计算得到了发展，也就是我们常说的 MapReduce，并进一步出现了数据并行模式，也有的人喜欢称之为数据分布式模式。并行计算采用消息共享模式使用多台计算机并行运行或执行多项任务，核心原理是每台服务器上执行相同的程序，将数据进程拆分到不同的服务器上进行计算。\n需要注意的是，并行计算强调的是对数据进行拆分，任务程序在每台机器上运行。要达到这个目的，首先要做的是把单机模式中的应用和数据分离，才可能实现对数据的拆分。这里的应用就是执行任务的程序，任务就是提交的请求。还是来看上面的这个例子，运行在服务器上的用户管理、商品管理和订单管理等程序都是应用，用户提交的查询浏览商品、购买商品的请求就是任务。\n在单机模式中，应用和数据均在一台计算机或服务器上，要实现数据的并行，必须先将应用和数据分离以便将应用部署到不同的计算机或服务器上；然后，对同类型的数据进行拆分，比如说，不同计算机或服务器上的应用可以到不同的数据库上获取数据执行任务。\n这么讲可能比较抽象，来看看图：\n第一步，将应用与数据分离，分别部署到不同的服务器上。\n第二步，对数据进行拆分，比如把同一类型的数据拆分到两个甚至更多的数据库中，这样应用服务器上的任务就可以针对不同数据并行执行了。\n对于电商销售系统，根据商品类型将用户、商品和订单数据拆分到不同的数据库中，部署到不同的服务器上，比如运动鞋服类的数据放在数据库服务器 1 上，电脑数据的数据放在数据库 2。\n这种模式的好处是，可以利用多台计算机并行处理多个请求，使得我们可以在相同的时间内完成更多的请求处理，解决了单机模式的计算效率瓶颈问题。但这种模式仍然存在如下几个问题，在实际应用中，我们还需要进行相对应的优化：\n相同的应用部署到不同的服务器上，当大量用户请求过来时，如何能比较均衡地转发到不同的应用服务器上呢？这也就是我们常说的“负载均衡”的问题，等后期有时间再展开聊聊； 当请求量较大时，对数据库的频繁读写操作，会导致数据库的 IO 访问成为瓶颈。这种就可以使用“读写分离”的模式，也就是“主从库”的方式来解决，主数据库负责读写操作，然后再同步数据给从库，从而可以做到读数据库只接收读请求，写数据库只接收写请求，需要注意的是保证数据一致性； 当有些数据成为热点数据时，会导致数据库访问频繁，压力增大。解决这个问题的方法是引入缓存机制，将热点数据加载到缓存中，一方面可以减轻数据库的压力，另一方面也可以提高查询效率。 由此我们可以看出，数据并行模式实现了多请求并行处理，但如果单个请求特别复杂，比如说需要几个小时甚至几天的时候，这种模式的整体计算效率还是不够高。其主要问题是：对提升单个任务的执行性能及降低时延无效。\n任务并行 既然数据并行是存在一定缺陷的，我们就可以想是不是可以提高单个任务的执行性能，或者缩短单个任务的执行时间呢？也就出现了任务并行的模式，有的人可能喜欢称之为“任务分布式”，都是一个概念。\n任务并行指的是，将单个复杂的任务拆分为多个子任务，从而使得子任务可以在不同的计算机并行执行。\n我们仍以电商销售系统为例，任务并行首先是对应用进行拆分，比如按照领域模型将用户管理、商品管理、订单管理拆分成多个子系统分别运行在不同的计算机或服务器上。简单来说就是，原本包括用户管理、商品管理和订单管理的一个复杂任务，被拆分成多个子任务在不同的服务器上执行。\n可以看出，任务并行模式完成一项复杂任务主要有两个核心步骤：首先将单任务拆分成多个子任务，然后让多个子任务并行执行。我们可以这样类比，任务拆分对应于部门领导，不同子系统对应不同的开发人员，不同子程序执行不同任务就像不同的程序员使用不同的技术栈一样，并且运行子系统或者子任务的计算机又可以组成一个服务。\n在这种模式中，由于多个子任务可以在多台服务器上运行，因此通过将同一任务待处理的数据分散到多个服务器上，在这些服务器上同事进行处理，就可以加快任务执行的速度。因为，只要一个复杂任务拆分出的任意子任务执行时间变短了，那么这个任务整体的执行时间也就相对而言变短咯。\n当然，任务分布式也存在一定的缺点，它在提供了更好的性能、扩展性、可维护性的同时，也带来了设计上的复杂性问题。毕竟对一个大型的复杂业务进行拆分并不是一件轻松的事情。从长远收益来看，这个短期设计上的阵痛是值得的。我们在平时也要注意多积累，有些技术可能仅仅是自己感兴趣，但不要因为短期内或公司的业务用不上就放弃不去学习，要有长远目标，慢慢多学一点点，回头来看会有不一样的感悟噢～～\n分布式是什么？？ 看到这里，有些人就可能会觉得，啰里八嗦讲了一堆，诶 分布式到底是什么呢？\n用大白话说来说分布式就是，将相同或相关的程序运行在多台服务器上，从而实现特定目标的一种计算方式。\n从这个角度来看，数据并行、任务并行其实都可以算作是分布式的一种形态。从这些计算方式的演变中不难看出，产生分布式的最主要原因是，数据量的暴增，如何更有效地追求高性能、可用性以及可扩展性。。\n总结 这篇博客，简单聊了分布式的起源，从最初的单机模式到数据并行，再到任务并行。起初我是想从 GFS 和 MapReduce 的角度来阐述，但脱离业务，从数据出发可能会让不懂大数据的同学来说有点抽象，分布式文件系统和分布式计算引擎等后期有时间再拎出来单独唠唠（开始挖坑叻。。。）\n单机模式指的是，所有业务和数据均部署到同一台机器上。这种模式的好处是功能、代码和数据集中，便于维护、管理和执行，但计算效率是瓶颈。也就是说单机模式性能受限，也存在单点失效的问题。\n数据并行（也叫作数据分布式）模式指的是，对数据进行拆分，利用多台计算机并行执行多个相同任务，通过在相同的时间内完成多个相同任务，从而缩短所有任务的总体执行时间，但对提升单个任务的执行性能及降低时延无效。\n任务并行（也叫作任务分布式）模式指的是，单任务按照执行流程，拆分成多个子任务，多个子任务分别并行执行，只要一个复杂任务中的任意子任务的执行时间变短了，那么这个业务的整体执行时间也就变短了。该模式在提高性能、扩展性、可维护性等的同时，也带来了设计上的复杂性问题，比如复杂任务的拆分。\n在数据并行和任务并行这两个模式的使用上，用户通常会比较疑惑，到底是采用数据并行还是任务并行呢？一个简单的原则就是：任务执行时间短，数据规模大、类型相同且无依赖，则可采用数据并行；如果任务复杂、执行时间长，且任务可拆分为多个子任务，则考虑任务并行。在实际业务中，通常是这两种模式并用。\n","description":"","tags":null,"title":"分布式 001——聊聊分布式的起源","uri":"/tech/distributedsystem/ds001_introduce/"},{"categories":null,"content":"十月杂谈——人生海海，愿有岸有帆 关于假期 十月的开始，是在放假诶，真的很棒！调休了一天，提前回家，没有什么比放假更开心的事情啦～～\n回上海之后，顺路去看了一下 KubCon，emmm 可能是去的比较晚了吧，收摊收的比较早，就简单地逛逛转转就回父母那边了。也许是比较累了，早上起的有点早。作为一名云原生小白，会感到自己有很多知识需要去补，先从基础知识抓起吧。\n与国庆相邻的是中秋🎑，之前读大学的时候，对于中秋的定位是比较尴尬的，因为假期时间短，也就很少回父母身边，本应该是团圆的日子，结果却发出“如果很想念的话，就抬头看看月亮吧”的感叹。这两年倒还不错，能和家人团聚在一起。但随之而来的就是长辈们的“亲切问候”。细节就不想说了，也就是大家所常聊的那些，但对我来说，不太喜欢。我放弃了很多看似很好的选择，只想活成我想要的样子，我也不知对或错，我也不知该往哪走，但我知道自己想要的是什么，也大概知道下一个目标在哪，二十刚出头，走点弯路很正常的嘛。\n我一直提倡的一个观点，就是要想自己完全独立，首先需要做的就是经济独立，从而才能保证人格独立。所以，从大学阶段我就几乎“断奶”了。目前工作的收入，也差不多够日常的支出，再通过技术变现，积累点小的财富。我也不知从何开始，突然觉得，如果手里的余额低于某个数，很会不安全感。多备一点，以防不时之需嘛。而且，我也感觉到自己的观点与长辈们相冲突，但至少我独立了，他们也无可奈何我。随着时间的推移，矛盾终会爆发，但我不想向生活低头，emmm 至少现在还不想。\n假期中，还和朋友吃了烤肉，最后又去逛了逛卡普空周边店，只是单纯想看看怪猎 IP 的周边，不由的想说二次元的钱真好赚，虽然很多东西看着就有买的欲望，对我来说，只要不是“强需求”就没必要。我也就逛逛而已了嘛。\n假期的最后，去了无锡看 2023CYML，受“口罩😷”的影响，好久没见过这么热闹的线下比赛了。本来准备参赛的，一分钟都排好了，结果最后半个月发生了腱鞘炎，可能是练球练多了，也可能是打游戏打的，总不能说是写代码写的吧，呜呜呜呜，天朝苦命打工人😭。其实，反过来想，单纯的做一名观众也挺舒服的，没有比赛的负担，可以更轻松地去看比赛。其中，也不得不感叹，很多新面孔，很刷，但预赛看起来很容易审美疲劳，差不多的音乐，差不多的穿搭，玩着差不多的招。决赛的话，我最喜欢的应该是 shy 的“青鸟”，完成度很高，编排看起来也很舒服。\n然后就假期结束，回杭州躺一天，准备上班叻。\n身体状态 自从去年阳了之后，会感觉到身体素质大不如从前，也可能是年纪大了（bushi。。\n有假期就有补班，吐槽一句调休是什么勾八政策，直接多给几天假期不就得了，今年除夕不放假，把老祖先的传统都给丢咯。\n回归正题，回来上班之后，突然头疼难受，然后还发热🥵 就觉得该不会是自己又阳了吧，至于是几阳，我也不知道，反正只要我不测，我就没阳，是不是这个道理。。。实在无语，三年防疫，最后依托答辩呢。过去的事情就不提了，但仔细一想，如果后半辈子都是这种状态，当社畜上着班，然后隔段时间给你来一下，唉 生活没了盼头。买药的时候，也会想着，现在是不是穷人都不配生病了？？现实就是结结实实的灰色幽默。\n身体差了肯定是要练的嘛， 然后就和室友去开始尝试撸铁。第一周说不好的痛苦，练哪哪疼，一疼疼几天，以至于周六和朋友干饭的时候，走路都一歪一歪的。到了第二周的时候，身体慢慢习惯了，虽然有点酸痛，但都属于能够接受的范围，也开始逐渐接受这个强度，开始慢慢喜欢上了。写这篇博客的时候是第三周，也还是好累啊。\n总体来说，虽然有点累，但还是挺享受的，工作避免不了久坐，还喜欢下意识的喜欢跷二郎腿，这都是不好的，要改。每天下班，撸完铁，做好有氧，回到家里，洗个澡。属于自己的夜生活也正式开始咯。可能是看看书，可能是打打游戏 写写代码，最后顶着疲惫不堪的身体入睡。\n还是想看看健身两个月之后的样子，虽然目前看起来没啥效果，也可能是自己比较偏瘦，身体显得不是很壮，但还是挺怕吃重了之后，万一不健身了的时候，身体变得臃肿可咋办呢，hhhh。\n哦对了，还有点想买 iWatch，算了，不是强需求没必要买。不是为了健身而买手表，更不会为了买手表而健身，只会徒增烦恼罢了。\n读书 这个月读了两本书，第一本是《长安的荔枝》，属于畅销网文小说类型的，本来对于这类书籍是不太喜欢的，但同事推荐说挺好看的，然后假期往返途中，在高铁上用 iPad 看完的，好久没用 iPad 看过书了，随着想扩宽自己的技术路线，对于闲书读的是越来越少，大不如从前几年。这本书讲还是比较浅显易懂的，侧面反应的是人心，里面比较好的点大概是几处转折。虽然最后完成了任务，但却失去了很多，我们不也正是这样嘛，一边在得到，一边在失去，得到了之后，会发现不如自己当时所期待的，失去了的，有可能是再也无法挽回的。知足常乐就好～～\n第二本是麦家老师的《人生海海》，这本书越读到后面，越没有勇气往下读，就很难受。也许就像是书里所阐述的观点：真正的英雄主义，不是勇敢地去死，而是勇敢地选择活着。谈谈几个印象比较深的点吧。首先是老巫头，从“我”的角度代入故事，自然对于一肚子大道理的爷爷很敬佩，但也恰恰是这些繁文缛节，被条条框框所限制，被周围人的看法所影响，从而选择告密。“我”多么希望这是假的啊，但却是事实。。当时老保长说上校当兵在前线的事情，我甚至一度怀疑，老保长说的是假的，毕竟印象不太好，谎话连篇也不足为奇，一个英雄的故事，结果却从他口中来阐述，总觉得有点别扭。还有就是林阿姨和上校的爱情故事。一开始觉得上校有点吊不琅珰的，读到后面发现，真的 emmm 说不好的难受。不知以这种方式安排他俩在一起，是不是算是相互救赎呢🙏。最后就是，小瞎子学会上网之后，污蔑“我”的父亲是鸡奸犯，“我”的内心也是很痛的，不相信、不理解、埋怨、愤恨都有，后期父亲还想着给小瞎子找大夫，结果却因为“这层原因”，让我觉得很脏。比较庆幸的是在林阿姨家看见上校的“金子”，也就放下心来。我现在大概率是不会同情小瞎子这类人，反而该死，最好是死的透透的，可怜之人，必有可恨之处。\n我小时候，心是比较软的，看不得任何苦难，随着自己的成长，慢慢没了这种感觉，或者是把这种想法深深藏了起来，不想让别人看见，显得自己是无懈可击的。也有可能是，自己的现状是靠自己一步一步熬过来的，所以看见碌碌无为的人，总会觉得是他们自身造成的，也就不值得同情。\n写在最后 这个月算是又开始了新的尝试——健身，但牺牲的是自己的时间。近期会感觉有点力不从心，需要进一步提高效率，把更多的时间放在基础知识的学习上。还有就是开始尝试读读《毛泽东选集》，察势者明，趋势者智。\n","description":"","tags":null,"title":"人生海海，愿有岸有帆","uri":"/life/23_10-life/"},{"categories":null,"content":"集群：如何构建分布式的消息队列集群（下） 我们接着上一讲的内容，继续来看如何构建集群。先来看元数据存储服务的设计选型。在消息队列的集群架构中，元数据存储服务的选型和实现是整个架构设计的核心，其他模块的设计都是围绕着元数据存储服务来展开的。\n元数据存储服务设计选型 如果博客一路看到这篇的话，想必对于下面的内容并不会感觉到陌生。我们知道业界主要有基于第三方存储引擎和集群内部自实现元数据存储两种方案。先来分析一下这两种方案的具体实现。\n基于第三方存储引擎 这个方案最重要的一件事就是组件选型。\n从技术上来看，一般只要具备可靠存储能力的组件都可以当作第三方引擎。简单的可以是单机维度的内存、文件，或者单机维度的数据库、KV 存储，进一步可以是分布式的协调服务 Zookeeper、etcd 等等。\n正常来说，在设计的时候，结合自身的业务需求选择一中存储引擎就行。但是也有如 Pulsar 支持插件化的元数据存储服务，用来简化不同场景下的部署成本，比如单机运行、集成测试、线网部署等等。\n从分布式的角度来看，单机维度的存储能满足的场景有限，也会有单机风险。所以处于实际生产需求考虑，一般都会选用分布式的协调服务，比如使用 Zookeeper、etcd 等来当集群的元数据存储服务。所以基于第三方存储引擎的集群架构图一般如下所示：\n在这个架构图中，如果把元数据服务替换成 Zookeeper，也就成了 Kafka 和 Pulsar 的架构了。\n如图所示，这是一个有单独的元数据存储集群和多台 Broker 节点组成的消息队列集群。Broker 连接上 Metadata Service 完成节点发现、探活、主节点选举等功能。其中 Controller 的角色是由某一台 Broker 兼任的。\n细心的小朋友可能已经发现，图中 Controller 和 Metadata Service 是分开的，各自都承担着不同的职责。Controller 是无状态的，因为它不负责保存数据，只负责计算逻辑。所以在这种情况下，一般就会让集群中的某台 Broker 来承担 Controller 的功能。当这台 Broker 挂了后，可以依赖元数据存储服务把 Controller 切换到新的 Broker。因为它是无状态的，所以切换是非常快的。\n但使用这种方案，集群中最少得有 6 个节点，这会导致部署成本、运维复杂度变高。那有没有可能简化架构呢？？我们继续啊来看集群内部实现元数据存储的方案。\n集群内部自实现元数据存储 简单来说，可以通过在多台 Broker 的进程中实现分布式的元数据存储，从而解决依赖第三方组件的一些弊端。整体架构如下图所示：\n从技术实现上来看，主要有三种思路：\n直接在 Broker 内部构建一个小型的元数据存储集群来提供服务； 通过某些可以内嵌到进程的小型的分布式存储服务来完成元数据的存储； 通过某些可以内置的单机持久化的服务，配合节点间的元数据同步机制来完成元数据的存储。 第一种方案需要在 Broker 中实现一个元数据集群。这个元数据集群和 Broker 集群最大的差别在于它只需要承担单个集群的元数据管理存储，数据量和规模很小，集群一般不需要扩容。所以这个集群适合使用“通过配置发现节点的方案”来构建集群。Kafka 的 KRaft 架构用的就是这种方案。\n第二种方案是利用某种可以内嵌到进程的存储服务来存储元数据，比如 Mnesia 或 RocksDB。如果是单机的存储引擎，比如 RocksDB，那么主要适用于单机部署的场景。单机存储引擎的方案如果要实现元数据的集群化，那么就得在节点之间实现相互同步数据的机制，这个就相对复杂许多。而如果是分布式的存储引擎，如 Mnesia，那么就简单许多，几乎没有工作量，直接调用存储引擎的接口存储元数据即可。\n第三种方案是在节点上部署一个持久化的单机存储引擎，如 RocksDB 等。然后在 Broker 内维护节点间的元数据数据的一致性。这种方式也是一种实现比较简单的方案，开发难度低于第一种方案，高于第二种方案。\n从业界实现来看，目前第一种和第二种方案都有在使用。第三种方案主要用在单机模式下，问题是要维护多个节点的存储服务之间的数据一致性，有一定的开发工作量，并且保持数据强一致比较难。\n总结来看，在集群中实现元数据服务的优点是，后期架构会很简洁，不需要依赖第三方组件。缺点是需要自研实现，投入研发成本比较高。而如果使用独立的元数据服务，产品成型就会很快。这也是当前主流消息队列都是依赖第三方组件来实现元数据存储的原因。\n接下来，我们就用实际案例结合前面这些基础知识点，来看一下 Zookeeper、Kafka 是如何构建集群的。\nZookeeper 的集群构建 Zookeeper 是一个分布式的数据协调服务，本质上是一个简单的、分布式、可靠的数据存储服务。核心操作就是数据的写入、分发、读取和 Hook。从客户端看，主要操作就是写入喝读取。从服务端看，主要操作就是集群构建、数据接收、存储、分发和 Hook。\n在集群构建上，它会事先在配置中定义好集群中所有节点的 IP 列表。然后集群启动时，会在这些几点之间进行选举，经过多数投票机制，选举出一个 Leader 节点，从而构建成为集群。在单节点上，集群构建相关的配置一般如下所示，配置中会包含所有节点信息。\n1 2 3 server.0=hadoop102:2888:3888 server.1=hadoop103:2888:3888 server.2=hadoop104:2888:3888 在节点启动的时候，节点之间就会两两进行通信，触发投票。然后根据票数的多少，基于多数原则，选举出一个 Leader 出来。当 Leader 节点发生宕机或者增加节点时，就出重新触发选举。\n多数投票是一个经常用到的投票机制，即某个节点获得票数超过可投票的节点的一半后，就可以当选为 Leader。从实现角度，一般是通过集群中节点之间的通信和间隔随机投票的机制来完成投票，以保证能够在短时间内完成选举。\n当选举完成后，Leader 会主动给各个 Follower 节点发送 ping-pong 请求，以确定节点是否还活着。当 Follower 心跳异常时，就会剔除该节点，当集群中可用的节点数少于总节点数的一半，就会选举不出 Leader，从而导致集群异常。\n因为 ZooKeeper 只是一个数据存储服务，并没有很多管控操作，Leader 节点就负责数据的写入和分发，Follower 不负责写入，只负责数据的读取。当 Leader 收到操作请求时，比如创建节点、删除节点、修改内容、修改权限等等，会保存数据并分发到多个 Follower，当集群中有一半的 Follower 返回成功后，数据就保存成功了。当 Follower 收到写入请求时，就把写入请求转发给 Leader 节点进行处理。\n因为功能和定位上的差异，ZooKeeper 上是没有 Controller 和元数据存储的概念的。它是比较典型的基于固定配置构建集群的方式。\nKafka 的集群构建 之前我们有说过，目前主流消息队列的集群主要是基于第三方组件来构建的。而 Kafka 正是这种方案的典型实现，接下来我们就看一下 Kafka 基于 Zookeeper 和基于 KRaft 构建集群的两种实现方式。\n基于 Zookeeper 的集群 在这种架构中，Kafka 将 Zookeeper 作为节点发现和元数据存储的组件，通过在 Zookeeper 上创建临时节点来完成节点发现，并在不同的节点上保持各种元数据信息。\nBroker 在启动或重连时，会根据配置中的 Zookeeper 地址找到集群对应的 Zookeeper 集群。然后会在 ZooKeeper 的 /broker/ids 目录中创建名称为自身 BrokerID 的临时节点，同时在节点中保存自身的 Broker IP 和 ID 等信息。当 Broker 宕机或异常时，TCP 连接就会断开或者超时，此时临时节点就会被删除。\n注册完这些信息后，节点发现就算完成了。节点之间的探活依赖 ZooKeeper 内置的探活机制，前面讲过，这里不再赘述。接下来来看一下 Kafka 中的 Controller。\n在 Kafka 中，Controller 是一个虚拟概念，是运行在某台 Broker 上的一段代码逻辑。集群中需要确认一台 Broker 承担 Controller 的角色，那 Controller 是怎么选出来的呢？我们来看一看。\nKafka 的 Controller 选举机制非常简单，即在 ZooKeeper 上固定有一个节点 /controller。每台 Broker 启动的时候都会去 ZooKeeper 判断一下这个节点是否存在。如果存在就认为已经有 Controller 了，如果没有，就把自己的信息注册上去，自己来当 Controller。集群每个 Broker 都会监听 /Controller 节点，当监听到节点不存在时，都会主动去尝试创建节点，注册自己的信息。哪台节点注册成功，这个节点就是新的 Controller。\nController 会监听 ZooKeeper 上多个不同目录，主要监听目录中子节点的增加、删除，节点内容变更等行为。比如会通过监听 /brokers/ids 中子节点的增删，来感知集群中 Broker 的变化。即当 Broker 增加或删除时，ZooKeeper 目录中就会创建或删除对应的节点。此时 Controller 通过 Hook 机制就会监听到节点发生了变化，就可以拿到变化节点的信息，根据这些信息，触发后续的业务逻辑流程。\nKafka 集群中每台 Broker 中都有集群全量的元数据信息，每台节点的元数据信息大部分是通过 Controller 来维护的，比如 Topic、分区、副本。当这些信息发生变化时，Controller 就会监听到变化。然后根据不同的 Hook（如创建、删除 Topic 等），将这些元数据通过 TCP 调用的形式通知给集群中其他的节点，以保持集群中所有节点元数据信息是最新的。\n可以看下图，我们用 Topic 的创建流程，来串联集群中的 Controller 的集群管理和元数据存储。\n如图所示，Kafka 创建 Topic 有两种形式（图中 1 和 2），即通过 Broker 来创建和通过 ZooKeeper 来创建。当调用 Broker 创建 Topic 时，Broker 会根据本地的全量元数据信息，算出新 Topic 的分区、副本分布，然后将这些数据写入到 ZooKeeper。然后 Controller 就会 Hook 到创建 Topic 的行为，更新本地缓存元数据信息，通知对应的 Broker 节点创建分区和副本。 所以，也可以通过直接生成计划然后、写入到 ZooKeeper 的方式来创建 Topic。\n基于 KRaft 的集群 从架构的角度，基于 KRaft 实现的 Kafka 集群做的事情就是将集群的元数据存储服务从 Zookeeper 替换称为内部实现的 Metadata 模块。这个模块会同时完成 Controller 和元数据存储的工作。\n我们前面讲过，集群元数据需要分布式存储才能保证数据的高可靠。所以 Kafka KRaft 架构的 Metadata 模块是基于 Raft 协议实现的 KRaft，从而实现元数据可靠存储的。\n因为 Kafka 的 Metadata 模块只需要完成元数据存储，所以它的设计思路和 ZooKeeper 是一样的，是主从架构。即通过在配置文件中配置节点列表，然后通过投票来选举出 Leader 节点。这个节点会承担集群管控、元数据存储和分发等功能。\nMetadata 模块的配置如下所示。即通过配置项 controoler.quorum.votes 配置允许成为 Controller 的节点列表，然后这些节点之间会通过投票选举出 Leader 节点，这个 Leader 会完成 Controller 和元数据存储的工作。这个 Leader 相当于基于 ZooKeeper 版本中的 Controller 和 ZooKeeper 的 Leader。\n1 2 process.roles=broker,controller controller.quorum.voters=1@localhost:9093 所以在这个版本架构的实现中，就只有 Controller 了，然后 Controller 自带了元数据存储的功能。Broker 之间通过投票选举出来的 Leader 节点就是 Controller。此时，所有 Broker 都会和 Controller 保持通信，以维护节点的在线状态，从而完成节点发现。当 Controller 发现 Broker 增加或异常时，就会主动执行后续的操作。\n所以，从链路来看，这个架构简化了通过监听 ZooKeeper 来发现节点变更的流程，链路更短，稳定性更高。和基于 ZooKeeper 的架构一样，每台 Broker 依旧有集群全量的元数据信息，这些元数据信息的维护也是通过 Controller 完成的。\n接下来，我们来看一下 KRaft 架构下创建 Topic 的流程，来看下图：\n这里因为没有 ZooKeeper，所以创建 Topic 只有通过 Broker 创建的方式。通过 Admin SDK 调用 Broker 创建 Topic，如果 Broker 不是 Controller，这个请求就会转发到当前的 Controller 上。Controller 会根据本地的元数据信息生成新 Topic 的分区、副本的分布，然后调用对应的 Broker 节点完成分区和副本数据的创建，最后会保存元数据。\n其他的操作，比如删除 Topic、修改配置、创建 ACL 等流程是一样的。更多细节如果感兴趣的话，可以去看一下官方的 KIP。\n讲到这里，你会发现基于 KRaft 的 Kafka 架构比基于 Zookeeper 架构简单清晰非常多，操作链路也短很多。这样可以解决基于 Zookeeper 架构中一些难以解决的问题，如集群可承载分区数量上限较低，缓存不一致等等。\n总结 目前，消息队列的主流实现方式都是依赖第三方组件来完成数据存储，常见的有 ZooKeeper、etcd 等。为了简化架构，我们还可以通过在集群内自建元数据存储服务来替代第三方组件，虽然需要研发投入，但从架构长期演进的合理性来看，我是推荐这种方式的，毕竟后期架构会很简洁。\nZooKeeper 集群的组件，是基于配置文件中指定集群中其他节点的 IP 地址和端口来实现节点发现的，属于单播发现机制。这种方式的缺点就是扩容需要修改配置、重启集群。所以，还有一种通过配置多播地址和端口来实现集群发现的方式，其好处是可以动态发现节点，属于单播的一种升级，目前 Elasticsearch 和消息队列 RabbitMQ 都属于多播的实现。从 Kafka 的集群构建来看，基于独立的元数据存储服务，会导致架构复杂和引入缓存不一致等问题。集群内部实现元数据存储，可以简化架构，避免不一致。从技术合理性来看，或许尝试内置元数据存储是个不错的方案。\n","description":"","tags":null,"title":"MQ010——分布式消息队列（下）","uri":"/tech/bigdata/bigdata_mq010/"},{"categories":null,"content":"集群：如何构建分布式的消息队列集群？（上） 有状态服务和无状态服务 在正式讲解如何构建一个分布式的消息队列集群之前，我们可以先来了解一下什么是有状态服务，以及什么是无状态服务。\n这两个词在我们日常开发中也是经常遇到的，这二者之间最重要的一个区别在于：是否需要在本地存储持久化数据。简单来说就是，需要在本地存储持久化数据的就是有状态服务，反之就是无状态服务。\n说这两个，主要是因为有状态服务和无状态服务构建集群的思路完全是不一样的。HTTP Web Server 就是典型的无状态服务。在搭建 HTTP Web 集群的时候，我们经常会使用 Nginx 或者其他网关后面挂一批 HTTP 节点，此时后端的这批 HTTP 服务节点就是一套集群。\n如上图所示，因为 HTTP Web 是无状态的服务，不同的节点不需要知道其他节点的存在。Nginx 认为后端所有的节点的功能是一样的，所以请求经过 Nginx 后，只需要根据一定转发策略，如轮询、加权轮询、按 Key Hash 等将请求转发给后端的 Web 服务节点即可。然后在节点增减的时候，Nginx 会感知到节点的增减。执行转发或者不转发就可以咯。\n至于消息队列通常来说都是有状态服务。消息是和分片绑定，分片是和节点绑定。所以，当需要发送一个消息后，就需要发送到固定的节点，如果把消息发送到错误的节点，就会失败。所以，为了将消息发送到对的节点和从对的节点削峰数据，消息队列在消息的收发上，就有服务端转发和客户端寻址两种方案。\n所以，消息队列集群应该是按照有状态来设计的。接下来，我们就看看如何设计出一个集群化的消息队列服务。\n消息队列的集群设计思路 当前业界主流的分布式集群，一般都是基于主从（Master/Slave）思想来设计的。即通过一个组件来管理整个集群的相关工作，比如创建和删除 topic、节点上下线等等。这个组件一般叫做 Master 或 Controller。\n然后还需要有一个组件来完成集群元数据（比如节点信息、Topic 信息等等）的存储，这个组件一般叫做元数据服务。当然还有一批数据流节点来完成数据的读写和存储工作，这个组件一般叫做 Broker。\n元数据存储 我们先来看一下集群中的元数据是如何存储的。\n消息队列集群元数据是指集群中 Topic、分区、配置、节点和权限等信息。元数据必须保证可靠、高校的存储，不允许丢失。因为一旦元数据丢失，其实际的消息数据也会变得没有意义。\n从技术上看，业界主要有第三方存储引擎和集群内部自实现存储两种方案。\n依赖第三方存储引擎是指直接使用第三方组件来完成元数据信息的存储，比如 Zookeeper、etcd、单机或分布式数据库等等。这种方案的优点是拿来即用，无需额外的开发成本，产品成型快，稳定性较高。缺点是需要依赖第三方组件，会增加额外的部署维护成本，并且受限于第三方组件的瓶颈和稳定性，也可能会有数据一致性问题。像 Kafka、Pulsar 基于 Zookeeper 都是用的这种方式。\n集群内部自实现存储是指在消息队列应用内部自定义实现元数据存储服务，相当于在消息队列集群中实现一个小型的 Zookeeper。这种方案的优点是集群内部集成了这部分能力，部署架构就很简单轻量，应用自我把控性高，不会有第三方以来问题。缺点是开发成本较高，从头开始自研，相对于成熟组件而言，稳定性上短期内会比较弱，需要投入时间打磨。Kafka 去 Zookeeper 后的 KRaft 架构中的元数据存储，就是基于这个思路实现的。\n节点发现 接下来，我们一起看看看如何完成节点发现。我们知道集群是由多个节点组成的，此时组成集群的最基本要求就是：所有节点知道对方的存在或者有一个组件知道所有节点的存在，这样才能完成后续的集群管理和调度。这个过程就是节点发现的过程。\n从技术上看，当前业界主要有配置文件、类广播机制、集中式组件三种手段来完成节点发现。\n配置文件：通过指定文件配置所有节点 IP，然后节点启动后根据配置文件去找到所有的节点，从而完成节点发现。 类广播机制：通过广播、DNS 解析等机制，自动去发现集群中所有节点。比如通过解析 DNS 域名，得到域名绑定的所有 IP，从而发现集群中所有节点。 集中式组件：所有节点都向集中式组件去注册和删除自身的节点信息，此时这个组件就会包含所有节点的信息，从而完成节点发现。 第一种方案的好处是实现简单，在节点发现这块几乎不需要额外的开发成本，缺点就是集群扩容需要修改配置文件，水平扩容不方便，需要重启。比如 Zookeeper 和 KRaft 就是用的这种方案。\n第二种方案好处是可以自动发现新节点，自动扩容集群。缺点是开发成本很高，需要通过广播或者类似的机制发现集群中的其他节点。\n第三种的好处是可以动态地感知节点的变更，水平扩容非常方便，实现也简单。所以当前主流消息队列都是用的这种方案。Kafka 基于 Zookeeper 的版本，RocketMQ 和 Pulsar 都是用的这种方案。\n完成节点后，接下来就需要能够感知节点的变更，以便在节点故障时及时将其踢出集群。而这种动作就得依靠节点探活来实现。\n节点探活 从实现角度来看，一般需要有一个角色来对集群内所有节点进行探活或者保活，这个角色一般是主节点或第三方组件。\n如下图所示，技术上一般分为主动和定时上探测两种，这两种方式的主要区别在于心跳探活发起方的不同。从技术和实现上看，差别都不大；从稳定性来看，一般推荐主动上报。因为由中心组件主动发起探测，当节点较多时，中心组件可能会有性能瓶颈，所以目前业界主要的探活实现方式也是主动上报。\n从探测策略上看，基础都是基于 ping-pong 的方式来完成探活。心跳发起一般会根据一定的时间间隔发起心跳探测。如果保活组件一段时间没有接收到心跳或者主动心跳探测失败，就会提出这个节点。比如每 3 秒探测一次，连续 3 次探测失败就剔除节点。探测行为一般会设置较短的超时时间，以便尽快完成探测。\n以 Kafka 为例，它是基于 Zookeeper 提供的临时节点和 Hook 机制来实现节点保活的。即节点加入集群时会创建 TCP 长连接并创建临时节点，当 TCP 连接断开时就会删除临时节点。临时节点的变更会触发后续的相关操作，比如将节点加入集群、将节点剔除集群等等。\n所以基于 Zookeeper 实现节点发现和保活就很简单，只要通过 SDK 创建临时节点即可，只要 TCP 连接存活，临时节点就会存在。那么怎样确认连接存活呢？底层还是通过 ping-pong 机制、客户端主动上报心跳的形式实现的。\n因为 Zookeeper 具备这两个机制且组件相对成熟、稳定性较高，所以很多消息列队都会用 Zookeeper 来实现节点发现和探活。完成节点探活后，接下来我们看看集群的主节点是怎么选举出来的。\n主节点选举 从技术上看，理论上只要完成了节点探活，即节点健康的情况下，这批节点就都是能被选为主节点的。当然，有的集群可以配置哪些节点可以被选举为主节点，哪些节点不能被选举主节点，但是这点不影响后续的选举流程。\n主节点的选择一般有相互选举和依赖第三组件争抢注册两种方式。\n相互选举是指所有节点之间相互投票，选出一个得票最多的节点成为 Leader。投票的具体实现可以参考 Raft 算法，这里就不展开。目前业界 Zookeeper、ElasticSearch、Kafka KRaft 版本等都是用的这种方案。\n依赖第三方组件争抢注册是通过引入一个集中式组件来辅助完成节点选举。比如可以在 Zookeeper、etcd 上的某个位置写入数据，哪个节点先写入成功它就是 Leader 节点。当节点异常时，会触发其他节点争抢写入数据。依此类推，从而完成主节点的选举。\n在消息队列中，这个主节点一般称为 Controller，Controller 主要是用来完成集群管理相关的工作，集群的管理操作一般指创建和删除 Topic、配置变更等等行为。\n所以抽象来看，一般情况下消息队列的集群结构如下所示：\n其中，Metadata Service 负责元数据的存储，Controller 负责读取、管理元数据信息，并通过集群中的 Broker 执行各种操作。此时从实际架构实现的角度来看，Broker 的元数据上报可以走路径 1，通过 Controller 上报元数据到 Metadata Service，也可以直连 Metadata Service 走路径 2 上报元数据。两条路径没有明显的优劣，一般根据实际的架构实现时的选型做考虑。\n当完成元数据存储、节点发现、节点探活、主节点选举后，消息队列的集群就创建完成了。接下来我们通过集群启动、创建 Topic、Leader 切换三个动作来分析一下集群的运行机制。先来看一下集群启动的流程。\n消息队列的集群构建流程 集群启动 集群启动其实就是节点启动的过程，可以看下图：\n节点启动大致分为以下四步：\n节点启动时在某个组件（如图中的 Controller 或 Metadata Service）上注册节点数据，该组件会保存该节点的元数据信息； 节点注册完成后，会触发选举流程选举出一个主节点（Controller）； 节点会定期向主节点（或 Metadata Service）上报心跳用来确保异常节点能快速被剔除； 当节点异常下线或有新节点上线时，同步更新集群中的元数据信息。 从运行的角度看，完成这一步，集群就算已经构建完成了。接下来我们看看如何创建 Topic。\n创建 Topic 创建 Topic 大致分为以下四步：\n客户端指定分区和副本数量，调用 Controller 创建 Topic； Controller 根据当前集群中的节点、节点上的 Topic 和分区等元数据信息，再根据一定的规则，计算出新的 Topic 的分区、副本的分区，同事选出分区的 Leader（主分片）； Controller 调用 Metadata Service 保存元数据信息； Controller 调用各个 Broker 节点创建 Topic、分区、副本。 再来看看删除 Topic 和扩容分区是如何执行的。\n如果要删除 Topic，首先依旧要先往 Controller 发送一个删除 Topic 的指令；然后 Controller 会通知 Topic 分区所在的节点，删除分区和副本数据，删除 Topic；最后再删除 Metadata Service 中的 Topic 元数据/扩容分区的操作也是类似的，Controller 接收到扩容分区的指令，根据逻辑计算出新分区所在的节点，然后通知对应的节点创建分区，同时保存相关元数据。\nLeader 切换 Leader 切换的流程可以分为以下四步：\nController 会持续监听节点的存活状态，持续监控 Broker 节点是否可用； 根据一定的机制，判断节点挂掉后，开始触发执行 Leader 切换操作； Controller 通过 RPC 调用通知存活的 Broker2 和 Broker3，将对应分区的 Follower 提升为 Leader； 变更保存所有元数据。 从客户端的视角来看，服务端是没有机制通知客户端 Leader 发生切换的。此时需要依靠客户端主动更新元数据来感知已经发生 Leader 切换。客户端一般会在接收到某些错误或者定期更新元数据来感知到 Leader 的切换。\n总结 集群构建的思路分为有状态服务和无状态服务，两种类型服务的构建思路是不一样的。有状态服务需要解决元数据存储、节点发现、节点探活、主节点选举等四部分。\n元数据存储主要有依赖第三方组件实现和集群内自定义实现元数据存储两个思路。第三方组件主要有 ZooKeeper、etcd 等，依赖第三方组件是当前主流的选择，因为其实现较为简单，前期稳定性较高。自定义实现元数据存储是指在消息队列 Broker 集群内实现元数据存储服务，从而简化架构，实现虽较为复杂，但长期来看相对更合理。\n节点发现主要有静态发现和动态发现两个思路。静态发现是指通过配置文件配置好集群的所有节点，各个节点之间通过配置内容来发现对方，从而组建成一个集群。动态发现是指依赖一个中心组件或者类广播机制来动态完成节点之间的相互发现，即当节点上线或下线的时候，及时感知到变化，从而将节点加入到集群或者从集群中剔除。\n节点探活主要分为主动上报和定时探测两种，业界主要使用主动上报的实现形式。\n主节点在消息队列中一般叫做 Controller，一般通过节点间选举或者依赖第三方组件争抢注册来完成选举。Controller 主要用来完成集群内的管理类操作，如节点上下线、Topic 创建 / 删除 / 修改、Leader 切换等等。Controller 由集群中的某个 Broker 担任。\n","description":"","tags":null,"title":"MQ009——分布式消息队列（上）","uri":"/tech/bigdata/bigdata_mq009/"},{"categories":null,"content":"九月杂谈——置身事内的大梦 《西江月·世事一场大梦》〔宋〕苏轼\n世事一场大梦，人生几度秋凉？夜来风叶已鸣廊。看取眉头鬓上。\n酒贱常愁客少，月明多被云妨。中秋谁与共孤光。把盏凄然北望。\n标题名取之于这个月的的一本书《置身事内》和这几天最近在循环的一首歌《大梦》。\n随着“一个叫木头，一个叫马尾”，到“我看到人们漫步在路上”。九月也就随之结束了。这个月过的整体上还不错，似乎慢慢找到了自己的方向，并不断去奔向。这个过程很神奇，也是不断质疑自己，不断肯定自己的过程。\n谈谈生存 上个月和同事去过书店之后，就想着还是得读点闲书的嘛。于是在推荐下，选择了《置身事内》，jd 上买的，加上有京豆的折扣到手也就十几块钱，不由地感叹，在中国读书的成本真的是比较低的，可能也就是因为这样，导致很多人不珍惜读书的机会。\n《置身事内》这本书是从宏观与微观上来，讲解中国的经济变化，而且通读下来，很多内容都是自己刚好经历过的，或者说是未来可能要面对的。这本书写的比较通俗易懂，可以当作经济学科普类的读物来看，但写的也比较无聊，好几次看着看着就想睡觉。。。在现如今的环境下，如果有时间的话，还是值得一读的。\n简单说几个对我而言印象比较深的点吧。在说到京东方和合肥的故事，那一段只能说双方是互相成就彼此。当京东方选择定址的时候，接二连三被夏普插足。但合肥也是一个敢于“豪赌”的城市，面对前来搅局的夏普，当地政府给出“绝不动摇”的回复。并且给予大力的支持，从而得到发展。后来合肥选择蔚来也是如此。这不得不佩服合肥政府的魄力。大学是在合肥读的，但合肥给我的整体感觉是有冲劲，有目标，但实际在做的过程却似乎有点一塌糊涂，大学四年读完，整个城市没有发生什么实际性的变化。反观杭州，待了半年多，由于亚运会，真的是“造了一座城”。这也是体现书中所说的的一个观点，土地是一样的，但是所处的地理位置不同，价值也就不一样。那么这个观点是否可以来类比人呢？？这样想是不是有点太讽刺了。在华东地区，江浙沪属于房价比较高的城市，但在后疫情时代，大环境不稳定，经济下沉，房价也随之波动。拿余杭的房价来举例吧，未来科技城互联网行业比较多，但是现在裁员风波此起彼伏，人人自危，如果没有稳定的收入来源，谁敢轻易买房呢？？而且，如果买个房，按 500w 的预算，普通家庭夫妻双方每个月在经济条件允许的情况下，假设一共还 5w 的房贷，除去首付，还得还将近 10 年，这十年还得保证没有什么意外开支，如果有了小孩，又是一笔支出。在这个环境下，是否还有必要买房呢？？\n工作的“劣”与“良” 最近的工作挺无聊的，几乎不用写代码，总之似乎显得都不像是搞技术的，有点本末倒置。\n现在的市场，简单概括就是劣币驱逐良币，快速上线迭代，赚快钱，是目前国内大部分互联网企业都默认的选择。我一直认为好的作品是需要投入成本，花费时间和精力慢慢打磨的，但随之而来的问题就是，谁来为这个买单？？客户嘛，从甲方的角度来说，一般都是既要又要，当你生产内容的成本上去了，客户会真的觉得值得花这个钱嘛？？如果更便宜的，整体上大差不差的呢？？肯定会选择后者的。\n其实，在生活中来说，很简单。比如像现在国内的电商平台，一开始我极度反感 pdd 的，买东西都是天猫、京东居多。但后来，其他的平台要是想同等的优惠，还需要做活动，领券、拼单之类的操作，为了卷价格、用户留存率，运营方也是用尽了手段。从我的角度来说，是比较懒的，与其让我东拼西凑的，还不如直接原价购买，有一次偶然使用了 pdd，价格确实低一点，质量好像也没自己想要的那么糟糕，生活用品也会考虑从 pdd 下单。今年上半年，发现京东也发起了“百亿补贴”的活动，而且京东的服务和售后都是比较放心的，电子商品或者大件还是会考虑京东，多花钱少一点焦虑是值得的。再来看看淘宝，服务比不上京东，价格打不过 pdd。所以主流的电商平台，都最后价格都会逐渐趋同，上下肯定会有波动，但不太夸张。但是各个优惠策略都会不同，最后留住的用户也就不同。有的时候 pdd 某个物品对比其他平台特别便宜，买之前可以先问问自己，你敢买吗？？\n放在工作中也是同理，如果一切为了迎合市场，生产出来一堆垃圾，有必要吗？？可能自己是接触过顶级的开源项目，以及有强迫症，是个偏执狂，对这一切都比较排斥。之前看过一个段子说的是“每天的工作就是在一坨💩山上继续拉答辩”，这个例子虽然有点恶心，但很生动形象。既然自己有代码洁癖，就好好要求自己呗。如果能保持住就继续坚持咯。\n尝试“解耦”手机 不知从何时起，开始想摆脱手机的束缚。先来想一下手机在我日常生活中的作用。回复微信、购物、外卖、接打电话和听歌，还有就是照相。如果不考虑这些软件的使用场景，电脑和 iPad 完成可以替代，但如果在工作中，想点个外卖呢？iPad 体积就显得有点大。回复微信、听歌这些使用电脑可以替代。购物使用 iPad 也可以。仅仅是屏幕大小不同，结果却导致不同的用户体验和适用场景。\n一开始想到的就是使用 Apple Watch，这玩意我一开始就感觉很鸡肋，对我而言用处不大。而且苹果的宣传片总显得有点 CPU 用户，强行把健康和一款产品绑定在一起，这是不合理的。但如果蜂窝版的 Watch 支持了微信、听歌、接打电话，是不是就意味着在日常出门可以不用手机了呢？但随之而来的是，现在不带手机出门，或者说低电量出门，会莫名有点觉得缺失安全感。因为手机已经极大程度融入进日常生活了。再加上 eSIM 卡貌似不再支持中国大陆的运营商，整个流程就直接作废。\n后来想想，手机只是个工具，融合的更多是为了更方便用户的使用。简单来说，想摆脱的不是手机，而是浪费在手机上的时间，于是我对于每个 App 的屏幕使用时长进行了限制，并卸载了知乎、小红书等软件，这类软件本质来说都是一样，都是为了吸引用户使用。最后只对手机保留其最基础的功能。这样一通操作下来，手机屏幕的平均使用时间被压在了两个小时以内。争取下一个阶段控制在一小时左右。\n有的时候，最怕的就是给自己创造需求，从而陷入痛苦之中。。\n总结 这个月初去了桐庐，爬山比较友好（没有难度），爬到山顶有个瀑布，虽然不算太高，但离近一点看，还是挺不错的。下午的话去看了“破房子”，这种乡村建筑，让我想起了小时候老家的环境。可惜的是现在老家再也没有小时候的那种味道，大多是二层的小平房，没有乡土气息。。\n参与了 GOSIM 和 KubCon，第一场是周日到的，里面有五个论坛，比较有意思的是无论是“元宇宙和游戏”，还是“人工智能”都有提到 Rust，看来 Rust 必将是大势所趋。KubCon 则有点赶，到会场的时候，都已经开始清场，只能到处瞎逛逛就回家叻。两个大会给我的感觉是，自己对于底层的基础知识掌握的还不够，英语交流可以听得懂，但想流畅的说出来，还需要一段时间锻炼，也是因为没有说的氛围和环境的缘故。还有一点比较有意思，国外的开发者大多数都有大肚腩，这也给自己提个醒，保持锻炼，防止成为油腻男开发。\n开始补《哈利波特》系列，虽然是“儿童文学”，但看起来还是比较有意思的。比较遗憾的是，邓布利多的扮演者——米高·约翰·甘邦 也于近日离开了人间，去了魔法世界🙏 R.I.P 🕯️\n收藏了两首喜欢的音乐：康士坦的变化球——《美好的事可以不可以发生在我身上》和瓦依那——《大梦》，也因为这两首歌开始看《乐队的夏天 3》。\n九月也开始认真对待 Rust，但有点越学越痛苦的感觉，希望能早日渡过瓶颈期～～\n哦对，今天是中秋🥮，别忘了抬头看看月亮啊，如果能看得见的话。\n","description":"","tags":null,"title":"置身事内的大梦","uri":"/life/23_09-moon/"},{"categories":null,"content":"Kafka 系统架构 首先来看一下 Kafka 的架构图：\n如上图所示，Kafka 由 Producer、Broker、Zookeeper 和 Consumer 四个模块组成。其中，Zookeeper 用来存储元数据信息，集群中所有元数据都持久化存储在 Zookeeper 中。之前的内容，我们有讲过，使用 Zookeeper 作为元数据存储服务会带来额外的维护成本、数据一致性和集群规模限制（主要是分区数）等问题。所以 Kafka3.0 使用内置的 Raft 机制替代 Zookeeper。\nKafka 有 Topic 和分区的概念，一个 Topic 可以包含一个或多个分区。消费方面，通过 Group 来组织消费者和分区的关系。\n从消息的生命周期来看，生产者也需要通过客户端寻址拿到元数据信息。客户端通过生产分区分配机制，选择消息发送到哪个分区，然后根据元数据信息拿到分区 Leader 所在的节点，最后将数据发送到 Broker。Broker 收到消息并持久化存储。消费端使用消费分组或直连分区的机制去消费数据。如果使用消费分组，就会经过消费者和分区的分配流程，消费到消息后，最后项服务端提交 Offset 记录消费进度，用来避免重复消费。\n讲完基础概念和架构，我们继续围绕着前面所提到的五个模块来分析一下 Kafka，先来看一下协议和网络模块。\n协议和网络模块 Kafka 是自定义的私有协议，经过多年发展目前有 V0、V1 和 V2 三个版本，稳定在 V2 版本。官方目前没有支持其他协议，比如 HTTP，但是商业版的 Kafka 都会支持 HTTP 协议，主要原因还是 HTTP 协议使用的便携性。\nKafka 协议从结构上看包含协议头和协议体两部分，协议头包含基础通用的信息，协议体由于每个接口的功能参数不一样，内容结构上差异很大。\nKafka 协议的细节在通信协议中已经讲过，这里就不做过多的赘述。关于协议的更多详细信息还可以参考 官方文档。\nKafka 服务端的网络层是基于 Java NIO 和 Reactor 来开发的，通过多级的线程调度来提供性能。Kafka 网络层细节在网络模块 也有讲过，可以自己翻回去看。。\n数据存储 下面，我们继续来看 Kafka 1的存储层，Kafka 同样分为元数据存储和消息存储两部分。\n元数据存储 上面我们说过，Kafka 的元数据是存储在 Zookeeper 里面的。元数据信息包括 Topic、分区、Broker 节点和配置信息等。Zookeeper 会持久化存储全量元数据信息，Broker 本身不存储任何集群相关的元数据信息。在 Broker 启动的时候，需要连接 Zookeeper 读取全量元数据信息。\nZookeeper 是一个单独的开源项目，它自带了集群组网、数据一致性、持久化存储和监听机制等完整的能力。它的底层是基于 Zab 协议组件集群，有 Leader 节点和 Slave 节点的概念，数据写入全部在 Leader 节点完成，Slave 负责数据的读取工作。\n从 Zookeeper 的角度来看，Kafka 只是它的一个使用者。Kafka 用 Zookeeper 的标准使用方式向 Zookeeper 集群上写入、删除和更新数据，以完成 Kafka 的元数据管理、集群构建等工作。所以每台 Broker 启动时，都会在 Zookeeper 注册、监听一些节点信息，从而感知集群的变化。\n另外，Kafka 集群的一些如消费进度信息、事务信息，分层存储元数据，以及 3.0 后的 Raft 架构相关的元数据信息，都是基于内置 Topic 来完成存储的。把数据存储在内置 Topic 中，算是一个比较巧妙的思路了，也是一个值的借鉴的技巧。Kafka 中存储不同功能的元数据信息的 Topic 列表如下所示：\n数据类型 Topic 名称 消费进度 _consumer_offsets 事务消息 _transaction_state Kafka Raft 版本的元数据 _cluster_metadata 分层存储元数据 _remote_log_metadata 消息数据 在消息数据存储方面，Kafka 的数据是以分区为维度单独存储的。即写入数据到 Topic 后，根据生产分区分配关系，会将数据分发到 Topic 中不同的分区。此时底层不同分区的数据是存储在不同的“文件“中的，即一个分区一个数据存储“文件“。这里提到的“文件“也是一个虚指，在系统底层的表现是一个目录，里面的文件会分段存储。\n如下图所示，当 Broker 收到数据后，是直接将数据写入到不同的分区文件中的。所以在消费的时候，消费者也是直接从每个分区读取数据。\n在底层数据存储中，Kafka 的存储结构是以 Topic 和分区维度来组织的。一个分区一个目录，目录名称是 TopicName + 分区号。每个分区的目录下，都会有 .index、.log、.timeindex 三类文件。其中，.index 是偏移量（offset）索引文件，.log 是消息数据的存储文件，.timeindex 是时间戳索引文件。两个索引文件分别根据 Offset 和时间检索数据。\n在节点维度，也会持久存储当前节点的数据信息（如 BrokerID）和一些异常恢复用的 Checkpoint 等数据。由于每个分区存储的数据量会很大，分区数据也会进行分段存储。分段是在 .log 进行的，文件分段的默认数据大小也是 1G，可以通过配置项来修改。\nKafka 提供了根据过期时间和数据大小清理的机制，清理机制是在 Topic 维度生效的。当数据超过配置的过期时间或者超过大小的限制之后，就会进行清理。清理的机制也是延时清理的机制，它是根据每个段文件进行清理的，即整个文件的数据都过期后，才会清理数据。需要注意的是，根据大小清理的机制是在分区维度生效的，不是 Topic。即当分区的数据大小超过设置大小，就会触发清理逻辑。\n在存储性能上，Kafka 的写入大量依赖顺序写、写缓存、批量写来提高性能。消费方面依赖批量读、顺序读、读缓存的热数据、零拷贝来提高性能。在这些技巧中，每个分区的顺序读写诗高性能的核心。\n接下来，我们看一下 Kafka 的客户端关于生产者和消费者的实现。\n生产者和消费者 Kafka 客户端在连接 Broker 之前需要经过客户端寻址，找到目标 Broker 的信息。在早期，Kafka 客户端是通过连接 Zookeeper 完成寻址操作的，但是因为 Zookeeper 性能不够，如果大量的客户端都访问 Zookeeper，那么就会导致 Zookeeper 超载，从而导致集群异常。\n所以在新版的 Kafka 中，客户端是通过直连 Broker 完成寻址操作的，不会直接和 Zookeeper 进行交互。即 Broker 与 Zookeeper 进行交互，在本地缓存全量的元数据信息，然后客户端通过连接 Broker 拿到元数据信息，从而避免对 Zookeeper 造成太大负载。\n生产者 生产者完成寻址后，在发送数据的时候可以将数据发送到 Topic 或直接发送到分区。发送到 Topic 时会经过生产分区分配的流程，即根据一定的策略将数据发送到不同的分区。\nKafka 提供了轮询和 KeyHash 两种策略 轮询策略是指按消息维度轮询，将数据平均分配到多个分区。Key Hash 是指根据消息的 Key 生成一个 Hash 值，然后和分区数量进行取余操作，得到的结果可以确定要将数据发送到哪个分区。生产消息分配的过程是在客户端完成的。\nKafka 协议提高了批量（Batch）发送的语义，所以生产端会在本地先缓存数据，根据不同的分区聚合数据之后，在根据一定的策略批量将数据写入到 Broker。因为这个 Batch 机制的存在，客户端和服务端的吞吐性能会提高很多。\n客户端批量往服务端写有两种方式：一种是协议和内核就提供了 Batch 语义，一种是在业务层将一批数据聚合成一次数据发送。这两种虽然都是批量发送，但是它们的区别在于：\n第一种批量消息中的每条数据都会有一个 Offset，每条消息在 Broker 看来就是一条消息。第二种批量消息是在这批量消息就是一条消息，只有一个 Offset。 在消费端看来，第一种对客户端是无感的，一条消息就是一条消息。第二种需要消费者感知生产的批量消息，然后解析批量，逐条处理。 消费者 Kafka 的消费端只提供了 Pull 模式的消费。即客户端是主动不断地去服务端轮询数据、获取数据，消费则是直接从分区拉取数据的。Kafka 提供了消费分组消费和直连分区消费两种模式，这两者的区别在于，是否需要进行消费者和分区的分配，以及消费进度谁来保存。\n大部分情况下，都是基于消费分组消费。消费分组创建、消费者或分区变动的时候会进行重平衡，重新分配消费关系。Kafka 默认提供了 RangeAssignor（范围）、RoundRobinAssignor（轮询）、 StickyAssignor（粘性）三种策略，也可以自定义策略。消费分组模式下，一个分区只能给一个消费者消费，消费是顺序的。\n当客户端成功消费数据后，会往服务端提交消费进度信息，此时服务端也不会删除具体的消息数据，只会保存消费位点信息。位点数据保存在内部的一个 Topic（__consumer_offset）中。消费端同样提供了自动提交和手动提交两种模式。当消费者重新启动时，会根据上一次保存的位点去消费数据，用来避免重复消费。\n最后我们来看一下 Kafka 对 HTTP 协议和管控操作的支持。\nHTTP 协议支持和管控操作 Kafka 内核是不支持 HTTP 协议的，如果需要支持，则需要在 Broker 前面挂一层代理。\n管控的大部分操作是通过 Kafka Protocol 暴露的，基于四层的 TCP 进行通信。还有部分可以通过直连 Zookeeper 完成管控操作。\n在早期很多管控操作都是通过操作 Zookeeper 完成的。后来为了避免对 Zookeeper 造成压力，所有的管控操作都会通过 Broker 再封装一次，即客户端 SDK 通过 Kafka Protocol 调用 Broker，Broker 再去和 Zookeeper 交互。\nKafka 命令行提供了管控、生产、消费、压测等功能，其底层就是通过客户端 SDK 和 Broker 进行交互的。我们在代码里面也可以通过客户端 SDK 完成相应的操作，不用必须通过命令行。\n因为历史的演进，在一些命令行里面，还残留着直连 Zookeeper 的操作。而我们也可以通过直接操作 Zookeeper 中的数据完成一些操作，比如更改配置、创建 Topic 等等。\n总结 最后，我们再来总结一下 Kafka。\n协议层只支持私有的 Kafka Protocol 协议； 网络层是基于原生的 Java NIO 开发，底层也是通过多路复用、异步 IO、Reactor 模型等技术来提高网络模块的性能； 存储层是每个分区对应一份具体的存储文件，分区文件在底层会分段存储，同时支持基于时间和大小的数据过期机制； 元数据存储是通过 Zookeeper 来实现的，所有的元数据都存储在 Zookeeper 中； 客户端的访问同样也需要经过客户端寻址机制。老版本可以通过 Zookeeper 获取元数据信息，新版本只能通过 Broker 拿到元数据信息。拿到所有元数据信息后，才会直连 Broker； 生产端支持将数据写入到 Topic 或指定写入某个分区，写入 Topic 时需要经过生产分区分配操作，选择出最终需要写入的分区，同时支持批量写入的语义； 消费端也有消费分组的概念，消费时需要在多个消费者和消费分组之间进行消费的负载均衡，同时也支持指定分区消费的模式。 Kafka 从生产到消费的全过程：\n在生产端，客户端会先和 Broker 建立 TCP 连接，然后通过 Kafka 协议访问 Broker 的 MetaData 接口或渠道集群的元数据信息。接着生产者会向 Topic 或分区发送数据，如果是发送到 Topic，那么客户端会有消息分区分配的过程。因为 Kafka 协议具有批量发送语义，所以客户端会先在客户端缓存数据。然后根据一定的策略，通过异步线程将数据发送到 Broker； Broker 收到数据之后，会根据 Kafka 协议解析出请求内容，做好数据校验，然后重整数据结构，将数据按照分区的维度写入到底层不同的文件中。如果分区配置了副本，则消息数据会被同步到不同的 Broker 中进行保存； 在消费端，Kafka 提供了消费分组和指定分区消费两种模式。消费端也会先经过寻址拿到完整的元数据信息，然后连接上不同的 Broker。如果是消费分组模式消费，则需要经过重平衡、消费分区分配流程，然后连接上对应分区的 Leader，接着调用 Broker 的 Fetch 接口进行消费。最后一步则是需要提交消费进度来保存消费信息。 ","description":"","tags":null,"title":"MQ008——剖析 Kafka 架构设计","uri":"/tech/bigdata/bigdata_mq008/"},{"categories":null,"content":"消费端：消费者客户端 SDK 有哪些设计？ 前言 上一篇内容讲了生产端，这次继续来聊聊有关消费端的内容。从技术上看，消费端 SDK 和生产端 SDK 一样，主要包括客户端基础功能和消费相关功能两部分。客户端基础功能之前已经讲过，这里也就不做过多的赘述。\n从实现上看，消费相关功能包括消费模型、分区消费模型、消费分组（订阅）、消费确认和消费失败处理五个部分。我们一个一个来看。\n消费模型的选择 为了满足不同场景的业务需求，从实现机制上来看，主流消息队列一般支持 Pull、Push 和 Pop 三种消费模型。\nPull 模型 Pull 模型是指客户端通过不断轮询的方式想服务端拉取数据。它是消息队列中使用最广泛和最基本的模型，主流的消息队列一般也都支持这个模型。\n它的好处是客户端根据自身的处理速度去拉取数据，不会对客户端和服务端造成额外的风险和负载压力。缺点是可能会出现大量无效返回的 Pull 调用，另外消费及时性不够，无法满足一些需要全链路低耗时的场景。\n为了提供消费性能，Pull 模型都会支持批量读，即在客户端指定需要拉取多少条数据或者拉取多大的数据，然后传递给服务端。客户端拉取到数据并处理完成后，再重复拉取数据处理。如前面讲的，这种拉取模式的缺点是可能会出现长时间轮询到空数据的情况，从而浪费通信资源，提高服务端的负载。\n比如下面这个场景，当 Topic1 数据已经被消费完，此时如果消费者频繁来拉取数据并立即返回结果，客户端就会不停地重复请求服务端。当空数据请求特别多的时候，就会造成资源损耗，不利于提高吞吐，也有可能导致负载问题。\n为了解决这个问题，正常的思路是在客户端根据一定策略进行等待和回避。这样做的话，就会出现如何设置等待时间的问题，客户端等待时间设置不合理就会出现消费不及时的情况。\n为了解决空请求带来的问题，一般服务端会协助处理，有如下两种思路：\n1. 服务端 hold 住请求 当客户端根据策略拉取数据时，如果没有足够的数据，就先在服务端等一段时间，等有数据后一起返回给客户端。这种方案的好处是，可以尽量提高吞吐能力，不会有太多的空交互请求。缺点则是如果长时间不给客户端回包，会导致客户端请求超时，另外当数据不够时，hold 住请求的时间太长就会提高消费延时。\n2. 服务端有数据的时候通知客户端 当服务端不 hold 住请求，立刻返回空数据，客户端收到空数据时则不再发起请求，会等待服务端的通知。当服务端有数据的时候，再主动通知客户端来拉取。这种方案的好处是可以及时通知客户端来拉取数据，从而降低消费延时。缺点是因为客户端和服务端一般是半双工的通信，此时服务端是不能主动向客户端发送消息的。\n所以在 Pull 模型中，比较合适的方案是客户端告诉服务端：最多需要多少数据、最少需要多少数据、未达到最小数据时可以等多久三个信息。然后服务端首先判断是否有足够的数据，有的话就立即返回，否则就根据客户端设置的等待时长 hold 住请求，如果超时，无论是否有数据，都会直接给客户端返回当前的结果。\n这种策略可以解决频繁不可控的空轮询请求。即使全是空轮询，对单个消费者来说，其 TPS 也是可以预估的，即总时间 / 等待时长 = 总轮询次数。而如果需要降低消费延时，可以通过降低最小获取的数据大小和最大等待时长来提高获取的频率，从而尽量降低延时。通过这种方案，我们可以把理想的消费延迟时间降低到两次 Pull 请求之间的时间间隔。\n在一些业务消息的场景中，因为应对的场景规模有限，可以将最大等待时长设置为 0，此时消费模型就变成了“请求—返回”的模式，当没有数据的时候就会立即返回数据，其余逻辑交给客户端自己处理。\nPush 模型 Push 模型是为了解决消费及时性而提出来的。这个模型的本意是指当服务端有数据时会主动推给客户端，让数据的消费更加及时。理想中的思路如下图所示，即当服务端由数据以后，会主动推给各个消费者。在实际的 Push 模型的实现上，一般有 Broker 内置 Push 功能、Broker 外独立实现 Push 功能的组件、在客户端实现伪 Push 功能三种思路。\n1. Broker 内置 Push 功能 第一种，Broker 内置 Push 功能是指在 Broker 中内置标准的 Push 的能力，由服务端向客户端主动推送数据。\n这种方案的好处是 Broker 自带 Push 能力，无需重复开发和部署。Broker 内部可以感知到数据堆积情况，可以保证消息被及时消费。缺点是当消费者很多时，内核需要主动维护很多与第三方的长连接，并且需要处理各种客户端异常，比如客户端卡住、接收慢、处理慢等情况。这些推送数据、异常处理、连接维护等工作需要消耗很多的系统资源，在性能上容易对 Broker 形成反压，导致 Broker 本身的性能和稳定性出现问题。所以这种方案在主流消息队列中用得较少，为了保证消息投递的高效及时（比如全链路的毫秒级耗时），才会采用这种方案。\n2. Broker 外独立实现 Push 功能的组件 第二种，Broker 外独立实现 Push 功能的组件是指独立于 Broker 提供一个专门实现 Push 模型的组件。通过先 Pull 数据，再将数据 Push 给客户端，从而简化客户端的使用，提高消费数据的及时性。\n这种方案的好处是将 Push 组件单独部署，解决了 Broker 的性能和稳定性问题，也能实现 Push 的效果。缺点是虽然实现了 Push 的模型，但其本质还是先 Pull 再 Push，从全链路来看，还是会存在延时较高的问题，并且需要单独开发独立的 Push 组件，开发和运维成本比较高。\n从实际业务上来讲，这种模型的使用场景较为有限，主要用在回调、事件触发的场景，在实际的流消费场景用的不是很多。主要是因为通过第三方组件的 Push 灵活性不够，性能会比 Pull 第。\n3. 客户端实现伪 Push 功能 **第三种，在客户端实现伪 Push 功能是指在客户端内部维护内部队列，SDK 底层通过 Pull 模型从服务端拉取数据存储到客户端的内存队列中。**然后通过回调的方式，触发用户设置的回调函数，将数据推送给应用程序，在使用体验上看就是 Push 的效果。\n这种方案的好处在于通过客户端底层的封装，从用户体验看是 Push 模型的效果，解决用户代码层面的不断轮询问题，降低了用户的使用复杂度。缺点是底层依旧是 Pull 模型，还是得通过不断轮询的方式去服务端拉取数据，就会遇到 Pull 模型遇到的问题。\n在客户端实现伪 Push，是目前消息队列在实现 Push 模型常用的实现方案，因为它解决了客户体验上的主动回调触发消费问题。虽然底层会有不断轮询和消费延时的缺点，但是可以通过合理的编码设计来降低这两个问题的影响。\n因为 Push 模型需要先分配区和消费者的关系，客户端就需要感知分区分配、分区均衡等操作，从而在客户端就需要实现比较重的逻辑。并且当客户端和订阅的分区数较多时，容易出现需要长时间的重平衡时间的情况。此时为了解决这个问题，于是就有了 Pop 模型。\nPop 模型 Pop 模型想解决的是客户端实现较重，重平衡会暂停消费并且可能时间较长，从而出现消费倾斜的问题。\n它的思路是客户端不需要感知到分区，直接通过 Pop 模型提供的 get 接口去获取到数据，消费成功后 ACK 数据。这就像发起 HTTP 请求去服务端拉取数据一样，不用感知服务端的数据分布情况，只需要拉到数据。这种方案的好处是简化了消费模型，同时服务端可以感知到消费的堆积情况，可以根据堆积情况返回哪些分区的数据给客户端，这样也就简化了消息数据的分配策略。\n从实现上来看，它将分区分配的工作移到了服务端，在服务端完成了消费者的分区分配、进度管理，然后暴露出新的 Pop 和 ACK 接口。客户端调用 Pop 接口去拿去数据，消费成功后调用 ACK 去确认数据。可以类比 HTTP 中的 Request 和 Response 使用模型。\n分区消费模式 我们知道，消息队列的数据是在 Partition/Queue 维度承载的，所以消费过程中一个重要的工作就是消费者和分区的消费模式问题，即分区的数据能不能被多个消费者并发消费，一条数据能不能被所有消费者消费到，分区的数据能不能被顺序消费等等。\n从技术上看，在数据的消费模式上主要有独占消费、共享消费、广播消费和灾备消费四种思路\n独占消费 **独占消费是指一个分区同一个时间只能被一个消费者消费。**在消费者启动时，会分配消费者和分区之间的消费关系。当消费者数据和分区数量都没有变化的情况下，两者之间的分配关系不会变动。当分配关系变动时，一个分组也只能被一个消费者消费，这个消费者可能是当前的，也可能是新的。如果消费者数量大于分区数量，则会有消费者被空置；反之，如果分区数量大于消费者数量，一个消费者则可以同时消费多个分区。\n独占消费的好处是可以保证分区维度的消费是有序的。缺点是当数据出现倾斜、单个消费者出现性能问题或 hang 住时，会导致有些分区堆积严重。Kafka 默认支持的就是独占消费的类型。\n共享消费 **共享消费是指单个分区的数据可以同时被多个消费者消费。**即分区的数据会依次投递给不同的消费者，一条数据只会投递给一个消费者。\n这种方式的好处是，可以避免单个消费者的性能和稳定性问题导致分区的数据堆积。缺点是无法保证数据的顺序消费。这种模式一般用在对数据的有序性无要求的场景，比如日志。\n广播消费 **广播消费是指一条数据要能够被多个消费者消费到。**即分区中的一条数据可以投递给所有的消费者，这种方式是需要广播消费的场景。\n实现广播消费一般有内核实现广播消费的模型、使用不同的消费分组消费和指定分区消费三种技术思路。\n内核实现广播消费的模型，指在 Broker 内核中的消息投递流程实现广播消费模式，即 Broker 投递消息时，可以将一条消息吐给不同的消费者，从而实现广播消费。 使用不同的消费分组对数据进行消费，指通过创建不同的消费者组消费同一个 Topic 或分区，不同的消费分组管理自己的消费进度，消费到同一条消息，从而实现广播消费的效果。 指定分区消费，是指每个消费者指定分区进行消费，在本地记录消费位点，从而实现不同消费者消费同一条数据，达到广播消费的效果。 三种方案的优劣对比：\n广播消费类型 优点 缺点 内核实现 客户端成本低，无多余工作 服务端开发工作量大 消费分组实现 统一消费模型，无需服务端开发 需要创建很多消费分组 指定分区消费 统一消费模型，避免创建很多消费分组 客户端编码工作较重，使用相对复杂 灾备消费 灾备消费是独占消费的升级版，在保持独占消费可以支持顺序消费的基础上，同时加入灾备的消费者。 当消费者出现问题的时候，灾备消费者加入工作，继续保持独占顺序消费。\n好处是既能保持独占顺序消费，又能保证容灾能力。缺点是无法解决消费倾斜的性能问题，而且还需要准备一个消费者来做灾备，使用成本比较高。\n消费分组 消费分组是用来组织消费者、分区、消费进度关系的逻辑概念。为什么需要消费分组呢？\n在没有消费分组直接消费 Topic 的场景下，如果希望不重复消费 Topic 中的数据，那么就需要有一个标识来标识当前的消费情况，比如记录进度。这个唯一标识就是消费分组。\n在一个集群中可以有很多消费分组，消费分组间通过名称来区分。消费分组自身的数据是集群元数据的一部分，会存储在 Broker 的元数据存储服务中。消费分组主要有管理消费者和分区的对应关系、保存消费者的消费进度、实现消息可重复被消费三类功能。\n消费分组和 Topic 是强相关的，它需要包含 Topic 才有意义，一个空的消费分组是没有意义的。消费分组内有很多个消费者，一个消费分组也可以订阅和消费多个 Topic，一个 Topic 也可以被多个消费分组订阅和消费。\n因为 Topic 不存储真实数据，分区才存储消息数据，所以就需要解决消费者和分区的分配关系，即哪个分区被哪个消费者消费，这个分配的过程就是消费重平衡。\n从流程上来看，当新建一个消费分组的时候，就需要开始分配消费者和分区的消费关系了。分配完成后，就可以正常消费。如果消费者和分区出现变动，比如消费者挂掉、新增消费者、订阅的 Topic 的分区数发生变化等等，就会重新开始分配消费关系，否则就会存在某些分区不能被订阅和消费的情况。\n协调者 从实现上来看，如果要对消费者和分区进行分配，肯定需要有一个模块拥有消费分组、所有的消费者、分区信息三部分信息，这个模块我们一般命名为协调者。协调者主要的工作就是执行消费重平衡，并记录消费分组的消费进度。\n在消费分组创建、消费者变化、分区变化的时候就会触发重新分配。分区分配的操作可以在协调者内部或消费者上完成。\n在协调者完成，即协调者首先获取消费者和分区的信息，然后再协调者内部完成分区分配，最后再把分配关系同步给所有消费者。 在消费者完成，即负责分配的消费者获取所有消费者和分区的信息，然后该消费者完成分区分配操作，最后再把分配关系同步给其他消费者。 从技术上来看，这两种形式的优劣区别并不大，取决于代码的实现。一般在创建消费分组和消费者 / Topic 分区变化的时候，会触发协调者执行消费重平衡。\n从实现的角度来看，协调者一般是 Broker 内核的一个模块，就是一段代码或者一个类，专门用来完成上述的工作。当有多台 Broker 时，协调者的实现有多种方式，比如 Kafka 集群每台 Broker 都有协调者存在。通过消费分组的名称计算出来一个 hash 值和 _consumer_offset 的分区数，取余计算得出一个分区号。最后这个分区号对应的 Leader 所在的 Broker 节点就是协调者所在的节点。客户端就和计算出来的这台 Broker 节点进行交互，来执行消费重平衡的相关操作。\n当有了协调者后，就需要确认哪个分区给哪个消费者了，此时就需要一个分配策略来执行，这就是消费分区分配策略。\n消费分区分配策略 再具体实现上，一般内核会默认提供几种分配策略，也可以通过定义接口来支持用户自定义实现分区分配策略。分区分配策略的制定一般遵循以下三个原则：\n各分区的数据能均匀地分配给每个消费者，保证所有消费者的负载最大概率是均衡的，该原则最为常用； 在每次重新分配的时候，尽量减少陪去和消费者之间的关系变动，这样有助于加快重新分配的速度，并且保持数据处理的连续性，降低处理切换成本； 可以运行灵活地根据业务特性指定分配关系，比如根据机房就近访问最近的分区、某个 Topic 的奇数分区分配给第一个消费者等等。 所有消息队列的默认策略都是相对通用的，一般都会包含有轮询、粘性、自定义三种策略。\n轮询 轮询就是指用轮询的方式将分区分配给各个消费者，保证每个消费者的分区数量是尽量相同的，从而保证消费者的负载最大概率上是均衡的。思路是拿到所有主题的所有分区和所有消费者，根据拿到的顺序（实际实现中可能会先全部打乱，以确保随机性）将分区逐个分配给消费者。分配到最后的效果是，每个消费者所分到的分区数是一样的，最多相差 1 个分区。比如 tp0 有 3 分区，tp1 有 2 分区，tp2 有 3 分区，分配后效果如下。\n消费者 1：tp0-0、tp2-1、tp1-1\n消费者 2：tp2-2、tp0-1、tp2-0\n消费者 3：tp1-0、tp0-2\n因为 Topic 一般会有多个分区，默认情况下写入大部分是均匀的。这个方案的优点是，从随机性的原理来看，打乱分区后再分配给每个消费者，消费者的负载大概率是均匀的。但是也有可能出现不均衡，比如当消费组同时订阅多个分区时，有可能会将同一个 Topic 的多个分区都分配给一个消费者，从而出现消费者的负载倾斜。\n在轮询的基础上，为了解决随机轮询的情况，某些流量搞的 Topic 可能会分配给同一个消费者。为了解决这种情况，就可以调整一下轮询的策略，比如在随机的基础上，将 Topic 的不同分区尽量打散到不同的消费者，从而保证整体消费者之间的分区是均衡的，如下所示：\n消费者1：tp0-0、tp2-1、tp1-1\n消费者 2：tp0-1、tp2-0、tp1-0\n消费者 3：tp0-2、tp2-2\n主要的核心思路都是为了消费者更加均衡，避免消费倾斜。\n粘性 粘性是指尽量减少分区分配关系的变动，进而减少重平衡所耗费的时间和资源损耗。即当已经分配好消费者和分区的消费关系后，当消费者或者分区出现变动，就会触发重平衡。从底层来看，可能就是一个消费者掉了或者新增分区。此时需要重新进行分配的消费者和分区其实是有限的，大部分的分配关系可以不动。而此时，如果使用轮询算法，则要全部打算重来，耗时就会非常长，并且浪费资源，即把原先不需要重新分配的关系都重新分配一遍。\n粘性的效果如下，比如当上面的消费者 3 挂了后，只需要将 tp1-0、tp0-2 平均分给消费者 1 和 2 即可，消费者 1 和 2 原先分配的分区不用动。\n消费者1：tp0-0、tp2-1、tp1-1、tp1-0\n消费者 2：tp0-1、tp2-0、tp1-0、tp0-2\n在实际的实现中，为了减少重新分配关系，有一个非常常用的算法是一致性哈希。一致性哈希的算法经常用在负载均衡中。用一致性哈希实现粘性分配策略的优点是，当节点或者分区变动时，只需要执行少量的分区再分配即可。\n自定义策略 在一些消息队列中，也会提供一些与自己相关的特色的分区分配策略。比如 Kafka 就提供了轮询策略改进版的 RoundRobinAssignor 分配策略。这些策略的核心出发点，都是为了解决消费者和分区之间的分配均衡、重平衡耗时、业务场景需要等诉求。\n自定义分区分配算法，和生产端数据的分区分配策略是一样的，内核会提供接口，用户可以根据自身需求自定义算法，然后指定配置生效即可。比如 Kafka 提供了 org.apache.kafka.clients.consumer.internals.PartitionAssignor 接口来提供自定义分区分配策略。\n消费确认 那么当数据被消费成功后，就必须进行消费确认操作了，告诉服务端已经成功消费了这个数据。消费确认就是我们在消息队列中常说的 ACK。一般情况下，消费确认分为确认后删除数据和确认后保存数据两种形式。\n确认后删除数据是指集群的每条消息只能被消费一次，只要数据被消费成功，就会回调服务端的 ACK 接口，服务端就会执行数据删除操作。在实际开发过程中，一般都会支持单条 ACK 和 批量ACK 两种操作。这种方式不利于回溯消费，所以用得比较少。\n消费成功保存消费进度是指当消费数据成功后，调用服务端的消费进度接口来保持消费进度。这种方式一般都是基于配合消费分组一起用的，服务端从消费分组维度来保存进度数据。\n为了保证消息的回溯消费和多次消费，消息队列大多数用的是第二种方案。数据的删除交由数据过期策略去执行。\n保存消费进度一般为服务端保存和客户端自定义保存两种机制实现。\n服务端保存是指当消费端消费完成后，客户端需要调用一个接口提交信息，这个接口是由服务端提供的”提交消费进度“接口，然后服务端会持久保存进度。当客户端断开重新消费时，可以从服务端读取这个进度进行消费。服务端一般会通过内置的 Topic 或者文件来持久保存该数据。这种方式的优点是客户端会封装好这些逻辑，使用简单，无序管理进度相关的信息，缺点就是不够灵活。服务端保存一般是默认的方案。\n在提交位点信息的时候，底层一般支持自动提交和手动提交两种实现。\n自动提交一般是根据时间批次或数据消费到客户端后就自动提交，提交过程客户端无感知； 手动提交：是指业务根据自己的处理情况，手动提交进度信息，以避免业务处理异常导致的数据丢失。 提交方式 优点 缺点 自动提交 实现简单，业务无感知，使用成本低 可能会漏消费数据，导致数据丢失 手动提交 安全可控 需要代码提交，使用成本较高 如果想避免数据丢失的情况下，优先考虑手动提交的方式。\n客户端自定义保存是指当消费完成后，客户端自己管理保存消费进度。此时就不需要向服务端接口提交进度信息了，自定义保存进度信息即可，比如保存在客户端的缓存、文件、自定义的服务中，当需要修改和回滚的时候就比较方便。这种方案的的优点是灵活，缺点是会带来额外的工作量。\n消费失败处理 我们知道，一个完整的消费流程包括消费数据、本地业务处理、消费进度提交三部分。那么从消费失败的角度来看，就应该分为从服务端拉取数据失败、本地业务数据处理失败、提交位点信息失败三种情况。下面我们逐一来看。\n从服务端拉取数据失败，和客户端的错误逻辑处理是一致的，根据可重试错误和不可重试错误的分类，进行重复消费或者向上抛错。\n本地业务数据处理失败，处理起来就变囧复杂了。如果是偶尔失败，那么在业务层做好重试处理逻辑，配合手动提交消费进度的操作即可解决。如果是一直失败，即使重试多次也无法被解决，比如这条数据内容有异常，导致无法被处理。此时如果一直重试，就会出现消费卡住的情况，这就需要配合死信队列等功能，将无法被处理的数据投递到死信队列中，从而保存异常数据，并保证消费进度不阻塞。\n提交位点信息失败，其处理方法通常是一直重试，重复提交，如果持续失败就向上抛错。因为如果提交进度失败，即使再从服务端拉取数据，还是会拉到同一批数据，出现重复消费的问题。\n总结 在消费端，为了提高消费速度和消息投递的及时性，需要选择合适的消费模型，目前主流有 Pull、Push 和 Pop 三种模型。\n这三种模型的应用场景都不一样。目前业界主流消息队列使用的都是 Pull 模型。但为了满足业务需求，很多消息队列也会支持 Push 模型和 Pop 模型。其中，Push 模型的及时性更高，实现较为复杂，限制也比较多。Pop 模型本质上是 Pull 模型的一种，只是在实现和功能层面上，与 Push 的实现思路和使用场景不一样。所以在模型的选择上来看，因为场景复杂，三种模型都是需要的。\n常用的消费模式一般有独占消费、共享消费、广播消费和灾备消费四种。为了避免堆积，保证消息消费顺序，一般需要选择分区独占的消费模式。从单分区的维度，共享消费的性能是最高的。广播消费主要是通过创建多个消费分组、指定分区消费来实现的。灾备消费的场景用的则相对较少。\n从设计上看，消费端要解决的问题依次分为三步：\n满足基本的消费需求，能消费到数据，确认数据； 满足稳定性和性能的需求，能快速稳定地消费到数据； 支持功能方面的需求，比如回溯消费、消费删除、广播消费等等。 为了能满足基本的消费需求，服务端会提供消费和确认接口，同时在客户端封装消费和确认操作中，底层通过网络层和服务端建立、维护 TCP 连接，然后通过协议完成基本的消费操作。\n如果要回溯消费，则需要单独记录消费进度。这样就能抽象出消费分组的概念，用来管理消费者、分区和消费进度的关系。通过消费分组来记录消费进度，从而实现数据的多次分发。另外，消费分组机制也可以用在广播消费的场景。\n在消费确认的过程中，一般需要客户端回调服务端提供的确认接口。确认接口分为确认删除和确认记录消费进度两种模式。主流方式是在确认的时候记录消费进度。\n异常处理主要是为了保证数据能被正常消费，重点关注不丢数据、不重复消费、不阻塞住消费三个问题，我们需要针对不同的问题做不一样的处理。\n","description":"","tags":null,"title":"MQ007——剖析消费者 SDK","uri":"/tech/bigdata/bigdata_mq007/"},{"categories":null,"content":"生产端：生产者客户端 SDK 有哪些设计要点？？ 前言 大部分开发者在使用某个组件或框架的时候，都希望能够做到开箱即用，作为一款成熟的产品来说，也确实应该做到。那么，在使用的过程中是否会有疑问，这些框架的 SDK 底层是如何工作的呢，由哪些功能模块所组成的呢？消息队列的客户端主要包含生产、消费、集群管控三类功能。我们先用 MQ 中的生产者为例，来进行一个浅层次的设计分析。。从客户端 SDK 实现的角度来看，生产模块包含客户端基础功能和生产相关功能两部分，其中基础功能是客户端所有功能共有的。如下图所示：\n基础功能是蓝色部分，包括请求连接管理、心跳检测、内容构建、序列化、重试、容错处理等等。生产功能是黄色部分，包括客户端寻址、分区选择、批量发送、生产错误处理、SSL、幂等和压缩等等。\n客户端基础功能 连接管理 在网络模块，讲过客户端和服务端之间基本都是通过各自语言的网络库，创建 TCP 长连接进行通信的。在大部分实现中，为了避免连接数膨胀，每个客户端实例和每台 Broker 只会维护一条 TCP 连接。\n建立一条 TCP 连接是简单的，关键的是，什么情况下建立连接呢？？一般来说有初始化创建连接和使用时创建连接两种方式。\n初始化创建连接：指在实例初始化时就创建到各个 Broker 的 TCP 连接，等待数据发送。好处是提前创建好可以避免发送的时候冷启动；缺点是需要提前创建好所有的连接，可能导致连接空跑，会消耗一定的资源。 使用时创建连接：指在实例初始化时不建立连接，当需要发送数据时再建立。好处是发送时再连接，连接的使用率会较高；缺点是可能出现连接冷启动，会增加一点本次请求的耗时。 因为客户端会有空闲连接回收机制，创建连接的耗时一般较短，所以在实际的架构实现中，两种方式都会有用到，优劣区别并不是很明显。不过，从资源利用率的角度考虑，建议使用晚建立连接的方式。\n因为连接并不是任何时候都有数据，可能出现长时间连接空闲。所以连接都会搭配连接回收机制，连接建立后如果连接长时间空闲，就会被回收。连接回收的策略一般是判断这段时间内是否有发送数据的行为，如果没有就判断是空闲，然后执行回收。\n因为单个 TCP 连接发送性能存在上限，就需要在客户端启动多个生产者，提高并发读写的能力。一般情况下，每个生产者会有一个唯一的 ID 或唯一标识来标识客户端，比如 ProduceID 或客户端的 IP+Port。\n单个 TCP 的瓶颈和很多因素有关，比如网路带宽、网络延迟、客户端请求端的 socketbuff 的配置、TCP 窗口大小、发送速率导致本地数据反压堆积、服务端请求队列的堆积情况、收包和回包的速度等等。\n接下来继续看看客户端和服务端之间的心跳检测。\n心跳检测 心跳检测是客户端和服务端之间保活的一种机制，检测服务端或者客户端的一方不可用时，另一方可以及时回收资源，避免资源浪费。一般都是通过 ping-pong 的方式来发起探测。之前的内容有提到过，消息队列一般都是基于 TCP 协议通信的。所以客户端和服务端之间的心跳机制的实现，一般有基于 TCP 的 KeepAlive 保活机制和应用层主动探测两种形式。\n基于 TCP 的 KeepAlive 保活机制：是 TCP/IP协议层内置的功能，需要手动打开 TCP 的 KeepAlive 功能。通过这种方案实现心跳检测，优点是简单，缺点是 KeepAlive 实现是在服务器侧，需要 Server 主动发送检测包，此时如果客户端异常，可能出现很多不可用的 TCP 连接。这种连接会占用服务器内存资源，导致服务器端的性能下降。\n应用层主动探测：一般是 Client 向 Server 发起的，主要解决灵活性和 TCP KeepAlive 的缺陷。探测流程一般是客户端定时发送保活心跳，当服务端连续几次没收到请求，就断开连接。这样做的好处是，可以将压力分担到各个客户端，避免服务端的过载。\n错误处理 从请求的角度，有些错误是重试可以恢复的，比如连接断开、Leader 切换、发送偶尔超时和服务端某些异常等；有些错误是不可恢复的，比如 Topic / 分区不存在、服务端 Broker 不存在、集群和 Broker 长时间无响应等。所以，在客户端的处理中，也会将错误分为可重试错误和不可重试错误两类。\n因为网络环境、架构部署的复杂性，集群可能出现短暂网络抖动、Leader 切换等异常，可重试错误就是这类通过一次或多次重试可能恢复的异常；不可重试的错误，就是不管如何重试都无法恢复的异常。\n虽然实现思路很直接、很简单，但在客服端 SDK 的实现过程中，错误处理是一个包含很多细节的工作，一般需要考虑下面几个常见的点：\n如何定义可恢复错误和不可恢复错误； 完整的错误码的定义和枚举，如何定义一个好的错误码从而提高排查问题的效率； 错误后重试的代码实现方式是否合理高效； 判断哪些情况需要停止客户端，向上抛出异常，以免一些错误信息一直在 SDK 内空转，提高上层感知异常和排查异常的难度； 日志信息打印 debug、info 以及 error 日志时，是否包含了完整的内容。 发生错误后，客户端一般会提供重试策略，接下来一起看看重试机制的实现，\n重试机制 重试策略一般会支持重试次数和退避时间的概念。当消息失败，超过设置的退避时间后，会继续重试，当超过重试次数后，就会抛出消息或者将消息投递到配置好的重试队列中。\n退避时间是可以配置的，比如 1s、10s 或者 60s 等。当出现错误时，就会按照退避策略进行退避，再尝试写入。一般情况下，重试是有次数上限的，当然如果想的话也也可以配置无限重试。\n退避策略影响的是重试的成功率，因为网络抖动一般来说是 ms 级，某些严重的情况下可能会抖动十几秒。此时，如果退避策略设置的太短，在退避策略和重试次数用完后，可能消息还没生产成功；反过来，如果退避时间设置太长，可能导致客户端发送堵塞消息堆积。所以消息队列生产者的重试次数和退避策略的设置都是比较讲究的，需要结合业务的场景仔细设计。\n另外，客户端为了满足安全传输、性能和功能方面的需求，客户端都会支持传输加密、压缩、事务、幂等等功能。\n生产相关基础功能 客户端寻址机制 MQ 作为一个分布式系统，分区会分布在集群的不同节点上。所以从客户端的角度看，往服务端写入数据的时候，服务端有那么多台节点，请求该发送給台节点呢？？\n看见这个问题，可能大部分开发者都会觉得这并不是什么难题，类似我们发送 HTTP 请求，手动指定目标 Broker 的 IP 就行了。就是说在生产者写数据到 Broker 的时候，在代码里面手动指定分区对应的对端的 Broker 地址，然后将数据写到目标 Broker。\n这个思路没问题，但是我们手动指定对端 Broker 地址的时候，怎么知道这个分区在这台 Broker 上的对应关系存在哪里呢？？为了解决这个问题，就从而提出了 Metadata 寻址机制和服务端内部转发两个思路。\n1.Metadata 寻址机制 服务端会提供一个获取全量的 Metadata 的接口，客户端在启动时，首先通过接口拿到集群所有的元数据信息，本地缓存这部分数据信息。然后，客户端发送数据的时候，会根据元数据的内容，得知服务端的地址是什么，要发送的分区在哪台节点上。最后根据这两部分信息，将数据发送到服务端。\n消息队列的元数据是指 Topic、分区、Group、节点、配置等集群维度的信息。比如 Topic 有几个分区，分区的 Leader 和 Follwer 在哪些节点上，节点的 IP 和端口是什么，有哪些 Group 等等。\n在 Metadata 寻址机制中，元数据信息主要包括 Topic 及其对应的分区信息和 Node 信息两部分。可以看一下 Kafka 的元数据信息结构；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 主题分区元数据： { \"test1\": { \"Topic\": \"test1\", \"Partitions\": [ { \"ID\": 0, \"Error\": {}, \"Leader\": 101194, \"Replicas\": [ 101194, 101193 ], \"Isrs\": [ 101194, 101193 ] } ], \"Error\": {} } } 节点元数据： [ { \"ID\": 101195, \"Host\": \"9.130.62.0\", \"Port\": 6097 }, { \"ID\": 101194, \"Host\": \"9.130.62.1\", \"Port\": 6096 }, { \"ID\": 101193, \"Host\": \"9.130.62.2\", \"Port\": 6095 } ] 客户端一般通过定期全量更新 Metadata 信息和请求报错时更新元数据信息两种方式，来保证客户端的元数据信息是最新的。目前 Kafka 也是用的这个方案。\n2. 服务端内部转发机制 另外一种服务端内部转发机制，客户端不需要经过寻址的过程，写入的时候是随机把数据写入到服务端任意一台 Broker。具体思路是服务端的每一台 Broker 会缓存所有节点的元数据信息，生产者将数据发送给 Broker 后，Broker 如果判断分区不在当前节点上，会先找到这个分区在哪个节点上，然后把数据转发到目标节点。\n这么做的好处是，分区寻址在服务端完成，客户端的实现成本比较低。但是生产流程多了一跳，耗时增加了。另外服务端因为转发多了一跳，会导致服务端的资源损耗多一倍，比如 CPU、内存、网卡，在大流量的场景下，这种损耗会导致集群负载变高，从而导致集群整体性能降低。所以这种方案不适合大流量、高吞吐的消息队列。\n解决了请求要发送給哪个节点，下面就要思考消息数据要写入到哪个分区呢。\n生产分区分配策略 我们知道，数据可以直接写入分区或者写入对应的 Topic。写入 Topic 时，最终数据还是要写入到某个分区。这个数据选择写入到哪个分区的过程，就是生产数据的分区分配过程。过程中的分配策略就是生产分区分配策略。\n一般情况下，消息队列默认支持轮询、按 Key Hash、手动指定和自定义分区分配这四种分区分配策略。\n轮询是所有消息队列的默认选项。消息通过轮询的方式依次写到各个分区中，这样可以保证每个分区的数据量是一样的，不会出现分区数据倾斜。\n分区数据倾斜是指一个 Topic 的每个分区的存储的数据量不一样，有的分区数据量大，有的小，从而导致硬件的负载不均，集群性能出现问题。\n既然能解决数据倾斜，那是不是使用轮询就是最优解了呢？？答案是否定的，因为如果我们需要保证数据的写入是有序的，轮询就满足不了。因为在消费模型中，每个分区的消费是相互独立的，如果数据依次写入多个分区，在消费的时候就无法保持顺序。所以若要想数据有序，就需要保证 Topic 只有一个分区。这也是另外两种分配策略的思路。\n按 Key Hash 是指根据消息的 Key 算出一个 Hash 值，然后与 Topic 分区数取余数，算出一个分区号，将数据写入到这个分区中。公式参考：\n1 partitionSeq = hash(key) % partitionNum; 这种方案的好处是可以根据 Key 来保证数据的分区有序。比如某个用户的访问轨迹，以客户的 AppID 为 Key，按 Key Hash 存储，就可以确保客户维度的数据分区有序。缺点是分区数量不能变化，因为变化后 Hash 值就会变，导致消息乱序。并且因为每个 Key 的数据量不一样，容易导致数据倾斜。\n手动指定很好理解，就是在生产数据的时候，手动指定数据写入哪个分区。这种方案的好处就是灵活，用户可以在代码逻辑中根据自己的需要，选择合适的分区，缺点是业务需要感知分区的数量和变化，代码实现相对复杂。\n除了这三种默认策略，消息队列也支持自定义分区分配策略，让用户灵活使用。通常会在内核提供 interface 机制，用户如果需要指定自定义分区的分区分配策略，可以实现对应的接口，然后配置分区分配策略。比如 Kafka 可以通过实现 org.apache.kafka.clients.producer.Partitioner 接口实现自定义分区策略。\n批量语义 为了提高写入性能，有的生产者客户端会提供批量（Batch）写入的语义。客户端支持批量写入数据的前提是，需要在协议层支持批量的语义。否则就只能在业务中自定义将多条消息组成一条消息。\n批量发送的实现思路一般是在客户端内存中维护一个队列，数据写入的时候，先将其写入到这个内存队列，然后通过某个策略从内存队列读取数据，发送到服务端。\n批量发送数据的策略和存储模块的刷盘策略很像，都是根据数据条数或时间聚合后，汇总发送到服务端，一般是满足时间或者条数的条件后触发发送操作，也会有立即发送的配置项。\nKafka 是按照时间的策略批量发送的，提供了 linger.ms、max.request.size、batch.size 三个参数，来控制数据批量发送。\nlinger.ms：设置消息延迟发送的时间，这样可以等待更多的消息组成 Batch 发送。默认为 0 表示立即发送。\nmax.request.size：生产者能够发送的请求包大小上限，默认为 1MB。\nbatch.size：生产者会尝试将业务发送到相同的 Partition 的消息合包后再进行发送，它设置了合包的大小上限。\n为了支持对于性能和可靠性有不同需求的业务场景，客户端一般会支持多种数据发送方式。\n数据发送方式 消息队列一般也会提供同步发送、异步发送和发送即忘三种形式。\n同步和异步更多是语言语法的实现，同步发送主要解决数据发送的即时性和顺序性，一步发送主要考虑性能。下面，我们来重点看一下发送即忘（这个不太好理解）。\n发送即忘指消息发送后不关心请求返回的结果，立即发送下一跳。这种方式因为不用关心发送结果，发送性能会提升很多。缺点是当数据发送失败时无法感知，可能会有数据丢失的情况，所以通常适用在发送不重要的日志等场景。Kafka 提供了 ack = 0 来支持这种模式。\n讲完了发送相关的功能设计，接下来我们看一下管控操作在客户端中的实现方式。\n集群管控操作 集群管控操作一般是用来完成资源的创建、查询、修改和删除等集群管理动作。资源主要包括主题、分区、配置以及消费分组等等。\n命令行工具是最基础的支持方式。如下图所示，它的底层主要通过包装客户端 SDK 和服务端的相关功能接口进行交互。程序编码上一般由命令行、参数包装和底层 SDK 调用三部分组成。主要流程是接收参数、处理参数和调用 SDK 等相关操作。\n有的消息队列也会支持 HTTP 接口形式的管控操作。好处是因为 HTTP 协议的通用性，业务可以从各个环节发起管控的调用，不是强制使用 admin SDK。另外客户端封装 HTTP 接口实现命令行工具的成本也比较低。\n总结 消息队列生产者客户端的设计，主要关注下面三个部分：\n网络模块的开发和管理。这部分是为了完成和服务端的通信，比如请求和返回的构建、心跳检测、错误处理和重试机制等； 根据服务端提供的各个接口的协议结构，构建请求，完成序列化和反序列化后，通过网络模块发起请求并获得返回； 在前面两步的基础上，添加各个业务层面的功能，比如生产、消费、事务、幂等和 SSL 这类。 客户端和服务端交互的过程中，一般要经过元数据寻址，以正确找到分区所在的 Broker。如果我们想避免客户端寻址，只能在服务端内进行转发，但有性能和资源的损耗。所以在主打吞吐的消息队列组件中，转发的方案用的很少。\n从生产者的的角度来看，需要重点关注分区分配策略、批量语义和发送方式三个方面。请求内容构建和序列化属于协议设计的内容，主要取决于协议的具体设计和序列化 / 反序列化框架的选择。\n","description":"","tags":null,"title":"MQ006——剖析生产者 SDK","uri":"/tech/bigdata/bigdata_mq006/"},{"categories":null,"content":"二十三，九局下半 何为成长，也许是有了选择的能力，但却发现没有选择的权利。。\n有的时候，或者说大部分时候，做的事情都是身不由己。就在想啊，人如果不能做自己想做的事情，那么还有什么意思呢？？emmm 或者换个角度来说，现在所有的过渡是为了以后自己想做的事情嚒？？又或者真的有想清楚自己想做什么了嘛？？还是说，仅仅是因为目前做的事情比较无聊，而导致说，现在做的是自己不太喜欢的呢。。\n学会选择放弃 从我的角度来说，学会选择是想做的事情，学会放弃是极难的事情，如果二者综合在一起呢？？该如何才能做到学会选择放弃。。上一次独立选择是高考填志愿选择了计算机，再一次是现在。\n我是一个喜欢在质疑中成长的，在被别人看扁的时候，心里骂一句你懂个 der，然后按照自己的长远规划来慢慢实现，事实证明，也确实做到咯。这一次，我相信也是一样。一定的！！\n如果说是放弃了自己曾经所想追求的事情呢？？心里有矛盾，会不甘，会难受，但更多的是怕，怕自己后悔，怕让家人失望，怕一切的一切都不会如自己所料。\n我也不知现在的生活是否真的好或不好，或者是否真的适合自己，现在好像真的不知道自己想要变成什么样子，有点陷入舒适区，不肯挪动半步，有时候会想想，自己累了那么久，真的好想好想停下脚步，歇歇啊。。如果真的选择停下会有莫名的焦虑感，这种焦虑感不知从何而来，也许来自于天生的不自信吧，也有一部分是 peer pressure。人，只有站的足够高，才会明白自己是多么想要触碰到天空。鹰，不会留恋地平线！再加上自己是比较喜欢折腾的那一类人，所以，走下去吧，别回头，至于终点在哪？？我还在想，我还在找，我也许还在迷茫。。\n当自己选择放弃的想法涌入脑海的那一瞬间，后背不自觉的发出冷汗。。甚至有点不可思议，为什么自己是这么想的，后来想着想着也就释怀了吧。至少有始有终，属于给自己了一个交代，也算是弥补了遗憾。同龄人，很多是没得选择，我却有点一手王炸，打得稀烂的感觉，至少从他人视角来说确实如此。放弃读研，放弃大厂的 offer，孤身一人流放杭州，选择了一个有点养老的工作，也许是真的累了，想给自己喘口气的时间，\n但换个角度思考，现在的工作能够养活自己，工作上能发挥自己的所长，下班了有自己的时间。虽然有时候也有点糟心，但好在，这些也不重要。虽然还不知下一步该走向哪，那就厚积薄发，当作是场过渡咯～～\n意外的收获 既然喜欢折腾，那么就适当的搞搞破坏吧，也许是目前的技术栈总觉得很窄，而且所学的大部分技术都是为了满足生存，是真的自己所喜欢的吗？？并不是吧，既然不是那为何不去学呢！！学点看似无用，但自己感兴趣的。\n先从扩展一下自己的语言开始吧，首选的是 Go，因为还想体验一下传说中的 MIT6.824 这门课，里面的实验也都是使用 Go 完成的，不想懂分布式的悠悠球手不是好的游戏玩家嘛。学习 Go 的时候总觉得它的编程范式有点别扭，意外地看了一篇关于 Rust 和 Go 的对比，emmmm，要不然试试 Rust，难才有意思的嘛。\n就这样入了 Rust 的坑，也让我真正体验到了如何做一名合格的程序员。起初各种不适应，定义一个变量还需要考虑其是放在堆上还是栈上，以及所有权的机制、生命周期等这些都是什么玩意，慢慢在不断入门中，有点适应之后，再回来看看其它语言，不好意思，真的不熟！！学习 Rust 之后，开始习惯逛推，也关注了很多有意思的大佬，看他们分享的折腾记录，为何不自己动手试试呢。先打造个 IDE 吧，Vim 也算是在不断入门中放弃的，那段时间刚好天天都看见 NeoVim 的推送，可能这都是安排好的吧，于是就开始折腾了起来，自己配置了 nvim，lua 之前制作游戏 mod 用过，所以上手也比较快。 所以说，有时候仅仅出兴趣出发，往往会有意想不到的收获。折腾完 nivm 又看见关于 terminal 的配置，iTerm2 崩溃过几次之后，也决定换到 Kitty 或者 Alcritty，最终的选择是 Kitty，没人能拒绝自己的 macOS 多一个猫猫的图标，不是吗 哈哈哈哈。。\n在我从事这个行业之前，特别佩服那些能够独立折腾的玩家，后来入行之后，干的事情，很多都是比较乏味，有点循规蹈矩，现在算是找到了自己当初想要的模样了吧。而且，特别感谢自己遇见了开源，也正是这股黑客文化，能够促使我不断接触新的东西～～\n上一次认真对待一件事情，又是什么时候呢？？持续了多久？？\n逛书店 回想一下自己有多久没逛过书店了呢？？\n去年受疫情影响，似乎没怎么去过书店，沉迷于 Switch，再加上个人状态也不是特别好，就没读过几本书。而且大都是泛泛而读，没有啥实质性的收获。今年突然开始重新陷入技术学习的苦海，看的也都是技术相关的书籍，就突然感觉有点文化沙漠了。。\n前段时间，去书店，虽说书店不是很大，逛了一圈下来，却并没有发现自己想要的书，这是一件很可怕的，至少对我而言。以往逛书店，看见某个感兴趣的，可以牵连着找出许多想要的书，因为书会带着你去探索更多有意思的事情。这次没有，因为我不知道自己喜欢看什么类型的，历史相关的、哲学相关的、传记、心理学以及金融学，比较大众化的都有涉及，但却没有一个能够真正提取我阅读兴趣的。最后在一个拐角看见了《蛤蟆先生去看心理医生》，听名字就知道是关于心理学的，自己也该看看了。\n从九月开始，给自己定个小目标吧，每个月至少一篇纸质书，读完之后或多或少写点什么，留个记录。\n一个人 不知从何开始，感觉到每个人都是孤独的个体；不知从何开始，接受了一个人的状态；也不知从何开始，慢慢开始享受一个人的生活。。\n或好或糟，凡事都是两面性。有的时候想找人，说说话，吐槽最近的生活。可翻了一页列表，貌似没有适合倾诉的对象。于是，带上耳机，看看书、练练球、打打游戏，或者写写代码，也就过去了。也许就是这样的次数多了，也就习惯了吧。\n有可能我天生就是个浑身带刺的人，从小到大就不喜欢别人碰我，有点洁癖，有强迫症，不喜欢无意义的合群，所以有的时候的群体活动，我都会感觉到可能是在浪费时间，这段时间留给我自己发发呆也是蛮不错的，总好过强颜欢笑。但人总归来说还是群居动物，不是不懂社交，只是不想，或者感觉意义不是很大。\n还有就是，不知从何时起，我开始慢慢意识到原生家庭是一种负担，他们的亲朋好友，对我嘘寒问暖也好，指指点点也罢，我都不太喜欢，可能是真的关心我，也有的可能就是吃瓜的心态。有的时候总觉得自己作为晚辈，很多地方做的都很差劲，emmm 对亲戚来说，我不太喜欢去刻意维护，毕竟生活的环境不一样，每个人对生活的理解也不一样，你说的他们未必听得懂，他们说的，我也会或多或少觉得有点无聊。小时候，去舅舅家都会觉得格外亲切，随着他们的孩子先结婚生娃，他们的重心都会转变的嘛。我一直提倡的都是，当我们这一代有能力之后，我们的父母那一辈可以早点休息，他们那个年代是吃过苦的，现在作为他们的子女有能力，可以试着去享受生活。但从他们的角度来说，总会觉得自己做的还不够，还想着为子女多做点什么。他们是伟大的，但同时也是自私的，他们做的越多，往往会导致对子女的依赖性越大，也就越舍不得子女离开自己身边，我感觉这是病态的。。所以，我想靠着自己的能力，吃吃苦，从一无所有，到想去看看世界。\n现在回头看看自己，有能力、有自己的思想、有自己的认知，还有自己想做的事情。总体而言，是挺享受一个人目前的状态，但也会越来越孤僻。家里人，催着找对象，总想着各种理由推脱掉。如果遇不到合适的，那就算了吧。。应该是吧。因为就现在的情况来看，我不太想浪费自己的时间，去陪伴一个没那么喜欢的人。有的人可能会说，感情都是慢慢培养的嘛，也许吧。。\n简单来说，就是走一步看一步了，如果站在更高的角度，看现在的我，也没啥好烦心的。\n期待 对下一个阶段的自己有啥期待的呢？？\n多读点闲书，早睡，可以抽点时间打打游戏，多运动，多看看山山水水，还有就是坚持去学你想做的技术。\n最重要的一点就是，心理素质再强大一点咯。\n","description":"","tags":null,"title":"二十三，九局下半","uri":"/life/23/"},{"categories":null,"content":"如何设计元数据和消息数据的存储模块？？ 前言 存储模块作为 MQ 高吞吐、低延时、高可靠性的基础保证，可以说是最核心的模块。从技术架构的来看，存储模块主要包含功能实现和性能优化两个方面，这篇 blog 就重点来看一下其是如何实现的。\nMQ 的存储模块的主流程是数据的写入、存储、读取、过期。写入和持久化存储是基本功能，但因为消息队列独有的产品特性，主要被用来当缓冲分发，它的数据存储是临时的，数据持久化存储后，在一定的时间或操作后，需要能自动过期删除。\n而且 MQ 中的数据一般分为元数据和消息数据。元数据指的是 Topic、Group、User、ACL 和 Config 等集群维度的资源数据信息，消息数据是指客户端写入的用户的业务数据。\n元数据信息的存储 元数据信息的特点是数据量比较小，不会经常读写，但是需要保证数据的强一致和高可靠，不允许出现数据的丢失。同时，元数据信息一般需要通知到所有的 Broker 节点，Broker 会根据元数据信息执行具体的逻辑。比如创建 Topic 并生成元数据后，就需要通知对应的 Broker 执行创建分区、创建目录等操作。\n所以元数据信息的存储，一般有两个思路：\n基于第三方组件来实现元数据的存储； 在集群内部实现元数据的存储。 基于第三方组件来实现元数据的存储是目前业界的主流选择。比如 Kafka Zookeeper 版本、RocketMQ 和 Pulsar 用的都是这个思路。其中 Kafka 和 Pulsar 的元数据存储在 Zookeeper 中。\n这个方案最大的优点是集成方便，开发成本低，能满足消息队列功能层面的基本要求，因为可以直接复用第三方组件已经实现的一致性存储、高性能的读写和存储、Hook 机制等能力，而且在后续集群构建规划的过程中也可以继续复用这个组件，能极大程度降低开发难度和工作成本。\n但凡事都有利弊。其缺点也很明显，那就是引入第三方组件会增加集群系统部署和运维的成本，而且第三方组件自身的稳定性问题也会增加系统风险，第三方组件和多台 Broker 之间可能会出现数据信息不一致的情况，导致读写异常。\n另外一种思路，集群内部实现元数据的存储是指在集群内部完成元数据的存储和分发。也就是在集群内部实现类似第三方组件一样的元数据服务，比如 Raft 协议实现内部的元数据存储模块或依赖一些内置的数据库。目前 Kafka 去 Zookeeper 版本用的就是这个思路。\n这个方案的优缺点刚好与第一个相反。优点是部署和运维成本低，不会因为依赖第三方服务导致稳定性问题，也不会有数据不一致的问题。但是缺点是开发成本高，前期要投入大量的开发成本。\n消息数据的存储 与元数据的存储相比，消息数据的存储要复杂一点。一般情况下，MQ 的存储主要是指消息数据的存储，分为存储结构、数据分段、数据存储格式和数据清理四个部分。\n数据存储结构设计 我们先看数据存储目录结构设计。在消息队列中，与存储有关的主要是 Topic 和分区两个维度。用户可以将数据写入 Topic 或直接写入到分区。\n不过如果写入 Topic，数据也是分发到多个分区去存储的。所以从实际数据存储的角度来看，Topic 和 Group 不承担数据存储功能，承担的是逻辑组织的功能，实际的数据存储是在分区维度完成的。\n从架构角度上看，数据的落盘也有两种思路：\n每个分区单独一个存储“文件” 每个节点上所有分区的数据都存储在同一个“文件” 需要注意的是，这里的“文件”是一个虚指，即表示所有分区的数据是存储在一起，还是每个分区的数据分开存储的意思。在实际的存储中，这个“文件”通常以目录的形式存在，目录中会有多个分段文件。\n先来看第一个思路，每个分区对应一个文件的形式去存储数据。具体实现时，每个分区上的数据顺序写到同一个磁盘文件，数据的存储是连续的。因为消息队列在大部分情况下的读写是有序的，所以这种机制在读写性能上的表现是最高的。\n但如果分区太多，会占用太多的系统 FD 资源，极端情况下有可能把节点的 FD 资源耗完，并且硬盘层面会出现大量的随机读写情况，导致写入的性能下降很多，另外管理起来也相对复杂。目前 Kafka 在存储数据的组织上用的就是这种思路。\n具体的磁盘的组织结构一般有“目录+分区二级结构”和“目录+分区一级结构”地两种形式。不过从技术上来看，二者并没有太大的优劣区别。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 目录+分区二级结构： ├── topic1 │ ├── partrt0 │ ├── 1 │ └── 2 └── topic2 ├── 0 ├── 1 目录+分区一级结构： ├── topic1-0 ├── topic1-1 ├── topic1-2 ├── topic2-0 ├── topic2-1 └── topic2-2 再来看第二种思路，每个节点上所有分区的数据都存储在同一文件中，需要为每个分区维一个对应的索引文件，索引文件里会记录每条消息在 File 里面的位置信息，以便快速定位到具体的消息内容。\n因为所有文件都在一份文件上，管理简单，也不会占用过多的系统 FD 资源，单机上的数据写入都是顺序的，写入的性能会很高。缺点是同一个分区的数据一般会在文件中的不同位置，或者不同的文件段中，无法利用到顺序读的优势，读取的性能会收到影响，但是随着 SSD 技术的发展，随机读写的性能也越来越高。最简单的体现就是固态越来越便宜咯。如果使用 SSD 或高性能 SSD，一定程度上可以缓解随机读写的性能损耗。\n那么该如何选择呢？核心考虑是对读写的性能要求。\n第一种思路，单个文件读和写都是顺序的，性能最高。但是当文件很多且都有读写的场景下，硬盘层面就会退化为随机读写，性能会严重下降； 第二种思路，因为只有一个文件，不存在文件过多的情况，写入层面一直都会是顺序的，性能一直很高。但是在消费数据的时候，因为多个分区数据存储在同一个文件中，同一个分区的数据在底层存储上是不连续的，硬盘层面会出现随机读的情况，导致读取的性能降低。 不过随机读写带来的性能问题，可以通过给底层配备高性能的硬件来缓解。所以当前比较多的 MQ 选用的是第二种方案，但是 Kafka 为了保证更高的吞吐性能，选用的是第一种方案。\n但是不管是方案一还是方案二，在数据存储过程中，如果单个文件过大，在文件加载、写入和检索的时候，性能就会有问题，并且 MQ 有自动过期机制，如果单个文件过大，数据清理时会很麻烦，效率很低。所以，我们的消息数据都会分段存储。\n消息数据的分段实现 数据分段的规则一般是根据大小来进行的，比如默认 1G 一个文件，同时会支持配置项调整分段数据的大小。当数据段达到了规定的大小后，就会创建一个新的文件来保存数据。如果进行了分段，消息数据可能分布在不同的文件中。所以我们在读取数据的时候，就需要先定义消息数据在哪个文件中。为了满足这个需求，技术上一般有根据偏移量定位或根据索引定位两种思路。\n根据偏移量（Offset）来定位消息在哪个分段文件中，是指通过记录每个数据段文件的起始偏移量、中止偏移量、消息的偏移量信息，来快速定位消息在哪个文件。\n当消息数据存储时，通常会用一个自增的数值型数据（比如 Log）来表示这条数据在分区或 commitlog 中的位置，这个值就是消息的偏移量。\n在实际的编码过程中，记录文件的起始偏移量一般有两种思路：单独记录每个数据段的起始和结束偏移量，在文件名称中携带起始偏移量的信息。因为数据是顺序存储的，每个文件都记录了其对应的起始偏移量，那么下一个文件的起始偏移量就是上一个文件的结束偏移量。\n如果用索引定位，会直接存储消息对应的文件信息，而不是通过偏移量来定位到具体的文件。具体是通过维护一个单独的索引文件，记录消息在哪个文件和文件的哪个位置。读取消息的时候，先根据消息 ID 找到存储的信息，然后找到对应的文件和位置，读取数据。RocketMQ 用的就是这个思路。\n这两种方案所面临的的场景不一样。根据偏移量定位数据，通常用在每个分区各自存储一份文件的场景；根据索引定位数据，通常用在所有分区的数据存储在同一份文件的场景。因为前一种场景，每一分数据都属于同一个分区，那么通过位点来二分查找数据的效率是最高的。第二种场景，这一份数据属于多个不同分区，再使用二分查找就不是那么明智咯，可以选择使用哈希查找。\n数据消息存储格式 消息数据存储格式一般包含消息写入文件的格式和消息内容的格式两个方面。\n消息写入文件的格式指消息是以什么格式写入到文件中的，比如 JSON 字符串或二进制。从性能和空间冗余的角度来看，消息队列中的数据基本都是以二进制的格式写入到文件的。这部分二进制数据，我们不能直接用 vim/cat 等命令查看，需要用专门的工具读取，并解析对应的格式。\n消息内容的格式是指写入到文件中的数据都包含哪些信息。对于一个成熟的消息队列来说，消息内容格式不仅关系功能维度的扩展，还牵涉性能维度的优化。\n如果消息格式设计的不够精简，功能和性能都会大打折扣。比如冗余字段会增加分区的磁盘占用空间，使存储和网络开销变大，性能也会下降。如果缺少字段，则可能无法满足一些功能上的需求，导致无法实现某些功能，又或者是实现某些功能的成本较高。所以在数据的存储格式设计方面，内容的格式需要尽量完整且不要有太多冗余。\n这么说可能会感觉比较抽象，我们分析一下 Kafka 的消息内容格式设计来直观的感受一下。\n字段名 含义 baseOffset 用在 Batch 中，该批次消息的起始 offset lastOffset 用在 Batch 中，该批次消息的结束 offset count 表示该行记录包含了多少条信息 baseSequence 用在 Batch 中，起始序号，用来支持幂等和事务 lastSequence 用在 Batch 中，结束序号，用来支持幂等和事务 producerId PID，用来支持幂等和事务 producerEpoch 分区 leader 纪元，可以看作分区 leader 的版本号或更新次数 isTransactional 是否事务信息 isControl - position 该行记录在本文件的偏移量 size 该行记录的总大小 magic 当前数据存储格式的版本，kafka 有 v0、v1 和 v2 三种格式 compresscodec 压缩格式，NONE 表示不压缩 crc CRC 校验码，用来校验数据在传输过程中的准确性 isvalid 表示数据是否可用，比如是否被删除 offset 该行记录的在这个分区的偏移量 LogAppendTime 数据写入到文件的时间 keysize key 长度 valuesize payload 长度 sequence 序号，用来支持幂等和事务 headerKeys 消息 header 的内容 key 消息的 key payload 消息的内容 可以看到，Kafka 的消息内容包含了业务会感知到的消息的 Header、Key 和 Value，还包含了时间戳、偏移量、协议版本、数据长度和大小、校验码等基础信息，最后还包含了压缩、事务、幂等 Kafka 业务相关的信息。\n需要注意的是，因为 kafka 支持 Batch 特性，所以消息格式中还包含 base 和 last 等 Batch 相关信息。\n消息数据清理机制 前文提到过，消息队列的数据在持久化存储后，需要在一定策略后自动过期删除。那么数据过期机制是如何实现的呢？\n消息队列中的数据最终都会删除，时间周期短的话几个小时、甚至几分钟，正常情况一天、三天、七天，长的话可能数个月，基本很少有场景需要再消息队列中存储一年的数据。\n消息队列的数据过期机制一般有手动删除和自动删除两种形式，从实现上看主要有三种思路：\n消费完成执行 ACK 删除数据 根据时间和保留大小删除 ACK 机制和过期机制相结合 消费完成执行 ACK 删除数据，技术上的实现思路一般是：当客户端完成消费数据后，回调客户端的 ACK 接口，告诉服务端数据已经消费成功，服务端就会标记删除该行数据，以确保消息不会被重复消费。ACK 的请求一般会有单条消息 ACK 和批量消息 ACK 两种形式。\n因为消息队列的 ACK 一般是顺序的，如果前一条消息无法被正确处理并 ACK，就无法消费下一条数据，导致消费卡住。此时就需要死信队列的功能，把这条数据先写入到死信队列，等待后续的结果。然后 ACK 这条消息，确保消费正确进行。\n这种方案，优点是不会出现重复消费，一条消息只会被消费一次。缺点是 ACK 成功后消息被删除，无法满足需要消息重放的场景。\n根据时间和保留大小删除指消息在被消费后不会被删除，只会通过提交消费位点的形式标记消费进度。\n实现思路一般是服务端提供偏移量提交的接口，当客户端消费成功数据后，客户端会回调偏移量接口，告诉服务端这个偏移量的数据已经消费成功了，让服务端吧偏移量记录起来。然后服务端会根据消息保留的策略，比如保留时间或保留大小来清理数据。一般通过一个常驻的异步线程来清理数据。\n这个方案，一条消息可以重复消费多次。不管有没有被成功消费，消息都会根据配置的时间规则或大小规则进行删除。优点是消息可以多次重放，适用于需要多次进行重放的场景。缺点是在某些情况下（比如客户端使用不当）会出现大量的重复消费。\n结合前两个方案，就有了 ACK 机制和过期机制相结合的方案。实现的核心逻辑和方案二比较类似，但保留了 ACK 的概念，不过 ACK 是相对于 Group 概念的。\n当消息完成后，在 Group 维度 ACK 消息，此时消息不会被删除，只是这个 Group 也不会再重复消费到这个消息，而新的 Group 可以重新消费订阅这些数据。所以在 Group 维度避免了重复消费的情况，也可以运行重复订阅。\n前面我们虽然反复提到“删除”，但数据实际怎么删除也有讲究。我们知道消息数据是顺序存储在文件中的，会有很多分段数据，一个文件可能会有很多行数据。那么在 ACK 或者数据删除的时候，一个文件中可能既存在可删除数据，也存在不可删除数据。如果我们每次都立即删除数据，需要不断执行“读取文件、找到记录、删除记录、写入文件”的过程，即使批量操作，降低频率，还是得不断地重复这个过程，会导致性能明显下降。\n当前主流的思路是延时删除，以段数据为单位清理，降低频繁修改文件内容和频繁随机读写文件的操作。\n只有该段里面的数据都允许删除后，才会把数据删除。而删除该段数据中的某条数据时，会先对数据进行标记删除，比如在内存或 Backlog 文件中记录待删除数据，然后在消费的时候感知这个标记，这样就不会重复消费这些数据。\n总结 消息队列的存储分为元数据存储和消息数据存储两方面。\n元数据的存储主要依赖第三方组件实现，比如 ZooKeeper、etcd 或者自研的简单元数据存储服务等等。在成熟的消息队列架构中，基于简化架构和提升稳定性的考虑，都会考虑在集群内部完成元数据的存储和管理。\n消息数据的存储在功能层面包含数据存储结构设计、数据分段存储、数据存储格式、数据清理机制四个方面。\n消息数据的存储主要包含 Topic 和分区两个维度。Topic 起逻辑组织作用，实际的数据存储是在分区维度完成的。所以在数据存储目录结构上，我们都以分区为最小粒度去设计，至于选择每个分区单独一个存储文件，还是将每个节点上所有分区的数据都存储在同一个文件，方案各有优劣，你可以根据实际情况去选择。\n因为大文件存在性能和资源占用、数据清理成本等问题，一般情况下，我们都需要对数据文件进行分段处理，分段的策略一般都是按照文件大小进行的。\n数据存储格式可以分为基础信息和业务信息两个维度，数据格式需要遵循极简原则，以达到性能和成本的最优。数据的过期策略一般有三种，ACK 删除、根据时间和保留大小删除数据、两者结合。目前业界的实现比较多样，从选择上来看，两者结合的方案更合理。\n","description":"","tags":null,"title":"MQ005——元数据和消息数据的存储设计","uri":"/tech/bigdata/bigdata_mq005/"},{"categories":null,"content":"如何设计一个高性能的网络模块？？ 前言 这篇博客我们来扒一下有关消息引擎系统的第二个基础知识点——网络模块。对 MQ 来说，网络模块是核心组件之一，网络模块的性能很大程度上决定了消息传输的能力和整体性能。\n对于 Java 后端的开发人员来说，如果谈到网络模块的开发，大概率都会想到 Netty。Netty 作为 Java 网络编程中最出名的类库，可以说是独当一面的存在。那既然都这么说了的话，关于 MQ 的网络模块选型是不是直接使用 Netty 就可以了？？\n带着这份好奇心，继续往下看看吧。\n选型之前，我们得先知道要解决什么问题。消息引擎系统是需要满足高吞吐、高可靠、低延时，并支持多语言访问的基础软件，网络模块最需要解决的是性能、稳定性、开发成本三个问题。接下来就围绕这三点来思考消息队列网络模块应该怎样设计。\n网络模块的性能瓶颈分析 这里就基于最基础的 MQ 访问链路图进行分析。\n对于单个请求来说，请求流程是：客户端（生产者 / 消费者）构建请求后， 向服务端发送请求包 —\u003e 服务端接收包后，将包交给业务线程处理 —\u003e 业务线程处理完成后，将结果返回给客户端。其中可能消耗性能的有三个点：\n编解码的速度：见上一篇博客——MQ003—通信协议 网络延迟：即客户端到服务端的网络延迟，这一点取决于网络链路的性能，在软件层面几乎无法优化，与网络模块无关 服务端 / 客户端网络模块的处理速度：发送 / 接收请求包后，包是否能及时被处理，比如当逻辑线程处理完成后，网络模块是否及时回包。这一点属于性能优化，也是网络模块设计的核心工作，有机会的话会深入探究一下咯。 对于并发请求来说，在单个请求维度问题的基础上，还需要处理高并发、高 QPS 和高流量等场景带来的性能问题，主要包括以下三个方面：\n高效的连接管理：当客户端和服务端之间的 TCP 连接过多，如何高效处理、管理连接； 快速处理高并发请求：当客户端和服务端之间的 QPS 很高，如何快速处理（接收、返回）请求； 大流量场景：当客户端和服务端之间的流量很高，如何快速吞吐（读、写）数据。 大流量场景，某种意义上是高并发处理的一种子场景。因为大流量分为单个请求包大并发小、单个请求包小并发大两种场景，前者的瓶颈主要在于数据拷贝、垃圾回收、CPU 占用等方面，主要依赖语言层面的编码技巧来解决。第二种场景就是我们主要解决的对象。\n高性能网络模块的设计实现 知道了瓶颈在哪里，就具体来看一下如何设计出一个高性能的网络模块。从技术上看，高性能的网络模块设计可以分为如何高效管理大量的 TCP 连接、如何快速处理高并发的请求以及如何提高稳定性和降低开发成本等三个方面。\n基于多路复用技术管理 TCP 连接 从技术原理角度思考，高效处理大量 TCP 连接，在消息引擎系统中主要有单条 TCP 连接的复用和多路复用两种技术思路。\n1. 单条 TCP 连接的复用 这是在一条真实的 TCP 连接中，创建信道（channel，可以理解为虚拟连接）的概念。通过编程手段，把信道当做一条 TCP 连接使用，做到 TCP 连接的复用，避免创建大量 TCP 连接导致系统资源消耗过多。\n这种实现的缺点是在协议设计和编码实现的时候有额外的开发工作量，而且近年随着异步 IO、IO 多路复用技术的发展，这种方案有点多余。不过因为语言特性、历史背景等原因，像 RabbitMQ 用的就是这种方案。\n2. IO 多路复用 像现在主流的 Kafka、RocketMQ、Pulsar 的网络模块都是基于 IO 多路复用的思路开发的。\nIO 多路复用技术，是指通过把多个 IO 的阻塞复用到同一个 selector 的阻塞上，让系统在单线程的情况下可以同时处理多个客户端请求。这样做最大的优势是系统开销小，系统不需要创建额外的进程或者线程，降低了维护的工作量也节省了资源。\n目前支持 IO 多路复用的系统调用有 Select、Poll、Epoll 等，Java NIO 库底层就是基于 Epoll 实现的。\n不过，即使使用了这两种技术，单机能处理的连接数还是有上限的。\n第一个上限是操作系统的 FD 上限，如果连接数超过了 FD的数量，连接会创建失败。第二个上限是系统资源的限制，主要是 CPU 和内存。频繁创建、删除或者创建过多连接会消耗大量的物理资源，导致系统负载过高。\n所以可以发现，每个消息队列的配置中都会提到连接数的显示和系统 FD 上限调整。Linux 中可以通过命令查看系统的 FD 信息：\n1 2 3 4 5 6 // 查看能打开 FD 的数量 ulimit -n // 用户级限制 cat /proc/sys/fs/file-max // 系统级限制 // 临时修改最大数量 ulimit -n 100000 // 将最大值改为 100000 解决了第一个问题连接处理，下面来看如何快速处理高并发请求。\n基于 Reactor 模型处理高并发请求 先看单个请求的处理。\n我们都知道，两点之间直线最短。对于单个请求来说，最快的处理方式就是客户端直接发出请求，服务端接收到包后，直接丢给后面的业务线程处理，当业务线程处理成功后，直接返回给客户端。\n这种处理是最快的，但是还有两个问题需要解决：\n如何第一时间拿到包交给后端的业务逻辑处理？？ 当业务逻辑处理完成后，如何立即拿到返回值返回给客户端？？ 可能比较直观的思路就是阻塞等待模型，不断轮询等待请求拿到包，业务逻辑处理完，直接返回结果给客户端。这种处理是最快的。但是阻塞等待模型因为是串行的处理机制，每个请求需要等待上一个请求处理完才能处理，处理效率会比较低。所以，单个请求，最合理的方式就是异步的事件驱动模型，可以通过 Epoll 和异步编程来解决。\nOk，继续再来看看看高并发请求的情况。在高并发的情况下会有很多连接、请求需要处理，核心思路就是并行、多线程处理。那么如何并行处理呢？？这个时候就需要用到 Reactor 模型了。\nReactor 模型是一种处理并发服务请求的事件设计模式，当主流程收到请求后，通过多路分离处理的方式，把请求分发给相应的请求处理器处理。如下图所示，Reactor 模式包含 Reactor、Acceptor、Handler 三个角色。\nReactor：负责监听和分配时间。收到事件后分派给对应的 Handler 处理，事件包括连接建立就绪、读就绪、写就绪等； Acceptor：负责处理客户端新连接。Reactor 接收到客户端的连接事件后，会转发给 Acceptor，Acceptor 接收客户端的连接，然后创建对应的 Handler，并向 Reactor 注册此 Handler； Handler：请求处理器，负责业务逻辑的处理，即业务处理线程。 从技术上看，Reactor 模型一般有三种实现方式：\n单 Reactor 单线程模型（单 Reactor 单线程） 单 Reactor 多线程模型 （单 Reactor 多线程） 主从 Reactor 多线程模型 (多 Reactor 多线程） 我们具体分析一下，看消息队列更适合哪一种。\n单 Reactor 单线程模型，特点是 Reactor 和 Handler 都是单线程的串行处理。\n优点是所有处理逻辑放在单线程中实现，没有上下文切换、线程竞争、进程通信等问题。缺点是在性能与可靠性方面存在比较严重的问题。\n性能上，因为是单线程处理，无法充分利用 CPU 资源，并且业务逻辑 Handler 的处理是同步的，容易造成阻塞，出现性能瓶颈。可能性主要是因为单 Reactor 是单线程的，如果出现异常不能处理请求，会导致整个系统通信模块不可用。\n所以单 Reactor 单进程模型不适用于计算密集型的场景，只适用于业务处理非常快速的场景。\n相比起来，单 Reactor 多线程模型，业务逻辑处理 Handler 变成了多线程，也是就说，获取到 IO 读写事件之后，业务逻辑是同一批线程在处理。\n优点是 Handler 收到响应后通过 send 把响应结果返回给客户端，降低 Reactor 的性能开销，提升整个应用的吞吐。而且 Handler 使用多线程模式，可以充分利用 CPU 的性能，提高了业务逻辑的处理速度。\n缺点是 Handler 使用多线程模式，带来了多线程竞争资源的开销，同时涉及共享数据的互斥和保护机制，实现比较复杂。另外，单个 Reactor 承担所有事件的监听、分发和响应，对于高并发场景，容易造成性能瓶颈。\n在此基础上，主从 Reactor 多线程模型，是让 Reactor 也变成了多线程。\n当前业界主流 MQ 的网络模型，比如 Kafka、RocketMQ 为了保证性能，都是基于主从 Reactor 多线程模型开发的。\n这种方案，优点是 Reactor 的主线程和子线程分工明确。主线程只负责接收新连接，子线程负责完成后续的业务处理。同时主线程和子线程的交互也很简单，子线程接收主线程的连接后，只要负责处理其对应的业务即可，无须过多关注主线程，可以直接在子线程把处理结果返回给客户端。所以，主从 Reactor 多线程模型适用于高并发场景，Netty 网络通信框架也是采用了这种实现方式。\n缺点是如果基于 NIO 从零开发，开发的复杂度和成本都是比较高的。另外，Acceptor 是一个单线程，如果挂了，如何处理客户端新连接是一个风险点。\n为了解决 Acceptor 的单点问题，有些组件为了保证高可用性，会对主从 Reactor 多线程做一些优化，把 Acceptor 也变为多线程的模式。如下图：\n到此为止，基于 IO 多路复用技术和 Reactor 模型，我们已经可以解决网络模块的性能问题了，接下来继续深入探究如何提高网络模块的稳定性和降低开发成本。\n基于成熟网络框架提高稳定性并降低开发成本 这里的“稳定性”主要指代码的稳定性。因为网络模块的特点是编码非常复杂，要考虑的细节和边界条件非常多，一些异常情况的处理也很细节，需要经过长时间的打磨。但相对而言，一旦开发完成，稳定后，代码几乎不需要再改动，因为需求相对固定的。\n在 Java 中，网络模块的核心是一个基础类库——Java NIO 库，它的底层是基于 Unix / Linux IO 复用模型 Epoll 实现的。\n如果我们要基于 Java NIO 库开发一个 Server，需要处理网络的闪断、客户端的重复接入、连接管理、安全认证、编解码、心跳保持、半包读写、异常处理等等细节，工作量非常大。所以在消息队列的网络编程模型中，为了提高稳定性或者降低成本，选择现成的、成熟的 NIO 框架是一个更好的方案。\n而 Netty 就是这样一个基于 Java NIO 封装的成熟框架。所以大部分 Java 开发者一提到网络编程，自然而然会想到 Netty。\nKafka 网络模型 Kafka 的网络层没有用 Netty 作为底层的通信库，而是直接采用 Java NIO 实现网络通信。在网络模型中，也是参照 Reactor 多线程模型，采用多线程、多 Selector 的设计。\n看整个网络层的结果图，Processor 线程和 Handler 线程之间通过 Request Channel 传递数据，Request Channel 中包含一个 Request Queue 和多个Response Queue。每个 Processor 线程对应一个 Response Queue。\n具体流程上：\n一个 Acceptor 接收客户端建立连接的请求，创建 Socke 连接并分配给 Processor 处理； Processor 线程把读取到的请求存入 RequestQueue 中，Handler 线程从 RequestQueue 队列中取出请求进行处理； Handler 线程处理请求产生的响应，会存放到 Processor 对应的 ResponseQueue 中，Processor 线程对其对应的 ResponseQueue 中取出响应信息，并返回给客户端。 NIO 编程和 RPC 框架 其实，要想不关心底层的调用细节（比如底层的网络协议和传输协议等），可以直接调用 RPC（Remote Procedure Call）框架来实现。\n因为 RPC 调用的是一个远程对象，调用者和被调用者处于不同的节点上，想完成调用，必须实现 4 个能力。\n网络传输协议：远端调用底层需要经过网络传输，所以需要选择网络通信协议，比如 TCP。 应用通信协议：网络传输需要设计好应用层的通信协议，比如 HTTP2 或自定义协议。 服务发现：调用的是远端对象，需要可以定位到调用的服务器地址以及调用的具体方法。 序列化和反序列化：网络传输的是二进制数据，因此 RPC 框架需要自带序列化和反序列化的能力。 细心的话，可以发现 RPC 框架完成的工作等于同学协议和前文提到的网络模块设计两部分的工作。在当前的微服务框架中，RPC 已经是我们很熟悉、很常用且很成熟的技术了。\n那 RPC 框架作为消息队列中的网络模块会有哪些优缺点呢？我们以 gRPC 框架举例分析。gRPC 是 Google 推出的一个 RPC 框架，可以说是 RPC 框架中的典型代表。主要有以下三个优点：\ngRPC 内核已经很好地实现了服务发现、连接管理、编解码器等公共部分，我们可以把开发精力集中在消息队列本身，不需要在网络模块消耗太多精力。 gRPC 几乎支持所有主流编程语言，开发各个消息队列的 SDK 可以节省很多开发成本。 很多云原生系统，比如 Service Mesh 都集成了 gRPC 协议，基于 HTTP2 的 gRPC 的消息队列很容易被云原生系统中的其他组件所访问，组件间的集成成本很低。 但是当前主流的消息队列都不支持 gRPC 框架，这是因为如果支持就要做很大的架构改动。而且，gRPC 底层默认是七层的 HTTP2 协议，在性能上，可能比直接基于 TCP 协议实现的方式差一些。但是 HTTP2 本身在性能上做了一些优化，从实际表现来看，性能损耗在大部分场景下是可以接受的。\n所以如果是一个新设计的消息队列或者消息队列的新架构，通过成熟的 RPC 框架来实现网络模块是一个蛮不错的方案。\n总结 MQ 的网络模块主要解决的是性能、稳定性和成本三个方面的问题。\n性能问题，核心是通过 Reactor 模型、IO 多路复用技术解决的。Reactor 模式在 Java 网络编程中用得非常广泛，比如 Netty 就实现了 Reactor 多线程模型。即使不用 Netty 进行网络编程（比如 Kafka 直接基于 Java NIO 编程）的情况下，网络模块也大多是参考或基于 Reactor 模式实现的。因为 Reactor 模式可以结合多路复用、异步调用、多线程等技术解决高并发、大流量场景下的网络模块的性能问题。\n在 Java 技术栈下，网络编程的核心是 Java NIO。但为了解决稳定性和开发成本的问题，建议选择业界成熟的网络框架来实现网络模块，而不是基于原生的 Java NIO 来实现。成熟的框架分为成熟的 NIO 框架（如 Netty）和成熟的 RPC 框架（如 gRPC）。\n目前业界主流的消息队列都是基于 Java NIO 和 Netty 实现的。Netty 是我们网络模块编程的常用选型，大部分情况下，可能还是我们的最终选择。但是 Netty 好用并不意味着所有的 Java 网络编程都必须选择 Java NIO 和 Netty。\n当需要构建一个组件的网络模块的时候，要先知道这个组件的业务特点是什么，需要解决哪些问题，再来考虑使用什么技术。比如在客户端连接数不多、并发不高，流量也很小的场景，只需要一个简单的网络 Server 就够了，完全没必要选择 Java NIO 或 Netty 来实现对应的网络模块。随着技术架构的迭代，基于 RPC 框架的方案也是一个不错的选择。\n","description":"","tags":null,"title":"MQ004——网络模块","uri":"/tech/bigdata/bigdata_mq004/"},{"categories":null,"content":"2023.07 杂记——聊聊所谓的“价值” 前言 其实从我个人角度来说，是不太喜欢聊“理想”、聊“价值”这类假大空的名词，因为不接地气，往往会给人虚假的感觉。尤其这几年互联网行业在招人的时候都喜欢来考察那所谓的“价值观”，以及动不动就喊一些“集体荣誉感”、“使命感”、“责任感”等废话口号，但往大了说是不是整个国家都在喊口号呢？？\n所以说嘛，与其让别人来整天嚷嚷，不如先自己来吐槽一波咯。最近，怎么说呢。可能和自己的预期不太符，也可能是这才是真正的样子，又和几个朋友唠唠他们的近况，聊的多了，想的多了，就会产生自我怀疑，再严重点会有精神内耗。何必让它耗呢，对吧。\n我这个是比较“佛”的，对于名声啊之类的都不屑于顾，更多的是想做自己。当然对于“价值”也认为是虚名，无非是给自己套个圈，变得不自在咯。\n这篇文章内容会极其主观（其实自己的博客大部分都会很主观咯），某些内容可能会引起一些玻璃心的不适应，如果你看着比较膈应，趁早退出，哈哈哈哈。\n谈谈 22 年的毕业生 就业环境 因为我自己也是从 22 本科毕业，总体来说周围很多人也较多是。上周末和大学同学聊天的时候忽然感慨道：我们才毕业一年，为何有一种脱离学生身份好多年的错觉。\n江湖上都流传着“00 后整顿职场”的烂梗，但实际上却是：“没整顿职场，现实先教会做人”。事实上，没有选择的机会，很多时候只能咬着牙忍下去。因为你并不是不可替代的，一个公开的职位，毫不客气地说会有大把的应聘者，你不愿意干，自然会有人做。所以有的时候，能遇见一家比较人性化的公司也不是很容易。（随便扯了一点，下面看看大环境：\n这一年毕业的人，去年上半年赶上疫情，无论是找工作，还是考公、考研复试，都有着一定的影响。最💩的是去年一年反反复复的封了差不多一年，年底直接大家一起喜🐑🐑，zczh！！笑死。哈哈哈哈。\n所以 22 届毕业生，到目前为止，真正就业的到底有多少呢？？近三年受疫情影响，抛弃一些宏观上的数据来说，经济下沉已成事实。所以对于整个社会的影响都是有的。加上 20 年研究生扩招，有的专硕是两年毕业，然后会发现近两年的应届生（韭菜）格外的多，而且差距特别大。所以我更偏向于 22 年毕业生真的不容易。。\n原生家庭 基于上述的环境，我见过有不少同龄人还在伸手向父母要钱，其中有继续读书的、也有在家备考的、甚至还有无所事事的，相信大多数的家长都有着“别人家”孩子的思想，“别人都可以你怎么就不行”这句话似乎不经意间就会随口而出，这句话也是最容易刺痛孩子的内心，因为这是来自于他们最亲近的人的质疑与不信任。\n比较庆幸的是，至少我爸妈不会这么对我说吧。我个人虽然谈不上优秀，但却足够独立，首先保证经济独立，才能进一步在思想上取得独立！！所以我就会和爸妈说：放在同龄人里面，我至少不是最差的，也就马马虎虎能够得过且过吧。但我这种其实属于个例，很多人是找不到一份说得过去的工作，而且一大部分人是没有工作能力的。之前看过一个笑话但也是事实，招个三千左右的体力工，求职者还会考虑考虑，但拿着三千却可以轻轻松松招个大学实习生。现实即是灰色幽默。。\n我们的上一代，上上一代都有很深的社会、文化以及历史的创伤，这些原生家庭的创伤可能会代代遗传。当风平浪静、岁月静好的时候，这些都会被隐藏起来，或者表现的不太明显。但是当形势一旦紧张，大环境不怎么光明，人受到挤压，就很容易被激发。而在传统的中国家庭中，家长经常说的一句话就是“我是为你好”。孩子很少被看作一个有独立意识的主体，他们的自我往往是不被看见的。儒家文化和集体主义也强调人际关系的和谐，把人放在群体中。\n很多中国孩子承载了家长过多的期待，他们从小接受的爱就是有条件的——“只有我这样做，爸爸妈妈才会爱我。”有的好学生被妈妈不断数落着长大，妈妈的理由是“我希望你完美”。她的缺点，是不被妈妈接受的。但“追求完美”是一场让人精疲力尽的夸父逐日游戏。这个好学生后来成为了工作狂，一闲下来就有罪恶感。因为没有接受过无条件的爱，好学生小时候迎合父母，长大后迎合领导，即使离开了家，他们内化了的严苛父母还会继续批判自己，对内攻击。\n那么这类人，当不努力工作的时候，还能是谁？？过去三十年里，中国社会的基调就是高大猛好，要创造，要发展，要向上，人们相信的是明天会更好，一分耕耘一分收获，好学生的人格也是在这样的环境中形成的。但当在职场“大杀四方”的愿望遇到收缩的环境，好学生就很容易产生自尊体系的崩塌。然后有的就开始选择卷。。。我是比较讨厌“内卷”这个词的，没啥意思，真的没意义。你能熬，还有比你更能熬的。而且我一直在强调在绝对的实力面前，内卷就纯纯的小丑，都是徒劳。尽可能去寻找自己的闪光点，去发挥自己的优势，而不是跟风去熬。\n孤身杭漂 在意识到上述的问题之后，我开始尝试离开家人身边，流放在异地，孤身一人当个杭漂，有的时候会觉得长这么大终于能够自己独立面对生活，比较自由。但还是挺怕家里人担心的。来杭州的时候，很多人都很费解，手里有更好的选择，为何还选择现在的公司呢。。emmmm 怎么说呢。从某种意义上来说，现如今的工作无论是技术上，还是薪资上都不是最优的。但从我个人角度来说，是比较适合自己的。刚出学校门，加上自己喜欢瞎折腾，学的技术比较杂，很多都不精，需要时间去沉淀。而且从主观上来说，上海和杭州这两个城市，我更喜欢后者。经过去年那么一折腾，前者太失望了。。。简单来说，就是想换个城市独立地生活，然后尽可能选择有自己时间的工作啦。\n来杭三个多月，新鲜劲也慢慢消散，仿佛自己也逐渐变成社畜的样子。回头想想，在学校的时候评价一个学生的好与坏往往是看成绩；在公司里动不动就提绩效，搞些形式主义，透漏着一股 cpu 味；进入社会评判一个人的成功与否，直接关系到是否有车有房。这不对吗？？这是对的。这也是目前这个社会的风气。但如果拿这些或者这类标准来决定价值的话，我大概率是不及格。目前自己所想的大部分事情都与之背道而驰，有的人问我，你有认真考虑过以后吗？？有的吧，指的是我只想过以后某个阶段的自己是什么状态，但具体到在哪做什么事情就不得而知了。我不想被生活所约束，更想成为我自己。\n我本身对于技术，虽然谈不上热爱，但至少是不排斥。曾几何时，刚遇见“开源”的时候，原以为找到了值得自己付出一辈子为之努力的方向，但随之了解的越深入，接触到背后的逻辑，开源社区的运作、开源圈子以及开源商业化之后，开始有点质疑自己所做的事情是否真的有价值，虽然心里明白开源确实是大势所趋。参与开源，也算是成就了自己。\n不过，反过来想，投入自己的时间去学习去探索去钻研技术，虽然提升的是自己，但最后给到的反馈还是公司，所以真的有必要吗？？\n日子就这样过吧 工作是为了生活，那为何不直接选择生活呢？？互联网的发展，无形中将焦虑放大了。名校论、学历论、金钱论、车房论本质上没啥区别，没有谁比谁高级，对于自身的认知不同，看重的自然而然也就不一样咯。大部分人都在想着要过得比“别人”好。其实没必要，都一样。\n那么，我选择和自己和解、和生活和解🙏。\n有时候我就会想啊，也许最好的状态就是，意识到“我的存在本身就是价值，哪怕什么都不做，只是呼吸，我都是有价值的”。我的价值，不需要外界来定义！！这种状态，也就是自由。。\n","description":"","tags":null,"title":"杂记——聊聊所谓的‘价值’","uri":"/life/202307_value/"},{"categories":null,"content":"如何为消息引擎系统设计一个好的通信协议？ 前言 经过上面两篇博客的梳理，已经了解了 MQ 的基本概念。从功能上看，一个最基础的消息引擎系统应该具备生产、存储和消费的能力。也就是能够完成“生产者把数据发送到 Broker，Broker 收到数据后，持久化存储数据，最后消费者从 Broker 消费数据”的整个流程。\n从整个流程来拆解技术架构，最基础的消息引擎系统应该具备五个模块：\n通信协议：用来完成客户端（生产者和消费者）和 Broker 之间的通信，比如生产和消费； 网络模块：客户端用来发送数据，服务端用来接收数据； 存储模块：服务端用来完成持久化数据存储； 生产者：完成生产相关的功能； 消费者：完成消费相关的功能。 其实消息引擎系统，本质上讲就是个 CS 模型，即通过客户端和服务端之间的交互完成生产、消费等行为。那么客户端和服务端之间的通信流程是如何实现的呢？？\n这就是今天的重点——通信协议。为了完成交互，我们第一步就需要确定服务端和客户端是如何通信的。而通信的第一步就是确定使用哪种通信协议进行通信。\n通信协议基础 所有协议的选择和设计都是根据需求来的，我们知道 MQ 的核心特性是高吞吐、低延时、高可靠，所以在协议上至少需要满足：\n协议可靠性要高，不能丢数据； 协议的性能要高，通信的延时要低； 协议的内容要精简，带宽的利用率要高； 协议需要具备可扩展能力，方便功能的增减。 那没有没现成的满足这四个要求的协议呢？\n目前业界的通信协议可以分为公有协议和私有协议两种。公有协议指公开的受到认可的具有规范的协议，比如 JMS、HTTP、STOMP 等。私有协议是指根据自身的功能和需求设计的协议，一般不具备通用性，比如 Kafka、RocketMQ、Puslar 的协议都是私有协议。\n其实 MQ 领域是存在公有的、可直接使用的标准协议的，比如 AMQP、MQTT、OpenMessaging，它们设计的初衷就是为了解决因各个消息队列的协议不一样导致的组件互通、用户使用成本高、重复设计、重复开发成本等问题。但是，公有的标准协议讨论制定需要较长时间，往往无法及时赶上需求的变化，灵活性不足。\n因此大多数消息队列为了自身的功能支持、迭代速度、灵活性考虑，在核心通信协议的选择上不会选择公有协议，都会选择自定义私有协议。那私有协议要怎么设计实现呢？从技术上来看，私有协议设计一般需要包含三个步骤。\n网络通信协议选型，指计算机七层网络模型中的协议选择。比如传输层的 TCP/UDP、应用层的 HTTP/WebSocket 等； 应用通信协议设计，指如何约定客户端和服务端之间的通信规则。比如如何识别请求内容、如何确定请求字段信息等； 编解码（序列化 / 反序列化）实现，用于将二进制的信息的内容解析为程序可识别的数据格式。 网络通信协议选型 从功能需求出发，为了保证性能和可靠性，几乎所有主流的 MQ 在核心生产、消费链路的协议选择上，都是基于可靠性高、长连接的 TCP 协议。\n四层的 UDP 虽然也是长连接，性能更高，但是因为其不可传输的特性，业界几乎没有消息引擎系统用它通信。\n七层的 HTTP 协议每次通信都需要经历三次握手、四次关闭等步骤，并且协议结构也不够精简。因此在性能（比如耗时）上的表现比较差，不适合高吞吐、大流量、低延时的场景。所以主流协议在核心链路上很少使用 HTTP。\n应用通信协议设计 从应用通信协议构成的角度，协议一般会包含协议头和协议提两部分。\n协议头包含一些通用信息和数据源信息，比如协议版本、请求标识、请求 ID、客户端 ID 等等； 协议体主要包含本次通信的业务数据，比如一个字符串、一段 JSON 格式的数据或者原始二进制数据等等。 从编解码协议的设计角度来看，需要分别针对“请求”和“返回”设计协议，请求协议结构和返回协议结构一般如下图：\n设计的原则是：请求维度的通用信息放在协议头，消息维度的信息就放在协议体。下面结合 Kafka 协议来详细分析一下：\n协议头的设计 协议头的设计，首先要确认协议中需要携带哪些通用的信息。一般情况下，请求头要携带本次请求以及源端的一些信息，返回头要携带请求唯一标识来标识对应哪个请求。\n所以，请求头一般需要携带协议版本、请求标识、请求的 ID、客户端 ID 等信息。而返回头，一般只需要携带本次请求的 ID、本次请求的处理结果（成功或失败）等几个信息。\n接下来，我们分析一下 Kafka 协议的请求头和返回头的内容，以便于对协议头的设计有个更直观的认识。如下图所示，Kafka V2 协议的请求头中携带了四个信息。\n用来标识请求类型的 api_key，如生产、消费、获取元数据； 用来标识请求协议版本的 api_version，如 V0、V1、V2； 用来唯一标识该请求 correlation_id，可以理解为请求 ID； 用来标识客户端的 client_id。 Kafka V0 协议的返回头只携带了一个信息，即该请求的 correlation_id，用来标识这个返回是哪个请求的。\n这里有个细节你可能注意到了，请求协议头是 V2 版本，返回协议头是 V0 版本，会不会有点问题呢？\n其实是没有的。因为从协议的角度，一般业务需求的变化（增加或删除）都会涉及请求内容的修改，所以请求的协议变化是比较频繁的，而返回头只要能标识本次对应的请求即可，所以协议的变化比较少。所以，请求头和返回头的协议版本制定，是建议分开定义的，这样在后期的维护升级中会更加灵活。\n协议体的设计 协议体的设计就和业务功能密切相关了。因为协议体是携带本次请求 / 返回的具体内容的，不同接口是不一样的，比如生产、消费、确认，每个接口的功能不一样，结构基本千差万别。\n不过设计上还是有共性的，注意三个点：极简、向后兼容、协议版本管理。如何理解呢？\n协议在实现上首先需要具备向后兼容的能力，后续的变更（如增加或删除）不会影响新老客户端的使用；然后协议内容上要尽量精简（比如字段和数据类型），这样可以降低编解码和传输过程中的带宽的开销，以及其他物理资源的开销；最后需要协议版本管理，方便后续的变更。\n同样为了让你直观感受协议体的设计，我们看 Kafka 生产请求和返回的协议内容：\nKafka 生产请求协议如下：\nKafka 生产返回协议如下：\nKafka 生产请求的协议体包含了事务 ID、acks 信息、请求超时时间、Topic 相关的数据，都是和生产操作相关的。生产返回的协议体包含了限流信息、分区维度的范围信息等。这些字段中的每个字段都是经过多轮迭代、重复设计定下来的，每个字段都用用处。\n所以在协议体的设计上，最核心的就是要遵循“极简”原则，在满足业务要求的基础上，尽量压缩协议的大小。\n接下来我想讨论一下数据类型，在协议设计里，我们很容易忽略的一个事就是数据类型，比如上面 throttle_time_ms 是 INT32，error_code 是 INT16。\n数据类型很简单，用来标识每个字段的类型，不过为什么会有这个东西呢，不能直接用 int、string、char 等基础类型吗？这里有两个原因。\n消息队列是多语言通信的。不同语言对于同一类型的定义和实现是不一样的，如果使用同一种基础类型在不同的语言进行解析，可能会出现解析错乱等错误。 需要尽量精简消息的长度。比如只需要 1 个 byte 就可以表示的内容，如果用 4 个 byte 来表示，就会导致消息的内容更长，消耗更多的物理带宽。 所以一般在协议设计的时候，我们也需要设计相关的基础数据类型（如何设计可以参考 Kafka 的协议数据类型或者 Protobuf 的数据类型）。\n编解码实现 编解码也称为序列化和反序列，就是数据发送的时候编码，收到数据的时候解码。\n为什么要编解码呢? 如下图所示，因为数据在网络中传输时是二进制的形式，所以在客户端发送数据的时候就要将原始的格式数据编码为二进制数据，以便在 TCP 协议中传输，这一步就是序列化。然后在服务端将收到的二进制数据根据约定好的规范解析成为原始的格式数据，这就是反序列化。\n在序列化和反序列化中，最重要的就是 TCP 的粘包与拆包。TCP 是一个“流”协议，是一串数据，没有明显的界限，TCP 层面不知道这段数据的意义，只负责传输。所以应用层就要根据某个规则从流数据中拆出完整的包，解析出有意义的数据，这就是沾包和拆包的作用。\n沾包 / 拆包的基本思路：\n消息定长； 在包尾增加回车换行符进行分割，例如 FTP 协议； 将消息分为消息头和消息体，消息头中包含消息总长度，然后根据长度从流中解析出数据； 更加复杂的应用层协议，比如 HTTP、WebSocket 等。 早期，消息队列的协议设计几乎都是自定义实现编解码，如 RabbitMQ、RocektMQ 4.0、Kafka 等。但从 0 实现编解码器比较复杂，随着业界主流编解码框架和编解码协议的成熟，一些消息队列（如 Pulsar 和 RocketMQ 5.0）开始使用业界成熟的编解码框架，如 Google 的 Protobuf。Protobuf 是一个灵活、高效、结构化的编解码框架，业界非常流行，很多商业产品都会用，它支持多语言，编解码性能较高，可扩展性强，产品成熟度高。这些优点，都是我们在设计协议的时候需要重点考虑和实现的，并且我们自定义实现编解码的效果不一定有 Protobuf 好。所以新的消息队列产品或者新架构可以考虑选择 Protobuf 作为编解码框架。\n如果想关注如何在 MQ 中实现自定义编码，可以去深入了解 RocketMQ，它是目前业界唯一一个既支持自定义编解码，又支持成熟编解码框架的消息引擎系统。RocketMQ 5.0 之前支持的 Remoting 协议是自定义编解码，5.0 之后支持的 gRPC 协议是基于 Protobuf 编解码框架。用 Protobuf 的主要原因是它选择 gRPC 框架作为通信框架。而 gRPC 框架中默认编解码器为 Protobuf，编解码操作已经在 gRPC 的库中正确地定义和实现了，不需要单独开发。所以 RocketMQ 可以把重点放在 Rocket 消息队列本身的逻辑上，不需要在协议方面上花费太多精力。\n总结 无论是做业务开发，还是数据开发，都或多或少和 MQ 打过交道，很多程序员可能只停留在如何使用上，其实慢慢尝试往下走一步会有不一样的收获～～\n这篇博客也只是浅谈 MQ 底层关于通信协议设计的讨论。从功能支持、迭代速度、灵活性上考虑，大多数消息队列的核心通信协议都会优先考虑自定义的私有协议。私有协议的设计主要考虑网络通信协议选择、应用通信协议设计、编解码实现三个方面。\n网络通信协议选型，基于可靠、低延时的需求，大部分情况下应该选择 TCP。 应用通信协议设计，分为请求协议和返回协议两方面。协议应该包含协议头和协议体两部分。协议头主要包含一些通用的信息，协议体包含请求维度的信息。 编解码，也叫序列化和反序列化。在实现上分为自定义实现和使用现成的编解码框架两个路径。 其中最重要的是应用通信协议部分的设计选型，这部分需要设计协议头和协议体。重要的是要思考协议头和协议体里面分别要放什么，放多了浪费带宽影响传输性能，放少了无法满足业务需求，需要频繁修改协议内容。\n另外，每个字段的类型也有讲究，需要尽量降低每次通信的数据大小。所以应用通信协议的内容设计是非常考验技术功底或者经验的。有一个技巧是，如果需要实现自定义的协议，可以去参考一下业界主流的协议实现，看看都包含哪些元素，各自踩过什么坑。总结分析后，这样一般能设计出一个相对较好的消息队列。\n思考？？ 为什么业界的消息引擎系统有多种标准的协议呢？？\n业界的消息队列有多种标准的协议，如 MQTT、AMQP、OpenMessaging。主要是因为业务场景不一样，一套协议标准无法满足多种场景需要。\nMQTT 是为了满足物联网领域的通信而设计的，背景是网络环境不稳定、网络带宽小，从而需要极精简的协议结构，并允许可能的数据丢失。 AMQP 是主要面向业务消息的协议，因为要承载复杂的业务逻辑，所以协议设计上要尽可能丰富，包含多种场景，并且在传输过程中不允许出现数据丢失。因为 AMQP 协议本身的设计具有很多局限，比如功能太简单，所以不太符合移动互联网、云原生架构下的消息需求。 OpenMessaging 的设计初衷是设计一个符合更多场景的消息队列协议。 ","description":"","tags":null,"title":"MQ003——通信协议","uri":"/tech/bigdata/bigdata_mq003/"},{"categories":null,"content":"消息引擎系统的基本概念 前言——什么时候会用 MQ？？ 经过上一节 blog 的内容，以及了解了有关 MQ 的前置知识。那么是否会有想过 MQ 会用在哪些场景呢？\n在现如今的系统架构中，MQ 的定位就是总线和管道，主要起到解耦上下游系统、数据缓存的作用，通俗点就是“削峰填谷”。这个时候肯定会有人会想到 Redis 之类的数据库，与之不同的是它的主要操作就是生产和消费，而不太会关注计算、聚合和查询的逻辑。所以，在业务中不管使用哪款 MQ，其核心的操作永远是生产和消费数据。\n上次提到的订单下单流程就是一个典型的系统解耦、消息分发的场景，一份数据需要被多个下游系统处理。在大数据领域中，比较经典的就是日志采集流程，一般日志数据都很大，而且是实时产生的，直接发到下游，下游系统可能会扛不住崩溃，所以会把数据先缓存到 MQ 中。实际现如今的数仓，不仅仅是日志文件写入 Kafka 之类的消息引擎系统，有时候也会选择被存储在数据库中的业务数据，通过增量同步的方式传入到 MQ，然后再统一采集到 HDFS 上。\n针对以上场景，一款优秀的消息引擎系统必须满足：高性能、高吞吐和低延时等基本特性。\n架构层面的基本概念 Topic：在大部分 MQ 中，topic 都是指用来组织分区关系的一个逻辑概念。通常情况下，一个 topic 会包含多个分区。在 Kafka 中，发布订阅的是 topic，可以为每个业务、每个应用甚至是每类数据都创建专属的 topic；\nProducer（生产者）：向 topic 发布消息的客户端应用程序称为生产者，生产者程序通常会持续不断地向一个或多个主题发送消息。简单来说就是：指消息的发送方，发送消息的客户端；\nConsumer（消费者）：订阅这些主题消息的客户端应用程序称为消费者，和生产者类似，消费者也能够同时订阅多个注意的消息。说通俗点就是，指消息的接收方，即接收消息的客户端；\nBroker：Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。Broker 本质上是一个进程。Kafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成。虽然多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将不同的 Broker 分散运行在不同的机器上，这样如果集群中某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也依然能够对外提供服务。这其实就是 Kafka 提供高可用的手段之一；\nConsumerGroup/Subscription（消费分组 / 订阅）：一般情况下，消息队列中消费分组和订阅是同一个概念，后面统一用消费分组来称呼。它是用来组织消费者和分区关系的逻辑概念，也有保存消费进度的作用。\nMessage（消息）：指一条真实的业务数据，消息队列的每条数据一般都叫做一条消息。\nOffset/ConsumerOffset/Cursor（位点 / 消费位点 / 游标）：指消费者消费分区的进度，即每个消费者都会去消费分区，为了避免重复消费进度，都会保存消费者消费分区的进度信息。\nACK/OffsetCommit（确认 / 位点提交）：确认和位点提交一般都是指提交消费进度的操作，即数据消费成功后，提交当前的消费位点，确保不重复消费。\nLeader/Follower（领导者 / 追随者，主副本 / 从副本）：Leader 和 Follower 一般是分区维度副本的概念，即集群中的分区一般会有多个副本。此时就会有主从副本的概念，一般是一个主副本配上一个或多个从副本。\nSegment（段 / 数据分段）：段是指消息数据在底层具体存储时，分为多个文件存储时的文件，这个文件就叫做分区的数据段。即比如每超过 1G 的文件就新起一个文件来存储，这个文件就是 Segment。基本所有的消息队列都有段的概念，比如 Kakfa 的 Segment、Pulsar 的 Ledger 等等。\nStartOffset/EndOffset（起始位点 / 结束位点）：起始位点和结束位点是分区维度的概念。即数据是顺序写入到分区的，一般从 0 的位置开始往后写，此时起始位点就是 0。因为数据有过期的概念，分区维度较早的数据会被清理。此时起始位点就会往后移，表示当前阶段最早那条有效消息的位点。结束位点是指最新的那条数据的写入位置。因为数据一直在写入分区，所以起始位点和结束位点是一直动态变化的。\nACL（访问控制技术）：ACL 全称是 Access Control List，用来对集群中的资源进行权限控制，比如控制分区或 Topic 的读和写等。\n功能层面的基础概念 讲完了架构层面的基本概念，我们来看看功能层面的基本概念。\n相比于数据库的基本操作是增删改查，消息队列的基本操作就是生产和消费，即读和写。消息队列一般是不支持客户端修改和删除单条数据的。接下来我们就从功能的角度，来了解一些常见的基本概念。\n顺序消息：是指从生产者和消费者的视角来看，生产者按顺序写入 Topic 的消息，在消费者这边能不能按生产者写入的顺序消费到消息，如果能就是顺序消息。 延时消息 / 定时消息：都是指生产者发送消息到 Broker 时，可以设置这条消息在多久后能被消费到，当时间到了后，消息就会被消费到。延时的意思就是指以 Broker 收到消息的时间为准，多久后消息能被消费者消费，比如消息发送成功后的 30 分钟才能被消费。定时是指可以指定消息在设置的时间才能被看到，比如设置明天的 20:00 才能被消费。从技术上来看，两者是一样的；从客户端的角度，功能上稍微有细微的差别；从内核的角度，一般两种消息是以同一个概念出现的。 事务消息：消息队列的事务因为在不同的消息队列中的实现方式不一样，所以定义也不太一样。正常情况下，事务表示多个操作的原子性，即一批操作要么一起成功，要么一起失败。在消息队列中，一般指发送一批消息，要么同时成功，要么同时失败。 消息重试：消息重试分为生产者重试和消费者重试。生产者重试是指当消息发送失败后，可以设置重试逻辑，比如重试几次、多久后重试、重试间隔多少。消费者重试是指当消费的消息处理失败后，会自动重试消费消息。 消息回溯：是指当允许消息被多次消费，即某条消息消费成功后，这条消息不会被删除，还能再重复到这条消息。 广播消费：广播听起来是一个主动的，即 Broker 将一条消息广播发送给多个消费者。但是在消息队列中，广播本质上是指一条消息能不能被很多个消费者消费到。只要能被多个消费者消费到，就能起到广播消费的效果，就可以叫做广播消费。 死信队列：死信队列是一个功能，不是一个像分区一样的实体概念。它是指当某条消息无法处理成功时，则把这条消息写入到死信队列，将这条消息保存起来，从而可以处理后续的消息的功能。大部分情况下，死信队列在消费端使用得比较多，即消费到的消息无法处理成功，则将数据先保存到死信队列，然后可以继续处理其他消息。当然，在生产的时候也会有死信队列的概念，即某条消息无法写入 Topic，则可以先写入到死信队列。从功能上来看，死信队列的功能业务也可以自己去实现。消息队列中死信队列的意思是，消息队列的 SDK 已经集成了这部分功能，从而让业务使用起来就很简单。 优先级队列：优先级队列是指可以给在一个分区或队列中的消息设置权重，权重大的消息能够被优先消费到。大部分情况下，消息队列的消息处理是 FIFO 先进先出的规则。此时如果某些消息需要被优先处理，基于这个规则就无法实现。所以就有了优先级队列的概念，优先级是消息维度设置的。 消息过滤：是指可以给每条消息打上标签，在消费的时候可以根据标签信息去消费消息。可以理解为一个简单的查询消息的功能，即通过标签去查询过滤消息。消息过滤主要在消费端生效。 消息过期 / 删除（TTL）：是指消息队列中的消息会在一定时间或者超过一定大小后会被删除。因为消息队列主要是缓冲作用，所以一般会要求消息在一定的策略后会自动被清理。 消息轨迹：是指记录一条消息从生产端发送、服务端保存、消费端消费的全生命周期的流程信息。用来追溯消息什么时候被发送、是否发送成功、什么时候发送成功、服务端是否保存成功、什么时候保存成功、被哪些消费者消费、是否消费成功、什么时候被消费等等信息 消息查询：是指能够根据某些信息查询到消息队列中的信息。比如根据消息 ID 或根据消费位点来查询消息，可以理解为数据库里面的固定条件的 select 操作。 消息压缩：是指生产端发送消息的时候，是否支持将消息进行压缩，以节省物理资源（比如网卡、硬盘）。压缩可以在 SDK 完成，也可以在 Broker 完成，并没有严格限制。通常来看，压缩在客户端完成会比较合理。 多租户：是指同一个集群是否有逻辑隔离，比如一个物理集群能否创建两个名称都为 test 的主题。此时一般会有一个逻辑概念 Namespace（命名空间）和 Tenant（租户）来做隔离，一般有这两个概念的就是支持多租户。 消息持久化：是指消息发送到 Broker 后，会不会持久化存储，比如存储到硬盘。有些消息队列为了保证性能，只会把消息存储在内存，此时节点重启后数据就会丢失。 消息流控：是指能否对写入集群的消息进行限制。一般会支持 Topic、分区、消费分组、集群等维度的限流。 总结（扩展） 看完了上面的基础概念，下面就以 Kafka 为例，整体来看一下～～\nKafka 的三层消息架构：\n第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。\n第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。\n第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。\n最后，客户端程序只能与分区的领导者副本进行交互。\nKafka Broker 如何持久化数据？？\n总的来说，Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。不过如果你不停地向一个日志写入消息，最终也会耗尽所有的磁盘空间，因此 Kafka 必然要定期地删除消息以回收磁盘。怎么删除呢？简单来说就是通过日志段（Log Segment）机制。在 Kafka 底层，一个日志又进一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。\n谈谈消费者\n这里再重点说说消费者。上一篇博客中提到过两种消息模型，即点对点模型（Peer to Peer，P2P）和发布订阅模型。这里面的点对点指的是同一条消息只能被下游的一个消费者消费，其他消费者则不能染指。在 Kafka 中实现这种 P2P 模型的方法就是引入了消费者组（Consumer Group）。\n所谓的消费者组，指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它。为什么要引入消费者组呢？**主要是为了提升消费者端的吞吐量。**多个消费者实例同时消费，加速整个消费端的吞吐量（TPS）。BTW 这里的消费者实例可以是运行消费者应用的进程，也可以是一个线程，它们都称为一个消费者实例（Consumer Instance）。\n消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且更牛掰的的是它们还能彼此协助。假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个 Failed 实例之前负责的分区转移给其他活着的消费者。这个过程就是 Kafka 中大名鼎鼎的“重平衡”（Rebalance）。嗯，其实既是大名鼎鼎，也是臭名昭著，因为由重平衡引发的消费者问题比比皆是。事实上，目前很多重平衡的 Bug 社区都无力解决。每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，这个字段就是消费者位移（Consumer Offset）。\n注意，这和上面所说的位移完全不是一个概念。上面的“位移”表征的是分区内的消息位置，它是不变的，即一旦消息被成功写入到一个分区上，它的位移值就是固定的了。而消费者位移则不同，它可能是随时变化的，毕竟它是消费者消费进度的指示器嘛。另外每个消费者有着自己的消费者位移，因此一定要区分这两类位移的区别。我个人把消息在分区中的位移称为分区位移，而把消费者端的位移称为消费者位移。\n","description":"","tags":null,"title":"MQ002——消息引擎系统的基本常识","uri":"/tech/bigdata/bigdata_mq002/"},{"categories":null,"content":"开发者的落日？？ 前言 这篇文章，早就想写，但又怕自己资历太浅，见识不够，会的太少，写出来或多或少有点泛泛而谈，或者说蹭热度，毕竟最近遇上互联网寒冬，各个大厂裁员，这也是事实。\n熬过了💩一样的 2022，原以为今年会好那么一丢丢，但实际发现也就那么回事，整个行业危机似乎在某种程度上来说可以进一步加剧了。那么互联网的红利期是真的过去了吗？\n这是一切的开始，这也是人类的落日。\n谈谈程序员 从我的角度来说，我一直很喜欢程序员这个行业，从本质上来说，开发的本质是创造，而创造的过程中是连接着未来的。但不知从何时起出现了“码农”这个称呼，因为 CRUD 的操作，这一点从我接触这个行业开始就早已存在，我是极其特别讨厌这个称呼。因为它将整个行业形容成做的东西就是重复劳动，没有意义可言。\n那么这类人可以称之为程序员嚒？至少在我是不认可的，或者说不能当“职业的程序员”。GPT 的出现，可以说是划时代的产品，它将颠覆以往的编程方式，只会这种 CRUD 的操作人，也会进一步被淘汰，因为从本质上来说就没必要存在。但这却是这个行业的普遍现状，又有几个能做中间件开发呢？？\n所以普通的开发者要深刻理解一件事情，如今你暂时拿在手里的看似高薪不是个人能力的体现，是行业带动的结果，那么行业带动的结果。你要感谢两家公司微软和 Google。\n如果整个互联网行业只有 2 家公司可以存活的话，除了微软和Google，任何其他企业都没有资格，只能去死。\n微软大幅降低了编程的门槛，围绕操作系统诞生一整套的生态，把编程变成了一种普通人可以当成工作的玩意儿。从这角度来看，那怕你不懂编程，能读懂英文，也能七七八八理解一段简单的代码。\nGoogle 站在巨人的肩膀上，从提出分布式这个概念开始，几乎重塑了整个计算机行业。此后，Google 不满足于此，不仅疯狂制定顶层标准，而且在科技界的贡献持续造福全人类。\n可以这么说，互联网行业这些年的高光完全是行业热潮带动普通开发人员受益，而不是个人本身。我们都是风口上的猪而已。\n技术本身门槛的大幅降低导致【技术通货膨胀】，更多的人参与就代表每个人分到更少的蛋糕。回归公司的本质，一个专注于技术但是对业务 0 贡献的开发者为什么能拿高薪趴在电脑前？存量市场的竞争白热化，躺着赚钱的时代终结。不懂业务，疯狂跳槽，盲目转行，仅仅追逐技术能力的提升脱离商业本身的开发者最终会被弃之如敝履。\n综上所述，简单来说就是普通的技术越来越不值钱。\n人人皆可编程：Low Code Low Code Development Platform 是指无需编码（0 代码）或通过少量代码就可以快速生成应用程序的开发平台。\n低代码在干什么？我们直接引用行业大佬的一句话：\n低代码是基于可视化和模型驱动理念，结合云原生与多端体验技术，它能够在多数业务场景下实现大幅度的提效降本，为专业开发者提供了一种全新的高生产力开发范式。另一方面，低代码能够让不懂代码的人，通过“拖拉拽”开发组件，就能完成应用搭建。从意义上讲，低代码可以弥补日益扩大的专业技术人才缺口，同时促成业务与技术深度协作的终极敏捷形态。 看到了么？低代码是让不懂的人可以进行完成相关开发任务。这个领域的发展会迅速淘汰掉企业中的某些混子，然后向外蔓延开来。\n下面以大数据方面来举例（Java 后端开发的脚手架太多了 都是些烂梗 没意思），现如今无论公司规模大小，很多企业都想要整个大数据平台，可能会面临的问题就是，没有专业大数据开发者。如何在节省人力成本的情况下解决这个难题呢？？\n因为大数据的组件框架众多，搭建一套高可用能够落地的集群系统就存在着不小的难度，那么有没有可以一键部署安装的平台呢？？又该如何管理这些大数据组件呢？如果有的话，是否就可以让后端工程师通过写 SQL 完成大数据的工作呢？？还有一点就是各个工作流之间的上下游关系以及整个集群的任务调度是否可以通过“拖拉拽”的方式完成呢？？答案是肯定的。\n显而易见，后端开发写 SQL 算是基本功，只需了解各个大数据组件的用途，再看些行业大牛的分享就足以完成一个低代码版的大数据集群。是否可以进一步来说，其他领域也很难独善其身。\n丧钟为谁而鸣？\nFaaS 和 PaaS 关于云计算时代的一些名词不做过多解释，可以自行去查资料。\n从 2021 年开始，其实从 2020 年下半年就初露端倪。FaaS 重新被推上风口浪尖，普通开发者应该感到危机。\nFaaS 是 Functions as a Service 的简称，它往往和无服务架构（Serverless Architecture）一同被提起。PaaS 是 Platform as a Service 的简称，是一种云模型，你提供源码，平台将打包、发布、部署、运行、监控和扩缩微服务。\n为了好理解就拿 FaaS 举例。\n大家注意，FaaS 自上而下，和上文的低代码自下而上对普通开发者形成了双重挤压，对普通开发者的生存空间造成了严重影响。\nFaaS 在干什么？FaaS 抛弃了原来大型复杂应用的架构，将整个架构中的单元进行拆分，将各种软、硬件资源等抽象为一种服务提供给开发者使用，让他们不再担心基础设施、资源需求、中间件等等，专注于具体逻辑实现。\n看到了么？FaaS 已经将整个开发者最需要脑子和开发量的工作吃掉了。基础设施和中间件乃至服务器资源的管理，不需要开发者介入。这会导致什么后果？\n大批量【填鸭式】进入这个行业的开发者你们应该感到危机。因为 FaaS 正把你们变成实实在在的【工具人】。\n所谓工具人，就是低成本、易替换。\n谈谈对于大数据的影响 再次声明，只是个人的思考。我也希望未来几年回过来看自己使劲打自己脸。\n数据领域进入平台期，门槛降低，湖仓一体，批流结合。这一点可以看看 Apache 和数据领域的顶级项目和孵化器中的项目。\n未来低代码盛行，类 SQL、拖拉拽大行其道，会导致开发者们离原理越来越远，不懂底层设计，不懂顶层架构，结合上文拿大数据低代码举的例子，这一点应该不难理解，像阿里的 DataWorks 对于用户来说只要会写 SQL 就可以。数据领域天然 Low Code。\n愚者还在窃喜，智者却在悲伤。\n因为而致力于低代码和云计算领域的行业推动者正是微软、Google、阿里云这些行业引领者。\n它们成就了开发者盛世，也会亲手毁掉开发者。\n所谓，成也萧何败也萧何。\n不破不立 懂原理 目前数据领域还处于上升期，每过一段时间就会蹦出几个新概念。这些新概念势必会带动一些基础架构部门的发展，因为基础架构部门不向前跑，就会变成运维专家，变成答疑专家，就会自己干掉自己。\n所以，作为引领公司甚至行业的基础开发者，基于业务大胆启用新的技术方案前，只有对原理足够熟悉，才能做到顺利转型。盲目上马，不做出充分调研，技术能力不足会被其他领跑者拖死。可以想一下 MQ 之类的框架，微服务在用，大数据中也是必不可少，那么区别在哪呢？？又有多少用户仅仅是只掌握几条常用命令呢？？\n顶层架构设计 这一点我是比较佩服顶级的运维，很多开发者嘲笑运维不会写代码，也有可能只是个梗，一个好的运维是可以看见整个集群全貌的，这一部分仅仅只做开发是很难做到的。那么一个好的架构设计，尤其是基于业务系统的合理技术选型和正确的架构设计，这对开发者提出了相当高的要求，技术栈足够深入，场景足够丰富的情况下才能游刃有余。对于那些技术 Leader，这更是巨大的挑战。否则，一将无能，累死千军。要么你足够优秀可以当做火把给全队把路照亮，要么就要有足够的魅力发现和吸引那些是火把的人。\n懂业务 业务才是开发者的立足根本，对业务足够熟悉，才能最终站稳脚跟。随着开发门槛的不断降低，业务人员，尤其是一些专业的熟悉业务的且可以做分析的业务人员，它们对于开发会逐渐降低依赖，在低代码和套件化足够成熟的未来，只懂开发的开发者会被边缘化。\n参与开源 参与开源，拥抱未来，这一点不想再解释了。。\n所以，2023 年是一切的开始，也是开发者的落日？？\n","description":"","tags":null,"title":"2023，不想再谈技术？？","uri":"/tech/2023_mid/"},{"categories":null,"content":"关于消息引擎系统 一、前言 看见标题写的是“消息引擎系统”，咋一看是不是觉得比较陌生，那么换个说法呢，比如“消息队列”、“消息中间件”这些无论是在后端开发还是在大数据中想必都是耳熟能详的啦。但从我的角度来说，更喜欢称呼其为“消息引擎系统”。因为消息队列给出了一个不太明确的暗示，仿佛类似 Kafka 之类的框架是利用队列的方式构建的；而消息中间件的提法有过度夸张“中间件”之嫌，让人搞不清楚这个中间件到底是做什么用途的。\n像 Kafka 这一类的系统国外有专属的名字叫 Messaging System，国内很多文献将其简单翻译成消息系统。我个人认为并不是很恰当，因为它片面强调了消息主体的作用，而忽视了这类系统引以为豪的消息传递属性，就像引擎一样，具备某种能量转换传输的能力，所以我觉得翻译成消息引擎反倒更加贴切。\n讲到这里，说点题外话。我觉得目前国内在翻译国外专有技术词汇方面做得不够标准化，各种名字和提法可谓五花八门。我举个例子，比如大名鼎鼎的 Raft 算法和 Paxos 算法。了解它的人都知道它们的作用是在分布式系统中让多个节点就某个决定达成共识，都属于 Consensus Algorithm 一族。如果你在搜索引擎中查找 Raft 算法，国内多是称呼它们为一致性算法。实际上我倒觉得翻译成共识算法是最准确的。我们使用“一致性”这个字眼太频繁了，国外的 Consistency 被称为一致性、Consensus 也唤作一致性，甚至是 Coherence 都翻译成一致性。\n二、用途 根据维基百科的定义，消息引擎系统是一组规范。企业利用这组规范在不同系统之间传递语义准确的消息，实现松耦合的异步式数据传递。\n常见的官网不说人话系列，读起来云里雾里的。其实简单来说就是：系统 A 发送消息给消息引擎系统，系统 B 从消息引擎系统中读取 A 发送的消息。\n最基础的消息引擎就是做这点事的！不论是上面哪个版本，它们都提到了两个重要的事实：\n消息引擎传输的对象是消息； 如何传输消息属于消息引擎设计机制的一部分。 三、传输信息 既然消息引擎是用于在不同系统之间传输消息的，那么如何设计待传输消息的格式从来都是一等一的大事。试问一条消息如何做到信息表达业务语义而无歧义，同时它还要能最大限度地提供可重用性以及通用性？稍微停顿几秒去思考一下，如果是你，你要如何设计你的消息编码格式。\n一个比较容易想到的是使用已有的一些成熟解决方案，比如使用 CSV、XML 亦或是 JSON；又或者你可能熟知国外大厂开源的一些序列化框架，比如 Google 的 Protocol Buffer 或 Facebook 的 Thrift。这些方法借助开源框架实现都是不错的选择，那么像 Kafka 这种事如何实现的呢？答案是：它使用的是纯二进制的字节序列。当然消息还是结构化的，只是在使用之前都要将其转换成二进制的字节序列。\n消息设计出来之后还不够，消息引擎系统还要设定具体的传输协议，即用什么方法把消息传输出去。常见的有两种方法：\n点对点模型：也叫消息队列模型。说通俗点就是，系统 A 发送的消息只能被系统 B 接收，其他任何系统都不能读取 A 发送的消息。日常生活的例子比如电话客服就属于这种模型：同一个客户呼入电话只能被一位客服人员处理，第二个客服人员不能为该客户服务。 发布 / 订阅模型：与上面不同的是，它有一个主题（Topic）的概念，你可以理解成逻辑语义相近的消息容器。该模型也有发送方和接收方，只不过提法不同。发送方也称为发布者（Publisher），接收方称为订阅者（Subscriber）。和点对点模型不同的是，这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。生活中的报纸订阅就是一种典型的发布 / 订阅模型。 而像现在主流的 MQ 大部分都是同时支持这两种消息引擎模型。好了，现在我们了解了消息引擎系统是做什么的以及怎么做的，但还有个重要的问题是为什么要使用到这类框架呢？\n四、削峰填谷 写这篇博客的时候，我查询了很多资料和文献，最常见的就是这四个字。所谓的“削峰填谷”就是指缓冲上下游瞬时突发流量，使其更平滑。特别是对那种发送能力很强的上游系统，如果没有消息引擎的保护，“脆弱”的下游系统可能会直接被压垮导致全链路服务“雪崩”。但是，一旦有了消息引擎，它能够有效地对抗上游的流量冲击，真正做到将上游的“峰”填满到“谷”中，避免了流量的震荡。消息引擎系统的另一大好处在于发送方和接收方的松耦合，这也在一定程度上简化了应用的开发，减少了系统间不必要的交互。\n说了这么多，可能你对“削峰填谷”并没有太多直观的感受。接下来用 Kafka 举个例子来说明一下在这中间是怎么去“抗”峰值流量的吧。回想一下，你在某宝是如何购物的。看见想要的商品点击立即购买。之后会进入到付款页面。这个简单的步骤中就可能包含多个子服务，比如点击购买按钮会调用订单系统生成对应的订单，而处理该订单会依次调用下游的多个子系统服务 ，比如调用支付宝的接口，查询你的登录信息，验证商品信息等。显然上游的订单操作比较简单，它的 TPS 要远高于处理订单的下游服务，因此如果上下游系统直接对接，势必会出现下游服务无法及时处理上游订单从而造成订单堆积的情形。特别是当出现类似于秒杀这样的业务时，上游订单流量会瞬时增加，可能出现的结果就是直接压跨下游子系统服务。\n解决此问题的一个普通的做法是我们对上游系统进行限速，但这种做法对上游系统而言显然是不合理的，毕竟问题并不出现在它那里。所以更常见的办法是引入像 Kafka 这样的消息引擎系统来对抗这种上下游系统 TPS 的错配以及瞬时峰值流量。\n还是这个例子，当引入了 Kafka 之后。上游订单服务不再直接与下游子服务进行交互。当新订单生成后它仅仅是向 Kafka Broker 发送一条订单消息即可。类似地，下游的各个子服务订阅 Kafka 中的对应主题，并实时从该主题的各自分区（Partition）中获取到订单消息进行处理，从而实现了上游订单服务与下游订单处理服务的解耦。这样当出现秒杀业务时，Kafka 能够将瞬时增加的订单流量全部以消息形式保存在对应的主题中，既不影响上游服务的 TPS，同时也给下游子服务留出了充足的时间去消费它们。这就是 Kafka 这类消息引擎系统的最大意义所在。\n五、结束语 其实从广义上讲，消息引擎系统是有缓冲作用、具备类发布和订阅能力的存储引擎。关于 MQ 的演进，无论是从需求发展路径上看是：消息 —\u003e 流 —\u003e 消息和流融合，还是从架构发展角度的单机 —\u003e 分布式 —\u003e 云原生 /Serverless，本质上走的都是降低成本的方向。\n为了降低成本，弹性是最基础的要求。所以消息引擎系统在技术上，对计算弹性的需求提出了计算存储分离架构，对低存储成本的需求提出了分层存储的概念，对资源复用的需求提出了多租户的概念。\n为了吸引用户，现如今常见的消息引擎系统都在尽量提高自己的竞争力，围绕着功能、容灾、多架构、生态建设展开。\n不过要注意，消息和流只是业界的趋势，不是我们作为使用者必然的非此即彼的选择。在开发者实际使用的时候，我也发现很多人会将 Kafka 当做一个业务消息总线在用，也有人使用 RocketMQ 传递大流量的日志，当做大数据架构中的管道在用。\n所以要学会变通，学技术做框架没有现成的，更不会一成不变，要有敏锐的洞察力，才不会被淘汰。\n补充：什么是消息和流？\n消息，就是业务信息，在业务机构（比如微服务架构）中用来做信息传递，做系统的消息总线，比如用户提交订单的流程。 流，就是在大数据框架中用来做大流量时的数据削峰，比如日志的投递流转。 ","description":"","tags":null,"title":"MQ001——消息引擎系统入门篇","uri":"/tech/bigdata/bigdata_mq001/"},{"categories":null,"content":"Rust--02 ｜ 编程开发中，必须掌握的基本概念 牢骚话😩 上一讲我们了解了内存的基本运作方式，简单回顾一下：栈上存放的数据是静态的，固定大小，固定生命周期；堆上存放的数据是动态，不固定大小，不固定生命周期。\n这一讲，来梳理一下编程开发过程中一些常见的基础概念。按照习惯，我会将其分为四大类：数据（值和类型、指针和引用）、代码（函数、方法、闭包、接口和虚标）、运行方式（并发并行、同步异步和 Promise / async / await），以及编程范式（泛型编程）。\n有的时候，很多人都说在搞开发，写代码。从某种程度上来说确实如此。如果说，仅仅是把需求翻译成代码也算程序员的话，那么什么才是职业的程序员呢？？怎么做才是职业的程序员呢？？我的答案是从基础做起，夯实软件开发相关的基础知识，而 Rust 恰恰是可以从一定程度上反应程序员是否合格的标准，比如所有权、动态分派以及并发处理等。\n说了点废话，下面开始正片～～\n数据 数据是程序操作的对象，不进行数据处理的程序是没有意义的，我们先来重温和数据有关的概念，包括值和类型、指针和引用。\n值和类型 严谨地说，类型是对值的区分，它包含了值在内存中的长度、对齐以及值可以进行的操作等信息。一个值是符合一个特定类型的数据的某个实体。比如 64u8，它是 u8 类型，对应一个字节大小、取值范围在 0～255 的某个整数实体，这个实体是 64。\n值以类型规定的表达方式（representation）被存储成一组字节流进行访问。比如 64，存储在内存中的表现形式是 0x40，或者 0b 0100 0000。\n这里需要注意的是，值是无法脱离具体的类型讨论的。同样是内存中的一个字节 0x40，如果其类型是 ASCII char，那么其含义就不是 64，而是 @ 符号。\n不管是强类型的语言还是弱类型的语言，语言内部都有其类型的具体表述。一般而言，编程语言的类型可以分为原生类型和组合类型两大类。\n原生类型（primitive type）是编程语言提供的最基础的数据类型。比如字符、整数、浮点数、布尔值、数组（array）、元组（tuple）、指针、引用、函数、闭包等。所有原生类型的大小都是固定的，因此它们可以被分配到栈上。\n组合类型（composite type）或者说复合类型，是指由一组原生类型和其它类型组合而成的类型。组合类型也可以细分为两类：\n结构体（structure type）：多个类型组合在一起共同表达一个值的复杂数据结构。比如 Person 结构体，内部包含 name、age、email 等信息。用代数数据类型（algebraic data type）的说法，结构体是 product type。 标签联合（tagged union）：也叫不相交并集（disjoint union），可以存储一组不同但固定的类型中的某个类型的对象，具体是哪个类型由其标签决定。比如 Haskell 里的 Maybe 类型，或者 Swift 中的 Optional 就是标签联合。用代数数据类型的说法，标签联合是 sum type。 另外不少语言不支持标签联合，只取其标签部分，提供了枚举类型（enumerate）。枚举是标签联合的子类型，但功能比较弱，无法表达复杂的结构。\n指针和引用 在内存中，一个值被存储到内存中的某个位置，这个位置对应一个内存地址。而指针是一个持有内存地址的值，可以通过解引用（dereference）来访问它指向的内存地址，理论上可以解引用到任意数据类型。\n引用（reference）和指针非常类似，不同的是，引用的解引用访问是受限的，它只能解引用到它引用数据的类型，不能用作它用。比如，指向 42u8 这个值的一个引用，它解引用的时候只能使用 u8 数据类型。\n所以，指针的使用限制更少，但也会带来更多的危害。如果没有用正确的类型解引用一个指针，那么会引发各种各样的内存问题，造成系统崩溃或者潜在的安全漏洞。\n刚刚讲过，指针和引用是原生类型，它们可以分配在栈上。\n根据指向数据的不同，某些引用除了需要一个指针指向内存地址之外，还需要内存地址的长度和其它信息。\n如上一讲提到的指向 “hello world” 字符串的指针，还包含字符串长度和字符串的容量，一共使用了 3 个 word，在 64 位 CPU 下占用 24 个字节，这样比正常指针携带更多信息的指针，我们称之为胖指针（fat pointer）。很多数据结构的引用，内部都是由胖指针实现的。\n代码 数据是程序操作的对象，而代码是程序运行的主体，也是我们开发者把物理世界中的需求转换成数字世界中逻辑的载体。我们会讨论函数和闭包、接口和虚表。\n函数、方法和闭包 函数是编程语言的基本要素，它是对完成某个功能的一组相关语句和表达式的封装。函数也是对代码中重复行为的抽象。在现代编程语言中，函数往往是一等公民，这意味着函数可以作为参数传递，或者作为返回值返回，也可以作为复合类型中的一个组成部分。\n在面向对象的编程语言中，在类或者对象中定义的函数，被称为方法（method）。方法往往和对象的指针发生关系，比如 Python 对象的 self 引用，或者 Java 对象的 this 引用。\n而闭包是将函数或者说代码和其环境一起存储的一种数据结构。闭包引用的上下文中的自由变量，会被捕获到闭包的结构中，成为闭包类型的一部分。\n接口和虚表 接口是一个软件系统开发的核心部分，它反映了系统的设计者对系统的抽象理解。作为一个抽象层，接口将使用方和实现方隔离开来，使两者不直接有依赖关系，大大提高了复用性和扩展性。\n很多编程语言都有接口的概念，允许开发者面向接口设计，比如 Java 的 interface 和 Rust 的 trait 等。\n我们可以看一下如下场景：在 HTTP 中，Request/Response 的服务处理模型其实就是一个典型的接口，只需要按照服务接口定义出不同输入下，从 Request 到 Response 具体该如何映射，通过这个接口，系统就可以在合适的场景下，把符合要求的 Request 分派给对应的服务。\n面向接口的设计是软件开发中的重要能力，而 Rust 尤其重视接口的能力。当我们在运行期使用接口来引用具体类型的时候，代码就具备了运行时多态的能力。但是，在运行时，一旦使用了关于接口的引用，变量原本的类型被抹去，就无法单纯从一个指针分析出这个引用具备什么样的能力。\n因此，在生成这个引用的时候，我们需要构建胖指针，除了指向数据本身外，还需要指向一张覆盖了这个接口所支持方法的列表。这个列表，也就是所谓的虚表（virtual table）。\n由于虚表记录了数据能够执行的接口，所以在运行期，我们想对一个接口有不同实现，可以根据上下文动态分派。\n比如我想为一个编辑器的 Formatter 接口实现不同语言的格式化工具。我们可以在编辑器加载时，把所有支持的语言和其格式化工具放入一个哈希表中，哈希表的 key 为语言类型，value 为每种格式化工具 Formatter 接口的引用。这样，当用户在编辑器打开某个文件的时候，我们可以根据文件类型，找到对应 Formatter 的引用，来进行格式化操作。\n运行方式 程序在加载后，代码以何种方式运行，往往决定着程序的执行效率。所以我们接下来讨论并发、并行、同步、异步以及异步中的几个重要概念 Promise/async/await。\n并发（concurrency）和并行（parallel） 并发和并行是软件开发中经常遇到的概念。\n并发是同时与多件事情打交道的能力，比如系统可以在任务 A 做到一定程度后，保存该任务的上下文，挂起并切换到任务 B，然后过段时间再切换回任务 A。\n并行是同时处理多件事情的方式，也就是说，任务 A 和任务 B 可以在同一个时间下工作，无需上下文切换。\n并发是一种能力，而并行是一种手段。当系统拥有了并发的能力后，代码如果跑在多个 CPU core 上，就可以并行运行。所以我们平时都谈论高并发处理，而不会说高并行处理。\n同步和异步 同步是指一个任务开始执行后，后续的操作会阻塞，直到这个任务结束。在软件中，我们大部分的代码都是同步操作，比如 CPU，只有流水线中的前一条指令执行完成，才会执行下一条指令。一个函数 A 先后调用函数 B 和 C，也会执行完 B 之后才执行 C。同步执行保证了代码的因果关系（causality），是程序正确性的保证。然而在遭遇 I/O 处理时，高效 CPU 指令和低效 I/O 之间的巨大鸿沟，成为了软件的性能杀手。下图对比了 CPU、内存、I/O 设备、和网络的延迟：\n我们可以看到和内存访问相比，I/O 操作的访问速度低了两个数量级，一旦遇到 I/O 操作，CPU 就只能闲置来等待 I/O 设备运行完毕。因此，操作系统为应用程序提供了异步 I/O，让应用可以在当前 I/O 处理完毕之前，将 CPU 时间用作其它任务的处理。\n所以，异步是指一个任务开始执行后，与它没有因果关系的其它任务可以正常执行，不必等待前一个任务结束。\n在异步操作里，异步处理完成后的结果，一般用 Promise 来保存，它是一个对象，用来描述在未来的某个时刻才能获得的结果的值，一般存在三个状态：\n初始状态，Promise 还未运行； 等待（pending）状态，Promise 已运行，但还未结束； 结束状态， Promise 成功解析出一个值，或者执行失败。 如果你对 Promise 这个词不太熟悉，在很多支持异步的语言中，Promise 也叫 Future / Delay / Deferred 等。除了这个词以外，我们也经常看到 async/await 这对关键字。\n一般来说，async 定义了一个可以并发执行的任务，而 await 则触发了这个任务并发执行。大多数编程语言中，async/await 是一个语法糖（syntactic sugar），它使用状态机将 Promise 包装起来，让异步调用的使用感觉和同步调用非常类似，也让代码更容易阅读。\n编程范式 为了在不断迭代时，更好地维护代码，我们还会引入各种各样的编程范式，来提升代码的质量。所以最后来谈谈泛型编程。\n如果你来自于弱类型语言，如 C / Python / JavaScript，那泛型编程是你需要重点掌握的概念和技能。泛型编程包含两个层面，数据结构的泛型和使用泛型结构代码的泛型化。\n（强类型和弱类型的定义一直不太明确，wikipedia 上也没有一个标准的说法。。按照习惯一般是看类型在调用时是否会发生隐式转换，所以说 python 是弱类型。不过 wikipedia 在介绍 python 时确实说它是 strongly typed。但如果按照类型是否会隐式转换，Rust 是强类型，Python 和 C 是弱类型）\n数据结构的泛型 首先是数据结构的泛型，它也往往被称为参数类型或者参数多态，比如下面这个数据结构：\n1 2 3 4 struct Connection\u003cS\u003e { io: S. state: State, } 它有一个参数 S，其内部的域 io 的类型是 S，S 具体的类型只有在使用 Connection 的上下文中才得到绑定。\n可以把参数化数据结构理解成一个产生类型的函数，在“调用”时，它接受若干个使用了具体类型的参数，返回携带这些类型的类型。比如我们为 S 提供 TcpStream 这个类型，那么就产生 Connection这个类型，其中 io 的类型是 TcpStream。\n读到这里可能会产生疑惑，如果 S 可以是任意类型，那我们怎么知道 S 有什么行为？如果我们要调用 io.send() 发送数据，编译器怎么知道 S 包含这个方法？\n这是个好问题，我们需要用接口对 S 进行约束。所以我们经常看到，支持泛型编程的语言，会提供强大的接口编程能力，后续有时间可以聊聊 Rust 的 trait，再详细探讨这个问题。\n数据结构的泛型是一种高级抽象，就像我们人类用数字抽象具体事物的数量，又发明了代数来进一步抽象具体的数字一样。它带来的好处是我们可以延迟绑定，让数据结构的通用性更强，适用场合更广阔；也大大减少了代码的重复，提高了可维护性。\n代码的规范化 泛型编程的另一个层面是使用泛型结构后代码的泛型化。当我们使用泛型结构编写代码时，相关的代码也需要额外的抽象。\n这里用我们熟悉的二分查找的例子解释会比较清楚：\n左边用 C 撰写的二分查找，标记的几处操作隐含着和 int[] 有关，所以如果对不同的数据类型做二分查找，实现也要跟着改变。右边 C++ 的实现，对这些地方做了抽象，让我们可以用同一套代码二分查找迭代器（iterator）的数据类型。\n同样的，这样的代码可以在更广阔的场合使用，更简洁容易维护。\n小结 本节内容讨论了四类基本概念：数据、代码、运行方式和编程范式。\n值无法离开类型单独讨论，类型一般分为原生类型和组合类型。指针和引用都指向值的内存地址，只不过二者在解引用时的行为不一样。引用只能解引用到原来的数据类型，而指针没有这个限制，然而，不受约束的指针解引用，会带来内存安全方面的问题。\n函数是代码中重复行为的抽象，方法是对象内部定义的函数，而闭包是一种特殊的函数，它会捕获函数体内使用到的上下文中的自由变量，作为闭包成员的一部分。\n而接口将调用者和实现者隔离开，大大促进了代码的复用和扩展。面向接口编程可以让系统变得灵活，当使用接口去引用具体的类型时，就需要虚表来辅助运行时代码的执行。有了虚表，我们可以很方便地进行动态分派，它是运行时多态的基础。\n在代码的运行方式中，并发是并行的基础，是同时与多个任务打交道的能力；并行是并发的体现，是同时处理多个任务的手段。同步阻塞后续操作，异步允许后续操作。被广泛用于异步操作的 Promise 代表未来某个时刻会得到的结果，async/await 是 Promise 的封装，一般用状态机来实现。\n泛型编程通过参数化让数据结构像函数一样延迟绑定，提升其通用性，类型的参数可以用接口约束，使类型满足一定的行为，同时，在使用泛型结构时，我们的代码也需要更高的抽象度。\n","description":"","tags":null,"title":"Rust02——程序员的基本素养，编程必会的基础知识","uri":"/tech/rust/prepare/02_basic/"},{"categories":null,"content":"（电子）装备清单 本篇内容仅仅是从我个人的使用习惯以及日常的装备出发，来梳理一下各个装备分别起到什么作用。\n先简单过一遍有哪些电子设备：\niPad Air3 + Apple Pencil（ 入坑的产品） iPhone11（感觉还可以做几年钉子户） 联想小新 Pro13（Windows 主力本） MacBook Pro（M1 Pro 10+14 core，32 + 1T） Sony WF-1000XM4（降噪体验最好的耳机） Nintendo Switch OLED（能够捧在手里玩塞尔达还要啥自行车） 客制化键盘（哪个程序员还没折腾过键盘？？） 平板 从我的角度来说，iPad 可以说是果子最成功的电子产品。虽然最近几年国产的平板确实还不错，但总归来说还是有差距的。所以可以简单把平板归类为：iPad 和其他。\n谈谈当时为何选择 Air3。当时 19 年首发的时候，刚好大一下，凭借着自己的能力有一点点经济基础，作为计算机学生自然而然对电子设备比较感兴趣。那一年上半年，果子推出了 mini5 和 Air3 两款。一开始我比较想入的是 mini5，大小尺寸捧在手里刚刚好，可以当作 Kindle 来使用，而且看视频的话比手机屏幕大，理论上会更舒服。可一想到了 iPad 可以当生产力工具，如果再加上 pencil 平时上课出门就能够摆脱厚重的书本，岂不快哉。所以最好选择了 Air3。\n“买前生产力，买后爱奇艺“真的是这样吗？？其实不然。当时秉持着生产力的理念，不下任何一款游戏、任何一个娱乐视频播放器（B 站除外。。hh😅），比较好的一点就是这个习惯一直持续至今，包括手机也是。那么没有娱乐软件，都拿 iPad 做了些什么呢？\n19 年是自媒体行业相对而言比较火爆的一年，就想着能否使用 iPad 来尝试做图剪视频呢？当时 iPadOS 生态还不健全，Adobe 全家桶几乎就是不可用的状态，于是寻找平替产品，做图方面用的是 Affinity Photo 和 Affinity Design，虽然比不过 PhotoShop，但好在方便，基本的操作都能实现；视频的话就 LumaFusion，我愿称之为当时 iPad 上最强的视频剪辑软件。还有一些好用的软件例如 procreate 这类的，由于我天生手残，从小就讨厌上美术课，也画不出来什么东西，虽然软件很好用，但我太菜咯。。就没怎么用过。\n比较好的看书软件话，微信阅读倒是不错。19—20 年这两年，几乎都是以电子书为主的，很方便。其实一开始我不太想用这软件的，看这几年鹅厂作妖，无论是游戏还是产品做的都是什么垃圾，比较抵触的。后来使用下来的感觉就是“真香”！首先几乎白嫖就能有书读，这个对于中国的用户来说真的太友好了，谁愿意多花钱呢。。没啥广告，阅读页面比较整洁，可以结合自己的阅读习惯做一些相应的调整。而且还能画线标注重点。emmm，微信阅读也就成了我安利比较多的软件了 哈哈哈哈。\n上面提到了 B 站，是唯一一个视频软件，众所周知小破站是个学习软件 hhhh。平时看看纪录片、一些技术视频或者关注的 up 主都是不错的选择。B 站可以说是大学生获取信息的平台之一，很多第三方技能的学习都可以借此来完成。\n上面的这些内容，大部分操作没有 pencil 都可以完成，那多花六七百买的笔是不是智商税呢？？当然不是！！！Notablility 和 GoodNote5 就可以很好发挥 pencil 的作用。一开始重度使用的是 Notability，书写体验要好一点（个人主观感受）。可以选择直接新建一个文件，或者把课本导入再写写画画都是很方便的，还可以配合墨墨背单词来分屏使用。可它不做人，从买断制变成了按月付费，就无语。然后就果断弃坑转头入了 GoodNote5，后来习惯了，用起来区别也不是很大。\niPad 可以说是我最最喜欢的产品，可以说是大学时候的主力设备，也陪伴了我的成长，但当不再是学生的身份，iPad 变得似乎有些尴尬，所有码字的内容能放在电脑上，就不会放在 iPad 上，iPad 的输入体验是真的糟糕，在不外接键盘的情况下。pencil 能用到的地方也越来越少了。。现如今只能说变成了看论文，看视频的工具。这类内容放在手机上看太小，电脑又不够便携。iPad 也就成了“第三块屏幕”，看似没用，如果没有的话，会感觉少了点什么，仅仅是屏幕大小的不同，也就决定了产品定位。\n有想过换 iPad Pro，毕竟屏幕素质更好，而且还支持 ProMotion，但如果不再重度使用的话，Air3 就足够咯，那就这样吧。。\n手机 先如今，如果说最重要的电子设备肯定是手机，它是将用户和服务端连接起来的重要枢纽之一。\n之前我一直是重度安卓机用户，因为可以 root，能够随便倒腾。也可能是年纪大了，慢慢就折腾不动了，体验了 iPad 的优点之后，在下半年果子发新机的时候，就入了 iPhone11，其实如果再让我选的话，会直接入手 11Pro。11 拿在手里还是有点大了，后面出的 mini 机型续航跟不上，而且也只支持单卡，就不在考虑范围之内了。高刷也是挤牙膏到 13Pro 才有。所以手机对于我而言就是个工具，能用就行。\n换了 iPhone 之后最大的感觉就是不再在意各种参数了，因为够用。对，够用就行。很多时候是供应商强推一堆不必要的升级然后都去跟风生产，作为一名普通用户来说，并没有啥实质性的作用吧。所以如果现在这款机子电池续航能撑得住的话，会继续当钉子户。\n从我的使用来说，手机最大的作用无外乎以下几点：\n通信，这也是手机最原始的功能。但一般电脑在身边，方便的话像微信这类的就转到电脑上，解放了手机。（键盘打字更舒服，节约了手机拿起放下的时间成本）；\n购物，这一点手机还是比较方便的，涉及到安全性考虑，Web 端每次重新登录都要扫码重新验证，这一点就不如手机来的方便，而且包括物流查询等；\n支付手段，不知何时起开始习惯了移动端付款，又一次见了新版的人民币，下意识的认为这是不是假钱 哈哈哈，在国内还是很方便的，大环境在这摆着嘛，这也导致了花钱没感觉，就是个数字。。。包括出门坐地铁、公交之类的；\n听歌，出门的时候戴耳机，一般都是直接连接手机，因为方便嘛。\n拍照，emmm 不怎么拍照，但貌似所有的设备只有手机的拍照功能好一点，随手咔嚓一张咯，剩余靠自己做后期呗；\n碎片时间：大学的时候喜欢刷知乎，心里感觉要高级一点，后来发现与短视频都一样。现在的话，可能会看看公众号、掘金之类的吧，知乎、小红书需要查东西的会随手看一下啦。至于短视频、游戏这些，手机上是不会下这类软件的。\n所以说平时主要用到的这些功能，没必要换新机，再等等吧。只能说。。\nBTW，去年 14Pro 的“灵动岛”一开始使用挺惊艳，后来太突兀了，从产品来说就是用软件交互层面来掩盖硬件上的短板。等什么时候没有岛了再说吧。。。\n电脑 这毕竟是吃饭的家伙。\nWindows 本的话是联想的小新 Pro13，一般来说都是工模机，硬件方面动手能力强的话可以直接换，13 寸主打的就是便携。16G 运行内存，大部分开发都能做，甚至能跑三个小的虚拟机集群，知足吧。。\nmacOS 是 14 寸的 M1 Pro，32 + 1T，配置拉高一点，多撑几年吧，事实也的确如此，后续出的新机固然很牛掰，对于我这种非专业用户来说几乎没啥提升。无非就是用户体验上会好一丢丢？？\n为何搞两台？？emmmm...... 如果说 Windows 开发真的舒服的话，也不会折腾 macOS 了，还是类 unix 系统好用，之前一度想过把 Windows 本重新装个好看一点的 Linux，后来看了下各个软件的兼容性还是放弃了。。\n其实二者装的工具都差不太多，开发的话 IDEA、VSCode 都是必装的，其余的结合各个系统的特点来了。macOS 比较好的就是，高素质的屏幕支持高刷、出色的音效，最重要的是可以直接使用 cli，这对我来说是最方便的，需要一个可视化界面来使用 Chrome、微信以及音视频软件等，其余的操作例如服务的启动，文件管理这部分工作就可以使用 iTemr2 来完成。所以读到这的你如果有好看的壁纸请一定要推荐给我，用的还是默认的。。。有关 macOS 从开发的角度倒腾了哪些好玩的，等有时间单独分享一篇。至于 Windows 的话，就那回事，似乎没啥好说的。。\n之前上大学的时候，特别羡慕那些在星巴克喝着咖啡，用着 mac 的人，现如今看就是纯纯的社畜。。Windows 搞个主机用来打 3A 大作才是王道！\n耳机 耳机的话，还是推荐降噪，毕竟用过就回不去了。当时第一款降噪耳机是 AirPods Pro，不知是不是第一次戴降噪耳机，戴上之后整个世界都安静了！！！那种感觉是真的惊艳，无可替代！！！可惜的是，AirPods Pro 丢了。。。还是在图书馆丢的，给我难受了半个月。原以为图书馆里最起码都是有素质的人，看来并不是。。\n后来暑期首发入了 sony wf1000 xm4，价格有点小贵，谁知半年之后疯狂背刺，一点都不保值。。。但如果从综合的使用体验 xm4 绝对是最顶的，无论是降噪还是音质，大法毕竟是大法。有利就有弊，牺牲的用户的佩戴体验，耳塞戴上会胀满耳朵里，耳机的腔体偏大，长时间佩戴会有点不舒服，这一点不如苹果。\n后来入了 AirPods Pro2，但没有第一次佩戴 Pro 时候的感觉了。。\n游戏机 如果非要说在 PS5 和 Nintendo Switch OLED 选一个的话，我还是会选择 Switch，能够捧在手里玩游戏其他的还能说什么？工作或者学习一天，本来想打游戏解压一下，结果还需要正襟危坐是不是很难受！！所以嘛，虽然 ns 的性能不怎么好，但是能玩到一些高质量的游戏就可以呗。\n高中的时候喜欢打手游，高考结束之后突然顿悟感觉一点意思都没有，妥妥国内资本圈钱的手段罢了。后来上了大学四年，不能说一点游戏没玩过吧，加在一起不到一百个小时。由于 20 年初，疫情爆发，一款叫动森的游戏进入大众的视野，也就在那时突然觉得 switch 还挺有意思的，再加上想弥补小时候没有 PSP 的遗憾，就入了。\n在 ns 玩的第一款游戏是《怪物猎人：崛起》，第一次玩动作游戏，玩了几百个小时才明白这游戏是怎么玩的，太菜了😭。后面又入了野炊，可惜的是当时玩了五六个小时觉得无聊，就放下了。下一款投入时间玩的游戏应该就是《异度神剑 3》，Mio！！！也让我入了 JRPG 的坑。后面还有《P5R》（玩到现在还没通关，后期真的越玩越累，但又不想烂尾。。）今年春季赶上塞尔达季票打折，就入了大师模式，接触大师模式才感觉到乐趣。有限的资源，变强的怪物，还能回血，直接变成魂类游戏可还行 哈哈哈。《王国之泪》当然也首发入啦～～还有很多优秀的游戏，比如马里奥系列、宝可梦系列、《十三机兵》都是值得入的。\n玩 NS 的时候，然后感觉又回到了小时候，可以去做自己想做的事情，都说成年人的世界很累很糟糕，但如果有 switch 的陪伴呢？\n键盘 程序员的键盘一定要与众不同才叫帅！！但实际上没啥必要，平时码码字写写代码，搞个差不多的键盘就行，也可能是老了折腾不动了吧。小键的话 Box 白轴用起来还是挺舒服的，大键的话 看个人使用情况，键帽看见喜欢的或者打油了就换呗。。\n其实主力的电子设备就是电脑、手机、平板，决定它们实际用途除了系统不一样之后，更重要的是屏幕可交互的尺寸，今年 WWDC 看见有 Vision Pro 还是挺震撼的，期待“下一种”交互方式早点应用到生活之中。\n","description":"","tags":null,"title":"二夕的装备清单","uri":"/life/about_devices/"},{"categories":null,"content":"RUST--01 ｜ 内存：值，放在栈上还是堆上？？ 牢骚话 学习 Java、Python 或者 Scala 的时候，通常都会从最基本的语法讲起，为何谈起 Rust 却偏偏要从这些较为抽象的基础知识谈起呢？其实不然，从我自己的经历来说，吃过基础知识没学透，后期回来补课的痛苦。。。\n比如，以最基础的内存为例，很多人其实并没有搞懂什么时候数据应该放在栈上，什么时候应该在堆上，直到工作中实际出现问题了，才意识到数据的存放方式居然会严重影响并发安全，无奈回头重新补基础，时间精力的耗费都很大。\n作为一名开发者，会遇见很多工具、框架和语言，但这类东西无论怎么变，底层的逻辑都是通用的，正所谓“万变不离其宗”。\n在学习一门新的语言中，最基本的概念就是代码中的变量和值，而存放它们的地方是内存，那么你真的有了解过内存吗？？\n内存 从写代码开始，我们就无时无刻不和内存在打交道。比如下面这行代码：\n1 let s = \"hello world\".to_string(); 首先，“hello world” 作为一个字符串常量（string literal），在编译时被存入可执行文件的 .RODATA 段（GCC）或者 .RDATA 段（VC++），然后在程序加载时，获得一个固定的内存地址。当执行 “hello world”.to_string() 时，在堆上，一块新的内存被分配出来，并把 “hello world” 逐个字节拷贝过去。\n当我们把堆上的数据赋值给 s 时，s 作为分配在栈上的一个变量，它需要知道堆上内存的地址，另外由于堆上的数据大小不确定且可以增长，我们还需要知道它的长度以及它现在有多大。\n最终，为了表述这个字符串，我们使用了三个 word：\n第一个表示指针; 第二个表示字符串的当前长度（11）; 第三个表示这片内存的总容量（11）; 在 64 位系统下，三个 word 是 24 个字节。也可以看下图，更直观一些：\n刚才例子中的字符串的内容在堆上，而指向字符串的指针等信息在栈上，那么有个问题就是：数据什么时候可以放在栈上，什么时候需要放在堆上呢？\n这个问题也是比较考验程序员的基本功是否扎实的，很多使用自动内存管理语言比如 Java/Python 的开发者，可能有一些模糊的印象或者规则：\n基本类型（primitive type）存储在栈上，对象存储在堆上； 少量数据存储在栈上，大量的数据存储在堆上。 这么回答，虽然对，但并没有抓到实质。如果在工作中只背规则套公式，一遇到特殊情况就容易懵，但是如果明白公式背后的推导逻辑，即使忘了，也很快能通过简单思考找到答案，所以接下来我们深挖堆和栈的设计原理，看看它们到底是如何工作的。（btw 如果连公式都不会背的话 emmmm。。。。。dddd😁）\n栈 栈是程序运行的基础。每当一个函数被调用时，一块连续的内存就会在栈顶被分配出来，这块内存被称为帧（frame）。\n栈是自顶向下增长的，一个程序的调用栈最底部，除去入口帧（entry frame），就是 main() 函数对应的帧，而随着 main() 函数一层层调用，栈会一层层扩展；调用结束，栈又会一层层回溯，把内存释放回去。\n在调用的过程中，一个新的帧会分配足够的空间存储寄存器的上下文。在函数里使用到的通用寄存器会在栈保存一个副本，当这个函数调用结束，通过副本，可以恢复出原本的寄存器的上下文，就像什么都没有经历一样。此外，函数所需要使用到的局部变量，也都会在帧分配的时候被预留出来。\n整个过程可以再看看这张图辅助理解：\n那一个函数运行时，怎么确定究竟需要多大的帧呢？这要归功于编译器。在编译并优化代码的时候，一个函数就是一个最小的编译单元。\n在这个函数里，编译器得知道要用到哪些寄存器、栈上要放哪些局部变量，而这些都要在编译时确定。所以编译器就需要明确每个局部变量的大小，以便于预留空间。\n于是乎我们可以这么理解：在编译时，一切无法确定大小或者大小可以改变的数据，都无法安全地放在栈上，最好放在堆上。比如一个函数，参数是字符串：\n1 2 3 4 5 fn say_name(name: String) {} // 调用 say_name(\"Lindsey\".to_string()); say_name(\"Rosie\".to_string()); 字符串的数据结构，在编译时大小不确定，运行时执行到具体的代码才知道大小。比如上面的代码，“Lindsey” 和 “Rosie” 的长度不一样，say_name() 函数只有在运行的时候，才知道参数的具体的长度。所以，我们无法把字符串本身放在栈上，只能先将其放在堆上，然后在栈上分配对应的指针，引用堆上的内存。\n放在栈上的问题 从刚才的图中也可以直观看到，栈上的内存分配是非常高效的。只需要改动栈指针（stack pointer），就可以预留相应的空间；把栈指针改动回来，预留的空间又会被释放掉。预留和释放只是动动寄存器，不涉及额外计算、不涉及系统调用，因而效率很高。\n所以理论上说，只要可能，我们应该把变量分配到栈上，这样可以达到更好的运行速度。那为什么在实际工作中，我们又要避免把大量的数据分配在栈上呢？这主要是考虑到调用栈的大小，避免栈溢出（stack overflow）。\n一旦当前程序的调用栈超出了系统允许的最大栈空间，无法创建新的帧，来运行下一个要执行的函数，就会发生栈溢出，这时程序会被系统终止，产生崩溃信息。过大的栈内存分配是导致栈溢出的原因之一，更广为人知的原因是递归函数没有妥善终止。一个递归函数会不断调用自己，每次调用都会形成一个新的帧，如果递归函数无法终止，最终就会导致栈溢出。\n堆 栈虽然使用起来很高效，但它的局限也显而易见。当需要动态大小的内存时，只能使用堆，比如可变长度的数组、列表、哈希表、字典，它们都分配在堆上。\n堆上分配内存时，一般都会预留一些空间，这是最佳实践。比如你创建一个列表，并往里添加两个值：\n1 2 3 let mut arr = Vec::new(); arr.push(1); arr.push(2); 这个列表实际预留的大小是 4，并不等于其长度 2。这是因为堆上内存分配会使用 libc 提供的 malloc() 函数，其内部会请求操作系统的系统调用，来分配内存。系统调用的代价是昂贵的，所以要避免频繁地 malloc()。\n对上面的代码来说，如果说需要多少就分配多少，那列表每次新增值，都要新分配一大块的内存，先拷贝已有数据，再把新的值添加进去，最后释放旧的内存，这样效率很低。所以在堆内存分配时，预留的空间大小 4 会大于需要的实际大小 2 。\n除了动态大小的内存需要被分配到堆上外，动态生命周期的内存也需要分配到堆上。\n上文中我们讲到，栈上的内存在函数调用结束之后，所使用的帧被回收，相关变量对应的内存也都被回收待用。所以栈上内存的生命周期是不受开发者控制的，并且局限在当前调用栈。而堆上分配出来的每一块内存需要显式地释放，这就使堆上内存有更加灵活的生命周期，可以在不同的调用栈之间共享数据。\n放在堆上的问题 然而，堆内存的这种灵活性也给内存管理带来很多挑战。\n如果手工管理堆内存的话，堆上内存分配后忘记释放，就会造成内存泄漏。一旦有内存泄漏，程序运行得越久，就越吃内存，最终会因为占满内存而被操作系统终止运行。\n如果堆上内存被多个线程的调用栈引用，该内存的改动要特别小心，需要加锁以独占访问，来避免潜在的问题。比如说，一个线程在遍历列表，而另一个线程在释放列表中的某一项，就可能访问野指针，导致堆越界（heap out of bounds）。而堆越界是第一大内存安全问题。\n如果堆上内存被释放，但栈上指向堆上内存的相应指针没有被清空，就有可能发生使用已释放内存（use after free）的情况，程序轻则崩溃，重则隐含安全隐患。根据微软安全反应中心（MSRC）的研究，这是第二大内存安全问题。\n小结 对于存入栈上的值，它的大小在编译期就需要确定。栈上存储的变量生命周期在当前调用栈的作用域内，无法跨调用栈引用。\n堆可以存入大小未知或者动态伸缩的数据类型。堆上存储的变量，其生命周期从分配后开始，一直到释放时才结束，因此堆上的变量允许在多个调用栈之间引用。但也导致堆变量的管理非常复杂，手工管理会引发很多内存安全性问题，而自动管理，无论是 GC 还是 ARC，都有性能损耗和其它问题。\n一句话对比总结就是：栈上存放的数据是静态的，固定大小，固定生命周期；堆上存放的数据是动态的，不固定大小，不固定生命周期。\n","description":"","tags":null,"title":"Rust01——内存：栈与堆？？","uri":"/tech/rust/prepare/01_memory/"},{"categories":null,"content":"给姐姐，写在你出嫁之后 总想写些什么，但又不知该如何下笔，作为弟弟，本应该为你出嫁感到快乐、开心，结果却往往事与愿违。我也不知为何会这样，或许是不舍，或许是焦虑，更多的也许是说不清楚。\n不舍的是，这么多年，从我出生到现在，在家里就有你的陪伴，出嫁之后，家里只剩我和父母，总感觉少了一份温暖。你是否还记得，在我快要高考的时候，有一段时间各方面都很低落，不知该如何是好，面对父母的不理解，自己的迷茫不知所措，还好有你。当时我就说，咱爸妈做的最正确的事情，就是把你生在了我前面。。但有时候就会设想，如果咱俩换一下呢？？或许，关系可能会更糟糕吧。我可能会处处管着你，让你好好学习看书，还可能会强制给你灌输我的价值观，让你变得不像你自己。。但好在，这一切也都只是假如。对于姐姐这个身份，从我的角度来说看你是满分的，我时常和爸妈说，有个贴心的姐姐确实舒服，自己不用操心各种生活的琐事，无论什么事情都有你为我考虑在前。咱爸妈经常说，我俩上学属于比较省心的，那是因为你比我大，小时候每天上学放学能够和你在一起，因为你的不哭不闹，然后意识到作为一名学生这是最基本的也是应该的，一切都是在你影响下的模仿罢了。也正因为你比我早读了几年书，每当小学周末老师布置了大把的作业，因为贪玩而写不完的时候，总会缠着你帮我写 哈哈哈。可，随着时间的推移，我俩慢慢长大了，从中学到大学，渐行渐远，由于你理科不好，再也没人能够帮我偷懒了，慢慢的，我也只能靠自己。\n很多人都说咱爸妈这二十多年混得不太行，也没啥大出息，emmm 怎么说呢，从某一方面来说确实是的。那是因为除了我俩，他们也没啥好骄傲的了。由于出生在农村，周围很多家庭的父母，对于教育都不太注重，很多亲戚邻居家的孩子，都早早辍学打工，甚至有些思想比较极端的人认为，女孩子读那么多书干什么，最后不还是要嫁给人家。不能说这种人不对，在他们的眼光中，他们也只能活在这种环境中。也许是因为受到舅舅家各位哥哥姐姐的原因，小时候每次去姥姥家那边，都会给我俩进行一顿思想灌输，说谁谁谁怎么怎么样考上大学，由此来教育，让我们好好学习。说实话，当时的内心想的也就那回事，在我看来，那只不过是到了一定年龄段，做了该做的事情。后来实际会发现，学习如逆水行舟，不进则退。值得庆幸的是，你成为了家里第一个全日制的本科生。16 年，你高考，送你去考场，看着你走进考场，我的内心比我后来高考都紧张，因为不确定性太大了。怕你考不上大学，下一步该怎么走？？可能也正是因为你的“忽忽悠悠“，从出成绩，到填志愿，最后录取，都比我要顺利的多。这也许求而不得，往往不求而得吧。有时候我都羡慕甚至嫉妒你，我花了几倍的功夫做到的事情，你往往漫不经心的就完成了。\n当你上了大学，也算是第一步远离了生活长大的城市。当时我上高中，特别羡慕上大学的你。就会想自己啥时候才能熬到啊。高中的时候，可能由于是叛逆期吧，经常你回家就和你闹矛盾，不知道你还记不记得。其实，初中的时候也有好几次，现在回头想想还真是黑历史。。hhhh 但也许是出于对你的依赖，也知道你会无限的包容我才会这样。到后来，我上大学之后，慢慢体会到一个人在陌生环境的不容易，也读了很多书。那个阶段，脑子也逐渐开窍，开始慢慢承担起自己的责任，我俩之间也由你照顾我，变成我谦让着你。也好像是从那时候开始，在爸妈眼中，我似乎变得比你要懂事，更独立。如果可以的话，我不想这样。。一点都不想 真的。。近几年这样过度的由着你你任性，也造就了你的脾气比较大。但不在家人身边，又有谁会真心让着你呢\n焦虑的是，当你真正变成妻子的身份，在他们家过得到底是不是自己所期望的那样。大学毕业之后，赶上疫情，比较好的是，你当时找到了工作，不用像大部分应届生那样忙得焦头烂耳。有时候，我就觉得父母喜欢瞎操心，刚刚大学毕业就着急你以后的未来，很没必要。我之前对你说过，如果你不想结婚，过年回老家怕被所谓的亲戚说三道四，我直接给你钱出去旅游，别受这气。比较可惜的是，我这钱没花出去 hhhh。\n当时你说李双双也是写代码的，顿时我的好感度就上来了，最起码来说，写代码的人都比较单纯简单，除了追求技术，对于其余的事情都不大感兴趣，也就不会搞那些花里胡哨的。他追你时候的表现确实值得表扬，刚开始我还担心他和我一样是个钢铁直男，不会讨你欢心，纯粹是我多虑了。相处了快到一年的时候，你们订婚了，从我的角度来看，速度或许有些太快了，因为紧接着的就是结婚。如果不是因为疫情，去年你就是他的妻子。去年疫情刚解封你去了他那边，还是比较好的，因为谁也不知道之后上海还会搞成什么样子。可能是距离产生美吧，当你们异地的时候，不会感觉到他的不好，但两个人同居，都有了自己的工作，那么生活中的小事到底谁负责呢？他是个典型的大男子主义，家务活不知道做，不会烧饭，而且还比较懒。这么一弄，家务活自然而然就落到你头上了。但我看来是不应该的，最起码从我的角度来说，作为一个男人就应该多承担点，如果真心喜欢一个女生，是需要细心呵护，爱情是靠两个人共同经营，而不是单方面付出的。就这样对他的印象分，也就逐渐下降。甚至我和你说过好几次，如果两个人真的磨合不来，他还是那屌样子，就算了吧，没必要受他一辈子气。这个时候的他和当时追你完全是两个样子。每次和你联系，都觉得你在那边过得好累，没有那个时候在家自由。但也许这就是生活吧，总归是要和现实和解的。\n当然，也不能站在我的角度来片面地看待他，他也不是全都缺点，毕竟他自己都夸自己优秀嘛。让我感到比较欣慰的是，去年年底，由于疫情的全面放开，谁到抵挡不住会感染。你成为家里第一个阳的，而且还不在身边，对你的担忧也就多了。我愿意按他惜命的性格，有可能连家都不会回，事实证明他还是不错的，得知你阳了，放下手边的工作，急匆匆地赶了回家照顾你。从这一点可以看出，他还是很在乎你的，也值得把你托付给他。如果在生活中，他能够考虑的更周到一点，更能为你着想一点，能够自觉地承担起自己的责任和义务，那就更好了。希望婚后，他可以做到。他是有自己的想法，但却不能付诸实践，现如今的生活形形色色的诱惑太多，一不小心就会迷失自我，作为年轻人，要学会静下自己的心，去好好思考，去努力，去寻找自身的价值所在。也可能我本身就是做技术的，关于互联网的诱惑都会刻意屏蔽，所以对我来说也就是个工具，不会浪费太多时间在上面。现如今的社会，是一个即将崩坏的形态，虚拟和现实相碰撞，有的人追求华丽的形式，有的人为了名利迷失了自我，更多的人都是随波逐流，无法思考。希望你俩以后也多投入时间在现实生活中，尽量过得简单一点，多读书！\n为何会说不清楚呢？？我想谈谈现如今的你。作为弟弟，我一直都认为对你很熟悉，但当你在那边过了快一年，恍惚变了一个人似的，我不知为何你会变成这样，身上的戾气有点重。。。\n生活，平平淡淡是常态，有不顺心的时候，也总有好的时候。不要因为暂时的不如意而感到烦恼，也不要想着为了未来怎么样怎么样而陷入精神内耗，要学会和自己和解，和周围的一切和解，但看待生活的心态变了，生活也会随之而改变。至少目前来看，我是一个挺”佛“的人，不为世事所动，也没啥太大的兴趣，自然就少了很多烦恼，但也不会有开心的感觉，所以也好也不好。你可别学我。我还是想让你开心一点的。在那边，嫁給他，就是他家人了。话语权方面，我也希望你能够做到独当一面，要沉得住气，不要因为一点小事而哭鼻子。最好是，也不要计较那么多，为了一群傻缺把自己气到不值得。当你把自己的认知提升到一定的高度，看他们做的很多事都很无聊，所以真的没必要。人总是复杂的，不能说某一个时间段对你好，他就是好人，反之他就不好。如果能处得来就更好不过，处不来也别强求自己委屈求全。我还是希望你在那边能开开心心、快快乐乐的。\n最后，如果说最近的开心事的话，那就是你说我快要当舅舅了。看到这个消息，我先是一愣，没反应过来，脑子差点宕机，总觉得有些突然。如果说对他/她 有什么期待的话，最好是能够像他/她舅舅，也就是我。哈哈哈哈~~也希望我能够以身作则，起到一个好的榜样的作用。希望他/她出生之后， 你们别给太大的压力，能够养成自己的思想，有独立的人格，不要把父母的期望和遗憾过度的强加给孩子。至于功名利禄放一边吧。这一点，我相信你能够做到的，而且做的比我好。\n罗里吧嗦，写了一堆废话，简单来说，我希望你俩有时间的话，多回家看看，仅此而已。\n","description":"","tags":null,"title":"给姐姐，写在你出嫁之后","uri":"/life/to_my_sister/"},{"categories":null,"content":"Q2 季度小结 绩效拿了全组最高耶～～\n","description":"","tags":null,"title":"Hello LQ","uri":"/life/work001/"},{"categories":null,"content":"遇见问题？？ 这两天在折腾一个数仓测试环境的迁移，MySQL 自然是必不可少缺少的咯，因为是测试环境，配置都是按最方便的来做，配置过程可参考：MySQL 安装\n前一天使用都是正常的，结果第二天不知什么原因，在使用 Maxwell 进行增量同步业务数据到 HDFS 过程中，爆出以下错误：java.sql.SQLException: Access denied for user 'root'@'aliyun001' (using password: YES) 这是一个常见的错误，遇到好几次，所以记录以下。\n解决？？？ 遇到该问题，立刻就尝试使用mysql -u root -p来登录数据库看看，结果仍然报错，同上。这时意识到数据库是进不去了。。。\n于是乎，可以先设置跳过密码：\n1 2 vim /etc/my.cnf skip-grant-tables #在[mysqld]下面添加这一行，忽略权限表 重启 MySQL：sudo systemctl restart mysqld.service\n进入之后选择 use mysql，然后 select user, host from user; 出现的结果令人惊讶！！！没有 root 用户了？？？没有就自己造一个！！！\n养成好习惯先刷新一下：flush privileges;\n创建create user 'root'@'localhost' identified by '123456';，然后报错：ERROR 1396 (HY000): Operation CREATE USER failed for 'root'@'localhost'，估计应该是没删干净？？再删一下：drop user root@'localhost';，刷新一下；这个时候再创建就 ok 了~~\n有了 root 用户之后，再给权限：mysql\u003e GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' WITH GRANT OPTION; #赋予所有库所有表操作权限；刷新一下~~\n再回到 /etc/my.cnf 删除 skip-grant-tables。重启数据库，这个时候就可以正常使用了~~\n如果为了方便还可以再设置一下 host 为 %：update user set host=\"%\" where user=\"root\";\n","description":"","tags":null,"title":"MySQL——Access denied for user 'root'@'localhost' (using password: YES) 问题解决","uri":"/tech/mysql_access_problem/"},{"categories":null,"content":"Windows 配置 Scala 开发环境 零、前言 谈起现如今的大数据开发框架，那么 Spark 想必是众所周知的。而 Spark 就是使用 Scala 语言编写的。所以问题来了，该如何配置一套 Scala 的环境呢？\n其实，有了 Java 的底子之后，配置一套 Scala 开发环境并不是很难，因为 Scala 一门以 JVM 为运行环境并将面向对象和函数式编程的最佳特性结合在一起的 静态类型编程语言，支持面向对象和函数式编程。\n一、Scala 环境搭建 前文提到，Scala 是运行在 JVM 上的，所以首先先保证开发环境已经配置了 JDK，这里不做过多赘述。（我使用的 JDK1.8）\n1.下载所需要的 Scala 版本，download；\n2.将下载好的 zip 文件压解至无中文的目录下，最好也不要有空格；\n3.打开 Windows 的系统属性中的环境变量，配置 Scala 的环境变量：SCALA_HOME 以及所属目录：D:\\DevelopmentTool\\scala-2.12.11\n配置 path 路径，将 bin 目录添加至系统环境 %SCALA_HOME%\\bin\n4.测试\n打开 terminal 终端，输入 scala 出现如下图所示表示配置好环境~~\n二、在 IDEA 中配置 Scala 开发环境 IDEA 懂的都懂 好用就完事了！！！下面将演示如何在 IDEA 集成 Scala 开发环境。\n1.在 Setting 的 plugins 中搜素 Scala -\u003e点击 Install-\u003e点击 ok-\u003e点击 apply，重启 IDEA；\n2.创建一个 projet，默认是不支持 Scala 的开发。需要手动引入 Scala 框架，在项目上，点击右键-\u003e Add Framework Support... -\u003e选择 Scala-\u003e点击 OK。\n注意：如果是第一次引入框架，Use libary 看不到，需要选择你的 Scala 安装目录，然后工具就会自动识别，就会显示 user libary。\n3.测试\n以上我们已经完成了 Scala 的开发环境，可以完成一些基础的相关。\n三、配置 Spark 开发环境 1.创建 Spark 项目，添加相关依赖：\n\u003cdependency\u003e \u003cgroupId\u003eorg.apache.spark\u003c/groupId\u003e \u003cartifactId\u003espark-core_2.12\u003c/artifactId\u003e \u003cversion\u003e3.0.0\u003c/version\u003e \u003c/dependency\u003e 添加依赖之后，就可以使用 Spark 相关的 API，但是在运行过程中，控制台可以会出现一些神奇的错误，如下所示：\nERROR Shell: Failed to locate the winutils binary in the hadoop binary path java.io.IOException: Could not locate executable null\\bin\\winutils.exe in the Hadoop binaries. at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:382) at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:397) at org.apache.hadoop.util.Shell.\u003cclinit\u003e(Shell.java:390) at org.apache.hadoop.util.StringUtils.\u003cclinit\u003e(StringUtils.java:80) at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:611) at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:274) at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:262) at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:807) at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:777) at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:650) at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2412) at scala.Option.getOrElse(Option.scala:189) at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2412) at org.apache.spark.SparkContext.\u003cinit\u003e(SparkContext.scala:303) at org.erxi.spark.core.rdd.operator.transform.AdClickCount$.main(AdClickCount.scala:8) at org.erxi.spark.core.rdd.operator.transform.AdClickCount.main(AdClickCount.scala) 这是因为在程序中使用了 Hadoop 相关的内容，比如写入文件到 HDFS。出现这个问题并不是程序的错误，而是windows 系统用到了 hadoop 相关的服务，解决办法是通过配置关联到 windows 的系统依赖就可以了。\n2.解决异常 安装 Spark：到官网 https://spark.apache.org/downloads.html 选择合适的版本下载，注意 Spark 与Hadoop 版本选择要相对应，建议下载预编译（Pre-built）好的版本，省得麻烦。解压文件，然后与配置 Scala 环境类似配置对应的 SPARK_HOME 与 path 变量 %SPARK_HOME%\\bin;\n安装 Hadoop：到官网 https://hadoop.apache.org/releases.html 下载与上边的 Spark 对应的版本。后与配置 Scala 环境类似配置对应的 HADOOP_HOME 与 path 变量 %HADOOP_HOME%\\bin。\n除此之外，还需要到这里 https://github.com/cdarlint/winutils 下载对应版本的 bin 目录中的 hadoop.dll 和 winutils.exe，复制到 hadoop 目录的 bin 目录下。\n完成上述操作之后，已经在 Windows 环境下搭建了可用于测试的 Spark 环境和 Hadoop 环境。最后还需要再 IDEA 中导入一下 HADOOP_HOME，这样运行程序就不会报错啦~~\n在 IDEA 中配置 Run Configuration，添加 HADOOP_HOME 变量：\n","description":"","tags":null,"title":"Windows 配置 Scala 开发环境","uri":"/tech/bigdata/scala/"},{"categories":null,"content":"标题写在变“羊”之前 占个坑 按照目前国内的这个趋势 躲得过初一 能躲得过十五嘛？？？？？？？？？\n","description":"","tags":null,"title":"标题写在我变“🐑”之前","uri":"/life/covid-19/"},{"categories":null,"content":"单例模式 为什么使用单例模式？ 单例设计模式：一个类只允许创建一个对象（或者实例），那么这个类就是一个单例类，这种设计模式就叫做单例设计模式，简称单例模式。\n单例模式的概念并不是很难，一看就能明白。接下来我们思考一下，为什么需要单例这种设计模式？它能解决哪些问题？\n实战案例：处理资源访问冲突 咱们先来看第一个例子。该例子中，我们自定义实现了一个往文件中打印日志的 Logger 类。具体的实现代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class Logger { private FileWriter writer; public Logger() { File file = new File(\"/Users/zhangsan/log.txt\"); writer = new FileWriter(file, true); // true表示追加写入 } public void log(String message) { writer.write(message); } } // Logger类的应用示例： public class UserController { private Logger logger = new Logger(); public void login(String username, String password) { // ...省略业务逻辑代码... logger.log(username + \" logined!\"); } } public class OrderController { private Logger logger = new Logger(); public void create(OrderVo order) { // ...省略业务逻辑代码... logger.log(\"Created an order: \" + order.toString()); } } 上述代码的功能并不是很复杂，但请停下来思考一下，这段代码存在什么问题。\n细心的同学可能已经注意到了，所有的日子都写入到同一个文件 /Users/zhangsan/log.txt 中。在 UserController 和 OrderController 中，分别创建了两个 Logger 对象。在 Web 容器的 Servlet 多线程环境下，如果两个 Servlet 线程同时分别执行 login() 和 create() 两个函数，并且同时写日子到 log.txt 文件中，那么就有可能存在日子信息相互覆盖的情况。\n为什么会出现相互覆盖呢？可以这样类比着理解。在多线程环境下，如果两个线程同时给同一个共享变量加 1，因为共享变量是竞争资源，所以，共享变量最后的结果有可能并不是加 2，而是只加了 1。同理，这里的 log.txt 文件也是竞争资源，两个线程同时往里面写数据，就有可能会存在相互覆盖的情况。\n那么该如何来解决和这个问题呢？通常的思路应该是加锁：给 log() 函数加互斥锁（Java 中可以通过 synchronized 的关键字），同一时刻只允许一个线程调用 log() 函数。具体的代码实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Logger { private FileWriter writer; public Logger() { File file = new File(\"/Users/zhangsan/log.txt\"); writer = new FileWriter(file, true); // true表示追加写入 } public void log(String message) { synchronized(this) { writer.write(mesasge); } } } 不过，仔细思考一下，这真的能解决多线程写入日志时相互覆盖的问题吗？答案是否定的！这是因为这种锁是一个对象级别的锁，一个对象在不同的线程下同时调用 log() 函数，会被强制要求顺序执行。但是，不同的对象之间并不能共享同一把锁。在不同的线程下，通过不同的对象调用执行 log() 函数，锁并不会起作用，任然有可能存在写入日志相互覆盖的问题。\n这里稍微补充一下，在刚刚的讲解和给出代码的中，故意“隐藏”了一个事实：我们给 log() 函数加不加对象级别的锁，其实都没有关系。因为 FileWriter 本身就是现场安全的，它的内部实现中本身就假了对象级别的锁，因此，在外层调用 write() 函数的时候，再加对象级别的锁实际上是多此一举。因为不同的 Logger 对象不共享 FileWriter 对象，所以 FileWriter 对象级别的锁也解决不了数据写入相互覆盖的问题。\n那么问题来了，该如何解决呢？实际上，要解决这个问题并不是很难。我们只需要吧对象级别的锁换成类级别的锁就可以了。让所有的对象都共享同一把锁。这样就避免了不同对象之间同时调用 log() 函数，而导致的日志覆盖的问题。具体的代码实现如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Logger { private FileWriter writer; public Logger() { File file = new File(\"/Users/zhangsan/log.txt\"); writer = new FileWriter(file, true); // true表示追加写入 } public void log(String message) { synchronized(Logger.class) { // 类级别的锁 writer.write(mesasge); } } } 除了使用类级别锁之外，实际上，解决资源竞争问题的办法还有很多，分布式锁是最常听到的一种解决方案。不过，实现一个安全可靠、无 bug、高性能的分布式锁，并不是件容易的事情。除此之外，并发队列（比如 Java 中的 BlockingQueue）也可以解决这个问题：多个线程同时往并发队列里写日志，一个单独的线程负责将并发队列中的数据，写入到日志文件。这种方式实现起来也稍微有点复杂。\n相对于这两种解决方案，单例模式的解决思路就简单一些了。单例模式相对于之前类级别锁的好处是，不用创建那么多 Logger 对象，一方面节省内存空间，另一方面节省系统文件句柄（对于操作系统来说，文件句柄也是一种资源，不能随便浪费）。\n我们将 Logger 设计成一个单例类，程序中只允许创建一个 Logger 对象，所有的线程共享使用的这一个 Logger 对象，共享一个 FileWriter 对象，而 FileWriter 本身是对象级别线程安全的，也就避免了多线程情况下写日志会互相覆盖的问题。\n按照这个设计思路，我们实现了 Logger 单例类。具体代码如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class Logger { private FileWriter writer; private static final Logger instance = new Logger(); private Logger() { File file = new File(\"/Users/shangsan/log.txt\"); writer = new FileWriter(file, true); // true表示追加写入 } public static Logger getInstance() { return instance; } public void log(String message) { writer.write(mesasge); } } // Logger类的应用示例： public class UserController { public void login(String username, String password) { // ...省略业务逻辑代码... Logger.getInstance().log(username + \" logined!\"); } } public class OrderController { public void create(OrderVo order) { // ...省略业务逻辑代码... Logger.getInstance().log(\"Created a order: \" + order.toString()); } } 实战案例二：表示全局唯一类 从业务概念上，如果有些数据在系统中只应保持一份，那就适合设计为单例类。\n比如，配置信息类。在系统中，我们只有一个配置文件，当配置文件被加载到内存后，以对象的形式存在，也理所应当只有一份。\n再比如，唯一递增 ID 号码生成器，如果程序中有两个对象，就会存在生成重复 ID 的情况，所以我们应该将 ID 生成器类设计为单例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import java.util.concurrent.atomic.AtomicLong; public class IdGenerator { // AtomicLong 是一个 Java 并发库中提供的一个原子变量类型, // 它将一些线程不安全需要加锁的复合操作封装为了线程安全的原子操作， // 比如下面会用到的 incrementAndGet(). private AtomicLong id = new AtomicLong(0); private static final IdGenerator instance = new IdGenerator(); private IdGenerator() {} public static IdGenerator getInstance() { return instance; } public long getId() { return id.incrementAndGet(); } } // IdGenerator 使用举例 long id = IdGenerator.getInstance().getId(); 如何实现一个单例？ 概括起来，要实现一个单例，我们需要关注的无外乎下面几个：\n构造函数需要是 private 访问权限的，这样才能避免外部通过 new 创建实例； 考虑对象创建时的线程安全问题； 考虑是否支持延迟加载； 考虑 getInstance() 是否加锁（性能是否高）。 1. 饿汉式 饿汉式的实现方式比较简单。在类加载的时候，instance 静态实例就已经创建并初始化好了，所以 instance 实例的创建过程是线程安全的。不过，这样的实现方式不支持延迟加载（在真正用到 IdGenerator 的时候，再创建实例），从名字中我们也可以看出这一点。具体的代码实现如下所示：\n1 2 3 4 5 6 7 8 9 10 11 public class IdGenerator { private AtomicLong id = new AtomicLong(0); private static final IdGenerator instance = new IdGenerator(); private IdGenerator() {} public static IdGenerator getInstance() { return instance; } public long getId() { return id.incrementAndGet(); } } 有人觉得这种实现方式不好，因为不支持延迟加载，如果实例占用资源多（比如占用内存多）或初始化耗时长（比如需要加载各种配置文件），提前初始化实例是一种浪费资源的行为。最好的方法应该在用到的时候再去初始化。不过，从我的角度来说，并不是很认同这种观点。\n如果初始化耗时长，那我们最好不要等到真正要用它的时候，才去执行这个耗时长的初始化过程，这会影响到系统的性能（比如，在响应客户端接口请求的时候，做这个初始化操作，会导致此请求的响应时间变长，甚至超时）。采用饿汉式实现方式，将耗时的初始化操作，提前到程序启动的时候完成，这样就能避免在程序运行的时候，再去初始化导致的性能问题。\n如果实例占用资源多，按照 fail-fast 的设计原则（有问题及早暴露），那我们也希望在程序启动时就将这个实例初始化好。如果资源不够，就会在程序启动的时候触发报错（比如 Java 中的 PermGen Space OOM），我们可以立即去修复。这样也能避免在程序运行一段时间后，突然因为初始化这个实例占用资源过多，导致系统崩溃，影响系统的可用性。\n2. 懒汉式 有饿汉式，对应的，就有懒汉式。懒汉式相对于饿汉式的优势是支持延迟加载。具体的代码实现如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class IdGenerator { private AtomicLong id = new AtomicLong(0); private static IdGenerator instance; private IdGenerator() {} public static synchronized IdGenerator getInstance() { if (instance == null) { instance = new IdGenerator(); } return instance; } public long getId() { return id.incrementAndGet(); } } 不过懒汉式的缺点也很明显，我们给 getInstance() 这个方法加了一把大锁（synchronzed），导致这个函数的并发度很低。量化一下的话，并发度是 1，也就相当于串行操作了。而这个函数是在单例使用期间，一直会被调用。如果这个单例类偶尔会被用到，那这种实现方式还可以接受。但是，如果频繁地用到，那频繁加锁、释放锁及并发度低等问题，会导致性能瓶颈，这种实现方式就不可取了。\n3. 双重检测 饿汉式不支持延迟加载，懒汉式有性能问题，不支持高并发。那我们再来看一种既支持延迟加载、又支持高并发的单例实现方式，也就是双重检测实现方式。\n在这种实现方式中，只要 instance 被创建之后，即便再调用 getInstance() 函数也不会再进入到加锁逻辑中了。所以，这种实现方式解决了懒汉式并发度低的问题。具体的代码实现如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class IdGenerator { private AtomicLong id = new AtomicLong(0); private static IdGenerator instance; private IdGenerator() {} public static IdGenerator getInstance() { if (instance == null) { synchronized(IdGenerator.class) { // 此处为类级别的锁 if (instance == null) { instance = new IdGenerator(); } } } return instance; } public long getId() { return id.incrementAndGet(); } } 网上有人说，这种实现方式有些问题。因为指令重排序，可能会导致 IdGenerator 对象被 new 出来，并且赋值给 instance 之后，还没来得及初始化（执行构造函数中的代码逻辑），就被另一个线程使用了。\n要解决这个问题，我们需要给 instance 成员变量加上 volatile 关键字，禁止指令重排序才行。实际上，只有很低版本的 Java 才会有这个问题。我们现在用的高版本的 Java 已经在 JDK 内部实现中解决了这个问题（解决的方法很简单，只要把对象 new 操作和初始化操作设计为原子操作，就自然能禁止重排序）。关于这点的详细解释，跟特定语言有关，我就不展开讲了，感兴趣的同学可以自行研究一下。\n4. 静态内部类 我们再来看一种比双重检测更加简单的实现方法，那就是利用 Java 的静态内部类。它有点类似饿汉式，但又能做到了延迟加载。具体是怎么做到的呢？我们先来看它的代码实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class IdGenerator { private AtomicLong id = new AtomicLong(0); private IdGenerator() {} private static class SingletonHolder{ private static final IdGenerator instance = new IdGenerator(); } public static IdGenerator getInstance() { return SingletonHolder.instance; } public long getId() { return id.incrementAndGet(); } } SingletonHolder 是一个静态内部类，当外部类 IdGenerator 被加载的时候，并不会创建 SingletonHolder 实例对象。只有当调用 getInstance() 方法时，SingletonHolder 才会被加载，这个时候才会创建 instance。instance 的唯一性、创建过程的线程安全性，都由 JVM 来保证。所以，这种实现方法既保证了线程安全，又能做到延迟加载。\n5. 枚举 最后，我们介绍一种最简单的实现方式，基于枚举类型的单例实现。这种实现方式通过 Java 枚举类型本身的特性，保证了实例创建的线程安全性和实例的唯一性。具体的代码如下所示：\n1 2 3 4 5 6 7 8 public enum IdGenerator { INSTANCE; private AtomicLong id = new AtomicLong(0); public long getId() { return id.incrementAndGet(); } } 重点回顾 1. 单例的定义 单例设计模式（Singleton Design Pattern）理解起来非常简单。一个类只允许创建一个对象（或者叫实例），那这个类就是一个单例类，这种设计模式就叫作单例设计模式，简称单例模式。\n2. 单例的用处 从业务概念上，有些数据在系统中只应该保存一份，就比较适合设计为单例类。比如，系统的配置信息类。除此之外，我们还可以使用单例解决资源访问冲突的问题。\n3. 单例的实现 单例有下面几种经典的实现方式。\n饿汉式 饿汉式的实现方式，在类加载的期间，就已经将 instance 静态实例初始化好了，所以，instance 实例的创建是线程安全的。不过，这样的实现方式不支持延迟加载实例。\n懒汉式 懒汉式相对于饿汉式的优势是支持延迟加载。这种实现方式会导致频繁加锁、释放锁，以及并发度低等问题，频繁的调用会产生性能瓶颈。\n双重检测 双重检测实现方式既支持延迟加载、又支持高并发的单例实现方式。只要 instance 被创建之后，再调用 getInstance() 函数都不会进入到加锁逻辑中。所以，这种实现方式解决了懒汉式并发度低的问题。\n静态内部类 利用 Java 的静态内部类来实现单例。这种实现方式，既支持延迟加载，也支持高并发，实现起来也比双重检测简单。\n枚举 最简单的实现方式，基于枚举类型的单例实现。这种实现方式通过 Java 枚举类型本身的特性，保证了实例创建的线程安全性和实例的唯一性。\n","description":"","tags":null,"title":"设计模式（一）-- 单例模式 001","uri":"/tech/designpattern/001_signle%E4%B8%80/"},{"categories":null,"content":"Blog010 —— 考研系列完结篇，但是还有生活 零、写在前面 说实在的，我不想去回忆关于考研的任何内容，备考过程也好，考试当天的过程也罢，都不愿意去提起，真的太折磨了。所有 APP 中推荐的关于考研的内容，都刻意的去点了 X，但有可能就是应为刻意而为之，反而越想去逃避，不想去面对这一切。似乎就好像不去主动面对，这一切就还没结束，结果也就不会到来。但时间是一直往前走，不会止步的。除了麻痹、自我安慰、欺骗自己，真的不知道该做些什么。考研结束的这几天，过得也特别颓废。什么都不想做，吃了睡，睡了吃，报复性的“糟蹋”自己，来“补偿”这一年的付出。。。\n每到深夜，闭上眼，脑中回想的都是这一年的点点滴滴，又回头看看备考期间所写下的博客。就像是开篇中所写下的写在之后所提到，我想用文字记录下这一切。当看到这段话的时候，说明我坚持下来了，我也做到去突破自己的壁垒，勇敢的去面对自己这一年的汗水与泪水。既然之前的都写了，为何不写完这最后一篇呢？\n一、回到起点 是的，就像这篇的标题一样，考研终于结束了。这一年来的备考过程也总算是画上了个句号。这一年回想起来，过得也还是挺快的。一步一步也就这样走向了终点。但，真正的生活也才刚刚开始而已。\n这一路走来的点点滴滴，宛如就在昨夜，仍然历历在目，甚至还以为现在真的是结束了吗？？或许，再给我点时间，我还能坚持坚持，还能再努力努力，还能做的更好一点呢。。\n但当专业课交完试卷，走出考场的那一刻起，都已成为过往。很感谢这一年每月的记录，才有现在的最终篇。\n走出考场，整个人都好像失去了目标、失去方向、失去走下去的动力。我好像回到了一年前的自己，又好像看见了三年前的自己。\n一年前的自己，刚刚开始准备考研，还在吃着上一届学长学姐考研的瓜，跟风吐槽着数学出的简单、英语有多难、政治肖大爷有多神。但作为这届刚刚结束这一切的考研人，我不愿去讨论，甚至不想与这个世界存在任何联系，我怕一点点的风吹草动会影响接下来的心情。去年这个时候面对的是不知该如何复习的迷茫感，现在是不知该做些什么的困惑，甚至不知道该向什么方向去努力。那时的自己，你不了解你所处的位置，也无法判断自己真正的能力与实力。但是，却有着极大的野心和孤独一掷的决心与勇气。你说，你要考个牛掰的学校，想体验一下去大城市读书的感觉。同时，你对自己的学习方法也有时摸不着头脑，有时又蜜汁自信。最后，你说不管结果如何，你会坦然去面对这一切的后果，因为你相信，只要坚持到底总不会太差，如果不是，那就是还没到最后。那么值得吗？？？我觉得值！！！这是一段极为难得的专注时光，得以有机会深入地去探求最真实的自我，也是一场与自己的比赛，与自己对话的机会。\n是啊，你现在走完了这一路，为什么不敢去面对当时的自己了呢？？没达到自己预期的样子。。。对，确实没达到。原以为的自己能够在考场上意气风发、洋洋洒洒地写完试卷，走出考场时，还不忘给自己一个微笑。考前，我曾一遍一遍地想象自己在考场上的自己，想着这一年的付出终于能发挥出来，所有的付出都能看得到回报，这一路的坚持也是值得的。但事与愿违，四场下来，一场比一场难受，但我不能表现出来，我怕会影响下一场考试，怕自己会崩溃，怕自己没有踏进下一场考试的勇气。可能，这也就是现实了吧。\n三年前的自己，那时的你带着高考的不甘，极其不情愿的来到现在的学校，都还不知考研对你意味着是什么，就把考研定为自己的目标，大一的时候还不怎么逃课，上课也很积极坐在最前排，对大学里的一切即充满新鲜感，同时也很迷茫。迷茫的是大学和高中完全是两个样子，没有统一的标准，不知道到底怎么做是对的，哪样是错的。那时的你，眼界还仅仅局限于校园内，似乎就感觉世界好大，但与我无关，老老实实的做个普普通通的学生就好了，不是吗？你也更不会想到现如今的自己，不会真正参与到这个更大的世界。但现在，我又好想逃离这个错综复杂的世界。。。\n二、倒计时的煎熬 进入十二月 进入十二月，代表着不足一个月，就得走进考场，那时候政治啥都没背，只把肖八的选择题给做完，其他的老师的模拟题也不愿意去做，对政治这门课，就有点摆烂。英语开始最后一遍过真题，虽然记住大部分的答案，能要求自己的就是读懂文章，并分析答案的选项，正确选项是如何选出来的，错误选项是如何设置干扰的。每天保持一篇作文的量。数学也结束了真题，可能太过于急于求成，做完之后，没有进行详细的、系统的复盘，就去模拟题中挣扎了。现在看来是极其不明智的做法，数学说到底，还是应该以真题为主，模拟题是在全部掌握真题的情况下来开拓眼界、拓展思路，见见新的题型和技巧用的。看周围的同学都在做模拟题，自己也就忍不住去跟风，不免有点本末倒置。\n突然就觉得时间不够用了，每天都对自己说，起的早一点、学得晚一点、多坚持一点。硬生生的压迫自己去学习，效率也就不会太高。但是我不敢对自己有丝毫懈怠，因为真的快到头了，留给自己的时间也不多了。加油，踏踏实实的走下去。\n倒计时两周 这个时候，突然人就崩溃了。感觉好像啥都会，但再仔细想想又觉得自己哪里都不太会。肖四已经到手，根本背不动，学校这边还有一堆恶心的人和事来搞人状态，就想着我只是考个研究生，为什么觉得全世界都和我为敌，到底做错了什么？？英语也被 21 年的真题给打击到。。数学更是被各种模拟题做的我怀疑人生。专业课由于只有参考数目，并不知道实际上复习的咋样，一直都是玄学状态。\n我不止一次想过，要不就这样了吧。实在是坚持不动了。考研，真的是太痛苦了，比我原本的预期要难受的多的多的多。但回过头来再想想，再苦再累也就还剩两周，走完吧，别给自己留有遗憾。考场都没踏上，咋就自己知道自己就一定做不到呢？\n倒计时五天 距离考试还剩一周，真的是过一天少一天。现在也不做新题了，每天翻翻看自己做过的试卷，从错题找原因，再回归到讲义，查缺补漏。也就是在这个时候，回归真题，才意识到真题和模拟题的作用是不等价的。肖四也把当时可能考到的点都背了背，反正每天都在坚持嘛，虽然是不可能背完的了，奇迹也创造不出来。英语单词逐渐开始慢慢减少记忆量，腾出更多的时间来给作文。专业课就根据考纲和之前的真题回忆，每天睡前不断回忆专业课的内容。\n到了这个时间点，反而没有前两周那么慌张，更从容，更平静了。开始慢慢调整自己的状态，虽然不能回到巅峰，但最起码别太差就好。到了临考前两天，晚上从图书馆回宿舍的时候，开始收拾资料，逐渐往宿舍搬，收到一半的时候，突然好舍不得，不禁就呆住去回忆这一年的点点滴滴，眼泪止不住的在眼角里打转，强忍不让其落下来。回宿舍的路上，望着天上的星星，我就在想，所坚持的这一切真的值得吗？？为了考研所放弃的太多太多，真的不会后悔吗？？\n还记得，在十月份的博客中写到：我还在等一场雪，来见证这场考试。周五看好去考场的路线回到酒店，晚上真的飘起了小雪。从唯心主义来说，真的就有很大信心去踏上明天的战场。\n三、但是还有生活 是的，现在距离考研结束已经快过去一周了。这一年就好像做了一场梦，考试结束，梦也就醒了。\n还记得高考结束之后，留下的最多的是疲惫感，现在也是。还有一种无力感，颓废感。从踏进大学校门的那一刻起，就把考研当做自己的最终目标，完成之后，不知道自己下一步该怎么走，该走向哪？？一时间，又好似觉得自己的努力有些可笑，有些一文不值，开始不断的否定自己。\n现在考研都在默认奇数年简单、偶数年简单，虽然事实的确如此，但难与不难，往往更取决于个人的主观感受，而不是你我说了算，我们要做的就是坦然去面对这一切，在考场上做到发挥出最好的自己。回答前面的问题，值得！！！如果再给我一次机会，我还会选择考研，因为只有历经了真正意义上身心的折磨，才能算得上是成长，遇见困难，要硬着头皮冲，而不只想着做逃兵，一直在退缩。有的时候，不逼自己一把，都不知道自己是什么样的。最重要的是，这场考试，虽然发挥的不是太好（巅峰状态的百分之七十），但没有留下太大的遗憾，我尽我所能，做到了最好的自己。\n除了这一切，但是还有生活。\n想想之前所规划的，考试结束之后，想做的事情，好像也没啥了。脱离开源社区半年，突然回去，既熟悉又陌生。熟悉的是那种来自开源人带来的感觉是不会变的，陌生的是又有了许多新的小伙伴、新的代码，还需自己花时间去了解一下。这半年来，没有时间去积累新的技术栈，现在也有时间去探索新的领域，做新的尝试。这半年来，由于备考而落下的书籍，也有时间去阅读了。btw 可以的话，我还想把大学期间读过对我影响比较大的书买纸质版的再来一遍。还有就是，当时想着去健身，现在也有了大把的时间去锻炼自己，让自己朝着更好的方向去发展。\n若干年后，你会怎样回想这一年？人生海海，这一年，我们记得肆虐的洪水，反反复复的疫情，更记得那些逆行的无畏身影，爱与善汇成浩荡星河，在奉献，在永不言弃的精神。这一年，我们记得巨星，灿烂而不朽的陨落，记得他们走过一地荒芜，留下生生不息。记得那些顽强和汗水写下的闪耀时刻。每一个巨浪都成就于微澜，每一个普通的灵魂里都有江河。这一年，我们记得，勇立潮头的你，披荆斩棘前行的你，每一天都努力让自己和周边世界好一点点的你，记得一路千山万壑，希望就是我们自己，都在路上！\n附：考研歌单\n《平凡之路》-- 朴树 《一群无知少年的梦想》-- 杨赛 《稻香》-- 周杰伦 《拼个世界给自己》 -- 姜云升 《没有理想的人不伤心》-- 新裤子 《Iridescent》-- Linkin Park 《Beautiful》-- Eminem 《猛犸》-- 后海大鲨鱼 《幸存者》-- 林俊杰 《孤勇者》-- 陈奕迅 最后，有的人说，奇数年的坚持，都是为了在偶数年迎来好运，希望下一年会好一点~~\n还有就是，去 TM 的 2021，终于结束了。。。。。\n","description":"","tags":null,"title":"大政的考研 Blog010 —— 但是还有生活","uri":"/life/kaoyan010/"},{"categories":null,"content":"Blog009 —— 幸存者，十一月复盘 一、再坚持一下 1.1 彻底崩溃 是的，就像标题所说的那样，随着距离考研时间的越来越近，心里也就越来越着急，紧张感、压迫感都在无形的逼近。总想着，还有好多好多没有复习，到底该怎么办啊！就这样想着想着，心态崩了，严格意义上来说，是考研这将近一年的时间中第一次崩溃。\n进入考研倒计时 100 天的时候，我在想，还不着急，还有三个多月呢，时间在一定程度上还是很充裕的，就想着是不是背诵记忆类的内容可以往后放一放，况且专业课复习的不咋滴，数学才是重点。慢慢的到了快倒计时 60 天 的时候，突然的有一种压迫感袭来。马上就剩下两个月了，两个月需要背那么多，你能做到么？？但问题是，其实数学和专业课复习的也不是很好啊。。要知道，我高三的时候都没这样过，有的时候还经常逃课，上课睡觉，考研给我整成什么样子了。我也想去外面玩，好好的睡个懒觉，这学期更是进山窝里到目前为止三个月的时间没有出去过！就算是高考在我眼前，五一假期的时候，我还是该浪浪该玩玩。也许，这就应了那句话：出来混，迟早是要还的。。。\n就这样，到了倒计时 50 天的时候，彻底崩溃，下一步不知该如何是好，整个人都充满了无力感。总想着剩下的时间，英语作文、新题型、翻译、完型都没开始；高数的一些边边角角小的知识点、几何应用、物理应用都不会；线性代数掌握的也不是好牢固，知识点都串不起来，做题的时候都是磕磕巴巴，甚至还做不出来；专业课，笼统的感觉好像全部都掌握的还行，每个点都能说出个一二三出来，但是到具体的题目，又不太行；至于政治，更别提了只听了马原部分，经济学部分掌握的还不好，史纲也知道个点点，其余的压根没看。下一步到底该怎么走。考四门，结果没有一门是能让我安心的。\n下一步该怎么办？是放弃吗？还是做无谓的坚持？？\n很多的崩溃可能往往就是那么一瞬间。（但是学过马哲之后，就要说这句话是错的了，这不明显忽略了量变对于质变的影响嘛）。\n1.2 还剩 50 天 对啊，你还剩 50 天，又不是下周就要考研了，干嘛这么着急呢？焦虑有用吗？也许只会有反作用吧。就像之前暑假时候的状态，想玩但是又不敢玩，只能硬着头皮学，反而没有怎么玩，学的也不咋滴。你现在的问题不是不想学，而是不知道该如何去学，既然是有学习的心，剩余的就是学什么的问题了。\n这一路走来，很多时候我们都习惯于放大自己的缺点，和强调自己的特殊性，认为好像只有自己会遇见这种问题，甚至会觉得，我只是想考个研，怎么全世界都在和我作对！其实不然，我们也只是百万考生中的一员，其实往大了说，大家的问题也都差不多。不排除肯定有复习的特别好的大佬，也肯定有氛围组的炮灰，但是我想说的是绝大多数人都一样。都会感觉到焦虑。在没出成绩之前，谁敢说自己就一定能考上呢？坚持到这个时间段，我们当下需要做的就是走好自己的每一步，过好自己的每一天。但是如果太刻意去强调每天都要学的扎扎实实的，在很大程度上也会有副作用。人是特别容易受主观因素影响的动物，没有人能够保证自己学的特别棒，真的没有，偶尔出现情绪波动都是再正常不过的事情了，我们要学会接受自己的不足，欣赏自己的不完美，只有这样才能把自己的心态给端平，也能够给自己一个喘一口气的机会。\n1.3 30 天倒计时 就这样，不算太顺，但也不能说是太差，进入了三十天倒计时。有的时候，我就会想，为什么通常把三十天左右当做一个结点呢？仅仅是因为一个月的时间在这个范围左右嘛。也许吧。但也有可能是接下来的每一天离自己即会更近一步，又会渐行渐远。。每每这个时候，我就会想起高三对自己说的话：我不去想是否能够成功，既然选择了远方，便只能风雨兼程。其实吧，事情远没有自己想的那么严重。如果不考研的话，我就是一个不起眼的二本院校普普通通的毕业生，再说直白点，本身就没啥好失去的。考研，考上了等于赚了，考不上就问问自己这一年的坚持对自己而言值得吗？？有收获吗？？现在的自己是当时自己所想的样子嘛？？\n和之前的博客里面所写的一样，从选择考研的那一刻起，我就在问自己，为什么要考研，或者说读研对于我来说意味着什么。我能够感觉到，就算是我读研毕业之后，工作能力也许并不会比现在的自己高出多少。这个答案，直到今天，我还在寻找。。。\n二、十一月复盘 ① 数学 数学分值 150，自然而然是重中之重。但是数学的学习真的很枯燥无味，到现在这个阶段才感觉到在复习前期对数学真的是低估了。从而导致数学的整体进度到中后期开始慢慢落了下了来。从辩证法的角度来看，这一点也不是一点好处没有的，就把高数和线代的强化部分又抽重点给过了一遍，也是因为之前暑假的时候为了赶进度而导致的原因吧。由此可见，学习是真的要学的扎扎实实，不能囫囵吞枣！\n这个月主要就是把武神的 17 堂课给看的差不多，但是后面的几个专题因为时间的原因只是结合课程把里面的一些掌握不太好的题型给做了，并没有全部完成，而且整个课程还剩物理应用没有复习。进入十二月的第一天给它啃了吧。不得不说，武神终究是武神， 17 堂课听得很痛苦，因为全是重难点，几乎没有太多的垃圾题目，刷起来难度就真的大很多。但是对于解决问题的角度，都提供了很好的解法，尤其是微分中值定理的证明，之前看见这种题目从心理上来说是比较畏惧的，无法充分利用题目的已知条件，不会正确的构造函数，但这些经过系统地训练之后，会发现都是有迹可循的。所以考研给我的感觉，后期的付出比天赋重要的多。再有就是二重积分的求解问题，这段时间真题刷下来，二重积分几乎是必考的，往往还会更倾向于大题目的考察，解决此类问题的时候，首先看区间是否是对称区间，以及是否能够通过平移利用函数的奇偶性来适当的简化计算量，以及对于直角坐标和极坐标之间的转化适用于什么样的题目，还有就是像星形线、摆线之类的比较特殊的曲线图像，心里要有个大概的了解，这样的话遇见题目才不会出现无从下手的情况。课程的质量还是可以保证的，干货满满，就是听起来很费精力！！！\n其次，就是从这个月下半旬开始，真题的套卷终于开始刷了，虽然半个月的时间只消化了八张真题试卷。以下是对从 11——18 年真题的简单小结：\n11 年：难度一般，由于是第一次以套卷的形式开始做数学，出现很多知识点串不起来，像填空题中出现的弧长公式、以及对于微分方程的综合应用掌握的一般，整张试卷下来计算上的细节容易出现丢分情况，物理应用是丢分点之一，二重积分的出题方式比较特殊，但是结合一元的情况还是应该要解出来的； 12 年：难度一般，曲率没有掌握，还有就是对于行列式的计算要学会灵活处理，旋转体的体积的处理、二重积分考察的是心形线，整个试卷我感觉最难的题目是数列极限的题目：用零点定理证明至少有一个零点，再用单调有界准则证明最多有一个零点，在第二问求极限的时候，还要充分利用第一问给的信息；线代大题要注意同解方程的应用； 13 年：难度一般：反常积分的敛散性掌握不熟；以及变上限积分的连续性判定这些小的知识点都不能忽视，实对称矩阵等价=具有相同的特征多项式，伴随矩阵与其代数余子式之间的关系，大题目则比较中规中矩，除了一个考察形心，这是个什么鬼？？还有最后的线代大题，利用技巧来处理问题要引起注意，傻乎乎的展开几乎不太可能实现； 14 年：难度有所上升，函数的性态（单调性、凹凸性等）与导数之间的关系，质心坐标？？微分方程解的形式，以及特征根需要注意。证明题其中数列极限，是个好题。还有多元微分学以及积分的应用来求体积都是要引起关注的点。证明矩阵相似，通常要用一个中间的矩阵作为过渡； 15 年：难度一般，高阶导数的求法，二重积分的计算要想到对称区间——奇偶性，微分方程的物理应用，题目不是很难，要耐下心来读题，以及后面的证明题，比较综合，也是不错的题目； 16 年：难，计算量大！选择填空都还行，主要是计算量真的大！题目思路都比较常规，几乎都能想到，就是算不完。在求定积分的时候遇见绝对值要分区间讨论，以及对于可导性的判断也不能少！微分方程的求解，关于常数 C 如何确定的问题，旋转体的侧面积计算（积分区间的上下限要注意），以及最后线代的大题，求高次幂要想到利用对角矩阵，但是计算量也是令人匪夷所思； 17 年：比较简单，求解极限的时候，分母是含有 x 的变上限积分，不能直接使用洛必达，要想到换元，后面的题目没啥可说的点。。。； 18 年，难，但是计算量我感觉并没有 16 年大，反而选填题的难度有所上升，大题中考到了求不定积分，这玩意的难度是个无底洞，需要注意冲刺时候的训练；还有求拉格朗日最值，计算量比较大；二重积分考的是摆线，画出图形，利用对称区间可以简化计算量。 从 15 年开始，偶数年的题目是真的难，计算量还大，我了个天，谁知道今年会怎么样呢。。\n在当前状态下，模拟卷没有时间就不做，务必要把真题吃透，做好！\n② 英语 英语这个月，算是复习的比较理想的一科了。先是过完了翻译的课程，随后新题型和完型填空又紧随其上。目前还在准备作文阶段，小作文已经初步形成，大作文希望在一周之内可以完成，毕竟留给的时间真的真的不多了。\n这个月则把真题又过了一遍，因为属于多刷了已经，里面的大部分答案都能记住，所以要做的就是通读阅读文章，扫清生词和长难句，以及弄清楚题目与选项之间的关系。要养成良好的做题思维。接下来的日子，真题再过最后一遍，我也希望是我人生中最后一遍过考研英语的历年真题！！\n③ 专业课 专业课怎么说呢。。笼统的看好像全部都掌握的差不多了，但是放到具体的问题来看，还是掌握的不太牢固，就比如排序的算法，对于考纲中给出的内容都能手动模拟出来，但是要是说全部手写代码的话，还是存在一定的困难的，（根据前两年的回忆版真题，只出现了个快速排序的代码要求，而且还有文字提示），对于 BST、AVL 和 B 之类的插入和删除都算是掌握了吧，画图过程都会，但是容易忘，所以在接下的时间要反复巩固。但对于链表、栈和队列只知道这些数据结构的增加结点和删除结点的方式，并没有往下深究，看着之前的回忆版真题，感觉这部分考的不是很深。还有就是时间和空间复杂度的计算要掌握，图比较侧重于迪杰斯特拉，前两年都考到了。还有各种数据结构的存储方式。\n数据库方面的话，难点还是在第三范式和 BCNF 的分解，无损连接和保持函数依赖性掌握的还行，求闭包之类的也可以，求最小依赖集比较生疏，还有就是求候选码容易漏。。写 SQL 的话，经过了一定量的练习，应该不会丢太多分，考得太难了也就无了呗。至于关系代数，回头还需要看看，至于元组演算的话，战略性选择放弃吧。还有重点就是事务和故障恢复，这部分既需要理解，又需要一定量的背诵。难度的话倒不是很难，剩余的我感觉更多的都是偏向于记忆类的知识点，后期需要回归教材，多看看书，把书变薄再变厚。\n加油！\n④ 政治 政治这个是我最不想提起的，因为真的很无聊。马原和史纲部分还能接受，到了毛中特的部分，那就是开始无脑吹。唉。\n里面的 keywords 看着都很熟悉，就是记不清，而且还没有花时间开始背诵。还剩三周多几天的时间，能够背的完么？选择方面，肖八快全部刷完了，前面两套做的是真的惨不忍睹，错的稀里哗啦。。。但好处是之前马原和史纲过了一遍，这块的错误率是比较低的，因为毛中特和思修对于我来说等于啥都不知，只能结合错题回归背诵手册来勾画知识点，反复记忆。到了第四套开始慢慢有了起色，最起码不是做的太难看了。\n说真的，政治我不想花太多时间，毕竟拉不开多大的分，我想的就是在最短的时间内，冲到 60 分以上，最起码证明自己的政治觉悟没有问题是吧，虽然上海还是旱区。。。\n三、幸存者 天，快亮了！是啊，终于快了，我等了好久，内心是期待的，是渴望这一天早点到来，这样身上的担子就能卸下来了，就能做点自己想做的事情。每当看不下去书的时候，我就在想考研结束的生活，我想看自己喜欢的书籍，睡个懒觉，继续为开源项目做贡献，阅读源码，增加查克拉，再玩玩悠悠球。还有二十几天，就能过上了，一定一定要调整好自己的状态，最起码在面临考试的时候不是恐惧的心理。\n但在期待着她到来的同时，又不愿早点到。因为没有复习好，还是会觉得如果再给我多一个月的时间，我肯定能把哪里哪里给补回来，把什么什么给学的好好的，但是时间对于每个人都是公平的，过去了就是过去了，在剩下的日子里要做的就是在现有的基础上，不断巩固加强，查缺补漏。还有就是，我不知道下一次这么为了自己的目标去奋斗，坚持是什么时候，在选定考研目标的时候，这是我读书以来第一次有机会自主选择自己的院校，所以从根本上来说，我是很喜欢这个为之努力，为之付出的过程的，因为我知道，随着时间的推移，我在慢慢的、一点一点的靠近她。但是我还怕就差一点点，原以为只是踮起脚尖够月亮，没想到回过头来已经是万丈深渊。这段煎熬的时光纵然不舍，但我还是想说享受这一次就好，今年一定要冲上岸！！\n其实在和对大多数的考研人比，我算是比较幸运的，在别人还在焦虑选择院校的时候，我的目标已定；因为是自主命题，所以很感谢导师和实验室的师哥师姐给予的帮助。如果没有你们的帮助，我的心态早就崩了。也正是由于你们的帮助，我敢于去搏一把，去挑战自己心里的那个最高点，去勇于做别人想做但又不敢做的。还有就是离不开家人的支持，家永远是最后的防线。所以从这些角度来说，我是考研大军中，为数不多的幸存者！\n背负伤的幸存者 争夺着有限名额\n想要闪烁就对自己更严格\n加油！冲！\n","description":"","tags":null,"title":"大政的考研 Blog009 —— 幸存者","uri":"/life/kaoyan009/"},{"categories":null,"content":"Blog008 —— 莫问终点，十月复盘 一、煎熬 ? 终点 : 放弃 1、10.24 十月份，10.24 程序员节~~ 打心底来说，我还是很喜欢这个职业的，至少从目前为止，也许以后毕业了从事“劳动密集型工作”面对资本家的压榨，会产生厌恶的心情呢，but who cares？以后的事情以后再说咯。\n软件工程，这个专业名字确实听起来确实很高大上，但是临近毕业大四的自己，有掌握软件工程的思想吗？？似乎差的很远吧。但是我喜欢编程所给我带来的东西。在现在这样一个信息化的时代，几乎人人都离不开互联网带来的便利。所以我们将来所从事的职业是一个可以改变世界的，这一点也是挺值得自豪的。还有就是在掌握一些技术栈之后，会慢慢发现这个在互联网影响下，现实和虚拟相互交织的世界到底是如何运转的，我们每天使用电子设备所产生的的数据是如何存储的，又以何种方式被利用等等，这些在我看来都是很有意思，也是值得思考和探索的。所以我很感谢当初的自己选择了这个专业，能给现在的自己一个机会，以程序员的视角去感受这个世界。\n回想去年的 10.24 可谓是真的极限运动，周四晚上连夜做着绿皮小火车，轰隆轰隆吵得头皮发麻，周五到达上海，上午睡一觉，晚上赶往年会会场--微软 Reactor，到晚上回家的时候地铁停运，只能打车，洗漱完成已经是两点多，第二天还得早起，接连两天，然后周天晚上再次连夜赶回合肥。有的同学问我，这么赶时间折腾自己，就是去做志愿者，有必要吗？我想或许不是很有必要，但是有意义，信仰充值。在去年的开源年会，是我第一次得到被肯定的感觉。让我发现世界上有很多和我一样的人，普通却并不平凡为开源输出自己的力量，也更让我找到了考研的目标。（具体的详细感受看 我与开源的那些事儿）其实最好的体验是在于回来之后，写了这篇博客，得到认可的“满足感”和“虚荣心”是无可替代的！\n2、越来越近了… 是的，十月份的结束，代表着距离考研也越来越近了。这个阶段的自己心情是十分矛盾的，一方面想着完了还有好多东西没看没复习还来得及嚒？？另一方面却想赶快结束这一切吧，真的是熬不动了。我想无忧无虑的熬一次夜，更想无所顾虑的睡一次懒觉。但是对于目前这个阶段来说，这无疑是一种奢侈。\n就带着这矛盾的心情，一面是厌学，不想看书；另一面又是逼着自己学习，因为我太渴望考研上岸。就总觉得是这是证明我自己的一次机会，证明自己大学这几年混得还不差，证明自己还是有能力的，证明我能做得到。更想让那些之前看不起我的人，对我刮目相看。似乎从中考失利，就被贴上差等生的标签，从高中到大学，所以当再一次站在选择的路口，我不想再窝窝囊囊只是为了有学上来逃避自己啥都不会的现实，这一次我想选个牛 X 的，更何况机会就摆在我面前，我真的舍不得放弃。嗯，是的。\n但是选择了好的学校，就代表着你需要承受踏上终点的一切负重。其中压力部分是最大的，竞争力也要强上很多，在往年三百七左右的平均分作为参考，以及近年来报考人数的持续增长，很多次很多次很多次有不断地想过问自己，要不要换一个学校，或者说要不就这样了吧？？\n但是我熬了这么久，不是想证明自己临场退缩，我所期待的的是“拟录取”这三个字，是明年的录取通知书。是明年可以骄傲地说：我从做得到，到现在已经做到了！！！\n说实话，这一段不知为何，写得戾气有点重。但我实在是不知道该怎么给自己调整心态，我不相信什么“心灵鸡汤”、“励志成功学”等等之类的，那都是强者拿来安慰或者忽悠弱者的。我想说的是：我能做的就是逼自己认清现实，意识到现在自己的处境。时间是不等人的，今天过去，是不会再回来的。只能尽自己最大的能力，调整好自己的心态，哪怕这心态已经“畸形”了。。。\n二、十月复盘 ① 数学 数学可谓是整个考研过程中最耗费精力和时间的科目，现在回想起来从去年大约这个时候开始过高数的课本教材到现在已经一年了，但是距离自己最初所期待或者说是所要求的目标还离的有不小的一段距离，离考研也越来越快了，到底怎么样，心里似乎也不是很有底。\n我从来没没有想过数学的强化阶段会持续这么长！！原以为暑假的时候听完强化课，做好讲义上的例题就算是强化结束了。但工作量远比我想的要大得多。满打满算高数部分到上周末才算是强化结束。线代预计还要三天以后。十月份数学的重心大部分都是强化收尾工作。把之前漏看的、掌握不牢固的以及某个知识点题目做得比较少，都拿出来重新过了一遍。\n先具体说一下高数吧，要是论对考点的熟悉程度的话，掌握最好的应该是求极限，函数求极限只要不是太偏太怪太难理论上是没问题的了，数列求极限有待加强（原因很简单，求极限放在第一章，每一次重新过的时候，前半部分的时间花的最多，就好比是英语单词书最熟悉的是第一页的词汇一样）；其次就像是求导求积分之类的题目，不能说是掌握的太好，但是在做此类题目的时候，进入状态的时间有点长；而且求积分这块，尤其是不定积分就像是个无底洞，它有些常见的套路和题型，但却没有那么容易想到，这块的还有个难点是微分中值定理的证明题，从我现在的水平来说，是有希望啃下的，毕竟在暑期的时候就特地有投入时间在这部分，（昨晚在听 17 堂课中该专题的时候，看见题目能自然而然的想到如何构造辅助函数）但我怕的是，由于这部分确实比较难，出题比较灵活，万一出现课下模拟都会做，但是一到考试看见真题的时候傻眼了，这是及其恶心、难受的一件事，不花时间吧，我似乎又不太放心。。\n在不定积分和定积分还有两个盲点：第一个是变上限积分的比阶之类的，第二就是定积分的应用，包括几何应用和物理应用。比较明显的特点就是不是很难，但缺乏训练导致掌握的比较差，之前想的就是跟着武神的 17 堂课，再集合真题和模拟题巩固练习，但有的时候看见此类题目，容易产生抵触的心理。\n高数的下半部分也就是上面的特点，不是很难，但是掌握程度却不太理想。。在这次重新强化的过程中，加强了对于微分方程、多元函数微分学、二重积分的练习，当时想的就是这啥玩意哈，之前都学了个啥！！！由此可见之前学的有多差，现在回头来看要的多了，但是在做题之前还是需要先看一下知识点。。加强练习啊！！！发现问题之后，要学会解决它，不能放任不管。微分方程的话，技巧性不是很强，计算量略微有点点大，套模板记公式。多元函数微分，难度有一点点，特别是定义那块，给我感觉是整个高数部分考定义最难的点了。。。计算的话，需要细心，特别容易绕晕。二重积分，计算量有！根据定义域画出函数图像，这一块要仔细点，我觉得是难点所在，最后剩下的就是计算问题，如果在部分再考难一点，直接放弃吗？？\n线代的话，整体就是比较玄学，说不会吧，多少会一点，但是看见题目的时候，很多时候都无从下手，知识点全部都搅合在一起，能做的也只能是多花时间、多思考、多练习。所以我又把线代的强化课听了一遍，听李老讲题的时候，哎确实是这个道理，只要注意力集中也都听得懂，但是到自己做题目，就是另一回事了，关键原因还是无法利用题目所给的已知条件，甚至有的时候看完答案还得想好久，离考研不到六十天，有的时候，我就在想线代要不给放弃了？？但是放弃的话就代表着数学最多最多考到一百算是不错的了，李老还出了个综合提醒课，下个月抽时间看看吧。加油！\n② 英语 英语的话，阅读能感觉到已经没有问题了，但是问题是除了阅读其他的好像都有问题，准确来说是都还没开始，作文等进入十一月份，就可以准备起来了，新题型的话，我想的是等到十一月中旬再开始，翻译的话，有时间就开始吧。至于完型填空，我的预期目标是最少要及格，不拉后腿就好，可以适当的战略性放弃点。\n但是在做完英语二之后的阅读，再看英一的阅读，对比下来，英一要难好多，也许是自己阅读根本就没掌握好呢。。做英一阅读的时候，题目与文章的定位点大部分都能准确找到，但是英一的文章对于词汇和长难句要求真的是高很多，解题技巧会了，还是基础不牢，地动山摇？？这个阶段给我来这一出，我是真的怕啊！！！\n③ 专业课 专业课这部分我真的很感谢给我提供过帮助的学长学姐，要不然我真的是一脸懵逼。\n数据库：拉了许多的数据库终于补救回来了，呃，应该是抢救。。整个考纲里面所要求的知识点都有所掌握，常见的题目也都掌握的还行，盲点还在于关系代数和 SQL，这部分要抽时间集中练习，然后坚持到考前，至于关系演算，实在是看不懂，是不是可以放弃。。对了，还剩一章数据库设计没有看。。\n数据结构：这部分总体来说是比较熟悉的。但是具体到考点是比较迷茫的，因为数据结构的出题形式真的太多了，可以是只考理论也是可以写代码，甚至是画图。这就很恶心。十月份的重点都花在对于数据结构的查缺补漏上面，下个月计划再花半个月时间在二叉树、图、排序和查找，这部分知识点牵涉比较多，也是难点所在。一定要克服！！\n④ 政治 政治的话，我感觉是不是有点晚了，到现在才把马原看完，题目还没看完。政治这个科目，我已经开始迷了，完全不知道下一步该怎么走，该学什么。不对，是要学的太多，不知该怎么学。。。\n初步打算，跟完腿姐的技巧课。《肖 1000》的马原和史纲部分正确率要提到百分之九十，至于毛中特和思修的话，跟着模拟卷走吧，政治不求多，但是要及格啊。最起码证明自己的思想觉悟没问题，更何况自己还是党的一份子呢。。。。\n三、莫问终点 是鹰就不留恋地平线，云层上见～\n对了，我还在等。等一场大雪，来迎接这个冬季的到来，来从容地踏上考场，来记录我这一年的坚持与付出。\n至于终点是哪儿？其实，已经不是太重要了，这大半年的备考，让我自己的心又静下来许多。有的时候看不下去书，就会胡思乱想，其实我本身是一个比较喜欢发呆式思考的。在这断断续续的思想火花中，我也渐渐地更明白自己是一个怎样的人，想成为什么样的人。之前就听很多人说，考研的结果固然重要，但是真正值得回味的是这其中的过程，是一次次勇于挑战自己，敢于知难而上，不满足于目前的现状。\n之前，我总想着，等考上研究生就怎么怎么样，可以给自己放个假。但也许，考研只是这些年给自己的一个奋斗目标，督促自己要努力前进；也许自己并不喜欢读书专研，从而可能导致自己读研的时候会放纵自己；也许自己就是个差生，不是读书的那块料呢？？\n是的，也许吧。但是不坚持怎么会知道结果呢。不去尝试，又怎么能体会到这其中的酸甜苦辣呢。不逼自己一把，又怎么会确认自己就做不到呢？\n距离考研的日子越来越近了，就像前面所说的我已经在尽我最大的努力调整自己的心态，最后的冲刺阶段任务只会越来越重，心态上的煎熬也会加倍。当之前自己付出，到冲刺的白热化阶段慢慢感受到回报的时候，这一切都是值得的。\n考研，只是一场考试，是我所选择踏上的一条路，没必要把自己折磨的那么累，陷入极度的内卷，但这并不意味着是放纵自己的理由。还是要努力的啊！加油吧！\n感谢这个世界还有音乐~~\n","description":"","tags":null,"title":"大政的考研 Blog008 —— 莫问终点","uri":"/life/kaoyan008/"},{"categories":null,"content":"Blog007 —— 再出发，九月复盘 一、开始倒数 1.1 大四开学 时间过得真快，一眨眼，开学就是大四的老学长了。。这三年过来的一点一滴，就宛如刚发生一样，历历在目。现在回头想想，这几年经历了好多，但在学校中又似乎没有太大的收获。\n还记得三年前，这个时候还嚷嚷着想复读，现在看来其实都一样。也许复读顺利考得要稍微好一点，也可能不太幸运，甚至还不如现在呢。但当现在再一次为了一场考试而努力的时候，那种感觉又回来了。很多人都拿考研和高三比较，我感觉吧，相对而言考研要容易一点。因为考研能考个好学校的可能性要大一点，但是反过来看，高考的报录比是要好一点的，但是想读好的学校门槛是不一样的。于是也就有了，选择大于努力这一说话，考研真的是一场信息战！如果让我再选择一次的话，也许我仍然回想复习，但是现在也挺好的。遇见了很多意想不到的事情，遇见了很多有意思的灵魂。\n仔细算一下，正儿八经当时高中所憧憬的大学生活，也只能到大二上。 其余的时间，虽说还在学校，但是学习的内容和处理的事情都逐渐和学校的事情脱节，甚至在一定程度上反感学校许许多多杂七杂八的事情。大一，上课坐前排，参加社团活动，还想着找个对象吧啦吧啦的。。对待各种事情都特别认真。（大一的时候给自己定的目标就是拿到奖学金，认为奖学金就是最高的荣誉，现在看看，呃 不能说一点用都没有吧，反正就是没有之前想的那么重要，也就那么一回事罢了）对于大学的上课方式，社交方面还是很新鲜的，但是慢慢发现，和实际想的还差的很远，特别是遇见很多恶心的事情之后，就感觉天呐，一个学校怎么能是这个样子的，就离谱！！按照当时的脾气还会想着吐槽，但当看得多了，经历的多了，也就认了、不对是佛了。。当时大一特别想创建悠悠球社团，果不其然大二的时候，最折磨我的就是这个社团，每天想的都是怎么推广悠悠球，怎么把悠悠球传播出去，怎么教社员，怎么…… 就这样，心思也不放在学习了。就很难受，说句我不太喜欢的话，“不忘初心”，那么问题来了，初心是啥呢？？我怎么做的意义又在哪呢？？社团是我自己要创的，甩不掉的。。。（现在看看，如果说大学期间最值得纪念的事情，也只剩下这个社团了）再就是大二寒假，发生疫情，也就是在这个时间段发生的事情足以影响到我的大学生活，甚至是整个人生。由于疫情，线上开发协作，从而接触到了开源，也就有了现在的我，一个完全脱离于大学眼界的我。。感谢相遇~~（这也是我为什么说我的校园生活只到大二上的原因，之后的生活等有时间可以细说）。\n还记得去年这个时候，我还在犹豫，我到底要不要考研，或者说为什么决定去考研。我回来了??\n1.2 返校生活 是的，回学校之后，我的状态慢慢在恢复。这一点是我自己都感觉到比较惊喜和意外的，连我自己都没想到回到学校之后，状态真的在好转。七八两月暑假，说实话，离自己所要的复习预期，差的太多太多，都出现厌学心理，已经是在弃考的边缘徘徊的人了。。\n也许是因为暑假在自习室没有参照物来对比，整个网上的言论都是“我很努力”的这种，就很搞人心态。回到学校之后，发现大家都差不多嘛，（也许是我的学习太差 bushi）哈哈哈哈\n想通问题，恢复状态我想还是放在最后来说。\n但是最让我无语的事情是大四的课竟然还如此之多，那就逃呗，只要不挂科，就啥都好说，是吧。\n还有一点就是，自己还不够自律，要懂得拒绝，不能受别人影响、\n二、九月复盘 ① 数学 回到学校的时候，高数和线代已经全部听完强化课了，就想着是不是已经无敌了，结果就是被题目恶狠狠的给教训了一顿，我还是依旧的菜鸡。。。\n起初，刷《考研数学真题大全解·上册》的时候，因为是之前较早的题目，难度不是很大，所以一口气能刷五六十道，还是很嘚瑟的，而且正确率也有一定的保证。但是刷着刷着就变味了，做着前面的章节忘着后面的，于是在刷题之前，还是得巩固一下知识点，《高数辅导讲义》算是三刷了吧，知识点必须要看，边看边在草稿纸上写写画画，好记性不如烂笔头，况且我还没有好记性，再把之前做标记的题目再给做一遍，但是我发现问题的是，之前会做的题目，现在反而不太会做了，之前不会的还是不会，害。。。对了，《严选题》的质量也是很高的，虽然做的比较慢，十月份结束之前一定要二刷，一定！！加油~~\n但这也是比较好的事情，最起码知道自己的不足，是吧（也只能这么想了）\n线代的话，就是一遍一遍的过讲义，把知识点給串起来。效果也就一遍比一遍要好，有意识的去逼自己思考某个知识点可能会关联的东西。然后再做《李林880》的线代部分，习题线代题目给我的感觉还是比较中规中矩的，不像高数的证明题那么让我感觉无奈，有时候给的感觉就是恰到好处想到那一步。就很爽！\n其实在看线代的时候，心里还是比较没底的，因为分值不是很大，所以投入的时间不是很多，就导致过了一段时间就会有部分知识点遗忘，再加上暑假的时候，看线代的强化课有点太追求进度，听得就有点囫囵吞枣，效果自然也就不咋地，特别是二次型那部分，基于以上原因，就决定重新听一边线代的强化课，带着脑子学习，而不是一味的接受知识。类似的情况还出现在高数的后半部分，多元函数微分学以及二重积分都是理解的不太透彻，所以决定重听一下，这些得在国庆假期完成，又回到了没有课的日子，一定要把握住啊！！\n② 英语 英语，怎么说呢，阅读做起来有点感觉了，但我怕的是因为之前刷过的试卷，所以二刷起来效果还行，就导致一种盲目自信的状态。因为是二刷，阅读在做起来，就在一定程度扫清了生词和长难句，所以读起来没有太磕磕巴巴，做题目也能找到定位点，或者是排除干扰选项，较好的还能分清错误选项是怎么设计出来的。\n但是效果太好，反而有点让我不太适应，我怕这一切都是因为是二刷，是因为我下意识的知道这篇文章是关于什么的，讨论的问题是啥。。。\n至于作文和新题型也还没开始，也不知道该何时开始，也不知该准备哪些资料，头大\n单词肯定是每天必不可少的一个环节，有的时候，不想做阅读，就想着今天我背单词了，所以等于我看英语了，来安慰自己。。。\n③ 专业课 这个月专业课算是正式开始了，目标院校的大纲也更新了，与往年相比变化不是很大，考得范围有的还缩小了，所以在复习层面来说，更具体了。但是具体到某些知识点该考哪些题型的时候，还是比较懵的，不知所云。\n这个怎么说呢，有利有弊，因为从我自己来说并不属于刷题类的学生，也不喜欢刷题，没有历年真题的透漏，等于在一定程度上弥补了这一劣势。但是坏处是，我自己也不知该如何复习。能做的就是一遍一遍的根据考纲过知识点，争取做到没有太大的漏洞。\n数据结构：开始算是二刷了吧，第一边只是侧重于知识点的学习，并没有做太多的题目，这一次看一章，死磕一章的课后习题，选择题做到全部拿下，算法大题目前只做历年 408 真题，有的较怪较难的算法题会考虑直接放弃，进度到二叉树。另外听说学院喜欢考对于知识点的理解，而不是代码本身，所以尽可能要做到掌握理解，用图形来表达其中的逻辑关系。\n数据库：这个算是比较头疼的，首先 SQL 写得就不多，而且还比较烂，看课后习题也只是能看懂答案，让我自己徒手写的话，有很大难度，所以之后的两个月要加强对于 SQL 的练习，这一部分可不能丢分啊！查询优化看的比较懵，就是稀里糊涂的。。。依赖与范式那章就直接差点”要了我的命“，国庆集中处理。至于数据库事务和恢复反而比预期学的要好。\n后期需要根据当前的盲点，不断“扫盲”。\n④ 政治 可算是开始政治了，但是也是九月中下旬才开始的，而且花的时间也不是很多，整体进度是比较拉的。说不着急是假的，但是不能慌。要稳住阵脚，一步一个脚印地往前走。\n因为之前对于哲学比较感兴趣，所以读了一些相关的书籍。学马原的时候，虽然是偏重于理解，反而是比较容易找到共鸣的，能在现实生活中找到投影。刷《肖 1000》正确率也还行。\nBtw，蹲坑的时候，政治刷题小程序效果还是不错的。哈哈哈哈。\n进度得加快，投入时间得多加点，加油！\n三、再出发 为什么说是“再出发”呢？？倒数 100 天，算是比较有仪式感的日子，也预示着距离考研的日子从三位数变成两位数了，时间留给自己的时间不是很多了，得有点紧张感，所以说接下来的每一天如果状态不是很好，都是对这一天的浪费。\n如果把考研分阶段的话，今年三月之前的日子算作“0”，“0”代表着有想考研的想法，也做了一些努力，搜集了一些信息，但是距离真正开始行动，还是有一定的转变的；三月开始到暑假之前属于“1“，在这期间，慢慢开始投入时间和精力准备考研，会觉得考研还早呢，我还有一定的自由时间，复习状态也就还没拉满，整体上是比较放松的，有时候还会啥都抓，导致啥都学了点，但没完全学的尴尬情况；再往后就是暑假”2“，大家都说暑假是至关重要的两个月，因为这段时间完全是自己掌握的，这一点是真的，但没想到的是，在家复习没有学校的学习氛围，每天更要面对许许多多的日常琐事，眼看着自己的进度达不到所想的预期，心烦；九月开学——”3“，状态恢复，更想通了许多问题，所以是在解决了上面”012”的迷茫与不解之后的再出发！\n在预报名成功的那一刻，我不由的说了一句，我等这一刻，等了三年。对，为了考研，我鞭策自己三年。眼看着就要到终点了，不更应该是期待的嘛。而不是焦虑不安，原因是感觉复习的不好，但是还没走进考场，就代表着全部都是未知的，去努力啊！！别停下来！！\n所以说，把心态从焦虑调整到期待之后，每天都会有收获。有的时候还会看一下鸡汤，虽然很俗，但是有用，这段阶段的自己神经是比较敏感脆弱的，需要的是鼓励。\n希望会有好的结果，一定一定一定！！！\n","description":"","tags":null,"title":"大政的考研 Blog007 —— 再出发","uri":"/life/kaoyan007/"},{"categories":null,"content":"Blog006 —— Iridescent，八月复盘 Il n'ya qu'un héroïsme au monde : c'est de voir le monde tel qu'il est et de l'aimer.\n一、暑期生活 1.1 一次又一次被自己打败 过得好快啊，感觉什么都没做，暑假就过去了。。。\n每次在放假之前都会高估自己的能力，常常给自己布置一堆任务，而往往完成的也就两三件，甚至一件都做不好。。。是的，这种状态从中学时期就开始出现，但到现在还依然没有改掉。为什么会给自己选择充电呢，从根本来说，我不想成为一个碌碌无为的人，还是有一颗上进的心的，要不然为什么会选择考研呢。。但事实是，完不成任务还是因为自己太懒，自己不够聪明，一个知识点别人学一遍就能记住掌握，自己却只能听个大概，为了不愿承认自己的能力不够，还硬着头皮往下走，结果到头来发现，欺骗的也只有自己。说白了，就是虚荣心作祟。。\n最要命的是，意识到自己的错误，却改不了！！\n之前上半年在学校临近放假的时候，就一直在想，到了暑假就好了，每天的时间都是自己的了，就能有大把时间用于考研复习，从而可以达到一个由量变到质变的过程。可也就停留在了“想”，与实际付出行动来说还是有很大的差距。\n最主要的体现就是心静不下来，明明知道这是一个难熬的过程，却想着可以早点结束，想着这块内容是不是不太可能会考，我是不是就没必要花太多时间在这儿，总想着投机取巧。不肯脚踏实地，一步一个脚印地慢慢走。也许是高估了自己的行动能力，整个暑假给数学的时间最长，以为自己数学学的还行，到了强化阶段，越复习面对一堆难题无从下手，更是一种逃避的态度，久而久之，对数学是越来越讨厌；其实不止数学，英语和专业课不也是的嘛，英语除了背单词，阅读题更是不想做，硬着头皮啃下一篇之后，就匆匆忙忙去对答案，很多题目都不找原因，为什么错，不去弄明白其逻辑关系；专业课更是三天打鱼两天晒网，不知道该看些什么，看着考纲，无能为力；至于政治，更是可笑至极，说着为了空出时间给其余科目，连碰都没碰，连考些啥内容都不知道……\n所以说整个暑假是什么都没做吗？？也不是吧，虽然状态不是很好，每天的学习时间也不是很长，没有达到自己所预期的目标，但完成了其中的一小半吧，具体的复习情况放在复盘内容。\n很多人说，最大的对手是自己本身。克服自己的懒惰，浇灭自己的虚荣心，改掉不良的习惯，加油啊！！要学会独自去面对风风雨雨，独自在知识的苦海中摸索。\n1.2 我在努力 虽然有很多坏习惯，但是我一直在努力改变自己，不求能够有多好，但保证不会越来越差。\n自习室八点半开门，知道晚起毁一上午，但明白早起毁一天，所以一般来说选择七点多起床。尝试过五六点起来背单词，困得不行；也有过睡到八点多再起来，但是到自习室都将近九点半，从而导致一上午背完单词，再做几题高数就中午了，效率太差。慢慢调整选择一个比较适合自己的时间。一开始刚放假，可能是在学校“憋”了太久，看书回来家就比较晚。吃完饭，洗好澡，十点多，就导致家里人的作息都被我打乱。考研是我自己所决定的，虽然说爸爸妈妈都很支持我，但是不能影响他们第二天工作，（主要还是爸妈比较心疼我，）所以就适当的回家早一点，这样一家人可以一起吃一口热乎的饭。\n看书看不下去，想着想哪，一会刷一下朋友圈，一会又看一下小破站。只能硬逼着自己改变，手机屏幕使用时间限时，朋友圈关闭，B 站换成青少年模式，取关不太有意义的博主。不想做题，就看着题目想思路，想不出就看答案，再自己在稿纸上演算一遍，还能怎么办呢？又不能真的不做，做不到主动，只能改变自己从被动的层面吸取知识。英语阅读啃不下来，先翻译，扫清生词和长难句，最起码做到能读懂再说，再根据阅读方法论慢慢梳理题目以及段落之间的逻辑关系，最后再看看讲解视频。没办法，学不下去啊，只能这样了，我也真的无能为力了，我甚至开始怀疑自己并不适合学习，才到这个点就耐不住性子了，开始急了。我也不知到底怎么做是对的，只能敷衍着走，最起码不愿意承认自己停下！\n1.3 折磨？调整？ 说起自己状态开始变差还得从六月底 AirPods Pro 丢了开始说起。说不心疼吧，是假的。至今我还能记起第一次带上降噪耳机的感觉，整个世界都安静了。原来自己每天生活的环境噪声这么大，这么小的机身是如何做到这么强的功能的…… 特别新奇和不可思议是当时的感觉。但随着慢慢习惯降噪之后，那种一开始的新鲜感也早已见，也许是耳机麦克风堵住了，降噪就变菜了。。作为苹果生态的一环，在手机和 iPad 切换也早已习惯。在丢了的那几天，就好像是少了好多东西，哪哪都不舒服，就这样开始不想学习。起初也想过买个华强北的。但是吧，买山寨不是我的习惯，再买个全新的？？感觉不值。暑期教育优惠，换个 MacBook 或者换个 iPad Pro 送耳机？？但是更期待 M2 芯片，自己的 iPad Air3 用起来也不差，就很烦。对这种状态一直环绕着初期。到七月底。每天被这些事情闹心。。。\n后来，慢慢想开了，其实自己或许也不依赖一副耳机，也或许并不一定要用苹果生态下的产品？？为了整个生态，舍弃了自己客制化的习惯，开始对于处理器、芯片、刷新率等不再讲究，音质也不再挑剔，似乎就感觉苹果的生态是最屌的，舍弃点有啥关系呢。就这样变成了韭菜。也就这样，我看上了 Sony WF 1000 XM4，体积不大，续航强，佩戴舒适度属于能接受的范围，没有生态。。。。但这又有啥呢，一再犹豫之后，在 AirPods Pro 丢了两个月之后，还是入手了 XM4。降噪的天花板，也让相信了蓝牙耳机也可以有音质。时隔两个月重新又有了降噪，虽然各方面能力都比 AirPods Pro 好得多，但第一次带上降噪的感觉再也回不来了。\n但我的状态回来了……\n在快对自己失去信心的时候，找回了之前的状态，虽然还没满血复习，但是足够了！！\n对了，顺便提一下，暑假期间我又迷上了变形金刚。这个算是我从小喜欢到大的 IP 了吧。虽然每天看柱子哥模型的评测浪费了不少时间，害……等上岸奖励自己一个，一定。（当时纠结要不要买柱子哥，买了 XM4 之后，就说等等吧，该有的都会有）\n最后再补上，还有奥运会。马龙太帅了，今年好像是在 08 年之后，再一次这么关注奥运会了，看见五星红旗在东京升起，国歌奏响的那一刻，民族自豪感油然而生。我们生活在一个这么好的时代，国家提供了安稳的环境，作为新时代的我们也应该奋发努力，想想再过十年左右社会的中流砥柱就是咱们这代人了！\n二、八月复盘 很遗憾，暑假的计划并没有完成。。\n① 数学 分别听完了高数和线代的强化课程，但也仅仅是听完了而已。距离消化里面的知识还有一段路需要走。看讲义，做例题，还需要克服自己好高骛远的尿性，不能不懂装懂，还要勤动手，答案是算出来的，而不是看出来的。\n原以为八月能够把高数讲义重新过一遍，但是很遗憾，一遍看讲义然后做严选题和 08 年以前的考研真题，效率是真跟不上，才到第二章结束。但好处是前两章的知识点很牢固，从基本的定义题目（这类题目我感觉是很恶心的）到计算，再往后是压轴的证明题，都可以应付的来，也并不是像自己所想的那样啥思路都没有。坏处是后面的又给忘了，特别是常微分方程和多元微分学，一看就会，会了就忘。还得努力啊！！\n起初，做严选题太难，就转去做宇哥的真题大全解上册，给自己找点求生欲吧。后来一想，考研不会考简单的，要学会迎难而上。啃严选题的时候，给我最大的感受就是，这题我应该会做，但不是那么好做，最后往往会停留在应该上。。给题目做好标记分类。一遍一遍来，反复磨，总会完成的。\n线代的话，因为之前看完基础课的时候，就顺带把讲义过了一遍，这次的复习感觉比听基础课要好得多。但到了后面的章节之后，越来越综合，知识点稍有不牢，就不知这个为什么是这样，这一步是哪来的。课程内容不是很多 5 天，但我花了将近 15 天才全部看完。中间真的不能耽搁，一落下，很难追上。再刷讲义，也比之前有了更多思考，也想的更多，牵涉到的知识点，也算是一种巩固的过程。\n今晚听了武神的直播答疑，说强化阶段是到 10 月底，这无疑是一针强心针，可以告诉自己不要慌，进度并没有落太远。慢慢来，比较快，加油！\n② 英语 英语就有点玄学，除了背单词能记住（其实也不一定记住了）。阅读还是很难有底。做完了之后，站在上帝视角来分析，会觉得确实是那么一回事，但自己做题的时候为什么就想不到呢。知行合一？？只是知道方法论，做不对题目的知道，算是知道吗？\n在月底的时候梳理这两个月做过的阅读，还是挺有成就感的。看着原来白纸黑字的被一片片红笔的注释不成样子（错的不成样子）也确实有点难受的。不能说没有掌握阅读方法论，但就是还缺点什么，不像做数学题目那样，只要是我自己做出的就不会出错。\n小三门之类的也快要提上日程了，英语的时间要要延长点了。\n③ 专业课 七月说专业课每天 1.5 小时起步，还是没做到。\n数据结构结合考纲把知识点提出来了，但问题是不知道考试题目会考到哪种程度，是只考一些定义性质，还是会考代码呢，考这些又会怎么考呢？？\n数据结构就是感觉零碎的知识点好多，做题之前过一遍的话，题目都是会做的但是时间一长就容易忘记。。而且对于数据数据结构考纲比较迷，像栈牵涉到的中缀表达式、图涉及到的求关键路径之类的，王道的书上有，但是考纲上写得比较迷糊的不知道该不该看，以及题目的形式都好迷。。\n数据库，很碎很杂很多，有点像文科但它又不是。。其中像关系代数、元组演算之类的自我感觉不会考（蜜汁自信），因为掌握的不太好。。但是像 SQL 感觉理论上属于必考的，数据库不写 SQL 说不过去吧，至于考得有多难，掌握到什么程度又不知该如何。\n④ 政治 看不下书的时候，看政治打发时间必备~~\n九月份马原\n三、Iridescent 世界上只有一种真正的英雄主义，就是认清了生活的真相后还依然热爱它。\n我知道考研难熬，但我没想到是如此煎熬。暑假的复习状态几乎一直处于复习的低谷。好几次出现了弃考的想法，总想着也许自己就这样了吧，不是块学习的料，不适合学习。起初想考研更多是对高考遗憾的一种弥补，也是怕自己到时候啥都不会找不到工作。\n但现在看来这两样似乎也就那么一回事，那么我考研的意义又在哪里呢？研究生的生活又会想是自己所期望的那样吗？或者说，自己真的有想过读研的生活是哪样的嘛？也许我就是单纯的不知自己该干嘛所做出的一种逃避呢？？\n忽然想起自己以前的博客说过，我也想成为一个闪闪发光的人。\n考研与其说是孤独朝圣，倒不如说是与自己的对话。学习如逆水行舟，学海无涯。面对知识的敬畏，自己的内心到底会怎么做。走下去，卷入无尽深渊，退出，接受自己的平庸无能？？有时候还会想读书有什么用？人活着的目的又在哪？人该追求些什么呢？当今社会的价值观如此畸形，自己的价值观又该如何评判呢？\n好吧，我承认，考研真的很容易胡思乱想。人均哲学家。。。。\n说到底，我想成为一个有能力的人。进一步的话，成为一个有能力影响他人的人。\nDo you feel cold and lost in desperation\nYou build up hope but failure's all you've known\nRemember all the sadness and frustration\nAnd let it go\nLet it go\n","description":"","tags":null,"title":"大政的考研 Blog006 —— Iridescent","uri":"/life/kaoyan006/"},{"categories":null,"content":"Hadoop 极简入门 零、前言 在 2021 年初的时候，Apache 退休了一些 Hadoop 生态圈的子项目。再加上其 MapReduce 思想最为人诟病，因为不太友好的编写代码方式，需要高昂的维护成本以及较低的运行效率，唱衰 Hadoop 的声音（甚至对于整个大数据生态的质疑声）日益高涨。。\n然而，MapReduce 作为一种编程范式，恐怕并没有那么容易被淘汰。纵使很多人说：你看 Spark 速度又快又稳定，这不是可以淘汰掉 Hadoop 的 MapReduce 吗？但是真的是这样吗？？\n所谓的快和慢都是相对而言的。某些互联网公司每天的离线调度任务动辄数十万起，这么庞大的基于 MapReduce 的离线计算如果要是用 Spark 来替代，与之相对应的是高昂的服务器成本。\n因此，我们可以说原来用 Hadoop MapReduce 能做的事情被更好更快的其他计算引擎来替代了，而不是 MapReduce 被淘汰了。而且后来的计算引擎也大都有借鉴 Map、Reduce 这类的概念！\n一、长话短说 1.1 Hadoop 是什么？？ Hadoop 是 Apache Software Foundation 开源的，根据 Google 开源的三篇大数据论文设计的，一个能够允许大量数据在计算机集群中，通过使用简单的编程模型进行分布式处理的框架。其设计的规模可从单一的服务器到数千台服务器，每一个均可提供局部运算和存储功能。Hadoop 并不依赖昂贵的硬件以支持高可用性。Hadoop 可以检测并处理应用层上的错误，并可以把错误转移到其他服务器上(让它错误，我在用别的服务器顶上就可以了)，所以 Hadoop 提供一个基于计算机集群的、高效性的服务。\n1.2 主要优势 主要拥有以下优势：\n高可靠性：Hadoop 底层维护多个数据副本，所以即使 Hadoop 某个计算元素或存储出现故障，也不会导致数据丢失； 高扩展性：在集群间分配任务数据，可方便地扩展数以千计的结点； 高效性：在 MapReduce 的思想下，Hadoop 是并行工作的，以加快任务处理的速度； 高容错性：能够自动将失败任务重新分配。 1.3 发展 经过多年的发展，Hadoop 这个单词的意思也随之发生改变，由之前一个具体项目的名称，到现在提到 Hadoop 大多是指大数据的生态圈，包括许多现在火的一腿的项目，例如 Spark、Hive、HBase 等等。\n如同 Spring 框架有着最基础的几个模块 Context、Bean 和 Core。其余的模块和项目都是基于这些模块构建的。Hadoop 与之大体一样，也有最基础的几个模块：\nCommon：支持其它模块的公用工具包； HDFS：一个可高吞吐访问应用数据的分布式文件系统； Yarn：一个管理集群服务资源和任务调度的框架； MapReduce：基于 Yarn 对于大数据集群进行并行计算的系统。 其他的，像 Hbase、Hive 等等都是在这几个模块基础上的高级抽象。Common 模块是 Hadoop 最为基础的模块，负责为其余模块提供了像 I/O、操作文件系统、序列化和远程方法调用等最为基础的实现。（如果想深入了解 Hadoop 具体实现的小朋友，可以挑战自己阅读一下 Common 的源码~~）\n二、HDFS 基础概念 HDFS 是 “Hadoop Distributed File System”的首字母缩写，是一个分布式文件系统，说简单点就是为了存储文件。但是和其他的文件系统的不同之处是 HDFS 设计为运行在低成本的硬件上（因此在学习 Hadoop 入门的时候，可以使用 Linux 虚拟机搭建一套集群出来玩玩），且提供高可靠性的服务器。HDFS 设计满足大数据量，高吞吐的应用情况。\n为了更好地理解分布式文件系统，咱们先看看下面的这些概念：\n2.1 文件 咦？谈起文件，想必大家都很熟悉，在不同的行业中，文件也有着不同的意思。在计算机科学领域，文件是在存储设备中是 N 个字节序列。而从计算机使用者的角度而言，文件是对所有 I/O 设备的抽象。每个 I/O 设备都可以视为文件，包括磁盘、键盘和网络等等。文件这个简单而精致的概念其内涵是十分丰富的，它向应用程序提供了一个统一的视角，来看待系统中可能含有的各式各样的 I/O 设备。\n2.2 文件系统 那么一台计算机上肯定不止一个文件，成千上万的文件怎么管理呢？因此需要我们需要一种对文件进行管理的东西，即文件系统。文件系统是一种在计算机上存储和组织数据的方法，它使得对其访问和查找变得容易，文件系统使用文件和树形目录的抽象逻辑概念代替了硬盘和光盘等物理设备使用数据块的概念，用户使用文件系统来保存数据而不必关心数据实际保存在硬盘的地址为多少的数据块上，只需要记住这个文件的所属目录和文件名。在写入新数据之前，用户不必关心硬盘上的那个块地址没有被使用，硬盘上的存储空间管理(分配和释放)功能由文件系统自动完成，用户只需要记住数据被写入到了哪个文件中即可。\n2.3 分布式文件系统 相对于单机的文件系统而言，分布式文件系统（Distributed file system）。是一种允许文件通过网络在多台主机上分享的文件系统，可让多计算机上的多用户分享文件和存储空间。\n在这样的文件系统中，客户端并非直接访问底层的数据存储区块和磁盘。而是通过网络，基于单机文件系统并借由特定的通信协议的帮助，来实现对于文件系统的读写。\n分布式文件系统需要拥有的最基本的能力是通过畅通网络 I/O 来实现数据的复制与容错。也就是说，一方面一个文件是分为多个数据块分布在多个设备中。另一方面，数据块有多个副本分布在不同的设备上。即使有一小部分的设备出现离线和宕机等情况，整体来说文件系统仍然可以持续运作而不会有数据损失。\n注意：分布式文件系统和分布式数据存储的界线是模糊的，但一般来说，分布式文件系统是被设计用在局域网，比较强调的是传统文件系统概念的延伸，并通过软件方法来达成容错的目的。而分布式数据存储，则是泛指应用分布式运算技术的文件和数据库等提供数据存储服务的系统。\n2.4 HDFS HDFS 正是 Hadoop 中负责分布式文件系统的。HDFS 采用master/slave 架构。一个 HDFS 集群是由一个Namenode（可以理解为资本家老板） 和一定数目的 Datanodes（打工人） 组成。Namenode 是一个中心服务器，负责管理文件系统的命名空间以及文件的访问控制。集群中的 Datanode 一般是一个设备上部署一个，负责管理它所在节点上的存储。HDFS 暴露了文件系统的命名空间，用户能够以文件的形式在上面存储数据。\n实际上，一个文件会被分成一个或多个数据块，这些块存储在一组 Datanode 上。Namenode 执行文件系统的命名空间操作，比如打开、关闭、重命名文件或目录。它也负责确定数据块到具体 Datanode 设备的映射。Datanode 负责处理文件系统客户端的读写请求。在 Namenode 的统一调度下进行数据块的创建、删除和复制。为了保证文件系统的高可靠，往往需要另一个 Standby 的 Namenode 在 Actived Namenode 出现问题后，立刻接管文件系统。\nHDFS 架构概述 NameNode（nn）：存储文件的 元数据，如文件名、文件目录结构、文件属性（生成时间、副本数、文件权限），以及每个文件的 块列表 和 块所在的 DataNode 等等； DataNode（dn）：在本地文件系统 存储文件块数据。以及 块数据的校验和； SecondaryNameNode（2nn）：每隔一段时间对 NameNode 元数据备份（把 NameNode 当做老板的话，SecondaryNameNode 就相当于小秘，但小秘毕竟是小秘备份的数据肯定没有老板完全，所以在掌握 Zookeeper 之后可以配置 HA，也就是说两个 NameNode 互相备份）。 三、MapReduce 基础概念 MapReduce 是一个使用简单的软件框架，基于它写出来的应用程序能够运行在由上千个商用机器组成的大型集群上，并以一种可靠容错的方式并行处理上 T 级别的数据集。\n一个 MapReduce 作业(job)通常会把输入的数据集切分为若干独立的数据块，由 map 任务(task)以完全并行的方式处理它们。框架会对 map 的输出先进行排序， 然后把结果输入给 reduce 任务。通常作业的输入和输出都会被存储在文件系统中。 整个框架负责任务的调度和监控，以及重新执行已经失败的任务。\n通常，MapReduce 框架和 HDFS 是运行在一相同的设备集群上的，也就是说，计算设备和存储设备通常在一起。这种配置允许框架在那些已经存好数据的设备上高效地调度任务，这可以使整个集群的网络带宽被非常高效地利用。\nMapReduce 框架由一个单独的 master JobTracker 和每个集群设备一个 slave TaskTracker 共同组成。master 负责调度构成一个作业的所有任务，这些任务分布在不同的 slave 上，master 监控它们的执行，重新执行已经失败的任务。而 slave 仅负责执行由 master 指派的任务。\n用户编写的 MapReduce 应用程序应该指明输入/输出的文件位置(路径)，并通过实现合适的接口或抽象类提供 map 和 reduce 函数。再加上其他作业的参数，就构成了作业配置(job configuration)。然后，job client 提交作业(jar 包/可执行程序等)和配置信息给 JobTracker，后者负责分发这些软件和配置信息给 slave、调度任务并监控它们的执行，同时提供状态和诊断信息给 job-client。\n简单来说，MapReduce 将计算过程分为两个阶段：Map 和 Reduce；\nMap 阶段并行处理数据； Reduce 阶段对 Map 结果进行汇总。 一个 Map 函数就是对一些独立元素组成的概念上的列表的每一个元素进行指定的操作。事实上，每个元素都是被独立操作的，而原始列表没有被更改，因为这里创建了一个新的列表来保存操作结果。这就是说，Map操作是可以高度并行的。而 Reduce 函数指的是对 Map 函数的结果（中间经过洗牌的过程，会把 map 的结果进行分组）分组后多个列表的元素进行适当的归并。\n四、Yarn 基础概念 YARN(Yet Another Resource Negotiator)是 Hadoop 的设备资源管理器，它是一个通用资源管理系统，MapReduce 和其他上层应用提供统一的资源管理和调度，它为集群在利用率、资源统一管理和数据共享等方面提供了巨大的帮助。\nYarn由ResourceManager、NodeManager、ApplicationMaster 和 Containe 四个概念构成。\nResourceManager（RM）：整个集群资源（内存、CPU 等）的老大； NodeManager（NM）：单个结点服务器资源老大； ApplicationMaster（AM）：单个任务运行的老大； Container：容器，相当于一台独立的服务器，里面封装了任务运行任务所需要的资源，如内存、CPU、磁盘、网络等。 了解了上面的大致概念之后，再细细分析一下：\n4.1 ResourceManager ResourceManager 是一个全局的资源管理器，负责整个系统的资源管理和分配。它主要由两个组件构成：调度器(Scheduler)和应用程序管理器(Applications Manager)。\n调度器根据容量、队列等限制条件，将系统中的资源分配给各个正在运行的 MapReduce 程序。应用程序管理器负责管理整个系统中所有 MapReduce程序，包括提交、与调度器协商资源以启动 ApplicationMaster、监控 ApplicationMaster 运行状态并在失败时重新启动它等。\n4.2 NodeManager NodeManager 是每个设备上的资源和任务管理器，一方面，它会定时地向 ResourceManager 汇报本设备上的资源使用情况和各个Container 的运行状态；另一方面，它接收并处理来自ApplicationMaster 的 Container 启动/停止等各种请求。\n4.3 ApplicationMaster 用户提交的每个 MapReduce 程序均包含一个 ApplicationMaster，主要功能包括：与 ResourceManager 调度器协商以获取资源(用 Container 表示)；将得到的任务进一步分配给内部的任务(资源的二次分配)；与 NodeManager 通信以启动/停止任务；监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务。\n4.4 Container Container 是 YARN 中的资源抽象，它封装了某个设备上的多维度资源，如内存、CPU、磁盘、网络等，当 AM 向 RM 申请资源时，RM 为AM 返回的资源便是用 Container 表示。\n五、结束语 本文走马观花的介绍了 Hadoop 相关内容。主要目的是给大家一个对大数据的分布式解决方案的感官印象，为后面的大数据相关文章提供一个基础的理解。\n最后要强调的是，思考大数据方向的问题是一定要记住分布式的概念，因为你的数据并不在一个设备中甚至不再一个集群中，而且计算也是分布的。所以在设计大数据应用程序时，要花时间思考程序和算法在单机应用和分布式应用所产生的不同(e.g. 加权平均值)。\n","description":"","tags":null,"title":"Hadoop001——入门篇","uri":"/tech/bigdata/bigdata_hadoop001/"},{"categories":null,"content":"Blog005 —— 事上炼，七月复盘 一、恍惚 1.1 怂了？？ 这才到哪了呢，就怂了！！明明每天给自己布置的任务量不是很大，却还是一次又一次高估自己的执行能力，整个七月份下来，没有几天实际上完成目标的。但是，平均下来给自己每天的任务量确实不是很大啊，但为什么就完成不了呢？？一身的小毛病却不能克服自己，总给自己找各种各样的理由，来推脱学习。王福政啊，你现在的思想和态度都很危险知不知道！！！当你的行动能力和效率无法满足自身的野心的时候，除了抱怨，怨天尤人还能做些什么呢？？\n以上，大概是这段时间，反反复复对自己说的话。虽然想放弃是真的，但认怂是不可能认怂的！！！\n考研过程中的备考压力远远超出我心里的预期，比我想的要难受的多。这也是为什么想要放弃的原因，似乎放弃了，就退出备考的赛道，可以好好的缓一口气，也就不会面对煎熬，不会面对失败，但也意味着辜负了父母的期望，前期的准备都是为了见证这一刻的放弃，承认自己的软弱。如果放弃，每次遇到点啥磕磕绊绊的象征性的坚持一两下，就会怀疑自己做不到，想逃避，下意识的想退缩。也就这样成为一个懦夫……\n所以说，认怂是不可能认怂的。当时做出准备考研的决定，并不是头脑一热，更多的是因为有自己想做的事情，寻找自己的闪光点，努力成为一个能够影响别人的！！！如果这时候选择了低头，这不就成了别人口中的反面教材了嘛。。多丢人啊，是不！！想放弃也许是多个坚持不下来的瞬间累计导致的，但选择站起来勇敢的直面这些瞬间，是自己能到做出的回应。认怂的话，自己心里说说就好，可别真的怂了哈~~ 坚持下去，一步一个脚印。\n1.2 长跑心态 7 月份，过得是真的快。当时想着放暑假了，没有学校那么多杂七杂八且无意义的事情，总算可以“闭关修炼”了。事实却是，整体上和学校的学习效率差不太多，又一次没达到预期，高估了自己。这也是为啥想放弃的原因，开始质疑自己，甚至有时候感慨自己真的不是学习的料。中高考考得都不咋地，还想考着考研翻身，这是有点痴心妄想嘛，别坚持五六年的努力，你一年就能跟得上？？但是，就这样认输，会有点不甘心。\n现在的世界好处是信息多而广，且好获得。但坏处是干扰信息太多。往往也是这些干扰信息最搞人心态！！！无论是知乎，还是 B 站、公众号之类的平台，凡是可以传播信息的地方都会出现标题党。最让我恶心的就是“考研人一天学习 XX 小时”、“如何保证一天有效学习 XX 小时”之类的文章或视频。给你一种感觉就是：反正我学能学到这么长时间，早上 6 点就能背单词，晚上 11 点还在复盘。如果你达不到这种程度，你自己看着办吧。WDNMD，您可真能学习啊！！！我自己是一个极其懒的人，能早上八点起来绝不起点起来看书的那种，而且注意力也很难集中。每当做一件事的时候，总会控制不住自己想另外一件事情。仔细想想，每天花在考研上的有效时间不超过四个小时每天。但就是在这种情况下，进度还能跟得上。所以我特别想知道那些每天做到学习八小时以上的是学到了什么程度。这也是我之前所提到的 考研在没有上考场的情况下，所有的参照物都是无用的。\n上面扯了那么多，不是想说我摸鱼都能学到这种程度，也不是想吐槽那些“卷王”，只是想说，我天天那么混都觉得好累！！！更何况现在才到备考中期强化阶段，距离考研还有五个月左右的时间该怎么熬啊！！考研不是短距离冲刺，不是说这段时间坚持坚持突击搞一下就行。更像是一场马拉松，虽然知道终点线，但一路上的磕磕绊绊，遇到哪些荆棘都是未知的。一路上没人能够帮你走下去，只有你自己。这也就有了“孤独朝圣”这一说话。更像是一场与自己的修行。但与马拉松不同的是，你还不知道你的对手如何。\n之前总是听考研的过来人说，别开始那么早，战线别拉太长。当时自己想的是，我能坚持，我要变强。也许按照当时的心态是可以坚持的，但随着距离考研越来越近，焦虑感、压迫感就会慢慢左右心态。所以能做到的只能是，调整好自己，给自己足够的弹性空间，在不那么长的学习时间内，保持自己最高的效率来学习。说白了，没有人说学多长时间就一定能够上岸的。干嘛那么折腾自己呢。。。\n1.3 当 代 毕 业 生 生 存 现 状 一个普通青年毕业后的生存故事。虽然距离毕业还有一年，但从小金身上或多或少看到了点自己的影子：从怀着赤子之心，想着要成为一个对社会有用的人，到慢慢遇到很多不情愿的事情，渐渐地磨平自己的棱角，但好在我还是我。正如罗曼·罗兰所说：世界上只有一种真正的英雄主义，就是认清了生活的真相后还依然热爱它 。当看到这个视频中小金将视频通话转成语音的时候，破防了。。。似乎，这半年来的心酸、难受都在那一刻哭了出来。就想到自己，这半年来有好几次我妈给我开视频，都被我给转成语音，也不知道是什么原因，至少不想让家里人看到我丧的那一面。成长，也许就是从小时候有什么委屈哇的一声在母亲的怀抱里就能哭出来，到习惯了报喜不报忧，让爸妈少为自己操点心，告诉他们自己过得还不错，我没有止步，还在努力。\n我不要在孤独失败中死去\n我不要一直活在地下里\n物质的骗局\n匆匆的蚂蚁\n没有文化的人不伤心\n二、七月复盘 这个月的复盘要严格批评自己，学习效率太差！！！\n① 数学 7.23 完成高数强化阶段的全部课程。本预计还空出一周时间留出来查缺补漏，但事与愿违，可能是真的学倦了，然后台风暴雨刚好给自己一个偷懒的理由，最后一周没有认真学习。八月加油吧！！\n总体上武神的强化课干货上是没得说的，但不幸的是听起来太痛苦，有的章节要是死磕的话需要听好几遍才有点效果。没有听宇哥的课有那么多快乐。强化阶段确实是比较过瘾的，没有基础阶段的苦恼，不用扣定义，更倾向于做题，属于学会即用，所见即所得的感觉，说直白点就是过瘾，当看见讲义上一道道被自己画 pass 的题号越来越多，成就感也是满满。但有时候题目做不出来的挫败感也是十分闹心的……\n高数整个强化下来，对于考试的侧重点有了个了解，题型以及考点之类的啊，不像之前那样啥都抓，往往是哪都不熟悉。高数的盲点少了点吧，难点无非还是证明不太会，盲点的话是定义类的选择题。不熟悉的地方就是定积分的物理应用吧，也不能说是不会只是不熟悉，需要点题目来积累信心。对于基本知识的应用理论来说没什么问题，具体的掌握的好与不好，还得靠之后的题目来检测。\n《严选题》还没开工，之前看有些同学说这本习题册的难度是有的，看来又是一段煎熬时光。\n预计八月十号之后开始线性代数的强化。十五天之内务必完成。这样一来，八月就完成了所有的强化课程。接下来就是刷题。千题百炼，加油吧！！！\n② 英语 英语这个月进度有点拉。除了每天坚持背 45 分钟单词，阅读有点三天打鱼两天晒网，八月需要调整过来，至少两天一篇。\n课程上，重新听了一遍唐叔的阅读方法论和长难句，阅读方面确实有提升，但是长难句越听越混，总体来说阅读能力有所提升。错误率控制在每篇一到两个，能够分别出不同的题目怎么解题，解题不到位的情况大部分还是文章读不太懂，少许是解题方法的错误，易错点：猜测题，无法联系上下文逻辑。比较擅长例证题、作者态度、中心思想之类的题目。实践出真知，好事多磨。\n③ 专业课 专业课则是放慢了脚步，结合考纲（害 终于想起来我们是有考纲的，而不是 408 的 DS）把数据结构的知识点做了个梳理，这一轮下来，对于专业课上，心更静了。不会有种飘飘然的感觉。花了一个月时间都是数据结构，数据库方面还是前三章。对于后面的内容就交给八月份吧。\n底线：每天 1.5 个小时起步，再不花时间，等后期只会干着急，等着哭吧！！！\n④ 政治 这玩意怎么说呢，我书都没带。但是说不着急，心里还是慌的。所以把徐涛的强化课当下饭视频看着玩，给到点心里安慰吧~~\n三、可以的！ 写到这的时候，我又回头看了看之前的博客，似乎给人的感觉是怨气有点重，就好比是深处深渊，却不甘于此，于是一步一步地前进。用努力去创造属于自己的那一份荣耀。更多是挣扎之后的倔强。虽然好像连续的这几个月都说着好难啊，好累啊的话，但如果我自己都不给自己点鼓励，那么谁还会相信我可以呢？？\n事上炼，谈何容易？？考研与其说是一段备考的经历，更像是一次寻找自己的过程，每当遇到困难的时候，每一次迷茫绝望都是和自己对话的过程。唯有练就强大的内心，才能坚定的向上走，迈向更高的台阶。\n光阴里的每一步都是修行，不知之间早已 自渡''。\n","description":"","tags":null,"title":"大政的考研 Blog005 —— 事上炼","uri":"/life/kaoyan005/"},{"categories":null,"content":"Maven 常见问题处理方法 一、'npm install node-sass --unsafe-perm' failed 报错信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 02:01 min [INFO] Finished at: 2021-07-10 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.6:npm (npm install node-sass --unsafe-perm) on project dolphinscheduler-ui: Failed to run task: 'npm install node-sass --unsafe-perm' failed. java.io.IOException: Cannot run program \"dolphinscheduler-dev\\dolphinscheduler-ui\\node\\node.exe\" (in directory \"dolphinscheduler-dev\\dolphinscheduler-ui\"): CreateProcess error=193, %1 不是有效的 Win32 应用程序。 -\u003e [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException [ERROR] [ERROR] After correcting the problems, you can resume the build with the command [ERROR] mvn \u003cargs\u003e -rf :dolphinscheduler-ui 错误分析：\n当执行 mvn -U install package -Prelease -Dmaven.test.skip=true 的时候，由于前端 Module 的 pom.xml 对于 NodeJs 没有配置对应的镜像，并且有某堵墙的存在，懂的都懂不多说哈，从而导致无法能够成功的拉去对应的资源，因此需要在对应的 pom.xml 文件中添加相关配置即可。\n解决方法：\n1 2 3 4 5 6 7 8 9 10 11 12 \u003cexecution\u003e \u003cid\u003einstall node and npm\u003c/id\u003e \u003cgoals\u003e \u003cgoal\u003einstall-node-and-npm\u003c/goal\u003e \u003c/goals\u003e \u003cconfiguration\u003e \u003cnodeVersion\u003e${node.version}\u003c/nodeVersion\u003e \u003cnpmVersion\u003e${npm.version}\u003c/npmVersion\u003e \u003cnodeDownloadRoot\u003ehttps://npm.taobao.org/mirrors/node/\u003c/nodeDownloadRoot\u003e \u003cnpmDownloadRoot\u003ehttps://registry.npm.taobao.org/npm/-/\u003c/npmDownloadRoot\u003e \u003c/configuration\u003e \u003c/execution\u003e 注： 其中 nodeDownloadRoot 和 npmDownloadRoot 为添加的淘宝镜像，如果添加该配置还无法解决问题，可以尝试把 node 和 npm 的 version 置换成本机所安装的版本即可。\n二、Could not transfer artifact org.springframework.boot:spring-boot-starter-parent:pom:2.1.18.RELEASE from/to central 报错信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Caused by: org.apache.maven.project.ProjectBuildingException: Some problems were encountered while processing the POMs: [ERROR] Non-resolvable import POM: Could not transfer artifact org.springframework.boot:spring-boot-starter-parent:pom:2.1.18.RELEASE from/to central (http://repo.maven.apache.org/maven2): Failed to transfer http://repo.maven.apache.org/maven2/org/springframework/boot/spring-boot-starter-parent/2.1.18.RELEASE/spring-boot-starter-parent-2.1.18.RELEASE.pom. Error code 501, HTTPS Required @ org.apache.dolphinscheduler:dolphinscheduler:1.3.6-SNAPSHOT, D:\\ideaProjects\\dolphinscheduler-dev\\pom.xml, line 165, column 25 at org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:176) at org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:102) at io.airlift.resolver.ArtifactResolver.getMavenProject(ArtifactResolver.java:177) ... 44 more Caused by: org.apache.maven.model.building.ModelBuildingException: 1 problem was encountered while building the effective model for org.apache.dolphinscheduler:dolphinscheduler-registry-zookeeper:1.3.6-SNAPSHOT [ERROR] Non-resolvable import POM: Could not transfer artifact org.springframework.boot:spring-boot-starter-parent:pom:2.1.18.RELEASE from/to central (http://repo.maven.apache.org/maven2): Failed to transfer http://repo.maven.apache.org/maven2/org/springframework/boot/spring-boot-starter-parent/2.1.18.RELEASE/spring-boot-starter-parent-2.1.18.RELEASE.pom. Error code 501, HTTPS Required @ org.apache.dolphinscheduler:dolphinscheduler:1.3.6-SNAPSHOT, D:\\ideaProjects\\dolphinscheduler-dev\\pom.xml, line 165, column 25 at org.apache.maven.model.building.DefaultModelProblemCollector.newModelBuildingException(DefaultModelProblemCollector.java:195) at org.apache.maven.model.building.DefaultModelBuilder.build(DefaultModelBuilder.java:419) at org.apache.maven.model.building.DefaultModelBuilder.build(DefaultModelBuilder.java:371) at org.apache.maven.model.building.DefaultModelBuilder.build(DefaultModelBuilder.java:362) at org.apache.maven.model.building.DefaultModelBuilder.build(DefaultModelBuilder.java:232) at org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:142) ... 46 more Process finished with exit code 1 错误分析：\n在网上拷贝的所有阿里云镜像比如：\n1 2 3 4 5 6 \u003cmirror\u003e \u003cid\u003enexus-aliyun\u003c/id\u003e \u003cmirrorOf\u003ecentral\u003c/mirrorOf\u003e \u003cname\u003eNexus aliyun\u003c/name\u003e \u003curl\u003ehttp://maven.aliyun.com/nexus/content/groups/public\u003c/url\u003e \u003c/mirror\u003e 查看官网之后发现：阿里不再支持http下载，只支持https。\n因此，先将maven镜像配置如下：\n1 2 3 4 5 6 \u003cmirror\u003e \u003cid\u003ealiyunmaven\u003c/id\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003cname\u003e阿里云公共仓库\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/public\u003c/url\u003e \u003c/mirror\u003e 然后还出现了一个问题，由于使用了HTTPS，存在着 SSL 证书验证的问题，因此需要在 IDEA 中添加了一行配置 Maven —\u003e Importing —\u003e VM options for importer:\n-Dmaven.wagon.http.ssl.allowall=true\n一般到这里问题理论上是可以正常解决了，但是由于 Windows 的环境会出现许多神奇的问题，如果项目还依然报错，可以尝试删除本地包，重新构建。\n","description":"","tags":null,"title":"Maven 配置问题汇总","uri":"/tech/datastructes/question001/"},{"categories":null,"content":"Blog004 —— 拼个世界给自己，六月复盘 一、瓶颈期 1、一条路走到黑 考研就像是在黑屋子里洗衣服，看不见洗到什么程度，也不知道自己和别人差在哪里，自己低头拼命的洗，只有打开灯的时候，拿出自己的衣服，才能知道结果如何，但在这一过程中难免也会有感觉洗不动的时候。\n不知不觉半年过去了，这半年宛如一个人走一条只知道目的地，但是却不知该怎么走的黑路，很多时候感到迷茫，感到困惑，明知道某个点该歇一歇，但就是不敢停下脚步，生怕自己一旦停下，被别人超越，就再也追不回了。考研和高考相比，不清楚自己的竞争对手，也就没有有效的对比，不知道该做到什么程度才算是好，才能达到了某个时间点该有的样子。毫无头绪。\n其实这半年来，每个月总有几天学不下去的时候，还记得当时三月底，怀着急功近利的目的，开始肝《十天搞定考研词汇》，每天一睁眼一闭眼都是单词，甚至有一种看见字母有头晕的感觉。但还好我坚持了下来，说一句鸡汤的话，付出总有回报，啃完单词，再开始刷真题的时候，大部分单词都认识，至少心理上不会太排斥。四月份五月份的时候，专业课还没有正儿八经的开始，就隐隐约约总有一种紧张感，怕时间来不及，怕学不会。现在回头来看，虽然专业课没有认真的看，但把教材和课后习题，在无聊的时候过了一遍，对照考纲，大部分的知识点还是比较熟悉的。再到六月，这个月真的是各种倒霉，倒霉，倒霉！！！这个月估算了一下，只看了二十二天的书，先是知道暑假学校不给留校，然后 AirPods Pro 在图书馆无故丢了，再到期末考试，最后学院还给安排个校内实习？？有意义嘛，唉。所以到现在开始复盘的时候，心里还是五味杂陈，这个世界怎么了嘛，呃，简单来说，阻碍你考研的只有你的学校！！！\n再往后，因为学校不给留校，把之前所有的规划都给打乱，好几天都在愁，暑假，都说是考研过程中，最关键的一个阶段，到底该怎么办？？怕暑假两个月之后，达不到自己所预期的效果，怕因为没有学习环境而学不下去，怕两个月之后，我还在继续怀疑我自己，怀疑自己或许根本不适合读书。在提出这些问题，自己心里也许是有答案的，至于答案具体是什么，得靠自己去探索。别人的回答，在某种程度上也只是想要得到内心的肯定罢了。\n既然知道自己想要的未来是光明的，一路走到黑，又何妨？？\n2、音乐复盘 音乐真的世界上最好的治愈。当无处发泄的时候，音乐便是最好的良药。\n《平凡之路》，是属于三月份的。大学三年下来，熬过了很多黑夜，经历了许多风风雨雨，自己的能力慢慢得到肯定之后，在工作和提升自己之间，经过内心的挣扎之后，还是选择了考研。似乎就好像，冥冥中这是我唯一要走的路。也就这样踏上了一条平凡的勇者之路。\n《一群无知少年的梦想》，四月份有幸在 2050 遇见了许多有梦想有朝气的年青人。带着自己的理想，有梦就去追。梦想在哪里呀？\n《稻香》，五月份的那一天会觉得吃的米也是不容易的。周杰伦的歌可谓是从小听到大的，每当听起这首歌的时候总有一种回到小时候的感觉。但是童年的纸飞机，再也不回来了，农村的稻草人也越来越少了。小时候的梦，早就记不清是什么了。回家吧，回到最初的美好。\n《拼个世界给自己》，六月份的新歌。大一的时候，听见僵尸的《网易云》，似乎找到了共鸣，慢慢他越来越火了，但他的歌还是依旧。黑夜中，看星空，飘着一个个的梦。在最无助的时候，能遇到一首走进内心的歌，是一次不可多得的机会。我都懂，我都懂，我都懂……\n二、半学期复盘 ①数学 因为数二考得内容比较少，对于数学整体的把握要好得多，学习的知识点也要少一点，从而学习量也就好一点。因为高数开始的比较早，在三月份结束的时候，就差不多结束了，四五月份查缺补漏以及刷题，基础上几乎没有大的盲点。五月份的同时把线代也过了一遍。\n五月中下旬开始高数部分的强化，不得不说，武神是真的强。本以为自己对于高数的知识点已经掌握的炉火陈青，但是听过武神的强化之后，对于考试的整体更通透了。到六月结束，本预计能强化到定积分结束，可是事与愿违，定积分只是开了个头，（如果最后十天能够稳下心来，好好学，估计是能达到预期的）。\n由于基础部分开始的早，结束的早，问题也就来了，像多元函数微分学、二重积分之类的就有些遗忘。本来还打算六月份抽时间再过一遍的，结果也耽误了。愁呀！！\n线代，在五月份整体过完一遍之后，六月份对照着笔记把《线性代数辅导讲义》的内容过了一遍。满分是 10 分的话，刷《线代讲义》的时候给自己打 7 分吧，确实有很多地方缺点思路。而且有些知识点掌握的不牢固。\n暑期目标：\n跟完强化课程 认真对待《讲义》以及《严选题》 完成以上两点，继续把《880》给整完 ②英语 英语基础部分的长难句和单词，怎么说呢，就属于边看题边巩固的过程，二者之间相互反馈。\n在过完 05 —— 15 年的真题之后，没有着急往下做。先是复盘了一遍，然后闲着无聊把唐迟的《阅读的逻辑》书和课程过了一遍。听课听起来挺舒服的，感觉做英语真题好像也就是那么一回事。但当自己实践的过程中，和方法论存在着不小的差距。\n最后一段时间，因为闲着无聊，把唐叔的《美国历史文化》给看了，下饭必备！！\n暑期目标：\n回顾阅读方法论以及长难句分析 重做考研真题 背单词是每天必备的 ③专业课 如果说数学和英语有点迷惑，但好歹知道迷惑的点，至于专业课，有点找不着北的感觉，没有真题，考纲也只是罗列出一些简单的标题，虽然问了学长学姐，但心里还是有点不太踏实。\n而且之前看书的时候，大部分都只是在书上勾勾画画，没有做太多笔记，（还是因为找不到重点）。数据结构王道的课后习题过了百分之八十，总体难度是可以接手的。数据库，就很迷，感觉比数据结构要更细一点，从而就导致边边角角都要复习到位。\n暑期目标：\n再过一遍专业课课本（做思维导图） 对于掌握不透的知识点单独拎出来 刷题？？ ④政治 呃，犹豫了很久，本来打算八月份开始的，但是由于学校不给留校，而我又懒得带那么多书，在纠结之后，九月份开始吧，希望还来得及。\n三、关于感谢 这半年来，首先感谢我自己选择了这条路。人这一辈子，总要努力一次到两次，那一次是什么时候，我不知道，但是考研肯定算一次。不管能不能上岸，路途中的额外收获都是自己不可多得的一次经历。每当晚上从图书馆回寝室的路上，看着天上的星星，就会想自己也再一次成为了披星戴月的人。有时候反复问自己，我会不会坚持，我会不会坚持，我会不会坚持。会！！！\n这个月来，我慢慢（暂时）退出了开源社，也很感谢伙伴们的理解，因为我自己是个完美主义，每件事必须全部到位，这样就会很多事挂在心上，没办法全身心的投入学习。想了很久，最终还是决定暂时退出一段时间。很感谢居居，当时找到她的时候，对她说了，直接回复 OK，来接我这个烂摊子，说起来确实有点惭愧。各位小朋友，等我回来。\n再有就是，给予我帮助的各位学长学姐们，可能一次又一次的打扰到你们，问一些确实很无聊的问题，真的很感谢你们能抽出时间为我解答疑惑，也就不至于让我无从下手。也是你们，看见你们上岸之后，或者读研的经历，让我有了走下去的动力，我也想一年之后和你们一样！\n还有就是我的爸爸妈妈。像我爸妈虽然学历不太高，但却一直鼓励姐姐和我能够多学点知识，多读点书，以后不至于因为自己的知识面匮乏而感到不足。像我们老家周围的同龄人，几乎早早的都辍学打工，很多家里人都认为挣钱比学习重要，在这么个氛围中，也很感谢老王和老袁支持我继续读书。在学习方面，他俩就没说过一次“不”字，哈哈哈哈。。对了，还有大园，也在一直鼓励着我。\n最后，对坚持下来的自己说一声不容易。感谢去年怀着一腔热血想抗击疫情，为社会做点事的自己；感谢那个遇见开源，并勇于探索的自己；感谢那个因为疫情耽误，在家自己啃 JDK 源码的自己，感谢一直坚持下来的我。\n有时候，很多情况下，不经意做出的决定往往会带来意想不到的结果。也许这就是生活吧。加油啊，冲吧大政！\n怀感恩之心，行正义之事\n","description":"","tags":null,"title":"大政的考研 Blog004 —— 拼个世界给自己","uri":"/life/kaoyan004/"},{"categories":null,"content":"Blog003 —— 五月天，五月复盘 一、逆水行舟 1.1 疲倦期 好快啊！三个月过去了。五月份，没有三月时的不知所措，四月时的激情也慢慢消散，剩下的更多的是不知为啥的坚持。。。\n起初一直感觉自己的进度都是有条不紊的走在前面，整个复习进度也就比较佛系，在闲暇时间还去学学玩玩新的技术，因为比起正儿八经的学习，我更喜欢“瞎倒腾”着玩儿。但是慢慢一个月又一个月的时间过去了，紧迫感也就随之而来。如果说之前的一段时间是兴奋期的话，现在应该可以定义为疲倦期。整个人就有点学不下的感觉，但也不是学不下，而是不知道下一步该学些什么。\n把所有的课（包含专业课，除去政治）基础知识都过了一遍之后，忽然感觉就不想看书了，这种感觉很难受，忽然间就失去了目标。。。到现在写这篇博客的时候，整个人都是佛的。这样一折腾，和之前相比，每天的任务量也减轻了很多。停止是不可能停止的，现在每天能做到的也只能是在保持一定的题目量的过程中，查缺补漏吧。我怕自己一旦决定休息一天，就会在第二天想着：昨天没看书，今天天气那么热，明天再好好看书。说白了，给自己找退路有各种各样的借口，但是走下去的理由也只有那一个！！！\n我很讨厌去逼着自己做一些不情愿的事情，在自己有了一定的选择能力之后，能够去选择做某一件事的时候，都会给自己找到合适的理由，但我没想到的是这条路，这么难熬啊！！！就算不情愿也得走啊，因为还有许多事情没有做没有能力去实现呢。我也一定能够成为我想成为的那个人。一定！！！\n1.2 悟学习 在备考过程中，不仅仅是学习或者说是巩固知识的过程，让我获得比较多的应该是多给自己留几个问号？ 学这个有什么用？为什么要学这个知识？？这个点和之前学的或者之后要学的有什么关联？这种思考方式放在其它学科能用么？？为什么要……？？为什么……？为什……？？？\n这大概我这三个月来，在脑子里反复的最多的几句话。我们学习往往的不是一个一个零碎的知识点，而是一个整体，一个生态。就好比：在学高数的时候，牵涉到微分中值定理的证明题时，往往需要构造函数，这个时候除了用一些常见的套路之外，还可用后面章节的微分方程来构造；原函数、导数和积分之间的关系又可以建立起彼此之间的联系。还有在数据结构中会有求时间复杂度，就又可以和求极限作类比。所以从我自身学习的角度来看待备考过程的话：与其说是为了考试而去学知识，倒不如说是为了教会我们学习而学习。\n忽然想到，还没几天就要高考了，三年，多美的一个字眼，而三年前现在的我，或许还在犹豫，在焦虑。中学时候，各科老师都喜欢按照他们自己的经验来做题，从而稀里糊涂的就给出一套方法来，用心听课、认真学习的同学再课后刷题就能取得高分。但是很遗憾我不属于这类的人。但我也不会为此而感到惋惜，也正是因为这样，才有了现在的我。有些时候，一个人的状态或者说是机遇，很可能是 求而不得，往往不求而得。\n在这段学习过程中，比较让我头疼的应该就是线性代数。就是比较玄乎。第一次听永乐爷爷的课时，一个头有三个头大；咬着牙一遍过下来，对于里面很多的知识点有了大致的印象，具体要是让我像高数那样说出个一二三来，是做不到的。。拿到题目也能摸索着做出来，就是为什么这么做，还是不太懂，只能说我知道这样做就是对的。。。。呃，就是差了点火候，对于学习来说还点再悟，给我的整体感觉就是隔层纱，没有戳破。\n二、五月复盘 五月天气逐渐热了起来，晚上可以听见青蛙叫，天上的星星也更亮了些。\n①数学 都说偶数年数学难，而高数更是难中之最？？所以在四月的基础上，进一步查缺补漏，把之前写得笔记、做的题目又拉出来过了一遍，对于各个章节的知识点，做到纲举目张，从而再统一串起来。\n到此，自我感觉良好，于是去做《李林880》，基础篇还是能手撕的，当做的综合篇的时候，直呼好家伙，题目有点意思哈，再啃啃，我自闭了了了。。。对不起，是我不配了，我迷了，不应该，我咋那么菜呢？？？我高数复习了个 der啊？？带着这种心情，我又低下头去刷《1800》了，也意识到是时候进入强化阶段了。\n然后就线代，由于四月份就已经前四章过了一遍，但是总体感觉是模模糊糊的，就又重新过了一遍，学习还得要做到温故知新的嘛！带着疑惑去学习，确实要比一开始好好得多，但是在完整学完之后，就像前面所提到的，还是很迷的。。\n我也说不清为啥，题目会做，很多定理却不知所云。如果再让我安排一次的话，我会选择把线代的复习进度再往后放一放，不开始那么早，直接就基础过完开始强化。可能吧。\n在复习线代的时候，对于高数花的时间自然而然就少了，从而就导致一些题目做起来有些生疏。\n②英语 单词！！！单词！！！单词！！！\n由于使用的是墨墨背单词，每天 220+，看了下每天背单词的总时长大概在 100 分钟左右。再加上中间有可能做点其它的时间，综合下来，每天背单词大约需要两个小时左右的时间。感觉有点多了吧！！！但好在这些时间没有白费，其最之间的体现就是在做真题上。\n阅读进度：每天一篇阅读：看题干、做题目、翻译、再看题目、对答案，最后找原因。一天的时间在一个小时十分钟到一个半小时之间，这个还是可以接受的。做完一张试卷之后，复盘，做总结下一张。然后就刷到了 2013 年了。在做阅读的时候，就好像把自己又带回了之前的那个年代，也算是一种额外的收获吧。\n每天干饭的时候，看了唐叔的《美国背景文化》，确实挺下饭的，哈哈哈哈！\n③专业课 上个月立的 flag，也算做到了，最起码勾勾画画把书本过了一遍。但是吧，在看完之后，我就感觉看得有点太早了，以后肯定会忘。。。。。。（不愧是我，23333）\n再来吐槽一下数据结构，问了下师哥师姐大部分都在夸王道的书好，好吗？？好？？吗？？？或许从应付考试来说还不错，但是从剖析数据结构来说，无论是知识点的讲解，还是给的代码，从我来看都是不合格的。就是有点浅显，在看王道的书的时候，我还把之前《大话数据结构》和《算法4》，无论是从通俗易懂还是硬核知识来说，都被吊打，而且吧，课后习题给的方法，先抛出代码质量来说，有时候边界值都没考虑到。。。。 吐槽结束。\n数据库，根据考纲把知识点过了一遍，也列了个思维导图。在看关系演算的时候，我又迷了。。。其余的还行，整体上保持在预期之内。后期还得花时间啊！！！\n三、低欲望 其实说实在的，最近才发现自己是属于低欲望却有着野心的那类人。这就导致很多人，拼命去奋斗、去争取的东西，比如成绩排名、个人荣誉、证书啊之类的，我往往都是不屑一顾的。就是感觉很没必要这样做的吧，或者说是很搞笑。就这样，慢慢的，慢慢的，逐渐对周围很多的事情失去了兴趣，生活也就过得越来越简单。也可能是因为我比较懒吧，懒到所有的事情，在无关紧要的情况下，能离远一点就远一点。就像前面所说的，我找不到去做这类事情的理由，对我来说就是在浪费时间。\n再接着就是有时候甚至会对生活失去兴趣，读书学习到底是为了什么呢？？追求学历文凭，只是为了找一份工作，然后结婚生子、养家糊口？？？我对我现在所坚持的事情产生了怀疑，就好比感觉自己所做的努力只是为了像一个普通人一样，仅仅是为了活着而已！！也许读书也就是为了让我们能够变成一个普通人，但是我总感觉，作为当代青年，一个知识分子，能够做的事情有很多，人应该是有理想。自幼读书开始，就想着上了大学就自由了，但后面的挑战也是接踵而至，反观现在无聊的时候，玩玩悠悠球，睡前听歌也只是消磨时光，每天过得生活就像是一个带着情感的机器人。有的时候想要逃离又不敢逃，怕一退缩，迎面而来的是各种咒骂与唾弃。\n人活着的意义是什么呢？？在大部分情况下，我们的明天和今天并没有什么太大的区别。活在当下，也许是最优解。但那是饿了找东西吃，困了就睡的的动物才会做的事情，人之所以为人，那是因为人会幻想未来。那么我想追求的是什么呢？？我的野心又想体现在哪呢？？技术与文明 ，这或许也是我喜欢开源文化、黑客文化的原因之一，只有看过更广阔的对的世界，接触到更前沿的技术，才会感叹自己的渺小与无知，才会明白自己还有很长的路要走，还有梦和理想值得自己为之去努力，去流汗，去坚持，并心甘情愿的为之而受尽煎熬！！！\n最后想用当时曾国藩的一句话送给走在路上的朋友们：千秋邈矣独留我，百战归来再读书 ！！！\n加油！！！\n","description":"","tags":null,"title":"大政的考研 Blog003 —— 五月天","uri":"/life/kaoyan003/"},{"categories":null,"content":"Blog002 —— 阳光正好，四月复盘 一、要命！！！ 经过三月份的折磨，似乎更能明白与花时间熬学习相比，调整好自己，适当的减压，注重学习效率是更重要的。于是我就做减法，做到了什么程度呢？？貌似减得有点多，就导致有点飘，完全有点静不下心来，踏踏实实地学习！！！\n要命！！！\n其实说实话，如果这个月抛去学习不谈，过得还是挺开心的。就先简单聊点这个月我到底干了啥吧。\n1.1 浪潮之巅 看完了吴军博士写得《浪潮之巅》，（都说考研期间不要看课外书，但是考研的课本真的太无聊了了了了。。。。）之前或许是自己，或许是周围的同学总能听到些抱怨：我们出生晚了，最好的时代已经离我们而去了 。但是在看《浪潮之巅》的时候，给我更多的感受是我们现在的时代正是处于互联网的“浪潮之巅”，云原生、5G 时代的到来，将会对于过去的网络再次产生翻天覆地的改变。当下的我们要做的是不怨天尤人，而是把握自己，逆风奔跑，向阳而生！\n生在这个时代最大的幸运就是可以看到商业和科学技术完美结合不断的改变这个世界的面貌，不断的改变我们的生活方式。 吴军博士不断的说能赶上科技发展的浪潮便不枉此生。因此生活在这个时代的我们是幸运的，因为年青，就有资本去学习自己想学的，去追求自己所想追求的。\n1.2 参与 DolphinScheduler 在三月的复盘中有提到，开始转型学习大数据，于是在一次偶然的机会接触到 DS 这个项目。有人说：万物始于 Hello World，但对于我来说参与开源的第一步应该是从 Markdown 开始。首先文档类的任务，与代码层面相比要简单的多，不至于像代码那样牵一发而动全身，而且提交 PR 之后，通过检测的机会也要大的多，可以说门槛是要小一点的。于是参与 DS 的第一份 PR 就是写文档，哈哈哈哈。当自己的 PR 被 merge 的时候，那份满足感是任何事情都替代不了的，特别还是参与 Apache 的顶级项目。\n感受到社区的友好之后，按照我的习惯肯定要撸源码玩玩，徒手撕源码才是真男人嘛！在阅读源码的时候，看看测试案例对于理解和使用来说都是不可缺少的。当时看见了有些类的测试案例还没写，就尝试自己写了一份，结果是显而易见的，PR 没通过检测，然后就导致周末去杭州得背电脑了。。。。。起初最初的问题是代码规范，这个还是比较好改的（与后面遇见的问题相比确实啥都不算），但问题是解决了一个问题，随之而来的是下一个问题，虽然社区的导师给予帮助，但还是很头大。在遇见问题的过程中，最重要的是学会自己动手去解决问题，这个时候就要吹爆 StackOverflow ，以及慢慢体验到 issue 和邮件列表的好处，因为可以从之前的记录中找到类似的问题，解决起来就要好得多。最后看见 LGTM 的时候，感觉一切都值了，所以说还是热爱开源的，还是想写代码的。\n1.3 2050 如果你问我年青人做什么最酷？？ 那一定是参与 2050 大会（也就是因为这个，决定去参加的时候，每天肾上腺激素分泌过多，肯定静不下心学习）。三天下来，有遗憾，有欢笑，也有收获。\n周五到杭州的时候，因为有点晚，遗憾的是错过了“开源人团聚”，但是从博悟馆出来的时候，看见了王坚博士，这何尝不是一种收获呢。这也是我的一种态度：求而不得，往往不求而得。起初见到博士的时候，是先听见他的声音（之前了解到2050是王坚博士以个人名义发起的时候，就临时补课看了很多博士的视频~~），这声音好熟悉，抬头一看，我天呐！！！那穿格子衫的可不就是博士嘛！！！这也是我第一次在现实生活中，见到互联网中大神级别的人物。但说到底，还是有点亏的吧。。。。\n第二天，比较开心的应该是遇见了道哥——吴翰清！！！对，没错，就是段子中传说黑进阿里的大神。只不过感觉有点可惜的是道哥再回到阿里之后，不再做开发，而是产品经理。在听完分享之后，不得不承认，到阅历或者说是知识体系到达一定高度之后，看世界的角度真的会发生改变。我们还在为了生活而感到焦虑的时候，有的人都已经在尝试模拟甚至创造生活。然后还有比较开心的就是看见了赵生宇学长，上次见面还是 2020 开源年会，一别就是几个月。当和学长谈到开源的时候，眼里是有光的。能够更深入的探讨一些问题，也是弥补了昨天的遗憾吧。\n五点半的闹钟，早起，六公里的约定 —— 逐日晨跑。还有什么比这更酷的事情吗？？ 虽然说一开始参与晨跑是为了获得 T 恤，但当一路坚持下来的时候，再想想还有什么是自己不敢挑战的呢？路途中，拿起奠基石，为 2050 添砖加瓦；还看见了一路一直坚持下来的小朋友，他们都未停止脚步，二十出头的我们，不更应该起到带头作用嚒。当回到终点，收到奖牌的时候，感觉这一切都足了！\n快乐的时光总是短暂的，奋斗的路还很长，杭州这座城市去的次数，虽然不是很多，但却是去一次爱一次。（回到合肥之后的感觉，就好比用惯了 IDEA 回到了 Eclipse。。。。）\n四月复盘 说真的，四月给我的感受就好像是什么都没做。。。。\n①数学 四月初，把三月份高数的盲点又花了一周左右的时间整理了一下。这应该可说是零死角了吧。哈哈哈。原本准备这个月把线性代数看完，但是实现往往是高估了我自己的能力和自觉性。\n线代怎么说呢，给我的感觉不像是高数那样，学完一个章节，就能做对应的题目，它更多是对于整个知识体系的融会贯通。再加上李永乐爷爷年级大了，听起来确实不太清楚，还不知汤汤的南京话有个性呢。。。。然后就磕磕巴巴把线代的前四章啃完了。\n高数方面开始二刷 1800，不得不说确实有必要二刷，第一遍做的时候，可能更偏向于基础知识的应用。到了二刷，在之前的基础上再加上一定的技巧，不管是做题速度、正确率方面，还是对于题目对的理解方面，都有了质的飞越。再想起之前还在为选哪本习题册而感到困惑的时候，现在感觉更多的是市场上主流的习题册都各有优缺点，认真啃透一本，再加以补充，我相信问题应该不大。\n②英语 英语重要的就是单词不能停！！说实话，背单词是真的那个痛苦啊，苦不堪言中，还有无聊。。。但哪又能咋办，硬着头皮走下去。长难句方面，看了唐叔的（主要是因为时间较短，一开始是当段子看的）发现，按他那么来玩确实有点意思，就认真又听了一遍，结合真题来，走向正轨。\n搜英语的经验贴，都说上真题，于是这个月把从 2005~2009 所有真题中的阅读精翻了一遍，做前两套试卷的时候，还有比较痛苦的，积累的越多，就稍微好点，每做完一套就复盘一套，会发现从一开始满是红笔的标注慢慢过渡到只标注难点的句子和不认识的单词，红色越少，进步越多，哈哈哈！五月再接再厉！！！\n③专业课 emmmmmmm。。。。从五月开始一定好好准备专业课。我感觉我把准备专业的时间，都用来学习新的知识去了，惭愧！！！\n数据结构，我感觉考得也不是很难嘛、、、、\n三、谈谈愧疚感 人在不努力或者说觉得自己还不够努力的时候，总会感觉到自己有点愧疚感，甚至是罪恶感。这到底是为什么呢？？每天为了努力而去努力，不是我想要的，也不是我所追求的。带着这样的情绪强迫自己去学习、去工作，是比较难受的。\n明知道这种状态不对、这种状态不好，为何不能及时调整自己呢？？可能是因为贪心太大，我们追求的有太多太多了，这个世界也是太丰富多彩了，以至于给人一种错觉，我不努力，就没资格去享受这个世界所给的一切，于是就陷入了这种状态。\n接受自己的不足，接受自己的不完美。对的，在继续往下走之前，应该先想想自己的能力，所处的环境以及自身的状态等客观因素，因为这些种种都是会影响一个人的主观感受。在图书馆中经常能看见有些同学早上七点之前就在图书馆背单词，晚上也一直到十点多。从我的角度来说，我这种状态我做不到，就算做到了也坚持不了多久，甚至可能会把自己的身体搞垮。\n记得之前问过自己一个问题：是逼自己一把，还是放自己一马？ 一开始想的是逼自己一把，因为一直在给自己找更高的任务，说白了就是和自己杠到底。但更多的时候却发现，具体在执行的时候反而变得更佛，更像是在逼自己一把的同时，在有限的空间给自己偷个懒。\n有的时候接受自己的不足，往往不是为了向生活妥协，反而是为了跑得更远，跳得更高！！就像开头所说的这个月如果不谈学习，我们还是好朋友。\n","description":"","tags":null,"title":"大政的考研 Blog002 —— 阳光正好","uri":"/life/kaoyan002/"},{"categories":null,"content":"Blog001——在路上,三月复盘 一、浮躁 我们生活在一个贩卖焦虑的时代，“小镇做题家”、“读书无用论”、“内卷”等等言论充斥这我们的生活。而这个社会中也往往有些人喜欢制造焦虑，什么你已经被你的同龄人所抛弃，你已经被你所处的社会所抛弃等等。我们时常会感叹道：我才二十刚出头，为何活着的这么累啊！！\n是啊，我们为何会这样想呢？？遵循自己的内心，按照自己喜欢的方式走下去不好嘛？？但是真的好难，在这个信息爆炸的时代，几乎无一人能幸免，一方面在享受科技带给我们的便利，另一方面却又被信息所左右，这个时代的我们太浮躁，心也很难静下来，也就很难能坐得住冷板凳，一天能做到、两天能做到那不叫坚持，真正的坚持往往是带着一种煎熬！！\n考研路上，怎一个“卷”字了得！！看看 2021 的考研成绩，出现四百分似乎一点都不觉得稀奇，往年比较好考的院校，也都成了热门，计算机专业更是把内卷体现到了极致。考研就是一座黑暗森林，每个考研人都是带枪的猎人，像幽灵般潜行于林间，轻轻拨开挡路的树枝，竭力不让脚步发出一点儿声音，连呼吸都必须小心翼翼：他必须小心，因为林中到处都有与他一样潜行的考研人，如果他发现了别的考研人，能做的只有一件事：开枪消灭之。在这片森林中，他人就是地狱，就是永恒的威胁，任何暴露自己目前选择的稍微好考的院校都将很快被无数考研人群起冲之，这就是考研的常态？？\n二、心情状态 三月份回到学校，考研的路途也算是真正的拉开序幕，一开始的时候，充满干劲，却也一脸茫然，找不到方向，不知该如何是好。然后慢慢的找到适合自己的方法，说实话还是挺享受这种过程的，苦吗累吗？？有点吧，但是真的很舒服，每天的付出的都能看得见，能得到正向的反馈就很舒服。而且每天晚上带着一点点疲倦感回到宿舍之后，简单洗漱之后，还有点自己的时间，写写代码，看看杂书，练练球，这也是我当时所理想的状态，我原以为能一直这样下去，结果人绷紧了，还是会出问题的\n在这个月快结束的时候，突然间，整个人不知怎么的就不好了。。。。可能是累了，也可能是倦了。当时几乎是把高数基础又重新过了一遍，汤汤 1800 的基础部分 也做了百分之八十左右，专业课的书本也过了一遍，然后突然间就失去了目标，书不想看，题也只能是机械式的刷，当感觉到的时候，也就意识到自己的状态需要调整。这也是第一次出现心情上的波动，因为离目标太远，不知道到底能否做得到！！怕付出到最后不是自己想要的结果！！！\n忽然想起了高三激励自己的一句话：我不去想能否成功，既然选择了远方便只能风雨兼程！ 现在回过头来看，不免是有点中二的，但也就是这股劲，push 着一步一步走啊，走啊。那到底什么是成功呢？？考上大学算是成功吧，也许在当时看来是的，从宏观角度上看，我们往往把成功定义的太狭隘、太片面。所谓的成功，也许是就是一道坎，跨过去一个，下一个更高。简单来说，慢慢走吧，也许漫无目的，也许有目标，但是请别停下！！\n三、三月份学习复盘 ①数学 因为之前数学书本已经过了一遍，在看了一些经验贴之后，意识到基础的重要性，所以又花了半个月的时间，结合汤汤的复习全书、基础三十讲以及课本，整理了一份高数基础笔记，把其中的定理能证的都证明了一遍，一些经典例题也都有添加，当看见打印出来的时候，心里还是有点小激动的，哈哈哈。\n因为之前《基础 30 讲》降价，就入手了一本，总结完基础之后，就开始配合宇哥的课程，开始刷 1800。从我的个人角度来说，宇哥的课如果基础不牢固的话，听起来真的有点飘，全程很难 get 到他想表达的点，而且笔记还不太好记。如果基础还行，跟下来，做题技巧确实能学到不少，然后就去 1800 虐菜。再简单说说 1800，题量是真的大！！！ 虽然题目不是很难，还记得当时第一次翻开习题册，第一面极限，磕磕巴巴只能做五六题，从课本过渡到考研的基础阶段，还是要磨的，还好过渡的比较平滑，到现在二刷前面的基础题，极限也几乎可以做到口算，提高篇的内容暂且不谈，因为还没做。\n如果说高数部分哪里还有盲点的话，大概是 多元微分学 以及 常微分方程部分，因为是最后复习的部分，花的时间没有前几章那么多，所以还得抽时间再看看，知识体系不能出现漏洞嘛。\n②英语 英语咋说呢，有一种不太踏实的感觉，起初可能我高估英语的难度了，觉得考研真题就一定很难，不看语法长难句就一定读不懂文章，带着这种想法，看了刘晓燕的长难句课程，再看真题的感受，大概是我好像不看长难句的课程也能把文章的大意读懂，翻译句子我还是喜欢按照自己的语感来，也不怎么分析句子成分，做题效果比自己当时想的要好。但是吧，我不能说长难句的课程就没必要看，因为自己是看了之后才做题目的，虽然这课程真的有点鸡肋的感觉，不看总觉得少了点什么，不太放心，看的话又有点浪费时间。。。。\n单词方面，尝试了一下“作死”的行为，可能是有点急功近利，就开始肝《十天搞定考研词汇》，到了第五天第六天的时候，整个人都快被单词折磨疯了，哦对，这或许也是我考研状态出现波动的原因吧。真的很折磨人，仅仅是背单词几乎占用了一天大部分时间，感觉有点不值得吧。。。。还好肝完了，单词不能说全到熟稔于心吧，但是看真题是够的了。所以我感觉单词还是很重要的吧。\n真题的话，目前只做了阅读部分，进度为 一天一篇：做题、翻译、分析题目。不知是我飘了，还是做的题目有点老（从 05 年开始做的），感觉考研阅读的难度似乎和六级差不多？？？？在有了上面的基础，大约是从 18 号开始正式做真题的，比预期要好！\n③专业课 如果有最不受程序员欢迎的编程语言排行榜的话，我一定给 C\\C++ 投上一票，甚至在开始学 C++ 的时候，我就在想为啥考研还指定编程语言啊，23333~ 大一初学编程的时候，就是因为 C语言 给我一种我不配写代码的感觉，玄学指针！！！当时被支配的恐惧，现在也是时候和它正面刚了，再逃下去就真的没路咯。。。\n数据结构方面，不算太难吧？？ （人言否。。）也可能是之前看过 JDK 源码以及经常刷题的缘故吧，只不过是换了一种语言实现罢了。所以上手还是比较快的。当让静下心来学 C++ 的时候，还是有点收获的，也让我感觉到为何 C++ 更适合刷题。\n但是中国的应试给我的感觉就是，一样东西变成了考试的内容，与实际使用来说，就变味了。。。。\n四、谈谈备考的生活 整体的感觉是疲惫且充实，启动备考的一个月也在忙碌中结束了。在这期间，对于编程方面做出了一个决定，从后端跨到大数据，目前抽空学完了 Hadoop。问我原因的话，大概是寒假的时候玩了玩 Flink，真的太有意思了，并且看了一些前沿的技术框架，想想还是转吧，哈哈。\n因为当时心情的波动，有想过好久没买悠悠球了，逛了一圈闲鱼，没有太想收的，就把准备买球的钱，买书了，现在我想说，亲 咱能退款不？？。。。。。 有一点点后悔吧。但是多看点书还是好的。\n开源组织这边，也转移到了以开源社为主，毕竟当了组长，还是要干活的呀，带头作用要有。也从一开始几乎把任务都揽到一个人头人，到慢慢学会分配出去，再到招募新的小朋友加入进来，再想想去年自己似乎也是在这个时候接触到开源的吧，真好！\n有人说，你不是准备考研吗，怎么天天还做这些，不怕耽误你自己么？？ ，先说句谢谢您哈！可是我想说，如果把这十个月左右的时间全部用在考研上，就算到时候上岸了，我会开心吗，也许吧。但我更想在这有限的时间里做点自己喜欢的事情，不做一个只读“死书”的考研狗。\n五、写在之后 之前一直在想，要不要把自己的考研历程给录下来，但是又嫌后期处理麻烦，索性就用博客来记录吧。而且在写之前，还在想，如果到时候没有上岸，是不是太丢人了吧，是啊，那可真拉胯，但我还是想把这一段时间用文字给记录下啦。\n考研的基础阶段，就好比是编程语言的基本语法，算作基本功；一些常用的结论、定理 有点想数据结构和设计模式，可以定义为内功了吧；再看看做题技巧，对应的是常用的框架？？也就是某种定义上的武功秘籍了吧，哈哈。所以说学习是有相通性的，作为一名学生，不能为了学习而学习，而是要学会学习而学习。\n与学习编程相比，考研学的内容可能真的不算太多，但是考研是有一个时间界限的，比的是在规定时间内，谁玩得好。这就很烦。在准备考研之前，我还在问我自己，到底为什么要考研，现在的答案是 我有我所想追求的，现在的身份、圈子，无法得到我想要的状态 ，所以要走下去！\n最后，从我个人的角度来说，还是想读书的，但我并不喜欢学校要求实践、学分、发论文的这种教育，我还没到 21 岁，我还有时间按照我所想的去“浪费”！\n","description":"","tags":null,"title":"大政的考研 Blog001 —— 在路上","uri":"/life/kaoyan001/"},{"categories":null,"content":" 如果可以的话，我想看看明年这个时候的自己是什么状态，或者 回到三年前，对那个时候的自己说一声：其实也没啥大不了，你一定可以成为你想成为的那个人。\n疫情还没结束，但 2020 就要过去了，似乎这一年过得有点无语、有点匪夷所思，一种说不清道不明的感觉。记得小学的时候，老师让写作文，关于未来，就想着 2020 年的生活怎么样，记得当时有一点是：可以在家上学，没想到的是，我们在这样一种环境实现了在家上学。\n今年过的好嘛？？还行吧，虽然和自己想的完全是两个样子，但是做了一些值得去做的事，认识了一些有趣的人，这就够了。\n如果说 2019 年是我沉淀的一年，那么我想用厚积薄发来形容今年的自己。19 年八月底，发了一个朋友圈。给我三年，\n现在回过头来想想，不免觉得有点中二，哈哈哈哈。但也正是这股中二的动力，一直 push 着我向前走。但其实事实是：说这句话，当时所想的奋斗目标，和自己的现在的样子完全是两个样子。 当时的目标，无外乎就是学习啊、证书啊、名次啊…… 这些世俗的东西，但同样是避免不了的。如果不世俗，又怎么能真正做到不世俗呢？？幸好，在寻找的过程中，找到了目前的自己想做的事情，也是我想真正坚持下去的事情。\n絮絮叨叨说了一堆没啥用的，而且还是关于 2019 的事情，其实关于今年，没啥好说的。就像是一场梦，还没醒来，就结束了。那就说说，今年对我影响比较大的三本书吧。\n《百年独孤》看完这本书是四月份。可能也是和当时自己的处境有关，感觉自己一个人总是孤立的、没人懂我。这本书也是我硬着头皮看完的，里面的人名可以说直接就劝退。为什么这本书对我的影响比较大呢？？当一个人能感受到孤独的时候，才能做到静下心来。就像马尔克斯在书中所写的一样：所有人都显得很寂寞，用自己的方式想尽办法排遣寂寞，事实上仍是延续自己的寂寞。寂寞是造化对群居者的诅咒，孤独才是寂寞的唯一出口。 刚好那个时候，对于Java特别感兴趣，也就是在这种孤独感的环境下，能够让我有足够的耐心去读 JDK 和 JVM 源码，从而可以有效的提高自己的编程水平和技巧，随着越深入的了解和学习，也就对写代码越来越着迷。（其实源码并未完全读完，着迷之后，就在各地找项目练手，刚好那个时候接触到开源，也就有了读一些顶级项目源码的机会，增加查克拉，哈哈哈哈）\n第二本书，我想说的是《人间简史：从动物到上帝》，这本书在书架上已经有一年多了，但是因为标题写得太大，我一向不是不喜欢读这类书籍的，总感觉有点空洞。当时看了一段作者 尤瓦尔·赫拉利的一期关于如何看待疫情的视频，便开始下手准备读下去。这本书，可谓不读不知道，从一个绝对想不到的宏观角度来阐述人类的发展。也正是受到这种宏观角度的影响，从而培养出了我一个良好的思考问题的习惯，可以出圈的来想问题，也就这样，使得我的思维能够超脱出现在的处境，能够找到自己，找到自己想要的时候，找到如何在自己有限的能力之下，做一些有意义的事情。\n最后我想说的是大刘的《三体》，这本书高中的时候就听说过，但一直拖到今年暑期才看完，《三体》除了是一部科幻作品之外，更重要的是关于人性的描绘，有人说，大刘在里面是不是过分的把人类描述的太丑陋了，但脱离人类的身份来思考这个问题，相信每个人都会得到一份属于自己的答案。也是这本书，让我找到活着的意义所在：人，在能够解决自身的基本需求之后，更重要的是要留下些东西。\n这些书都是上半年读的，至于下半年，读得更多的都是一些文言文，我绝对不会想到现在的自己，会“佛”到这种程度，哈哈哈哈哈。\n今年最大的收获就是接触到了开源，这是从我接触的悠悠球之后，重新找到能让我为之付出努力的事情，而且还和我的专业有关，如果说今年有啥值得吹得事情，那就是把自己的第一份 pr，提交给了 Apache 项目。\n最后，我想说，从做得到，到今天已经做到了。\n","description":"","tags":null,"title":"关于 2020_我想说","uri":"/life/about_2020/"},{"categories":null,"content":"第二章：面向对象 面向对象是学习编程过程中一个非常重要的思想，但是它却被很多人理解成了一个比较难，比较深奥的问题，其实不然。其实面向对象在理解之后还是很简单的，简而言之就是程序之中所有的操作都需要通过对象来完成。\n举例来说： 操作浏览器要使用window对象 操作网页要使用document对象 操作控制台要使用console对象 一切操作都要通过对象，也就是所谓的面向对象，那么对象到底是什么呢？这就要先说到程序是什么，计算机程序的本质就是对现实事物的抽象，抽象的反义词是具体，比如：照片是对一个具体的人的抽象，汽车模型是对具体汽车的抽象等等。程序也是对事物的抽象，在程序中我们可以表示一个人、一条狗、一把枪、一颗子弹等等所有的事物。一个事物到了程序中就变成了一个对象。\n在程序中所有的对象都被分成了两个部分数据和功能，以人为例，人的姓名、性别、年龄、身高、体重等属于数据，人可以说话、走路、吃饭、睡觉这些属于人的功能。数据在对象中被成为属性，而功能就被称为方法。所以简而言之，在程序中一切皆是对象。\n1、类（class） 要想面向对象，操作对象，首先便要拥有对象，那么下一个问题就是如何创建对象。要创建对象，必须要先定义类，所谓的类可以理解为对象的模型，程序中可以根据类创建指定类型的对象，举例来说：可以通过Person类来创建人的对象，通过Dog类创建狗的对象，通过Car类来创建汽车的对象，不同的类可以用来创建不同的对象。\n定义类：\n1 2 3 4 5 6 7 8 9 10 11 12 class 类名 { 属性名: 类型; constructor(参数: 类型){ this.属性名 = 参数; } 方法名(){ .... } } 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 class Person{ name: string; age: number; constructor(name: string, age: number){ this.name = name; this.age = age; } sayHello(){ console.log(`大家好，我是${this.name}`); } } 使用类：\n1 2 const p = new Person('孙悟空', 18); p.sayHello(); 2、面向对象的特点 封装\n对象实质上就是属性和方法的容器，它的主要作用就是存储属性和方法，这就是所谓的封装\n默认情况下，对象的属性是可以任意的修改的，为了确保数据的安全性，在TS中可以对属性的权限进行设置\n只读属性（readonly）：\n如果在声明属性时添加一个readonly，则属性便成了只读属性无法修改 TS中属性具有三种修饰符：\npublic（默认值），可以在类、子类和对象中修改 protected ，可以在类、子类中修改 private ，可以在类中修改 示例：\npublic\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class Person{ public name: string; // 写或什么都不写都是public public age: number; constructor(name: string, age: number){ this.name = name; // 可以在类中修改 this.age = age; } sayHello(){ console.log(`大家好，我是${this.name}`); } } class Employee extends Person{ constructor(name: string, age: number){ super(name, age); this.name = name; //子类中可以修改 } } const p = new Person('孙悟空', 18); p.name = '猪八戒';// 可以通过对象修改 protected\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Person{ protected name: string; protected age: number; constructor(name: string, age: number){ this.name = name; // 可以修改 this.age = age; } sayHello(){ console.log(`大家好，我是${this.name}`); } } class Employee extends Person{ constructor(name: string, age: number){ super(name, age); this.name = name; //子类中可以修改 } } const p = new Person('孙悟空', 18); p.name = '猪八戒';// 不能修改 private\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Person{ private name: string; private age: number; constructor(name: string, age: number){ this.name = name; // 可以修改 this.age = age; } sayHello(){ console.log(`大家好，我是${this.name}`); } } class Employee extends Person{ constructor(name: string, age: number){ super(name, age); this.name = name; //子类中不能修改 } } const p = new Person('孙悟空', 18); p.name = '猪八戒';// 不能修改 属性存取器\n对于一些不希望被任意修改的属性，可以将其设置为private\n直接将其设置为private将导致无法再通过对象修改其中的属性\n我们可以在类中定义一组读取、设置属性的方法，这种对属性读取或设置的属性被称为属性的存取器\n读取属性的方法叫做setter方法，设置属性的方法叫做getter方法\n示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Person{ private _name: string; constructor(name: string){ this._name = name; } get name(){ return this._name; } set name(name: string){ this._name = name; } } const p1 = new Person('孙悟空'); console.log(p1.name); // 通过getter读取name属性 p1.name = '猪八戒'; // 通过setter修改name属性 静态属性\n静态属性（方法），也称为类属性。使用静态属性无需创建实例，通过类即可直接使用\n静态属性（方法）使用static开头\n示例：\n1 2 3 4 5 6 7 8 9 10 class Tools{ static PI = 3.1415926; static sum(num1: number, num2: number){ return num1 + num2 } } console.log(Tools.PI); console.log(Tools.sum(123, 456)); this\n在类中，使用this表示当前对象 继承\n继承时面向对象中的又一个特性\n通过继承可以将其他类中的属性和方法引入到当前类中\n示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Animal{ name: string; age: number; constructor(name: string, age: number){ this.name = name; this.age = age; } } class Dog extends Animal{ bark(){ console.log(`${this.name}在汪汪叫！`); } } const dog = new Dog('旺财', 4); dog.bark(); 通过继承可以在不修改类的情况下完成对类的扩展\n重写\n发生继承时，如果子类中的方法会替换掉父类中的同名方法，这就称为方法的重写\n示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class Animal{ name: string; age: number; constructor(name: string, age: number){ this.name = name; this.age = age; } run(){ console.log(`父类中的run方法！`); } } class Dog extends Animal{ bark(){ console.log(`${this.name}在汪汪叫！`); } run(){ console.log(`子类中的run方法，会重写父类中的run方法！`); } } const dog = new Dog('旺财', 4); dog.bark(); 在子类中可以使用super来完成对父类的引用\n抽象类（abstract class）\n抽象类是专门用来被其他类所继承的类，它只能被其他类所继承不能用来创建实例\n1 2 3 4 5 6 7 8 9 10 11 12 abstract class Animal{ abstract run(): void; bark(){ console.log('动物在叫~'); } } class Dog extends Animals{ run(){ console.log('狗在跑~'); } } 使用abstract开头的方法叫做抽象方法，抽象方法没有方法体只能定义在抽象类中，继承抽象类时抽象方法必须要实现\n3、接口（Interface） 接口的作用类似于抽象类，不同点在于接口中的所有方法和属性都是没有实值的，换句话说接口中的所有方法都是抽象方法。接口主要负责定义一个类的结构，接口可以去限制一个对象的接口，对象只有包含接口中定义的所有属性和方法时才能匹配接口。同时，可以让一个类去实现接口，实现接口时类中要保护接口中的所有属性。\n示例（检查对象类型）：\n1 2 3 4 5 6 7 8 9 10 interface Person{ name: string; sayHello():void; } function fn(per: Person){ per.sayHello(); } fn({name:'孙悟空', sayHello() {console.log(`Hello, 我是 ${this.name}`)}}); 示例（实现）\n1 2 3 4 5 6 7 8 9 10 11 12 13 interface Person{ name: string; sayHello():void; } class Student implements Person{ constructor(public name: string) { } sayHello() { console.log('大家好，我是'+this.name); } } 4、泛型（Generic） 定义一个函数或类时，有些情况下无法确定其中要使用的具体类型（返回值、参数、属性的类型不能确定），此时泛型便能够发挥作用。\n举个例子：\n1 2 3 function test(arg: any): any{ return arg; } 上例中，test函数有一个参数类型不确定，但是能确定的时其返回值的类型和参数的类型是相同的，由于类型不确定所以参数和返回值均使用了any，但是很明显这样做是不合适的，首先使用any会关闭TS的类型检查，其次这样设置也不能体现出参数和返回值是相同的类型\n使用泛型：\n1 2 3 function test\u003cT\u003e(arg: T): T{ return arg; } 这里的\u003cT\u003e就是泛型，T是我们给这个类型起的名字（不一定非叫T），设置泛型后即可在函数中使用T来表示该类型。所以泛型其实很好理解，就表示某个类型。\n那么如何使用上边的函数呢？\n方式一（直接使用）：\n1 test(10) 使用时可以直接传递参数使用，类型会由TS自动推断出来，但有时编译器无法自动推断时还需要使用下面的方式\n方式二（指定类型）：\n1 test\u003cnumber\u003e(10) 也可以在函数后手动指定泛型\n可以同时指定多个泛型，泛型间使用逗号隔开：\n1 2 3 4 5 function test\u003cT, K\u003e(a: T, b: K): K{ return b; } test\u003cnumber, string\u003e(10, \"hello\"); 使用泛型时，完全可以将泛型当成是一个普通的类去使用\n类中同样可以使用泛型：\n1 2 3 4 5 6 7 class MyClass\u003cT\u003e{ prop: T; constructor(prop: T){ this.prop = prop; } } 除此之外，也可以对泛型的范围进行约束\n1 2 3 4 5 6 7 interface MyInter{ length: number; } function test\u003cT extends MyInter\u003e(arg: T): number{ return arg.length; } 使用T extends MyInter表示泛型T必须是MyInter的子类，不一定非要使用接口类和抽象类同样适用。\n","description":"","tags":null,"title":"TypeScript学习笔记02","uri":"/tech/typescript02/"},{"categories":null,"content":"第一章 快速入门 0、TypeScript简介 TypeScript是JavaScript的超集。 它对JS进行了扩展，向JS中引入了类型的概念，并添加了许多新的特性。 TS代码需要通过编译器编译为JS，然后再交由JS解析器执行。 TS完全兼容JS，换言之，任何的TS代码都可以直接当成JS使用。 相较于JS而言，TS拥有了静态类型，更加严格的语法，更强大的功能；TS可以在代码执行前就完成代码的检查，减小了运行时异常的出现的几率；TS代码可以编译为任意版本的JS代码，可有效解决不同JS运行环境的兼容问题；同样的功能，TS的代码量要大于JS，但由于TS的代码结构更加清晰，变量类型更加明确，在后期代码的维护中TS却远远胜于JS。 1、TypeScript 开发环境搭建 下载Node.js\n64位：https://nodejs.org/dist/v14.15.1/node-v14.15.1-x64.msi 32位：https://nodejs.org/dist/v14.15.1/node-v14.15.1-x86.msi 安装Node.js\n使用npm全局安装typescript\n进入命令行 输入：npm i -g typescript 创建一个ts文件\n使用tsc对ts文件进行编译\n进入命令行\n进入ts文件所在目录\n执行命令：tsc xxx.ts\n2、基本类型 类型声明\n类型声明是TS非常重要的一个特点\n通过类型声明可以指定TS中变量（参数、形参）的类型\n指定类型后，当为变量赋值时，TS编译器会自动检查值是否符合类型声明，符合则赋值，否则报错\n简而言之，类型声明给变量设置了类型，使得变量只能存储某种类型的值\n语法：\n1 2 3 4 5 6 7 let 变量: 类型; let 变量: 类型 = 值; function fn(参数: 类型, 参数: 类型): 类型{ ... } 自动类型判断\nTS拥有自动的类型判断机制 当对变量的声明和赋值是同时进行的，TS编译器会自动判断变量的类型 所以如果你的变量的声明和赋值时同时进行的，可以省略掉类型声明 类型：\n类型 例子 描述 number 1, -33, 2.5 任意数字 string 'hi', \"hi\", hi 任意字符串 boolean true、false 布尔值true或false 字面量 其本身 限制变量的值就是该字面量的值 any * 任意类型 unknown * 类型安全的any void 空值（undefined） 没有值（或undefined） never 没有值 不能是任何值 object {name:'孙悟空'} 任意的JS对象 array [1,2,3] 任意JS数组 tuple [4,5] 元素，TS新增类型，固定长度数组 enum enum{A, B} 枚举，TS中新增类型 number\n1 2 3 4 5 let decimal: number = 6; let hex: number = 0xf00d; let binary: number = 0b1010; let octal: number = 0o744; let big: bigint = 100n; boolean\n1 let isDone: boolean = false; string\n1 2 3 4 5 6 7 8 let color: string = \"blue\"; color = 'red'; let fullName: string = `Bob Bobbington`; let age: number = 37; let sentence: string = `Hello, my name is ${fullName}. I'll be ${age + 1} years old next month.`; 字面量\n也可以使用字面量去指定变量的类型，通过字面量可以确定变量的取值范围\n1 2 let color: 'red' | 'blue' | 'black'; let num: 1 | 2 | 3 | 4 | 5; any\n1 2 3 let d: any = 4; d = 'hello'; d = true; unknown\n1 2 let notSure: unknown = 4; notSure = 'hello'; void\n1 let unusable: void = undefined; never\n1 2 3 function error(message: string): never { throw new Error(message); } object（没啥用）\n1 let obj: object = {}; array\n1 2 let list: number[] = [1, 2, 3]; let list: Array\u003cnumber\u003e = [1, 2, 3]; tuple\n1 2 let x: [string, number]; x = [\"hello\", 10]; enum\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 enum Color { Red, Green, Blue, } let c: Color = Color.Green; enum Color { Red = 1, Green, Blue, } let c: Color = Color.Green; enum Color { Red = 1, Green = 2, Blue = 4, } let c: Color = Color.Green; 类型断言\n有些情况下，变量的类型对于我们来说是很明确，但是TS编译器却并不清楚，此时，可以通过类型断言来告诉编译器变量的类型，断言有两种形式：\n第一种\n1 2 let someValue: unknown = \"this is a string\"; let strLength: number = (someValue as string).length; 第二种\n1 2 let someValue: unknown = \"this is a string\"; let strLength: number = (\u003cstring\u003esomeValue).length; 3、编译选项 自动编译文件\n编译文件时，使用 -w 指令后，TS编译器会自动监视文件的变化，并在文件发生变化时对文件进行重新编译。\n示例：\n1 tsc xxx.ts -w 自动编译整个项目\n如果直接使用tsc指令，则可以自动将当前项目下的所有ts文件编译为js文件。\n但是能直接使用tsc命令的前提时，要先在项目根目录下创建一个ts的配置文件 tsconfig.json\ntsconfig.json是一个JSON文件，添加配置文件后，只需只需 tsc 命令即可完成对整个项目的编译\n配置选项：\ninclude\n定义希望被编译文件所在的目录\n默认值：[\"**/*\"]\n示例：\n1 \"include\":[\"src/**/*\", \"tests/**/*\"] 上述示例中，所有src目录和tests目录下的文件都会被编译\nexclude\n定义需要排除在外的目录\n默认值：[\"node_modules\", \"bower_components\", \"jspm_packages\"]\n示例：\n1 \"exclude\": [\"./src/hello/**/*\"] 上述示例中，src下hello目录下的文件都不会被编译\nextends\n定义被继承的配置文件\n示例：\n1 \"extends\": \"./configs/base\" 上述示例中，当前配置文件中会自动包含config目录下base.json中的所有配置信息\nfiles\n指定被编译文件的列表，只有需要编译的文件少时才会用到\n示例：\n1 2 3 4 5 6 7 8 9 10 11 \"files\": [ \"core.ts\", \"sys.ts\", \"types.ts\", \"scanner.ts\", \"parser.ts\", \"utilities.ts\", \"binder.ts\", \"checker.ts\", \"tsc.ts\" ] 列表中的文件都会被TS编译器所编译\ncompilerOptions\n编译选项是配置文件中非常重要也比较复杂的配置选项\n在compilerOptions中包含多个子选项，用来完成对编译的配置\n项目选项\ntarget\n设置ts代码编译的目标版本\n可选值：\nES3（默认）、ES5、ES6/ES2015、ES7/ES2016、ES2017、ES2018、ES2019、ES2020、ESNext 示例：\n1 2 3 \"compilerOptions\": { \"target\": \"ES6\" } 如上设置，我们所编写的ts代码将会被编译为ES6版本的js代码\nlib\n指定代码运行时所包含的库（宿主环境）\n可选值：\nES5、ES6/ES2015、ES7/ES2016、ES2017、ES2018、ES2019、ES2020、ESNext、DOM、WebWorker、ScriptHost ...... 示例：\n1 2 3 4 5 6 \"compilerOptions\": { \"target\": \"ES6\", \"lib\": [\"ES6\", \"DOM\"], \"outDir\": \"dist\", \"outFile\": \"dist/aa.js\" } module\n设置编译后代码使用的模块化系统\n可选值：\nCommonJS、UMD、AMD、System、ES2020、ESNext、None 示例：\n1 2 3 \"compilerOptions\": { \"module\": \"CommonJS\" } outDir\n编译后文件的所在目录\n默认情况下，编译后的js文件会和ts文件位于相同的目录，设置outDir后可以改变编译后文件的位置\n示例：\n1 2 3 \"compilerOptions\": { \"outDir\": \"dist\" } 设置后编译后的js文件将会生成到dist目录\noutFile\n将所有的文件编译为一个js文件\n默认会将所有的编写在全局作用域中的代码合并为一个js文件，如果module制定了None、System或AMD则会将模块一起合并到文件之中\n示例：\n1 2 3 \"compilerOptions\": { \"outFile\": \"dist/app.js\" } rootDir\n指定代码的根目录，默认情况下编译后文件的目录结构会以最长的公共目录为根目录，通过rootDir可以手动指定根目录\n示例：\n1 2 3 \"compilerOptions\": { \"rootDir\": \"./src\" } allowJs\n是否对js文件编译 checkJs\n是否对js文件进行检查\n示例：\n1 2 3 4 \"compilerOptions\": { \"allowJs\": true, \"checkJs\": true } removeComments\n是否删除注释 默认值：false noEmit\n不对代码进行编译 默认值：false sourceMap\n是否生成sourceMap 默认值：false 严格检查\nstrict 启用所有的严格检查，默认值为true，设置后相当于开启了所有的严格检查 alwaysStrict 总是以严格模式对代码进行编译 noImplicitAny 禁止隐式的any类型 noImplicitThis 禁止类型不明确的this strictBindCallApply 严格检查bind、call和apply的参数列表 strictFunctionTypes 严格检查函数的类型 strictNullChecks 严格的空值检查 strictPropertyInitialization 严格检查属性是否初始化 额外检查\nnoFallthroughCasesInSwitch 检查switch语句包含正确的break noImplicitReturns 检查函数没有隐式的返回值 noUnusedLocals 检查未使用的局部变量 noUnusedParameters 检查未使用的参数 高级\nallowUnreachableCode 检查不可达代码 可选值： true，忽略不可达代码 false，不可达代码将引起错误 noEmitOnError 有错误的情况下不进行编译 默认值：false 4、webpack 通常情况下，实际开发中我们都需要使用构建工具对代码进行打包，TS同样也可以结合构建工具一起使用，下边以webpack为例介绍一下如何结合构建工具使用TS。\n步骤：\n初始化项目\n进入项目根目录，执行命令 npm init -y 主要作用：创建package.json文件 下载构建工具\nnpm i -D webpack webpack-cli webpack-dev-server typescript ts-loader clean-webpack-plugin 共安装了7个包 webpack 构建工具webpack webpack-cli webpack的命令行工具 webpack-dev-server webpack的开发服务器 typescript ts编译器 ts-loader ts加载器，用于在webpack中编译ts文件 html-webpack-plugin webpack中html插件，用来自动创建html文件 clean-webpack-plugin webpack中的清除插件，每次构建都会先清除目录 根目录下创建webpack的配置文件webpack.config.js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 const path = require(\"path\"); const HtmlWebpackPlugin = require(\"html-webpack-plugin\"); const { CleanWebpackPlugin } = require(\"clean-webpack-plugin\"); module.exports = { optimization:{ minimize: false // 关闭代码压缩，可选 }, entry: \"./src/index.ts\", devtool: \"inline-source-map\", devServer: { contentBase: './dist' }, output: { path: path.resolve(__dirname, \"dist\"), filename: \"bundle.js\", environment: { arrowFunction: false // 关闭webpack的箭头函数，可选 } }, resolve: { extensions: [\".ts\", \".js\"] }, module: { rules: [ { test: /\\.ts$/, use: { loader: \"ts-loader\" }, exclude: /node_modules/ } ] }, plugins: [ new CleanWebpackPlugin(), new HtmlWebpackPlugin({ title:'TS测试' }), ] } 根目录下创建tsconfig.json，配置可以根据自己需要\n1 2 3 4 5 6 7 { \"compilerOptions\": { \"target\": \"ES2015\", \"module\": \"ES2015\", \"strict\": true } } 修改package.json添加如下配置\n1 2 3 4 5 6 7 8 9 { ...略... \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" \u0026\u0026 exit 1\", \"build\": \"webpack\", \"start\": \"webpack serve --open chrome.exe\" }, ...略... } 在src下创建ts文件，并在并命令行执行npm run build对代码进行编译，或者执行npm start来启动开发服务器\n5、Babel 经过一系列的配置，使得TS和webpack已经结合到了一起，除了webpack，开发中还经常需要结合babel来对代码进行转换以使其可以兼容到更多的浏览器，在上述步骤的基础上，通过以下步骤再将babel引入到项目中。\n安装依赖包：\nnpm i -D @babel/core @babel/preset-env babel-loader core-js 共安装了4个包，分别是： @babel/core babel的核心工具 @babel/preset-env babel的预定义环境 @babel-loader babel在webpack中的加载器 core-js core-js用来使老版本的浏览器支持新版ES语法 修改webpack.config.js配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ...略... module: { rules: [ { test: /\\.ts$/, use: [ { loader: \"babel-loader\", options:{ presets: [ [ \"@babel/preset-env\", { \"targets\":{ \"chrome\": \"58\", \"ie\": \"11\" }, \"corejs\":\"3\", \"useBuiltIns\": \"usage\" } ] ] } }, { loader: \"ts-loader\", } ], exclude: /node_modules/ } ] } ...略... 如此一来，使用ts编译后的文件将会再次被babel处理，使得代码可以在大部分浏览器中直接使用，可以在配置选项的targets中指定要兼容的浏览器版本。\n","description":"","tags":null,"title":"Typescript 学习笔记01","uri":"/tech/typescript01/"},{"categories":null,"content":"我与开源的那些事儿。 很幸运！！！是的，很幸运，除了幸运，我不知道该怎么形容我和 开源 的缘分。感觉就好像在冥冥之中，肯定会走上这条道路一样。\n缘起 2020注定是特别的一年，年初，谁也没想到，一场疫情把我们牢牢的困在家里，哪也去不了。。说实话，或多或少有点抱怨吧。但伴随而来的，是一场灾难。那个时候每天一早醒来，看见手机屏幕刷新的数据，冰冷的可怕，红线一直在升。。。当时就在想，为什么我不是学医的，待在家里什么都做不了，似乎捐钱变成了最可悲的方式。\n偶然一次，在知乎上看见关于开发者抗疫的活动——“Wuhan2020”。本身就是学计算机专业的我，对于技术方面的文章也比较感兴趣，就随手点了进去。（ 其实当时内心所想的是，可能有是一个营销号在做文章 ）。在大致了解了Wuhan2020整个项目之后，便开始搜集更多的与之相关的信息。最后偶然在一个公众号中，看见了“黑客松活动”。就水群，进去了，，哈哈哈哈。但当时还是个技术小白，啥都不懂，可以理解成比会写“hello world“强那么一点点。在那之后，也找到了Wuhan2020的官方公众号。那时，想着尽自己的一份力，但是无论是对于开源文化上还是技术上都感到了很大的局限性，说俗点，大概就是心有余而力不足吧。随后大约在四月份（ 精确点是4月4号，因为那一天整个世界都是灰色的 ），看见了Wuhan2020公众号招人，我想了想自己对于做图剪视频之类的，还算是比较擅长的，就去试试水。进入了设计组。这也算是我第一次真正接触到开源吧。\n幸运 说实话，除了幸运我不知道该怎么来形容这段经历。当时在设计组群里，几乎什么都没做，就发了一份作品＋自我介绍，然后有一位华师大的学姐，就加我为好友，说是带我一起和一位大佬做Apache相关的推广。哈？？Apache是什么？？当时的我是一脸问号。。。。然后就抱着试一试的心态跟着去了。。。（ 现在想想当时真的是有趣，如果我说我什么都不了解，甚至拒绝的话还会有现在的我么。。而且群里那么多人咋就单单选中了我呢，哈哈哈哈）然后和Apache的姜宁老师简单聊了一下，说到hugo啥的。我心里想hugo？？雨果还搞开源？？随后查了一下，是一款搭建静态博客的框架，这也是我正式使用github的起点吧，更新博客。学了点东西总要找点事情做的，要不然时间一长，不就那也记不住了，哈哈哈。\n慢慢的跟着学姐运营ALC-Beijing和Wuhan2020的公众号，也一起了解到更多有关开源的文化。习惯也由之前的天天逛CSDN、知乎变成Github、掘金之类的。成功搭建博客，给我学习新的知识也树立了信心。似乎一切都好了起来，那个时候武汉已经宣布解封。\n当时接触开源之前，总感觉自己怀才不遇，明明会的不少，懂得知识也挺多的，为什么就还只是一个普普通通的大学生呢？？还是做不到出圈，每天混学分，做着毫无疑义的事情。但当皓月姐姐加我好友的那一刻开始，就感觉那份属于我的运气该来了，还撞的特别准。\n随后也加入了开源社，慢慢认识了更多的小伙伴，一群人不认识也不了解，分布在各个地方，做着一件共同的事情，可能这就是我当时所理解的开源吧。\n受阻 当时想着为一些顶级的开源项目做贡献，就开始学会主动去吸取知识，那种学习给我的感觉是由心而发的，主动的。如果问我那时为什么想参与开源，大概是开源本身就具有向善的属性，也认为那是一种体现自己价值的方式。\n当五月份学校宣布返校的时候，回头学校之后，就开始感觉自己有出圈的能力了，也有出圈的想法，可能是技术层面，学校没有需要学习的，也可能是真正意识到现在的自己可以做一些更有意义的事情了。就逐渐向周围的同学唠叨着自己接触开源的事情，很多人的情况和我一样，一开始都是一脸懵圈，但遗憾的是懵圈之后，就什么都没了。这就好比一个主动跳入坑里的人，很难再拉下一个人主动入坑。其实准确点来说，都感觉开源离自身太远。从学生角度来思考，学好文化课，在课余时间参加活动、比赛之类的，赚学分，才是本职工作。至于开源，第一是不了解（不直接和自己的利益挂钩），第二是技术层面达不到。可以发现github上面的顶级项目几乎大多数都不适合学生来做，而且更多的是面向求职者或者说是已经工作了的，这样一来，即使有一腔热血，但是也被挡在门外。（回头想想自己，能想到把blog部署到github上，这样一来，几乎就和github捆绑在一起了，也就是这样能有更多的机会接触更多的项目。）带着这样的问题，我就在思考如何才能让身边的人参与开源，其实参与开源也不一定是技术层面，是不是？？\nCOSCon‘20 期盼已久的开源年会终于来了，尤其是今年年会的主题——“开源向善“ 。这可能也是我接触到开源的初衷。当时去之前，就在脑子里构想了很多有关开源的问题，在自身深入了解开源之后，总感觉没有自己想的那么简单，说大点可以是一种哲学，甚至是一种信仰。这是开源带给我最直观的感受。\n年会现场，也可谓是大型的网友见面会，虽然每个人都不一样，学着不同的专业、不同的城市、不同的年龄段，但是却都可以在彼此身上找到各自的影子，有时候有些事确实挺奇妙的。在第二天，无论是和庄表伟老师的聊天学习，还是和王伟老师的沟通交流，都刷新了我对于开源的认识，就好像是打破之前的定义，更深入的思考，对，这次是思考，不再是了解。如果说皓月姐姐是我接触开源的引路人，这大概就是遇见了自己的伯乐。\n天下没有不散的宴席，虽然很不舍，但是离别是必然的，愿下次再遇见，那个时候的自己更优秀。\n","description":"","tags":null,"title":"我与开源的那些事儿","uri":"/life/coscon/"},{"categories":null,"content":"大三了，二夕回来了？？ 转眼间，大学生活已经过去两年了，一切总感觉一切都还早，一切都不用那么着急，反正很多事情也不是着急的事。这学期临近开学，忽然不知怎么就有了一种无形的压迫感。这种压迫感似乎在怒斥着自己，你前两年都学了些什么？？ 仔细想想，好像什么都没有。。。。\n是的，什么都没有！代码写得还是一如既往的差劲，缺少能够独立思考的能力、做不到举一反三，一切的一切都只会按部就班。在台上依旧会紧张，更少了刚踏入大学门时的斗志。失败吧？？确实挺失败的。\n一开始一直想着考研，感觉打着考研的口号，就能贴上好学生的标签，就不会变得浑浑噩噩，但是环境的影响是必然的，因为自身所处的氛围，从而间接的决定了你所看到的上限。很多人，在大学阶段都在乎名利、奖学金啊之类的，说实话，当时我的也是。恨不得把所有的荣誉都贴在身上。随着时间的推移，慢慢接触了更多的大佬，了解到上一个层面，才知道这一切是多么可笑的事情。从我现在的自己看着两年前的自己，说成降维打击也不为过。当时忙来忙去的，说好听点叫做锻炼自己，实际上谁还不是为了那点可笑的学分呢？？学分有用嘛？？也许有吧，没用怎么才能拿奖学金呢？？那么问题来了，奖学金有用吗？？似乎没吧，能写到简历上吗？？搞笑的嘛？？所以现在回头来看，似乎才知道当时的自己做了许多毫无意义还徒添烦恼的事情。上了大学，很少有人为了学习烦心过，更多的在于这些组织关系的一些杂七杂八的事情，毫无意义且浪费时间。所以从大三开始，我要撕去前两年亲手为自己贴上的标签，做个简简单单的普通大学生。\n但是想撕标签，说的简单，做的时候还是顶着很大的压力，等于摧毁以前苦心营造出来的一个人设，再树立一个与之不同甚至相反的，周围人怎么看？？重新树立的我 还是我吗？？谁知道呢？？往下走就完事了。这也算是对于两年的自己一个交代。\n高三的高考失利，就注定在心里埋下考研的萌芽。当时看着各个高校的专业排名，最中意的是华东师范大学，其次是我喜欢上海这个城市。但是呢，上了大学之后，周围的人都在告诉你，像文达这种学校能考个安大就不错了。。。是呀，安大还是211呢，你稀罕嘛？？反正我可不想。随着最近的忧虑，我恍惚和当时的自己进行了一次对话。大政笑二夕多么的颓废，而二夕却在感叹当时的大政多么心高气傲。如果可以，我更想做回以前的自己。那个做出一点点成绩，就引以为傲的大政。那个血气方刚的中二少年。\n现在，我 回 来 了！！！先从目标开始，考研目标： 华东师范大学 ，说难听点，窝窝囊囊从中学到大学上的都是垃圾学校，考研再不翻身更待何时！！！ 我想把高三时候陪伴大政的一句话，送给现在的二夕： 我不去想是否能够成功，既然选择了远方，便只能风雨兼程。\n现在回答开头提出的问题：我回来了吗？？是的，一个全新的我回来了。\n","description":"","tags":null,"title":"我回来了？？","uri":"/life/%E6%88%91%E5%9B%9E%E6%9D%A5%E4%BA%86/"},{"categories":null,"content":"可能自己就是天生比较丧的原因，当第一次僵尸的《网易云》就入了坑，这几天，听见了他的《淹没》，就开始单曲循环。\n其实，说到底，rapper也好，yoer也罢，都是小众文化，想要的到大众的认可，谈何容易。但往往就是这种小众的圈子，入圈的人更能找到共鸣，因为有些话，只有小众人才能明白。\n以下内容是根据歌词所想所写：\n想去冒险，结果一直没有真正的去实践过。我也曾一个人做地铁坐公交到底站，带上耳机的惆怅感只有自己能懂。喝酒吗？？我不喝酒，喝酒伤身体，多喝点奶。有时自己的抑郁的时候，通常是手机开飞行模式，不想遭到任何事情打扰，关上房门，带上耳机，拿起悠悠，就进入另外一个世界了。\n你高考了没？？学习成绩怎么样啊？？对于自己的未来有想法嘛？？考不上大学是不是打算直接就去打工啊？？ 反正谁知道呢，走一步看一步就好。\n我是个yoer，但不是火力少年王那种，电视上面的都是基础招，都是垃圾，哎哟、好吧，其实大家玩的都差不多吧。反正你们也不懂，只是看看热闹罢了。玩的也就一般嘛 在圈子算低端吧。从来没指望这玩意能够赚钱，还不是因为自己喜欢啊。家里啊、家里人一开始最多认为我是三天的新鲜劲，过去就没了，支持嘛？？说不上吧，你想想你儿子整天玩个悠悠球，难不成你还供着他啊……至于现在，不反对就好。\n有时候，就很烦，玩悠悠球毕竟不是未来，鸡汤现在都烂大街咯，成功一定会来，就**放屁。我会不会坚持？？不知道，反正我没想过放弃。\n凌晨的卧室它会变成汪洋 在每晚一点半准时的重逢\n手机屏散发出微弱的光芒 抵抗这无形中巨浪的重重\n连秒针都变得肆意而猖狂 嘲弄他理想的荒唐\n苦笑的祭奠那逝去的张扬 还有他已不知去向的从容\n我想做到给他们看见 我想成为他们口中特例\n我想做到给他们看见 吐出这口憋了无数年的恶气\n失魂落魄的那个人啊，这个世界又何曾让他选\n一开始就只有这一条路给他走，死不悔改的丧家犬\n暴风雨并不会让人绝望，杀人的不是狂风\n遍体鳞伤的人 绝不会倒在最艰苦的长征\n积压的情绪爆发后 突入其来的平静让人惊讶\n生的了结最可能出现在某个无限美的黄昏\n嘴里说我知道我明白我会照做，心里说死也不要\n他们总逼着你喝下去有一种名字叫为了你好的毒药\n成功竟然比存在本身还重要 他们指着那些伟人\n时至今日我发现哪里有人群 入眼处尽是鬼魂\n愿世界没有歧视，小众文化forever！\n","description":"","tags":null,"title":"听姜云升——《反抗》","uri":"/life/%E5%90%AC%E5%A7%9C%E4%BA%91%E5%8D%87%E5%8F%8D%E6%8A%97/"},{"categories":null,"content":"致RIOT悠悠球协会全体成员的一封信、 社团名以及LOGO的由来 时间返回到一年前，也大约在这个时候，我可以确信我们的悠悠球社团能够成立，也大约在这个时候，想好了社团的名字，以及设计出社团的LOGO。\n还是想说说名字的来历吧，主要来源于我比较喜欢的一颗悠悠球 “start the riot” ；还有就是RIOT可以简单分成两部分来看：“RI” 其中R的词根的有再一次的意思，而”OT“呢？？这个可不是打游戏里面的OT，而是圈子里面提倡的一个概念”Original Throw“。因为大多数人，或多或少再小时候都接触过悠悠球，所以我希望的是当再一次接触到悠悠球，请不要再放下她。（ 还好学校里面的领导没文化，不知道riot其实是暴动、暴乱的意思，要不然说不定给我ban了，哈哈哈哈 ）\n至于社团的LOGO呢？？更偏向于街头涂鸦的那种感觉，给人的整体感觉也是比较青春有活力的。与传统的圆形或者中规中矩的方形所不同，甚至可以感觉到一点叛逆的味道在里面。。。\n为何创立？？ 为何创立社团？？以及有没有必要创立一个悠悠球社团？？ 其实这两个问题困惑了我许久。先谈谈第一个：悠悠球作为小众运动，对于绝大多数人而言，甚至还停留在儿时的玩具，只能够普普通通一上一下的简单操作，对于电视上出现的各种操作，更以为是特效。。。。。这个原因也是能说是其中的一点。想打破大家对于悠悠球的认识也是创立的一个主要原因。在刚上大学的时候，我就开始尝试着让更多人了解悠悠球，或者说入坑悠悠球，但是悠悠球相比于其他的玩物，上手难度比较大，因为是小众，文化基础不是很好。再加上需要付出时间和精力去练习等等诸多因素，从而导致更多的人都只是愿意看看。但是正是由于她的小众以及上手难度，这也是使得悠悠球更显得与众不同。在当时尝试推广之下，已经有了一定的群众基础，刚好赶上要举办元旦晚会，因此便和几位小伙伴上台表演了一番，虽然玩得都是基础招，对于许多没有真正了解过的人来说，这已经amazing了！！！是的，表演效果还是可以的。这也让我有了创办的信心。在2019年三月份，华东高校悠悠球联赛正式举办，当时因为一些原因，并没有去现场学习。但通过直播，仍然可以看见有许许多多的大学生对于悠悠球的热爱与执着，特别看见新手组的时候，对我而言感觉是最多的。在五一假期的时候，来到上海，参加了上海悠悠球聚会，起初我以为我是最差的，，但是看见很多意想不到的，有小朋友也有大叔，都是因为对于悠悠球的喜欢与热爱，我们得以相聚。玩悠悠球，玩得开心不就可以了，为什么想那么多呢？、如果创立社团可以让这份快乐延续和传播下去，岂不是更好？？从那时起，我就在心中埋下一颗种子，并尽力让其生根发芽。\n有必要吗？？或许正确的答案是没必要吧。创立社团对我自己而言更多的是徒增了许多烦恼（在实际的过程中也是如此）。但既然能够成立一个社团，又何必去管它有没有必要呢、、 干就完了！！\n为期一年？？ 实际上，在协会会长这个职位上，并没有满一年就下来了。。。\n起初，在刚成立的时候，还在幻想着，纳新能招多少多少人，以后举办什么什么活动之类的，理想总是美好的，实际证明这一切的幻想都是基于我自己对于悠悠球的喜欢，对于一个不冷不热的路人来说，我们更应该思考的是如何让他们对此感兴趣。。 所以说，不管是纳新还是举办活动，都比我预想的要差的很多，甚至在有一段时间，我就在想，社团还有必要继续运营下去吗？？这时，我想起《曾国藩》中的一句话：\n打破牙和血吞！！！\n哈哈哈，现在回头看来也没有那么严重，只不过是与心里的预期相差太多，有点接受不了，所以难免有点颓废。颓废过去，社团还是要经营的，最重要的每周的训练是必不可少的，只有在保证训练量的基础上，部员才能有所成长。就这样，新的一年即将到来，随之而来的还有元旦晚会，这也算是社团的一个隐藏起点吧。但是身份却发生了改变，相比较一年前，想在舞台上秀操作，那时更多的是想让协会的部员能够上台展示自己，这是社团的收获，也是你们的收获。和当时不变的还是，舞台肯定要炸，玩悠悠球不蹦迪，那不是在土嗨嘛？？（ 开个玩笑 ） 就这样，经过为期三个月的努力，社团可以呈现一个完整的舞台，足够了，是的。这既是对于社团部员的考核，也是对于我自己的一次检验，还好，不算太差。\n到了2020年，因为疫情原因，没能及时返校，部员的训练量也就落下了。回校之后，就在想，要不就这样吧？？反正接力棒就要交到下一届，到时候就与我无关了了了了、、、 内心还是挺纠结的。最后想了想，活动还是要办的，毕竟要为留下来的部员最大化的谋取福利，顺便可以培养下一届会长的办事能力。也算是对自己交个差吧。\n以上大概差不多就是这一年来经营社团方面的心态变化。接下来简单说一下个人的经验：\n做好牺牲自己（时间和金钱），当选择成立一个社团或者留任的时候，那就代表着你要担负起属于自己的那一份责任； 要有适当的计划，可以是长远性的，也可以是目前的，比如说在纳新结束后，可以根据部员的时间合理安排每周的训练，再具体点就是每周训练的内容； 调动部员的积极性，相比较参与社团活动，可能大部分部员都会选择做自己的事情，因为在他们看来参与社团活动是为了社团的发展之类的，而往往牺牲的是他们自己的时间，长而久之，就慢慢会退出社团活动，这时作为会长就要结合实际情况，调动部员的积极性； 在比较活跃或者说表现比较积极的部员，要培养他们的归属感，从而可以他们有参与社团活动、留在社团之类的想法，产生良性循环； 认真重视自己的社团，比如在每次训练的时候，可以逐一私给部员私发信息，让部员意识到其重要性，如果作为会长自己都不重视，凭什么要求部员积极呢？？ 谈谈收获。。 好像读到现在，整体给人的感觉是有点不太乐观的、甚至还是比较颓废的。但事情都是有两面性的。\n给我收获最大的莫过于看见部员的成长。从什么都不会，到可以玩出点东西；从内向腼腆，到敢于上台表演；从遭受别人的冷眼嘲笑，到慢慢有了掌声……\n记得当时纳新结束，有一个小部员，来找我练球，教他的时候，问他什么都不说，发球手还抖的噼里啪啦的，整个人就是特别内向，更别说在人群面前展示自己了，但是逐渐慢慢的，有了变化，在元旦晚会的时候，上台表演，听见来自台下观众的掌声，也可以肯定自己。这一切的变化，不能说都是来自于悠悠球，但是悠悠球在其中有不可或缺的因素。还有的部员说，我从小就双手不协调，不可能玩好的。但是我想说，只要你相信自己，并且听我的愿意花时间去练习，没有什么做不到的。是的， 只要坚持，结果总不会太差 。\n再说说我自己吧，因为把自己大部分时间都放在社团上，也就没了过多的时间抄招想招，每周都在想着教什么基础招，想必圈子里面很多的老前辈都知道基础招的重要性，从而就有了我现在的手感，这与教授部员基础招有着密不可分的关系。还有就是，心态被磨平了，做事情可以从更多的方面去思考问题，这些也全都是收获。\n那么现在再想有必要创立社团嘛？？我的回答是：有的。我把社团的定位是传播悠悠球的正确玩法，而不是培养比赛型选手，如果可以向圈子里面输送新人也是更好。但就说传播悠悠球的玩法，我想我尽我自己的能力，做的还行吧。\n如果说社团最大的难题在哪？？莫过于 传承 。\n我的故事到此为止\n没做好的 你来帮我完成\n永远保持热爱\n","description":"","tags":null,"title":"关于RIOT悠悠球协会","uri":"/life/%E5%85%B3%E4%BA%8Eriot%E6%82%A0%E6%82%A0%E7%90%83%E5%8D%8F%E4%BC%9A/"},{"categories":null,"content":"说起 《三体》 ，想必大家并不陌生，大约从初中就听说过这套书，但很遗憾的是，当时的我并不喜欢读书，直到现在，也就是大二的时候才读完。但庆幸的是，有些书幸好没有那么早的草草地过一遍，要不书中想表达的含义，在当时的经历与心境来说是无法理解和体会的。\n地球生命真的是宇宙中偶然里的偶然，宇宙是个空荡荡的大宫殿，人类是这宫殿中唯一的一只小蚂蚁。这想法让我的后半辈子有一种很矛盾的心态：有时觉得生命真珍贵，一切都重如泰山；有时又觉得人是那么渺小，什么都不值一提。反正日子就在这种奇怪的感觉中一天天过去，不知不觉人就老了……\n这是《三体1》当中叶文洁，对伪主人公汪淼所说的一段话，也是全书中我比较喜欢的一段话。读完书之后，在翻阅之前做的笔记的时候，看到这段。不得不佩服大刘的思维，在读第一本的时候，可能会觉得这只是叶文洁的感叹。但通读全书之后，何尝又不是每个读者心里发出的一声叹息呢。。从宏观的角度来看，与浩渺的宇宙相比，人类确实只是一粒尘埃。但同时，人类是幸运的，生活在地球上。可悲的是，人类本身却不知道爱惜这块土地。\n反观叶文洁，为何要给三体人发信息呢？？甚至不惜犯了反人类罪。当从汪淼的视角，第一次看见叶文洁的时候，不免觉得这样一位老太太有点可怜，失去了自己的女儿，看着她那照看小区里邻居家小孩的样子，哪能想得到是ETO的统帅。。 但结合叶文洁的遭遇，也不难发现，她之所以决定把三体人引来都是有原因的，甚至不惜牺牲丈夫的生命，是人类一次又一次的做出违反道德底线的事情，在文革那个特殊时期，国将不国，人成非人。从而给叶文洁的心中埋下不相信人类的种子，当来到红岸基地之后，凭借自己的技术和手段，在收到三体人的警告：“不要回答！不要回答！不要回答！” 但她还是毫不犹豫地发送信息，暴露出地球的坐标，也就有了三体以后的故事。\n全书中，我最喜欢的角色是：章北海 ；最欣赏的应该是： 维德 。一个是要多想，一个是前进，不择手段的前进！之前，在还没读《三体》之前，隐隐约约看了点书评之类的，知道章北海是一个坚定的失败主义者，那时候就在想，既然是一个失败主义者，为何还有那么多人粉他呢？？不是应该被批评的嘛？？所以一开始对于章北海并没有什么太好的印象，甚至还有点反感。。。。在读到的《黑暗森林》的时候，面对三体人的来临，几乎所有人都慌张失措的时候，联合国更因此，制定了反人类的面壁计划。在这个条件下，反观章北海，没有面壁者的权利有义务，却成为了一个合格的民间面壁者。当大刘写到他问自己的父亲，下一步该怎么做的时候，父亲告诉他：“北海，我只能告诉你那以前要多想”。设想一下，如果我们自己在当时的环境下，我们该如何去做？？更多的可能是崩溃，但他没有。知道人类的特性都明白，逃亡主义是不可能实现的，但面对敌我实力的悬殊，也唯有逃亡，才能为人类文明的延续留下火种，尽管流浪在宇宙中的新人类，已经成为非人。但是毫无疑问，他是成功的，也完成了自己的任务。再来看看看维德，第一反应是这个人未免有点太讨厌了，喜欢欣赏人绝望的时候，就凭这一点就很恶心，是不是。。但是慢慢读下去，发现他是一个彻底的功利主义者，更说出了很多金句，比如： 失去人性，失去很多，失去兽性，失去一切 。但是欣赏归欣赏，要是在现实生活中，要这么一个人，肯定是不愿意和他做朋友的，太危险了，得绕的远远的，哈哈哈~\n简单的说一下阅读感受，在读第一部的时候，能感觉到这本书的格局之大，也被大刘的一些科幻创意点子所惊呆，尤其是在说冯诺依曼用大量的士兵给秦始皇展示计算机模型的时候，绝对的是一大亮点，还有就是从工具人汪淼的视角，来揭开三体人，让人感觉不太像是科幻小说，更有点的侦探悬疑的感觉。再看第二部，主人公罗辑从一个混日子的大学教授，被指定为面壁者，从而慢慢经历在书的末尾与三体人正面对决，可谓惊叹，对于罗辑的心路历程，再看看年少时候到我们。反观第三部，程心被喷圣母biao，但是她做错了什么嘛、是人类选择了程心，在那个时代的人类，可怜更可笑，盲目地自大，所以选择程心是理所当然。在读到书的结尾的时候，被大刘一个接着一个抛出的科幻点子所惊艳，有一种喘不过气的感觉。但又有点急急促促的感觉。\n读科幻小说给我的最大感受，就是每次读的时候都把自己的思想扩展到宏观层面，感觉眼前的所有烦心事，在整个人类文明面前都是不值一提的，可以把问题思考的更深入点，就想到既然文明可以一直延续下去，那么该如何让自己更有意义，成为文明的一部分呢？？我得出的答案是，那就是做些有意义的事情，什么事情是有意义的呢？？放下小了说，就是活好当下。。。\n","description":"","tags":null,"title":"读后感——《三体》","uri":"/life/threebody/"},{"categories":null,"content":"今天想说说 关于知足 、 大家经常说“知足常乐”，但对于知足却没有一个明确的定义。\n语出《道德经》。认为“祸莫大于不知足”，不知满足，进而追求，定招灾祸。知其足，不追求，安于所得，无为无德，反而常常满足。知足才能避免灾祸，才能全生保身。\n今天我为数不多的一位朋友，遇到了点烦心事，和我唠嗑。然后我对她说“知足就好。” 她说：“ 我太喜欢这个词了，知足常乐”\n但怎么说呢、知足是个好词，每个人都渴望知足，但是从我的角度来说：其实我想要的是比知足多一丢丢，这样才能因为知不足，而保持学习。 知足确实是挺好的，但是人在成长的过程中，往往会由于自己的贪婪或者说是欲望，而不断提高对于自己的要求。当自己的要求更高、更严，从而可以在一定程度上促使自己变得更好、站得更高，那么在那个时候的自己，可能就会变得不那么知足，甚至有点贪得无厌。其实我感觉这些都是人之常情，如果所有人都安于泛泛而谈的知足，那么又有谁来推动社会的进步呢？？\n其实这种想法也是不对的，把贪婪说成知足，把知足说成安逸。我所理解的知足，是一种享受状态，是在于知道自己想得到什么之后，不用多想其他的什么，是完成目标之后的，有点小小的满足，甚至是骄傲的感觉，似乎整个世界都没有烦心事了，又好似整个世界的事情都与自己无关，可以安安稳稳地去做自己想做的事情，没有为了目标而去努力的劳累感。就这样，一切都安静了。。\n事实证明，知足状态下的我，可能会变得一塌糊涂，如果再这种状态下去，甚至会变得一无是处。在暑期，当忙完了所有要紧的事情的时候，当时的我已经精力交瘁，也有一种“知足”的感觉。因为感觉所有的事情都结束了，似乎可以让自己好好休息一段时间咯。当时理想的状态就是：每天写写代码，看看书，练练球，再学点额外的技能之类的。但是这几样，几乎没有一件事情是完成了的。这就是因为人的惰性，人只会着急与眼前的事情，很难去保证或者说坚持一些有意义的事情，让自己可以变得更优秀。\n等等，写到这里，我不由得想到，前面所说的我想要的是比知足多一丢丢 。这似乎就进入了一个死循环当中，每当处理完一些事情（￥%#\u0026噼里啪啦、乱七八糟之类的事），就会进入短暂的休息期，这个期间的自己是不想做任何事的，或者说不想做任何要动脑、动体力的事情，在这个状态下去，就会想是不是因为自己最近的不努力、懈怠，从而导致自己没有进步，与别人的差距又拉开了？？然后就感觉自己不再知足…… 长此以往下去，似乎会让自己变得更累，总感觉自己没有丝毫喘气的机会。。。\n那么问题来了？？究竟什么样的状态才是知足呢？？就如同五月天在歌词中写到：\n天上的星星笑地上的人，总是不能懂不能觉得足够。\n","description":"","tags":null,"title":"谈谈知足","uri":"/life/%E7%9F%A5%E8%B6%B3/"},{"categories":null,"content":"TwoSum 一、题目概述 给定一个整数数组 nums 和一个目标值 target ，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。\n你可以假设每种输入只会对应一个答案。但是，数组中同一个元素不能使用两遍。\n示例：\n给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9 所以返回 [0, 1] 二、解法分析 对于这个题目想必大家并不陌生，可以说是绝大多数人的开始刷题之路的敲门砖。如果是一开始起初接触刷题的朋友，看到这题，可能没有思路，也可能是暴力解法 ，对于我自己就是使用双重for循环遍历暴力解，：）\n下面将使用双重for循环和HashMap两种解法供大家参考：\n1、暴力解法 我们首先来简单的分析一下题目：需要从nums数组中寻找两个数，使这两个数的和等于目标值target，并且数组中同一元素不能使用两次。所以我们可以使用for循环来寻找，外层循环的条件是for(int i = 0; i \u003c nums.length; i++) 即从数组的第一个下标开始遍历，直到遍历到数组结束；内层循环的条件是for(int j = i + 1; j \u003c nums.length; j++) 注意内层循环开始的条件不是从数组的第一个下标开始的，而是从nums[i] 的下一个位置开始遍历，结束条件相同。\n就这样，咱们使用双重for循环如此暴力的遍历，直到遇见了符合nums[i] + nums[j] == target 条件时，返回数组对应的下标即可；如果遍历结束之后，仍然没有在该数组中找到需要的数，则抛出异常。\n代码实现如下：\n1 2 3 4 5 6 7 8 9 10 11 // 使用for循环遍历 暴力解题 public int[] twoSum02(int[] nums, int target) { for (int i = 0; i \u003c nums.length; i++) { for (int j = i + 1; j \u003c nums.length; j++) { if (nums[i] + nums[j] == target) { return new int[]{i, j}; } } } throw new IllegalArgumentException(\"Two Sum No Solution\"); } 2、HashMap解法 对于哈希表这种数据结构，这里就不做具体的说明，想要了解的小伙伴可以自己查阅一下相关文档。\n我们先定义一个数组res[] 用于存放最后返回的结果。然后再创建一个哈希表，HashMap\u003cInteger, Integer\u003e map = new HashMap\u003cInteger, Integer\u003e(); 然后对于这个数组进行遍历，每次遍历的时候取出一个数，然后再map 中查询，是否能找到一个合适的数，使两者之和等于目标值target ，如果找到直接返回即可；否则，将该数加入map 。依次进行遍历。\n代码实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 使用HashMap来解决该问题 public int[] twoSum01(int[] nums, int target) { int[] res = new int[2];// 存放返回的结果 if (nums == null || nums.length \u003c= 1) {// 判断传入的数组是否符合条件 return res; } HashMap\u003cInteger, Integer\u003e map = new HashMap\u003cInteger, Integer\u003e();// 创建哈希表 for (int i = 0; i \u003c nums.length; i++) { int num = nums[i]; int val = target - num; if (map.containsKey(val)) {// 在map中寻找 res[0] = map.get(val); res[1] = i; return res; } else { map.put(num, i); } } return res; } 3、结束语 这个也算是开的一个新坑吧，虽然数据结构篇还没有完结。。。。刷题，几乎是一个程序猿的必经之路。大家一起加油！！！\n源码地址 —\u003e TwoSum\n","description":"","tags":null,"title":"TwoSum","uri":"/leetcode/twosum/"},{"categories":null,"content":"两年前的这个时候，高考也已经告一段落。一直以来，都太强调学习，满脑子里想的都是”知识改变命运“这种空而大的口号。其实这一点，直到今天，还依然未变。要不看了这么多年的书，岂不是白看了嘛？？哈哈哈哈哈……\n在高三的时候，总想着，只要再努力一点，再多背一个单词，多做一道题目，就离考了大学更进一步，但其实不然。当拿到报考指南的那一刻，还是傻眼了。似乎有一种无力感，高考查完分之后的那种兴奋再也找不到了，就在想：当时熬的夜，还值得吗？？都说付出就会有回报，但结果呢？？这大概就是灰色而幽默的现实，当头一棒，给我敲醒。我只是个蝼蚁，还有很长的路要走！！\n在大一的时候，大部分的同学的共同语言，还是关于“高三”。似乎，之前的所有经历和高三相比都不值一提，还是当时眼界太低，能看见的只有高考呢？？上了大学，懵懵懂懂，总想着，摆脱了高中的条条框框的拘束，也有个平台可以展示自己了。其实现在反过来，想想当时自己为什么要加哪些组织、社团呢？？是真的喜欢吗？？还是单纯的为了学分呢？？还是利益相关呢？？大一刚入学的时候，感觉那些当着学生组织负责人的学长学姐好了不起，如果自己到了那个时候，会变得和他们一样优秀吗？？大一，也许在悔恨高中为什么不努力好好学习，也许是刚刚告别高三，还把看书、刷题当做一种习惯，但慢慢的，随着时间的推移，当时的屠龙少年，现在也变成了一条恶龙。（前段时间在整理书柜的时候，发现了大一时候学高数，演算的稿纸，还真的挺佩服那时候的自己）\n到了大二，渐渐的在学校里有了自己的圈子，创立了自己的社团，原以为会变成自己想要的样子，迎来的却是各种毒打，其实也算不上毒打，准确来说是劝退。当热情被慢慢消磨殆尽，坚持下来的可能就是责任了吧。那如果连责任心都没了呢？？我还有什么坚持下去的理由呢？？\n到现在，回过头来，看看高三时候的自己，可能会对他说：把一切都看淡一点，没什么大不了的。是的，没什么大不了的。说句鸡汤的话：只要你努力，总不会变得太差劲。\n其实这篇文章，在好久之前就想写，但一直找不到带入点，也不知该如何去说起。可能是最近的烦心事多了，又变得消极了点，心里有情绪，总归要抒发出来的嘛。\n","description":"","tags":null,"title":"写个两年前的自己","uri":"/life/%E5%86%99%E4%B8%AA%E4%B8%A4%E5%B9%B4%E5%89%8D%E7%9A%84%E8%87%AA%E5%B7%B1/"},{"categories":null,"content":"关于我？ 叫我二夕就好，可能看到这里，你会好奇，为啥起一个这么怪的名字呢？？\n当时在想昵称的时候一直找不到合适的，打算叫“无名”，但总感觉有点落了俗套。还好，中文是比较有意思的，把“无”和“名”下面的部分拿了，不就是“二夕”了嘛。。。。。哈哈哈哈哈哈\n玩什么？？ 常常会感慨自己是个老年人了，过了打游戏的年龄。在大学生活中，不打游戏，时间就多了起来。无聊的时候，总想找些东西打发时间。慢慢的，找到新的伙伴——悠悠球。停停停！！！我知道你想说：刚刚还感慨自己是老年人，现在又玩起小孩子的东西。\n大多数人对于悠悠球的印象可能还停留在儿时的玩具，是的，重新开始接触的时候，我也是那么认为的。但随着技术的提升，认识的玩家越来越多，会发现一个全新的世界。你会发现，有很多人都在为之而共同努力。只想把悠悠球，一种玩具，小众文化，推向大众。想得到大众的认可。\n除了玩？？ 除了玩，那肯定就是吃和睡咯……呸呸呸，这不是我！！！\n学的专业是软件工程，所以平时最多打交道的就是代码，哪还有时间吃吃睡睡的，捋了捋自己的头发。作为一个日常摸鱼的当代大学生，平时无非就是看看书，写写代码，听听歌。就这？？\n","description":"","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"前言 大政的Blog就这样稀里糊涂的开通了。\n有时候闲着无聊，总想着写点什么，可能是乱七八糟的想法，可能是一段书评，也有可能是一段歌词。因为相对于话语的直白，文字能表达的情感是更加细腻的，它也可以将有些事情一直保存下去。\n也有可能是我天生就有点内向，甚至比较丧，不太喜欢说话。\n当时之所以想开通Blog最主要是想督促自己保持学习的习惯，并且可以在这里记录一些关于学习的笔记。也有一部分原因是在这段时间接触了许多之前没有接触过的人和事，总想着这些美好的事和可爱的人更应该被文字所记录，而不是埋藏在我的心里。\n所以博客的内容可能是一串代码，一行文字，一条书评，一段歌词，或许是一句心里话。\n我既做不上神明，那当个野兽也好。\n","description":"","tags":null,"title":"Hello World ! Hello Blog !","uri":"/life/hello/"}]