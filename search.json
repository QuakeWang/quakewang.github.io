[{"categories":null,"content":"Oracle 同步数据至 Doris 前言 在上篇博客中，我们掌握了如何使用 Flink-CDC 和 Doris-Flink-Connector 将 MySQL 的数据同步至 Doris，本篇博客一起来探索如何将 Oracle 的数据同步至 Doris。本次使用的主要技术栈如下：\nDoris 2.1.6 Oracle_11g Flink 1.18.0 FlinkCDC 3.1.0 Doris-Flink-Connector 24.0.0 准备工作 Oracle 安装并配置 Oracle 的配置相较于 MySQL 来说会复杂一些，这里逐步来演示一下。采用的方式是使用 Docker 部署 Oracle，然后开启归档模式。\n安装 Oracle 11g 拉取 Oracle 11g 的镜像：\n1 docker pull registry.cn-hangzhou.aliyuncs.com/helowin/oracle_11g 执行以下命令以创建并运行 Oracle 11g 容器（其中：1521 为映射主机端口，8071 为管理界面端口，helowin 为 Oracle 数据库唯一实例 ID，端口号可以根据服务器实际情况进行映射，防止冲突即可）：\n1 2 3 4 5 docker run -d -p 3051:1521 -p 4891:8080 \\ --name oracle_cdc \\ -e ORACLE_HOME=/home/oracle/app/oracle/product/11.2.0/dbhome_2 \\ -e ORACLE_SID=helowin \\ registry.cn-hangzhou.aliyuncs.com/helowin/oracle_11g 这样我们就有了一个 Oracle 11g 的容器，可以使用 docker exec -it oracle_cdc bash 进入容器内部。\n配置 Oracle 环境 切换至 root 用户（默认密码为 helowin）： 1 su root 修改环境变量： 1 2 3 4 5 6 7 8 9 vi /etc/profile ## 下面的内容贴到文件末尾 export ORACLE_HOME=/home/oracle/app/oracle/product/11.2.0/dbhome_2 export ORACLE_SID=helowin export PATH=$ORACLE_HOME/bin:$PATH ## 退出保存，source 让其生效 source /etc/profile 创建 sqlplus 软链接： 1 ln -s $ORACLE_HOME/bin/sqlplus /usr/bin 通过在 /usr/bin 目录下创建软链接，使得 sqlplus 命令可以在系统的任何位置被直接调用，而不需要指定完整路径，方便后续操作。\n配置数据库恢复和归档日志 登录 SQL*Plus 并执行以下命令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 sqlplus /nolog -- 以 DBA 身份登录 CONN /AS SYSDBA -- 设置数据库恢复 ALTER SYSTEM SET DB_RECOVERY_FILE_DEST_SIZE = 10G; ALTER SYSTEM SET DB_RECOVERY_FILE_DEST = '/home/oracle/app/oracle/product/11.2.0' SCOPE=SPFILE; -- 启用归档日志模式 SHUTDOWN IMMEDIATE; STARTUP MOUNT; ALTER DATABASE ARCHIVELOG; ALTER DATABASE OPEN; -- 查看归档日志状态 ARCHIVE LOG LIST; Database log mode Archive Mode Automatic archival Enabled Archive destination USE_DB_RECOVERY_FILE_DEST Oldest online log sequence 60 Next log sequence to archive 62 Current log sequence 62 -- 为特定表启用增强日志记录 ALTER TABLE FLINKUSER.CUSTOMERS ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS; -- 为整个数据库启用增强日志记录 ALTER DATABASE ADD SUPPLEMENTAL LOG DATA; -- 创建用户并赋予 dba 角色 CREATE USER admin IDENTIFIED BY admin123; GRANT DBA TO admin; -- 为该用户赋予 dba 角色 创建表空间和用户 创建表空间： 1 2 3 CREATE TABLESPACE logminer_tbs DATAFILE '/home/oracle/app/oracle/product/11.2.0/logminer_tbs.dbf' SIZE 25M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED; 创建用户并授权： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 CREATE USER flinkuser IDENTIFIED BY flinkpw DEFAULT TABLESPACE LOGMINER_TBS QUOTA UNLIMITED ON LOGMINER_TBS; -- 授予必要权限 GRANT CREATE SESSION, CREATE TABLE, LOCK ANY TABLE, ALTER ANY TABLE, CREATE SEQUENCE TO flinkuser; GRANT SELECT ON V_$DATABASE TO flinkuser; GRANT FLASHBACK ANY TABLE TO flinkuser; GRANT SELECT ANY TABLE TO flinkuser; GRANT SELECT_CATALOG_ROLE, EXECUTE_CATALOG_ROLE TO flinkuser; GRANT SELECT ANY TRANSACTION TO flinkuser; GRANT EXECUTE ON DBMS_LOGMNR TO flinkuser; GRANT EXECUTE ON DBMS_LOGMNR_D TO flinkuser; GRANT SELECT ON V_$LOG TO flinkuser; GRANT SELECT ON V_$LOG_HISTORY TO flinkuser; GRANT SELECT ON V_$LOGMNR_LOGS TO flinkuser; GRANT SELECT ON V_$LOGMNR_CONTENTS TO flinkuser; GRANT SELECT ON V_$LOGMNR_PARAMETERS TO flinkuser; GRANT SELECT ON V_$LOGFILE TO flinkuser; GRANT SELECT ON V_$ARCHIVED_LOG TO flinkuser; GRANT SELECT ON V_$ARCHIVE_DEST_STATUS TO flinkuser; 创建示例表 切换到 flinkuser 并创建表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 sqlplus flinkuser/flinkpw -- 创建 customers 表 CREATE TABLE customers ( customer_id NUMBER PRIMARY KEY, customer_name VARCHAR2(50), email VARCHAR2(100), phone VARCHAR2(20) ) TABLESPACE LOGMINER_TBS; -- 创建 product 表 CREATE TABLE product ( product_id NUMBER PRIMARY KEY, product_name VARCHAR2(50), price NUMBER ) TABLESPACE LOGMINER_TBS; -- 查看表空间中的表 SELECT tablespace_name, table_name FROM user_tables WHERE tablespace_name = 'LOGMINER_TBS'; -- 插入 10 条模拟数据 INSERT ALL INTO customers (customer_id, customer_name, email, phone) VALUES (1, 'John Doe', 'john.doe@example.com', '123-456-7890') INTO customers (customer_id, customer_name, email, phone) VALUES (2, 'Jane Smith', 'jane.smith@example.com', '234-567-8901') INTO customers (customer_id, customer_name, email, phone) VALUES (3, 'Bob Johnson', 'bob.johnson@example.com', '345-678-9012') INTO customers (customer_id, customer_name, email, phone) VALUES (4, 'Alice Brown', 'alice.brown@example.com', '456-789-0123') INTO customers (customer_id, customer_name, email, phone) VALUES (5, 'Charlie Davis', 'charlie.davis@example.com', '567-890-1234') INTO customers (customer_id, customer_name, email, phone) VALUES (6, 'Eva Wilson', 'eva.wilson@example.com', '678-901-2345') INTO customers (customer_id, customer_name, email, phone) VALUES (7, 'Frank Miller', 'frank.miller@example.com', '789-012-3456') INTO customers (customer_id, customer_name, email, phone) VALUES (8, 'Grace Lee', 'grace.lee@example.com', '890-123-4567') INTO customers (customer_id, customer_name, email, phone) VALUES (9, 'Henry Taylor', 'henry.taylor@example.com', '901-234-5678') INTO customers (customer_id, customer_name, email, phone) VALUES (10, 'Ivy Chen', 'ivy.chen@example.com', '012-345-6789') SELECT * FROM dual; -- 验证插入的数据 SELECT * FROM customers; -- 插入 5 条模拟数据 INSERT ALL INTO product (product_id, product_name, price) VALUES (1, 'Product A', 10) INTO product (product_id, product_name, price) VALUES (2, 'Product B', 20) INTO product (product_id, product_name, price) VALUES (3, 'Product C', 30) INTO product (product_id, product_name, price) VALUES (4, 'Product D', 40) INTO product (product_id, product_name, price) VALUES (5, 'Product E', 50) SELECT * FROM dual; -- 验证插入的数据 SELECT * FROM product; -- 提交事务 COMMIT; Flink 配置 FLink 仍旧采用的是单机部署，直接解压即可，可以根据自己的服务器情况进行调整 flink-conf.yaml 配置文件。然后最关键的是依赖的配置，由于 License 的不同，这些需要用户自己去手动配置。主要需要的有：\ndoris-flink-connector-1.18-24.0.0.jar：Doris 的 Flink 连接器； flink-sql-connector-oracle-cdc-3.1.0.jar：Flink 的 Oracle CDC 连接器； ojdbc8-19.3.0.0.jar：Oracle 的 JDBC 驱动。 上述配置文件可以下载放在 flink/lib 目录下，可以参考下图（还包含了上一篇 MySQL 同步数据的配置文件）：\n完成上述配置之后，使用 start-cluster.sh 启动 Flink 集群。\n代码同步 可以创建 Maven 项目，并添加所需依赖如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u003cdependency\u003e \u003cgroupId\u003eorg.apache.flink\u003c/groupId\u003e \u003cartifactId\u003eflink-streaming-java\u003c/artifactId\u003e \u003cversion\u003e1.18.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.doris\u003c/groupId\u003e \u003cartifactId\u003eflink-doris-connector-1.18\u003c/artifactId\u003e \u003cversion\u003e24.0.0\u003c/version\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.apache.flink\u003c/groupId\u003e \u003cartifactId\u003eflink-connector-oracle-cdc\u003c/artifactId\u003e \u003cversion\u003e3.1.0\u003c/version\u003e \u003c/dependency\u003e 创建一个 Java 类命名为 OracleToDoris，并编写代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 import org.apache.doris.flink.table.DorisConfigOptions; import org.apache.doris.flink.tools.cdc.DatabaseSync; import org.apache.doris.flink.tools.cdc.oracle.OracleDatabaseSync; import org.apache.flink.configuration.Configuration; import org.apache.flink.cdc.connectors.oracle.source.config.OracleSourceOptions; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; import java.util.HashMap; import java.util.UUID; public class OracleToDoris { public static void main(String[] args) throws Exception { StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment(); env.setParallelism(1); env.disableOperatorChaining(); env.enableCheckpointing(1000); String database = \"test_db\"; String tablePrefix = \"\"; String tableSuffix = \"\"; HashMap\u003cString, String\u003e sourceConfig = new HashMap\u003c\u003e(); sourceConfig.put(OracleSourceOptions.DATABASE_NAME.key(), \"helowin\"); sourceConfig.put(OracleSourceOptions.SCHEMA_NAME.key(), \"FLINKUSER\"); sourceConfig.put(OracleSourceOptions.HOSTNAME.key(), \"127.0.0.1\"); sourceConfig.put(OracleSourceOptions.PORT.key(), \"3051\"); sourceConfig.put(OracleSourceOptions.USERNAME.key(), \"flinkuser\"); sourceConfig.put(OracleSourceOptions.PASSWORD.key(), \"flinkpw\"); sourceConfig.put(\"debezium.log.mining.strategy\", \"online_catalog\"); sourceConfig.put(\"debezium.log.mining.continuous.mine\", \"true\"); sourceConfig.put(\"debezium.database.history.store.only.captured.tables.ddl\", \"true\"); Configuration sourceConf = Configuration.fromMap(sourceConfig); HashMap\u003cString, String\u003e sinkConfig = new HashMap\u003c\u003e(); sinkConfig.put(DorisConfigOptions.FENODES.key(), \"127.0.0.1:8030\"); sinkConfig.put(DorisConfigOptions.USERNAME.key(), \"root\"); sinkConfig.put(DorisConfigOptions.PASSWORD.key(), \"123456\"); sinkConfig.put(DorisConfigOptions.JDBC_URL.key(), \"jdbc:mysql://127.0.0.1:9030\"); sinkConfig.put(DorisConfigOptions.SINK_LABEL_PREFIX.key(), UUID.randomUUID().toString()); Configuration sinkConf = Configuration.fromMap(sinkConfig); boolean ignoreDefaultValue = false; boolean useNewSchemaChange = true; boolean ignoreIncompatible = false; DatabaseSync databaseSync = new OracleDatabaseSync(); databaseSync .setEnv(env) .setDatabase(database) .setConfig(sourceConf) .setTablePrefix(tablePrefix) .setTableSuffix(tableSuffix) .setIgnoreDefaultValue(ignoreDefaultValue) .setSinkConfig(sinkConf) .setCreateTableOnly(false) .setNewSchemaChange(useNewSchemaChange) .setIgnoreIncompatible(ignoreIncompatible) .create(); databaseSync.build(); env.execute(String.format(\"Oracle-Doris Database Sync: %s\", database)); } } 这段代码展示了如何使用 Java 来配置和执行 Oracle 到 Doris 的数据同步任务。它首先设置了 Flink 的执行环境，包括并行度、算子链和检查点等基本参数。然后，代码分别配置了 Oracle 源和 Doris 接收端的详细信息，如数据库名称、主机地址、端口号、用户名和密码等。接着，它创建了一个 OracleDatabaseSync 实例，并通过一系列方法调用设置了同步任务的各种参数，包括数据库、表前缀后缀、是否忽略默认值等。最后，代码调用 create() 和 build() 方法来创建和构建同步任务，并执行这个任务。这种通过 Java 代码配置数据同步的方法比使用命令行更加灵活。它允许开发者根据需求动态调整参数，更容易集成到现有的 Java 应用中。\n编写完成代码之后，可以使用 mvn clean package 命令来打包，然后在可以在 Flink Web UI 中提交任务。如下图所示：\n当提交完成之后，可以在 Web UI 的 Jobs Running Jobs 看见提交的任务，当任务状态变为 RUNNING 之后，说明数据同步任务正在运行。\n这个时候可以在 Doris 中查看数据同步情况：\n1 2 3 4 5 6 7 8 9 10 11 mysql\u003e SELECT * FROM test_db.PRODUCT; +------------+--------------+-------+ | PRODUCT_ID | PRODUCT_NAME | PRICE | +------------+--------------+-------+ | 5 | Product E | 50 | | 2 | Product B | 20 | | 1 | Product A | 10 | | 3 | Product C | 30 | | 4 | Product D | 40 | +------------+--------------+-------+ 5 rows in set (0.01 sec) 这个时候如果插入新的数据，Doris 中也会同步更新数据，则说明数据同步成功。\nDoris-Flink-Connector 同步 如果感觉使用代码同步数据比较复杂，则可以使用 Doris-Flink-Connector 同步数据，在 MySQL 数据同步已经用过了，总体来说就是添加依赖至 $FLINK_HOME/lib 下，然后启动命令即可。\n依赖在上面已经添加了，这里就不再赘述了，直接启动命令如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 bin/flink run \\ -Dexecution.checkpointing.interval=10s \\ -Dparallelism.default=1 \\ -c org.apache.doris.flink.tools.cdc.CdcTools \\ lib/flink-doris-connector-1.18-24.0.0.jar \\ oracle-sync-database \\ --database test_db \\ --oracle-conf hostname=127.0.0.1 \\ --oracle-conf port=3051 \\ --oracle-conf username=flinkuser \\ --oracle-conf password=flinkpw \\ --oracle-conf database-name=helowin \\ --oracle-conf schema-name=FLINKUSER \\ --oracle-conf debezium.log.mining.strategy=online_catalog \\ --oracle-conf debezium.log.mining.continuous.mine=true \\ --oracle-conf debezium.database.history.store.only.captured.tables.ddl=true \\ --sink-conf fenodes=168.43.0.1:8030 \\ --sink-conf username=root \\ --sink-conf password=123456 \\ --sink-conf jdbc-url=jdbc:mysql://168.43.0.1:9030 \\ --sink-conf sink.label-prefix=label \\ --table-conf replication_num=1 这个命令使用 Flink 运行 Doris-Flink-Connector 来同步 Oracle 数据库到 Doris。解释一下主要参数：\nFlink 执行参数：\n设置检查点间隔为 10 秒 默认并行度为 1 主类和 JAR 文件：\n使用 org.apache.doris.flink.tools.cdc.CdcTools 类 从 lib/flink-doris-connector-1.18-24.0.0.jar 运行 同步模式：oracle-sync-database\n目标数据库：test_db\nOracle 配置：\n主机名、端口、用户名、密码 数据库名和 schema 名 日志挖掘策略和连续挖掘设置 仅捕获指定表的 DDL 历史 Doris 接收端配置：\nFE 节点地址 用户名和密码 JDBC URL 导入标签前缀 表配置：\n复制数量设为 1 补充：debezium 相关的三行参数的作用。\n这三行参数是针对 Oracle CDC (Change Data Capture) 的特定配置，它们对于 Oracle 数据同步有重要作用：\n--oracle-conf debezium.log.mining.strategy=online_catalog\n这个参数设置了日志挖掘策略为 \"online_catalog\"。 在这种模式下，Debezium（用于 CDC 的开源框架）使用 Oracle 的在线目录视图来获取必要的元数据信息。 这种方法通常比其他策略更快，因为它不需要解析重做日志来获取元数据。 --oracle-conf debezium.log.mining.continuous.mine=true\n启用连续挖掘模式。 当设置为 true 时，Oracle LogMiner 会持续不断地处理重做日志，而不是在每次查询时重新启动。 这可以显著提高性能，特别是在处理大量变更时。 --oracle-conf debezium.database.history.store.only.captured.tables.ddl=true\n这个配置指示 Debezium 只存储被捕获表的 DDL（数据定义语言）历史。 当设置为 true 时，它会减少存储的 DDL 历史量，只保留与被监控表相关的 DDL 语句。 这可以减少存储开销，并可能提高性能，特别是在大型数据库环境中。 总的来说，这些参数旨在优化 Oracle CDC 过程，提高性能，减少资源消耗，并确保更高效的数据捕获。它们特别适用于需要实时或近实时数据同步的场景，同时也考虑了系统资源的有效利用。\n可以在 Flink Web UI 中查看任务执行情况：\n可以看见所有任务的 Job State 都是 RUNNING，说明数据同步任务正在运行。可以在 Doris 中查看数据同步情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 mysql\u003e select * from test_db.CUSTOMERS; +-------------+---------------+---------------------------+--------------+ | CUSTOMER_ID | CUSTOMER_NAME | EMAIL | PHONE | +-------------+---------------+---------------------------+--------------+ | 4 | Alice Brown | alice.brown@example.com | 456-789-0123 | | 9 | Henry Taylor | henry.taylor@example.com | 901-234-5678 | | 5 | Charlie Davis | charlie.davis@example.com | 567-890-1234 | | 7 | Frank Miller | frank.miller@example.com | 789-012-3456 | | 2 | Jane Smith | jane.smith@example.com | 234-567-8901 | | 10 | Ivy Chen | ivy.chen@example.com | 012-345-6789 | | 3 | Bob Johnson | bob.johnson@example.com | 345-678-9012 | | 8 | Grace Lee | grace.lee@example.com | 890-123-4567 | | 6 | Eva Wilson | eva.wilson@example.com | 678-901-2345 | | 1 | John Doe | john.doe@example.com | 123-456-7890 | +-------------+---------------+---------------------------+--------------+ 10 rows in set (0.01 sec) 这个时候如果在 Oracle 中插入新的数据，可以发现 Doris 中也会同步更新数据。可以发现使用 Connector 进行数据同步是高效又方便。\n总结 到此为止我们完成了 Oracle 到 Doris 的数据同步，同样是提供了两种方式供读者选择，第一种选择的是代码实现，代码的总体结构比较简单，也只是设置一些参数。第二种则更方便一点，使用的是 Doris-Flink-Connector 来同步，可以直接使用 flink run 命令添加对应的参数完成数据的同步。\n我们在创建测试数据的时候设置表包含主键，对应到 Doris 就是主键数据模型，读者可以使用 SHOW CREATE TABLE 语句来进行检测，那如果某张表不包含主键该怎么进行同步呢？以及某些表不需要进行同步，这些参数又该如何设置呢？可以期待下篇内容！\n参考：\nOracle CDC Connector Flink Doris Connector OracleToDoris 代码 ","description":"","tags":null,"title":"Doris02——Oracle 数据同步","uri":"/tech/doris/doris002_sync-oracle2doris/"},{"categories":null,"content":"开启新篇章 逃离技术 书接上文，八月底告别了上一份工作，迎来了短暂的自由，虽然也只有一周而已，hhhh。上班一年多，终于能够无忧无虑的躺着了。该如何利用好这段时间呢？本来打算出去玩，平时节假日都是人山人海，我可不想当大聪明，这个时间点刚好可以错峰出行，转念一想今年从五月份回杭州之后，也一直没回过家，还是去姐姐家歇了一周。工作的时候想着放假，但假期来的时候反倒不知自己该做些什么了，看看书，打打游戏，练练球，哈哈。\n有时候就会明显感觉到自己被现在的生活说裹挟，被迫适应着过着。但当真正离开了之后就会发现，其实目前所在乎的也没那么重要，只不过是为了在这个陌生的城市生活，也才有了这一切。说不上差，当也会总觉得不好。有工作的生活是规律的，但也似乎是这种规律，导致自己被驯化了，就好像踏踏实实上班是理所当然的事情，为了固定的经济来源，哪怕做的不是自己太感兴趣的事情。。。既然这样，为何不逃离这个怪圈，去做点自己想做的事情呢。\n远离互联网的生活才会发现，其实，我们所谈论的技术可能大多数人并不关心其是如何运行的，就好比整个社会的运作，大部分人都是做好自己的本职工作就行，也不会想为什么会这样，互联网的世界也是如此。在这一周里，我尽可能的不用手机和电脑，我想看看没了这些设备对我有哪些影响。首当其冲的是 AI，目前 AI 对我来说更多的是工作中的帮助，LLM 的出现已经彻底改变了我的工作习惯和方式，也就喜欢更多的去追寻更好用的工具，Cursor 就是之一，习惯了之后就回不去了，当有一天打开 IDE，定义一个变量之后，我还在等待它会继续补全什么。但这些在普通的日常生活中是不太用的上的，有些 APP 可能会提供一些 AI 的场景和功能，但总觉得有点刻意而为，比起 AI 给的信息，我更喜欢是自己做决策。所以什么时候 AI 能够真正给大部分人的生活带来改变，或者以什么方式来改变生活呢？还是挺期待的。\n熙熙也长挺大了，快八个月了，上次见面还是四个月前，现如今自己能够爬高上低也是挺不的了的，不过对于看护的大人来说就要费神的多，所以过去的当天我妈和我姐就把小孩丢给了我，也是被折磨够了哈哈哈。对于我来说也是一个全新的体验，自己是不太喜欢搭理小孩子的，不知该如何去沟通交流。但熙熙还好，看见了就很欢喜，好在她也不怎么怕生，我也是第一次抱小孩，也是格外小心翼翼，也有点小紧张，孩子的笑容也真的很治愈，这种笑容也是孩子所独有的。但对我我自己来说，大概率是不会要孩子的，因为我不知该如何去做一个父亲，还有就是个人比较自私，时间还是留给自己为好，哈哈。\n还有就是有一次晚上散步，走到湖边，看见外面的景色还不错拍了一张照片，发给我家那位看，她说圣诞树，我先是一愣，心里想这不就普通的树吗，哪来的圣诞树。结果她说，两棵树之间树枝和树叶之间的空间。诶，一看确实是的。“生活中不缺少美，只是缺少发现美的眼睛”。\n这个月开始玩《异度神剑 终极版》了，想玩《XB3》的 DLC，还是先把前作都玩一遍比较好。虽然是老游戏重新复刻，但玩起来还是很有意思，可能是自己比较喜欢 JRPG 这类游戏的原因吧。虽然故事情节比较老套中二，但玩起来还是很燃，也难怪会说男人至死是少年，哈哈哈哈。主线故事的情节设计的还不错，一波三折折上折，前期会留有悬念，通过后期每一次的反转填补上之前的悬念。不过有些地方的情节设计还需要一点铺垫，后半部分一个点接一个点太密集，对于游玩体验不是很好吧。这部的主角修尔克不太喜欢，太圣母了，尤其是得知机神兵里面是穆姆卡，搞不懂男主的脑回路还保护起来，有点抽象。不过丹邦给的印象就很不错，属于那种有勇有谋值得信赖的，而且还愿意牺牲自己。从内容上来说，没有 2 和 3 那么印象深刻，可能是最后的结局还没打。等完结了三部曲，单独写个博客记录一下吧。又给自己挖坑了属于是。\n新篇章 误打误撞入了大数据这个圈子之后，也不知道从何时起开始对分布式和数据库感兴趣的，偶然的机会看见很多人在分享 6.824、15-445 之类的课程，还有看到了《DDIA》，就这样稀里糊涂的踏上了玩 Infra 的路上。可能这就是求而不得往往不求而得，也就有了新的工作。这一次入职没了第一份工作的那种紧张，更多的是从容，毕竟产品是开源的，之前也有了解过很多，于是就一拍即合。\n之前有写过，我想去重视工程师文化的团队，这种氛围是我追求的，同时搞开源和技术的大概是同一类人，这几周感受下来也确实是的。最起码是有自驱力的，对自己和事情负责，而不是去管那些多余的杂七杂八的流程，如果将大多数时间都浪费在规矩上，那么谁来做事呢？周围都是搞技术的人这种感觉太好了，不过感觉自己被大佬们包围，还得继续加油！办公室周围的同学给我的感觉都很年轻有活力，结果一问才发现有的已经工作很多年了，真的是深藏不露。还记得入职第一天吃午饭的时候，有同事率先提起了《黑神话：悟空》，瞬间就拉进了距离，果然是国民级的游戏。自己对于新环境融合的也比较快，最近一段时间也成长很多，不过也从侧面感觉到自己的不足，还有很长的路要走。不过也很期待下一个阶段的自己，看看半年后自己是什么样，能否独当一面？\n最近我也在想，是否真的讨厌工作，技术也只是谋生手段吗？是，也不是吧。更多想的是认真地做事，发挥出自己的所长，不喜欢被 PUA，讨厌互联网黑话，更不喜欢被画大饼，一步一步往下走就好。我理解的工作就是，我把事情给做好，得到对应的薪水报酬，至于工作上的规矩也简单越好。之前看过一个笑话说的是在某公司，一张桌子挪个位置都要报备，几分钟能解决的事情，能拖一个多月，这种就是无意义的。我很喜欢大家一起认真做事的氛围，而不是为了求生存给自己强行加戏，还有扯不完的犊子。\n九月完结 最近总会觉得人与人之间的联系挺淡的，和亲戚、朋友、同学、同事都是如此，当离开了这个圈子之后，一年到头几乎就不会主动联系。虽说现在通讯、交通工具越来越便捷，但对应的是变动也很快，快节奏真的好吗？当变更的成本变低，可能也越来越不会珍惜吧，怎么写到这里瞬间有点 emo 🥹。\n九月过的还是挺充实的，开启了新篇章，慢慢充实起来，没有那么内耗，可以更好地做自己想做的事情。\n","description":"","tags":null,"title":"开启新篇章","uri":"/life/24_09-new_chapter/"},{"categories":null,"content":"MySQL 同步数据至 Doris 开篇 摸了几个月，好久没写技术类型的博客，打算开新坑来写写关于 Doris 的点点滴滴，同时也是记录自己学习的一个过程。这个系列不会解释 Doris 以及牵涉到的大数据是什么，以及基本的使用技巧，这部分内容完全可以去看看各个项目的官方文档。更想写的是将 Doirs 聚焦于一个个具体的使用场景，比如本篇内容讲的就是如何同步 MySQL 的数据至 Doris，这里提供了两种方案供读者选择，分别是 FlinkCDC、Doris-Flink-Connector 。\n版本选择：\nDoris 2.1.6 MySQL 8.0 Flink 1.18.0 FlinkCDC 3.1.0 Doris-Flink-Connector 24.0.0 准备工作 MySQL 开启 Binlog 并建立测试库表 MySQL 开启 Binlog：sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf 。\n1 2 3 server-id = 1 log_bin = /var/log/mysql/mysql-bin.log binlog_format = ROW 重启 MySQL 服务：sudo service mysql restart。\n参考：https://debezium.io/documentation/reference/1.9/tutorial.html\n使用 MySQL 建立对应的库表：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 -- create database CREATE DATABASE app_db; USE app_db; -- create orders table CREATE TABLE `orders` ( `id` INT NOT NULL, `price` DECIMAL(10,2) NOT NULL, PRIMARY KEY (`id`) ); -- insert records INSERT INTO `orders` (`id`, `price`) VALUES (1, 4.00); INSERT INTO `orders` (`id`, `price`) VALUES (2, 100.00); -- create shipments table CREATE TABLE `shipments` ( `id` INT NOT NULL, `city` VARCHAR(255) NOT NULL, PRIMARY KEY (`id`) ); -- insert records INSERT INTO `shipments` (`id`, `city`) VALUES (1, 'beijing'); INSERT INTO `shipments` (`id`, `city`) VALUES (2, 'xian'); -- create products table CREATE TABLE `products` ( `id` INT NOT NULL, `product` VARCHAR(255) NOT NULL, PRIMARY KEY (`id`) ); -- insert records INSERT INTO `products` (`id`, `product`) VALUES (1, 'Beer'); INSERT INTO `products` (`id`, `product`) VALUES (2, 'Cap'); INSERT INTO `products` (`id`, `product`) VALUES (3, 'Peanut'); 配置 Doris 并建立对应的库 Doris 可以通过 doris-manager 进行安装配置，可视化页面操作，只要按照说明提供好对应的配置文件即可，还附属监控功能，很推荐👍。这里 Doris 使用的版本为 2.1.6。\n当完成配置之后，可以使用 jps 命令查看 Doris 的进程，如果启动成功，会看到 DorisFE 和 DorisBE 的进程。然后使用 mysql -uroot -P9030 -h127.0.0.1 命令可以连接 Doris 的 FE 节点。并创建对应的库即可。\n1 CREATE DATABASE app_db; Flink 配置 Flink 使用单机模式即可，需要在 lib 目录下导入对应的依赖。\n1 2 # 启动 Flink 集群 flink/bin/start-cluster.sh FlinkCDC 同步 FlinkCDC 这里选用的版本为 3.1.0，直接解压并在 Flink-CDC 的 lib 目录下添加依赖即可使用，因为我们的作业是同步 MySQL 的数据至 Doris，所以需要导入的依赖为：\nApache Doris pipeline connector 3.1.0 MySQL pipeline connector 3.1.0 编写 YAML 文件：vim mysql-to-doris.yaml。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 source: type: mysql hostname: localhost port: 3306 username: root password: 123456 tables: app_db.\\.* server-id: 5400-5404 server-time-zone: Asia/Shanghai sink: type: doris fenodes: 127.0.0.1:8030 username: root password: \"\" table.create.properties.light_schema_change: true table.create.properties.replication_num: 1 pipeline: name: Sync MySQL Database to Doris parallelism: 1 执行 Job\n1 flink-cdc/bin/flink-cdc.sh mysql-to-doris.yaml 可以在 Doris 的 FE 节点上使用 show tables from app_db; 查看同步的表。因为是使用 Binlog 同步，所以当 MySQL 的表有更新时，Doris 的表也会同步更新。使用 Flink-CDC 可以帮我们自动在 Doris 中创建对应的表格，是不是感觉很方便？别急，下面还有更好用的。\nDoris-Flink-Connector 同步 Doris-Flink-Connector 是 Doris 官方提供的连接器，可以支持通过 Flink 操作（读取、写入、修改、删除）Doris 中存储的数据。还是以刚才 MySQL 的数据为例，看看使用 connector 是如何同步数据的。\nConnector 整库同步功能底层依赖的是 Flink CDC，因而对于相应关系型数据的支持，请参考 Flink CDC 官方文档 Flink CDC Overview：https://nightlies.apache.org/flink/flink-cdc-docs-release-3.1/docs/connectors/pipeline-connectors/overview/。\n首先我们需要使用官方提供的 build.sh 脚本构建 jar 包，并将其放到 Flink 的 lib 目录下。这一步不是很难，读者可以自行尝试。另外截止目前最新的 24.0.0 已经提供好对应的 jar 包，直接下载对应的版本即可。除此之外，还需要再添加 flink-sql-connector-mysql-cdc 的 jar 包，否则可能会报类找不到的错误。完成上述配置之后就可以使用 Connector 进行 MySQL 整库同步了。同步命令如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 FLINK_HOME/bin/flink run \\ -Dexecution.checkpointing.interval=10s \\ -Dparallelism.default=1 \\ -c org.apache.doris.flink.tools.cdc.CdcTools \\ lib/flink-doris-connector-1.16-24.0.0.jar \\ mysql-sync-database \\ --database app_db \\ --mysql-conf hostname=127.0.0.1 \\ --mysql-conf port=3306 \\ --mysql-conf username=root \\ --mysql-conf password=123456 \\ --mysql-conf database-name=app_db \\ --sink-conf fenodes=127.0.0.1:8030 \\ --sink-conf username=root \\ --sink-conf password= \\ --sink-conf jdbc-url=jdbc:mysql://127.0.0.1:9030 \\ --sink-conf sink.label-prefix=label \\ --table-conf replication_num=1 \\ 具体的命令参数可以参考官方文档：https://doris.apache.org/zh-CN/docs/ecosystem/flink-doris-connector\n使用起来是不是很方便？连配置文件都不用写。检测结果的步骤这里同上，这里不做过多赘述。\n总结 到这里，我们完成了使用 Flink 同步 MySQL 数据至 Doris 的操作，现在的数据集成工具越来越好用，同步的操作也越来越方便，从需要用户建表，到写个配置文件，再到使用 Connector 直接使用命令即可完成整库同步。也给用户提供了更多的选择。不过到这里你是否会好奇，使用工具同步的过程，建立的表是什么类型的呢？\nApache Doris 主要有 Unique,Aggreate,Duplicate 三种数据模型，对于数据源（MySQL,Oracle,Postgres,SQL Server) 库中含有主键的表，将直接将该表映射成 Unique 表，而其他不包含主键的表，将直接映射成 Doris 中的 Duplicate 表，对于 MySQL 同步非主键表，需要 --mysql-conf scan.incremental.snapshot.chunk.key-column 来设置非主键表的 chunk key，且只能选择非空类型的一个字段，不同库表列之间使用 , 隔开。\n关于全量同步和增量同步也是一个比较有意思的话题，Connecor 在利用 Flink-CDC 进行同步的过程分为全量 + 增量两个阶段，其中全量读取阶段可以并发无锁读取，增量阶段则切分为单线程读取 Binlog，以房子重复拉取 Binlog 数据，对于增量同步的过程，可以根据业务能够接受的最低延迟来调整 CheckPoint 参数。\n好了，这篇博客的内容到此为止，简单讲解了如何同步 MySQL 的库表到 Doris 中，总体来说不是很难，按照步骤可以复现，如果有疑问欢迎留言～\n在下篇博客中我们会进一步探索数据集成与同步的更多用法～\n参考：\nStreaming ELT from MySQL to Doris Flink Doris Connector ","description":"","tags":null,"title":"Doris01——MySQL 整库同步","uri":"/tech/doris/doris001_sync-mysql2doris/"},{"categories":null,"content":"煎熬的八月 写在开篇 书接上文，在上篇的 blog 中的最后有写到，想开启新征程，则对应的就是做出行动。对于内向的我而言，其实是挺怕做出改变的，特别是离开一个熟悉的环境。但有时候又是无奈，不得不往前走。这个月还是挺充实的，经历了面试、拿 Offer、提离职、退房租房等一系列事情，就导致整个月都没有太空闲的时间。有时候想想好忙，又不知道在忙些什么，没头没尾的，到底为何要做呢？\n工作变动 其实从六月份开始，也就是《毫无意义的工作》那篇 blog 就已经产生了提离职的想法，只不过当时还没想好要继续做什么，目前的工作也比较轻松就再熬熬，或者等个大礼包也挺好的。事实是，我先提离职了。这个月提离职的时候，同事们都感觉挺意外的，虽然我整点下班，但没有耽误工作，效率也是比较高的，看待问题有着自己的想法，周围的同事陆陆续续被裁了很多，我还继续苟着，从他们的角度来说，可能是现在就业环境还不太好，为什么要主动提离职呢？我的回答倒是还好，也并不太意外。目前的公司想做很多事情，结果推不下去。每次要做什么，首先要考虑的就是成本，就导致很多时候无所事事。我还比较年轻，这不是我想要的生活，那么就得自己去寻找突破口。可以说是压死骆驼的最后一根稻草吧，所有的小事都无所谓，但久而久之的内耗就会成为问题。这里多说一句，对于管理者而言，还是应该多和同事进行沟通，内容也不仅仅是工作，但也要注意边界。\n在七月份就开始投简历，重新找工作，虽然也拿了几个，都不是很满意，可能都是偏业务的，就会想换了一家公司工作的内容也不会差多少吧，略微有点无聊。说来也巧，一次偶然间刷 Boss 就看见了我下家公司正在招聘，这家公司之前就有所耳闻，也是比较向往的。就抱着试一试的心态开始了沟通，HR 看了简历之后就开始约面试，一共有三轮技术面 + 一轮 HR 面。先说说面试感受吧，三轮的技术面给我的印象挺不错的，面试官的能力和工程思维都很强，面试过程中并不是一板一眼，根据投递者的简历来走，由浅入深一点一点来，相比较于背八股文，这种我是更喜欢的，在此点个赞。而且整个面试过程中，和面试官都挺聊得来，等着入职以后可以多多学习。这家公司的面试流程还是很快的，一面是 08.01 周四，下周一通知二面，然后周三晚上是二面 08.07，可能是二面的反馈比较好吧，第二天上午十点多 HR 就联系我准备三面，本来约的是周五晚上，因为自己有点事时间上冲突了，就改成了当天晚上的九点 08.08 周四。三轮技术面结束之后，就又是下一个周一，HR 联系说准备 HR 面，是她的 Leader，我心里想太不容易了，终于把三轮技术面给撑过去了。技术面问题虽然都不简单，每次面试结束之后，内心就感觉还不错，是可以进一下轮的。可能是双方沟通的比较舒服吧。HR 面也是比较顺利的，08.14 面，面试刚结束 HR 就开始收集材料，一开始没有告知面试结果就收集工资流水，这一点对于我的体验来说不是很好，毕竟涉及到隐私，后来对接的 HR 联系我说漏了“HR 面试是通过的”这一句话 hhhhh。也就等于四轮面试全过，开始进入到谈 Offer 的阶段。而且有意思的是那天刚好是我的生日，也算是下家公司给的第一份生日礼物吧，哈哈。周四走流程申请 Offer，HR 询问了手里其他 Offer 的情况，周五就给了 Offer。总体来说，效率是比较高的，而且面试过程也是很满意，在面试中也能有收获，也期待以后一起工作！\n拿完 Offer 之后，下一步就是提离职。现在这家公司整体工作环境来说还是可以的（可以准点下班），对于刚踏入职场小白时候的我来说刚刚好，当时团队的老大对我也不错，工作起来也都挺好的。后来就慢慢变得有点抽象了起来，公司的组织结构调整，一直到现在，和我刚入职的感觉不一样。每个人都在假装很忙碌，显得自己很重要，大家都是草台班子，何必遮遮掩掩呢。管理者喜欢增加很多不必要的中间环节由此来突显出自己的重要和能力，我是讨厌这一套的，时间长了就不断加深了离职的想法。当然离职之期也会把自己的所有工作给做好，这样也才能放心地走。\n搬家 杭州的租房真的好难受好难受好难受！！！也是这个月最头疼我的事情之一。之前是和同事合租，结果转正还没入职公司毁约了。房租是八月中下旬到期，起初想的是和大学同学合租，毕竟找个两室一厅的面积大一点，还挺舒服的。可是事与愿违，在我和他上班通勤中间的地段，靠近西湖文化广场，那边租房是真的难，因为是老城区，房屋都比较破旧，价格还不低，就很离谱。两个人看了两周多也没有一间太满意的。最后房租快要到期，只能自己单租一个。一个人住的话，好处就是安静、自由、更方便一点。但对应的就是想找个面积大一点的房子，价格也只会更高。\n搬家倒是挺省心的，一开始打算找日式搬家，看了一眼价格还是放弃了，就开始自己收纳东西。想想去年刚来杭州的时候，还是一人一包一箱，今年倒是一堆东西了，电脑主机、显示屏、书，还有杂七杂八的一堆。我有强迫症，对于收纳的过程来说还是比较享受的，把一件一件东西打包放置好，也就用了两个晚上。最后搬家公司找的是蓝犀牛，服务还是很好的，全程没有让我动手，只需告诉哪些物品需要搬运即可。师傅还说我打包收纳的很整齐，搬起来也就很快，哈哈。\n最近有一段时间没回家了，天天买着吃真的是吃腻了，好想吃家里做的饭菜，新搬的公寓里面条件也还行，买个锅和油盐酱醋就可以自己做饭咯，下一个阶段就可以开始做菜了。欢迎来做客~\n《黑神话：悟空》 等啊等啊等啊，终于来了！！！是个值得玩的游戏，也是属于中国玩家的游戏。虽然到目前为止，我还没全部通关，但体验来说还行。虽然没有预期的惊艳，但也绝不算差。放在和野炊、老头环一个水平线评分的话，满分 100，我会给到 80-85 这个区间，其中也包括了情怀加持。孙悟空，本身就是家喻户晓的人物，所以这款游戏只要不 baosi，基本就是个正经的游戏，对应的爆火也是必然！果不其然，确实很出圈，很多不玩游戏的博主都来蹭流量，再加上绿色通道，在数据上可以说是遥遥领先！\n从游戏本身来说的话，开场的 PV 演出很不错，画面表现很好，玩法也比较有意思，打斗的感觉中规中矩。难度方面的话，中等偏上，相较于魂类游戏会简单一点。可能自己喜欢玩魂类游戏和怪猎，所以上手难度并不是很大，刚开始的时候被大头和尚（幽魂）卡了一下，后面慢慢适应之后，打起来还是很得心应手的，哈哈。游戏的影神图做的也很棒，可以去了解每个怪，把整个剧情给串起来。每章结束的 PV 尤其的好，画面和音乐都是一流的。游戏的跑图比较无聊，而且很多空气墙，很多小怪都不想去主动打，一路只想推主线打 Boss，采集系统做的也不是很好，没有给玩家太强的探索欲望。\n谈谈游戏之外，在玩游戏之前看见了对于冯骥的采访——【独家对话《黑神话：悟空》制作人冯骥】，字里行间可以看出来是想做出一款好游戏的，他们团队也做到了！但随后又牵涉出主创杨奇的逆天言论，也是挺无语的。作为一名中国玩家，从我的角度只能说，游戏基于肯定，杨奇得批！至于大众主流的是两种观点：一部分人主张的是认清个体与集体的辩证关系，黑猴是游科全体成员的产物，不能因为一个人的言论，而打击了整个游戏，虽然杨奇的做法很恶心，但只要划清界限，也就没什么；还有的人认为杨奇是团队的主创，而且地位很高，也就是说，每卖出一份游戏，yq 都会有分成。我买了游戏，我就有理由去骂。作为消费者来说，这些都对。但最怕的就是随大流跟风的黑，以及无脑的维护。荣格心理学有说，人类绝大多数思想的塑造，都是通过群体思维（或者叫群体意识、集体潜意识），我们坚持这些观点不是因为我们“理性”，而是我们对集体的忠诚。当人类的意识被“群体思维”所塑造之后，就会进入了一个“舒适圈”，不会再接受新鲜的理论。尤其不能接受与群体思维相抵触的理论。如果指出某一个人的思想错误，会引发其尖锐的反抗情绪，就像身体免疫系统消灭入侵病毒一样。所以人类一点也不“理性”，我们的潜意识（或者说我们的本质）就是躺平的——既不愿意接触新的知识，也不愿意遭受质疑。\n又长了一岁 不知不觉又长了一岁，今年还是本命年。想起今年上半年去了一趟灵隐寺，看见了生肖为龙，今年犯太岁，我向来是不大信这个的，但知道了心里还多多少少会有点膈应。如今大半年过去了，感觉还是挺平稳的，还朝着好的方向去发展。有时候回想着自己还小，还年轻，想做什么就去做。但现实更多的是身不由己，很多事情没办法去做，和生活妥协了属于是。十二年前刚上中学，如今算是踏入职场，也即将要开启一个新的阶段，有了女朋友，去了想去的公司，也就挺好的。对于下一份工作，心里怀着期待，也有点压力，期待的是公司的团队氛围听说很不错，所做的技术也很牛，焦虑的是自己太弱，能不能跟上节奏。算了一步一步往前走吧！不过，最近真的好累，身体上和心理上都有。希望熬过这个月会好一点~~\n还有就是感觉可能是一个人习惯了，对于很多人或者事都看的挺淡的，从大局来说都无所谓，也会觉得人与人的交往不是很重要，有些难以维护或者单方面付出的，该断就断，其实也没啥，这也许是现如今快节奏社畜的基本属性吧。不过对于自己所珍视的会看的特别重，圈子变大了，好友变少了。有时候挺享受这种孤独感的，但也会觉得怪怪的。\n本来打算这个月离职之后出去玩一玩的，算是给自己的生日礼物，毕竟上班一年多已经很苦了（bushi。可能是最近太累了，也或许是没有太想去的地方，还有就是打算借这几天补充知识上的不足，就还没想好到底要不要出门玩。话说回来，不知道下一个无忧无虑的假期是什么时候，不出去转转也会觉得有点可惜。思想来去觉得还是先回一趟家吧，好久也没回去了，也想念家里的饭菜。\n去年就在想：2023 当作是一场过渡，2024 开辟新的道路，也算是做到了吧。\n踏上取经路，比抵达灵山更重要。\n","description":"","tags":null,"title":"寻找改变？","uri":"/life/24_08-change/"},{"categories":null,"content":"这个七月真的很热。 谈谈本月 如果说七月的话，那么想到的第一个词就是高温🥵，尤其是在杭州。这个月感觉好漫长，但仔细想想又好像是什么都没做。不过话说回来，似乎每个月都是这样子的吧。\n这个月又变回了一个人住，室友被裁，这一次他离开杭州，不知下次会在什么时候，还是有点点小感伤的。他大概大概比我早一周入职这家公司，当时他才大三下，也是一个很有能力的大学习，所学的专业是通信工程，随后自己转码开始打算法竞赛。从我的角度来说，是比较欣赏这种学生的，能够想清楚不要什么，从而去做出改变。我和他性格上也比较合得来，也是刚入职时候的饭搭子。随后房租到期，又一起合租了，也就一起租到了现在。我和他对工作的态度比较相同，给多少钱干多少事，剩余的情况看心情。大家都是社畜，摸鱼嘛，应该的，别因为工作耗费自己的身心健康。也就这样成为了摸鱼搭子，偶尔会溜出去喝个咖啡再回工位。本以为他签了三方之后，就可以稳定入职，结果公司的原因，单方面毁三方。不过好在，有能力在哪都能混一口饭吃，也在短期内找到了下一份工作。祝好。\n这个月第一次和推友线下见面了，还是挺有意思的，一起吃了喜贡。可能是工作之后，习惯了逛推，起初有一种大开眼界的感觉，但是后来发现，也就那么一回事，中推也就那么几个人在跳。现在的话，可能会更关注一些有趣的开发者吧。这个月底参与了 CommunityOverCode2024，虽然之前给 Apache 的项目做过一点贡献，第一次参与线下还是挺有趣的，大型网友见面会。其实怎么说呢，搞技术弄到最后感觉也是“混圈子”，只不过越是垂直发展可能最后的圈子就会越小，但质量也会相对应的越高。但计算机的这个圈子在某种程度上来说也更难靠“混”就能进去，从我的感觉来说，这个圈子的人彼此之间属于文人相轻。不会因为你的 title 有多牛，职位有多高，就觉得你很牛，更关键的是你做了哪些事情。在大会的开源集市先是去了“开源之夏”的展台，国内能够有这么一种活动，鼓励大学生走进开源还是挺好的。比较巧的是旁边就是开源社的展台，哈哈。还去了 Greptime 的摊位，顺了贴纸（贴纸真的好喜欢，设计的很棒，质量也很好！！）。还和 wayne 聊了会天，不得不说和大师聊天还是很有收获的，也感觉到了做 Infra 的不容易。\n最近比较火的一个新闻就是“萝卜快跑”，之前还在调侃失业了，还可以跑滴滴。现在自动驾驶的普及，后路算是堵死了。不过玩笑归玩笑，对自动驾驶的安全性还是值得考虑的，毕竟将自己的安全交给机器来说，还是有点不放心的。但最近打车出门的效果并不是很好，自己有点洁癖，好几次车上都有烟味，这一点是很难受的，就在想是不是可以接受新的事物，这么来看自动驾驶也是不错的。还有就是价格优势。emmmm 对于社会的影响应该也会很大，这就不是我这种小人物能影响的了。\n这个月还看了电影《抓娃娃》，电影的质量也还不错，属于可以从头看到尾不觉得无聊的那种。以前我是不太爱看喜剧电影的，可能是年纪大了，也可能是生活太累了，看点轻松的解解压也是不错的选择。电影并没有太重的说教，这一点还是很不错的。毕竟就是想看点能笑的，突然给观众强行转折的来那么一段还是有点反感的。电影看起来可以说是育儿版的《楚门的世界》。从父母视角来看是乐子，但从孩子本身来看是恐怖。马继业小时候看着还挺搞笑，长大了之后多多少少有点出戏。特别是“奶奶”假死的那一段，有一种哭笑不得的感觉。总的来说，还是可以去看看的，如果无聊的话。\n好的面试？？ 面试也是一种成长。去年再看耗子叔的《程序员练级攻略》里面有提到，早职业生涯早期可以通过面试来提升自己。加上工作已经一年多了，但仔细审视自己好像并没有太大的进步，最近对目前的工作也感觉比较无聊，也就抱着试试的心态开始投简历看看机会。和当时校招的时候不同，这一次我没怎么背八股文，更希望是从简历出发。LeetCode 算法题也只是简单刷了一点，保持题感的那种程度。\n但国内的面试怎么说呢？八股是跑不了的，甚至还会问你空档期（毕业到正式工作有半年空档），给我的感觉还是挺恶心的。面试的过程也只能说有好有坏。这次第一家遇到的就是纯问八股的，各个问题之间来回乱跳，毫无逻辑可言，面试的感觉也不是很好。面完结束之后，我只丢了一句：除了八股还有什么想问的吗？双方都沉默了一会，就结束了。二面倒是还行，更多是从简历本身出发。虽然最后拿到了 offer 但是驻场还比较偏远，也不在考虑范围之内，权当是练练手。面的第二家是做数据中台二开的，也是三面，周期挺长的，几乎是一周一面，估计是不太着急招人，或者说候选人比较多。一面应该是个小组长的感觉，算是这个月面试下来给我整体感觉最好的一个，从简历出发筛选出我的技术点，然后结合他们公司的业务来问。两个人聊的比较尽兴，本来是半小时的面试，拖到了一个小时左右。更多的是双方一起着手去解决问题，而不是一问一答的。二面是他们的团队总监，更多的是偏向于集群管理的角度，其中谈到了资源调度的问题，这方面也是在工作中并没有太深入研究，反映出自己的不足，也带来了新的启发。写这篇博客的时候，还在等 HR 三面。说实话，我很讨厌 HR 这类职业，目前接触的来说，更多是狗腿子，没有真正的闪光点。\n最近找工作的时候可以发现，合适的薪资范围大概对应的是 3-5 年的工作经验，1-3 去找合适的真的好少。\n身边的朋友都在说，目前我的工作不算太累，为啥还要想着裸辞或者说换工作呢？我也不太能够想的明白，可能感觉自己还能做更多的事情吧。\n再加上不错的面试博客：\n记在美国的一次校园招聘 Tech 公司面试杂谈 舒服的相处方式 不知不觉 100 天咯。总感觉两个人过了很长时间，但算起来也才三个多月。之前有提到我和她性格上差别还是挺明显的，却都能相互包容对方，这可能就是差异化互补吧，两个人都能看见对方的闪光点。我也不太清楚如何使用文字或语言去描述这种感觉，就会觉得有她在一起就刚刚好，没有刻意强求，就是那种顺其自然的好。最近因为天气原因，周末大部分时间都宅在家里不太想出门，一起看电影、一起打游戏，累了困了就往床上一趟的生活，还是挺舒服的，哈哈。\n这段时间的相互，彼此也能更了解对方，也慢慢适应和习惯了有她的存在。有时候就会觉得缘分好神奇，该遇见的总会遇见。和她在一起更多可能是感性的，平时自己一个人更多的是看书、写代码、打游戏，以理性为主的生活，过久了也就觉得麻木，对世间冷暖也就不太关心，过好自己的生活就行。和她在一起是“不讲理”的，她说她的理最大，太可恶叻。走在路边遇见好看的花花草草会陪她绕道去看，看见路边在叫的小猫会给它喂食物，这是之前的我从不会去做的事情，就感觉没必要。现在的话，会觉得今天又做了有趣的事情，哈哈。\n之前一个人的时候，偶尔会感觉自己孤单，但时间都是自己的。现在对于时间的平衡还得重新考虑，因为有一段时间是属于双方彼此的。好的相处模式是离不开双方的信任和理解的，这样才会有安全感，也才能慢慢走下去。\n迷茫 还是和以前一样，每过一段时间都会陷入阶段性的迷茫，虽然知道大的方向在哪，但怎么走，走多久呢？我想开启新征程。\n","description":"","tags":null,"title":"七月不太热？","uri":"/life/24_07-summer_hot/"},{"categories":null,"content":"《毫无意义的工作》 谈谈本月 “一场雨，把我困在这里。”随着一首《六月的雨》也就迎来了梅雨季。我是比较讨厌这段时间的，第一次意识到梅雨可能是中考刚结束的那段时间，当第一次注意到之后，每年也就都会有一段时间是属于下雨的。但长时间的下雨还是挺烦躁的。\n这个月上半月过得倒是挺快的，因为有端午节。因为上班太无聊，自己的内心早早地就期盼着过端午，好处是有三天假期。大概是工作之后，比上学的时候还盼望着假期的到来，也可能是对目前的工作真的很厌倦了。这个假期，第一天和我家那位去做了手工——涂石膏娃娃。第一次去做，还是挺有意思的。在一开始还担心自己是个手残，会涂的特别糟糕，但好在最后的结果还不错，哈哈。涂的过程中，时间过得还是很快，注意力比较集中可能也是一部分原因吧。这种事情，如果换做是之前的我，从理性的角度就会觉得，emmmmm，没太大必要去做的类型。因为比较无聊，也有点浪费时间。但现在从感性方面来说呢，与喜欢的人浪费时间也是一种浪漫。在往后的岁月里，留下属于彼此的记忆，一点一滴将故事写成了我们。\n晚上吃完饭，一起走走逛逛，压压马路好舒服。好像是上班之后，白天的时间属于工作，晚上才是自己的时间，所以大部分情况下都是吃完饭就宅在屋子里不想出门。久而久之，也就慢慢形成了自己的围城，不愿与人交流，甚至不太会去主动交流。还是挺怀念大学的时候，吃好晚饭，和同学在操场上散散步，吹吹牛。现在昔日的好友，长时间不联系，也就渐行渐远。其实这也很正常，毕竟人的精力是有限的，平时生活不在一个圈子，所涉及到的日常也就不同，也就没了共同语言。所以尽可能珍惜现在还常联系的朋友。\n假期第二天去了绍兴，看看鲁迅故里，毕竟是语文课本里面出来的人物。读中学的时候，是比较佩服鲁迅的，是有傲骨的人。“横眉冷对千夫指，俯首甘为孺子牛。”但后来随之自己读的书越多，了解的野史越多，有时候事实是和自己所想的不一样，也就没那么敬佩了。就像之前博客中提到的一样，一到假期只要出门，到处都是人人人。绍兴也是，尤其是鲁迅故里。里面的商业气息还是挺严重的，到处都是鲁迅相关的周边和 Q 版人物，不过这也是正常的营销手段，一个好的 IP，不搞点噱头宣传岂不是太可惜了。在到处人挤人的情况下，浅浅地溜了几个景点，黄酒棒冰还不错，但也挺贵的，绍兴的臭豆腐不好吃。这种地方就属于不去看看的话会觉得可惜，去了之后也就不太会想去第二次了。不过从杭州到绍兴还是挺方便的，去的时候坐的高铁，回来是地铁，反而觉得地铁更方便一点。\n这个月还出差去了南昌，只有第一次出差内心是比较欣喜的，现在的话，能推就推了吧。提起南昌，脑子里一片空白，第一想到的就是在江西，所以吃的比较辣，还有就是南昌拌粉。哦对了，还有滕王阁，其余好像还真的想不起来了。周日下午过去的，晚上简单吃了个饭，看后面两天都有雨，就想着今晚把比较出圈的景点都给逛一圈。也就是开始了特种兵的徒步。先是步行找地铁站，然后第一站是八一广场。还没出地铁站就看见有人卖小红旗，emmmm，有点讨厌。去了站，就可以直接看见“八一南昌起义纪念碑”，就绕着广场走了走，看见了教员写的“星星之火可以燎原”。对于毛，个人还是比较佩服的，去年也抽时间看了《毛选》，对于当代青年来说，还是有必要读读的，毛可以说是这场革命最成功的产品经理。后面的话就去了秋水广场，刚好看见了音乐喷泉，比较巧的是到的时间点也刚刚好，刚出地铁站就看见了。有意思的是地铁站下面的便利店门口贴着“矿泉水 2 元，上面卖 3 元”的广告牌，哈哈。在返程途中，去了万寿宫下，晚上的夜市还是挺好看的，人比较多，但走起来不算很堵，也有丝丝凉意。最后一站的话，就是滕王阁，一步一步走进的时候，慢慢看见滕王阁楼的顶端，给人的感觉还是挺震撼的。但没过一会天空就下雨了，也就打车回了酒店。南昌比较好的一点是物价比较低，可能是在杭州待久了，已经成为合格的社畜，被杭州的物价給绑架了。但与此相对应的是城市的基础设施，可能是在上海杭州这类城市生活惯了，在南昌或者老家那边就会感觉到很无语，这也是被惯坏的。严格来说，目前国内大多数城市的基础设施都是这个样，适应了稍微好一点的，对于常态化的反而感觉难受了。\n游戏方面，这个月更多的时间还是在玩《Splatoon3》，也成功上到了 S+。可能是年纪大了，对于游戏方面没有太争强好胜了，更多的是陪对象玩。自己的话，还是更喜欢玩单机 3A 游戏。\n裁员风波 从去年下半年到现在公司陆续都在裁人，有时候一直在嘲讽着说“赶快把我开了吧，这个班我上够了，喜提大礼包给自己放个假。”但事实却是自己苟住了，不仅没有被裁，反而自己所负责的业务线越来越多，属于在逆流中涌进，也是挺搞笑的。但看着周围之前有打交道的同事被裁，心里有一种说不去的感觉。可能有些人是在工作中遇见，当离开了之后，可能就再也见不到了吧，所以心里多多少少还是有点感伤的。我也不知道自己是否喜欢现在的工作，整体来说比较轻松，但做的事情没有特别硬核，如果抛弃技术洁癖，在这小作坊里面到处混混，还是挺快活的。不过，带给自己的影响也是挺大的，有时在工位上发呆，就会想现在的工作是否真的有意义？还是说只是养活自己，在社会上混口饭吃的工具罢了。看着公司里面有些人为了保全自己，每天假装忙碌的样子也是真的挺逗的。反观自己，已经摸鱼摆烂，也实属有点惭愧，在想着是不是自己也得随大流装一装呢，哈哈哈哈哈。可我不是这样的性格，只能说坚持做正确的事吧。\n现如今的就业环境也不太好，有时候在逛推或者是其他平台经常会看见“被裁”、“中年危机”等负面消息。就好像各行各业在疫情放开之后都进入了衰减期，目前所在的公司也是。还记得去年刚入职的时候，公司给我的感觉是一片欣欣向荣的景象，开展着新的业务，大规模地招人，几乎企微群里面每周都会新入职的同事。23 年上半年，也是疫情彻底放开的第一年，似乎一切都朝着好的方向发展。但往往事与愿违，到了下半年公司里面的氛围开始变了，先是公司组织结构的调整，对应的是很多销售同事被裁，带来的影响是业务量的下降。在公司的角度来说，这些业务本来也就不太赚钱，还养活了这么多人，这么大的成本，倒不如直接放弃。就这样去年年底公司引来了第一波大规模的裁员，HR 确实是一个恶心的职业，而且还是有实权的 HR，说句不好听的“管狗的比干活的都多”，也是挺抽象的。裁员的第二个大波是五月下旬到六月上旬，这一波涉及到一些经常沟通的同事，所以心里多多少少还是有点感伤的，也让我第一次意识到职场的冷酷。\n现如今的公司就我的个人体验来说就陷入了一种僵局，“先有鸡还是先有蛋”。像研发技术这类来说本身就属于成本部门，但如果没有技术也就做不出业务，所以前期的投入是很有必要的。每次想做什么事情的时候就得考虑成本，如果没有业务的支持，就是纯消耗。就这样陷入了恶性循环，没有业务，技术是消耗成本；没有技术，业务做不出去。随之而来的就是减少成本，缩减业务，赶紧倒闭吧。不过说来也搞笑，一般老板在这种时刻说一些动员的话，是鼓励员工积极一点，与公司共同渡过难关。但事实却是，“大难临头各自飞”哈哈哈哈。这就说明整个公司没有凝聚力，其实这样很正常。但一家互联网公司不尊重技术，开始搞一些杂七杂八的规章制度，属于在走下坡路，本末倒置。不过话说回来，技术总归还是为业务服务的。\n最近读了《毫无意义的工作》，挺有意思的一本书，结合当代的环境刚好可以说书里面所揭露的就是现在所经历的。我喜欢编程，爱折腾。当第一次写下“Hello World”的时候就在想，现如今的互联网大厦就是各位前辈一行一行代码走出来的。所以踏踏实实地走下去，如果能够参与开源，为一些顶级的项目作出贡献也是极好的一件事。互联网改变了世界，而开源吞噬了互联网。所以在浪潮之巅下，作为互联网时代的一份子还是挺好的。从这段话也可以看出我的观点，对于技术是比较肯定和认可的。也就是说自己的技能是有意义的，那么说从事的工作是有意义的吗？\n在这本书的开篇就写到“献给每一个想要实实在在工作的人”。我们经常会听到每个人都是螺丝钉这种话，随着社会的发展和劳动分工的复杂化，每个人现在都被分切在链条中的某个部分，要做的事情也就是仅仅服从上级的命令，也不明其意义，只要求保持稳定可以生存。这也就导致了人的价值、交换价值和使用价值都是分离的，也就更容易产生精神内耗，就会思考我做这件事到底有何意义，久而久之整个社会也就陷入比较低层的情绪当中。emmmm，其实这也很正常，年轻人哪有不内耗的呢。所以说，慢一点，给自己留点时间思考，也不见得是一件坏事。说的通俗一点，大部分的工作可能也就是为了养家糊口，为了能够在社会中生存，哪还能考虑是否有意义呢？（开摆叻。。。）\n书里面提到的一个观点是比较有意思的：1930 年，凯恩斯就曾预言道：“到 20 世纪末，科技水平将足够进步，人们每周的工作时间将缩短至 15 小时。”然而，实际情况却并没有发生，恰恰相反，一项项技术集结起来，变着法的使我们所有人更加忙碌。为什么会这样呢？实际上，自动化技术确实大幅度减少了生产性的工作。但与此同时，随着技术的发展各种各样的事实上毫无意义的工作应运而生，这些也就是书中说提到的毫无意义的工作。\n作者对于狗屁工作的定义是一份毫无意义且往往有害的定期领薪水的职业，其无意义或有害程度是如此之高，乃至从事这份职业的人都无法为其找出合适的存在理由，虽然要从事这份工作有一个条件，即从事者不得不假装这份工作的存在是完全合理的。这里再啰嗦一点我个人的看法。这些人在公司往往会表现的特别忙碌，处处为公司着想，还习惯把互联网黑话挂在嘴边，动不动就是“颗粒度”、“赋能”之类的。（不行，写不下去了，看见就恶心，yue 了🤮。）\n看到这里可能会好奇，哪些工作是狗屁工作呢？主要包括五大类分别是：\n随从：随从主要是为了衬托另一个人的重要性，让这个人看起来很重要或者让这个人感到自己很重要的工作。 打手：打手主要是那些有钱人花钱让其存在的岗位。 拼接修补者：拼接修补者的岗位，完全是为了应对组织的某个故障或缺陷而存在的，出于解决某个本不该存在的问题的需求，我们有了拼接修补工作。 打勾者：打勾者指的是那些被雇用来掩盖某个组织不作为的员工，雇用他们的组织可以对外声称他们正在做某件，他们其实没有做的事情。打勾者往往清楚的知道，这份工作不仅对实现表面上的目标，没有任何帮助，实际上还会带来阻碍，因为打勾工作浪费了原本可以投入在这些事物上的时间和资源。 分派者：分派者可以分为两类，第一类分派者的工作全部内容就是给他人派活。第二类分派者的主要工作便是制造狗屁工作给他人，监督这些狗屁工作的完成，甚至还要招更多的人来完成这些狗屁工作。 对于为什么会产生出这么多的无意义的工作呢？作者认为，显然不能单纯的从经济学角度解释。而要转向政治领域和道德领域。统治阶级意识到，如果老百姓生活幸福、工作高效、时间自由，那么就会埋下巨大的隐患。这是一个政治原因。另外一个道德原因在于，如果有人每天醒来后不愿意投入自律高效的工作中，那他就不配拥有好生活。这种道德理念正好为统治阶级所利用。\n我是比较讨厌看这类职场的书籍，因为觉得是浪费时间，更何况是自己闲暇的时间。但这本书还是挺有意思的，而且作者也是个无政府主义者，哈哈哈。\n顺便再来谈谈“加班”，先说观点，我不支持加班。也搞不懂为啥公司都鼓励加班，更想不通为什么有的员工愿意牺牲自己的时间来給公司卖命。这个时候就有人会说，这是认真负责，主打的就是一个今日事今日毕。那我想问，如果真的有能力，为何没有在规定时间内完成工作呢？反而是留到下班之后呢？现在也经常听到“降本增效”，也不是什么好词。为了降低成本，进行人员控制，可是最后会发现也就是个草台班子，还显摆着自己多么专业，也是挺“增笑”的。偶尔加班一两次还正常，长此以往就是要么员工能力有问题，要么就是部门管理有问题。当然，如果从事的是自己所热爱的工作另说。\n写在后面 还有一点就是，自己最近好像不太喜欢发朋友圈了，也可能是上了年纪了吧，随性一点的更偏向于发推，还有就是用博客去记录下来。至于朋友圈，或者说是微信这款产品，如果能不用就不用，戒掉手机！！！开始尝试做减法，慢慢做好眼前的事情，过好当下的生活咯。\n","description":"","tags":null,"title":"《毫无意义的工作》","uri":"/life/24_06-bullshit-jobs/"},{"categories":null,"content":"Redis——哨兵机制 前言 在上一篇博客中，讲解了有关 Redis 的主从模式，在这个模式下，如果从库发生故障了，客户端可以继续向主库或者其他从库发送请求，进行相关操作。但如果是主库挂了呢？就会直接影响从库之间的数据同步，因为从库没有相应的主库可以进行数据复制操作了。\n这个时候，如果客户端发送的是读请求，那么集群中的从库还可以继续提供服务，也就是说在纯读的业务场景下还能被接受。可一旦有写请求的操作了，按照主从模式下的读写分离要求，需要由主库来完成写操作。此时，因为主库挂了，没有实例可以来服务客户端的写操作请求了。\n无论是写服务中断，还是从库无法进行数据同步，在实际生产环境中都是不可接受的。所以，当主库挂了之后，需要一个新的主库来保持 Redis 集群的正常运行。通常会选择把集群中的一个从库切换为主库，这个时候就会涉及到以下三个问题：\n主库真的挂了吗？ 该选择哪个从库作为主库？ 怎么把新主库的相关信息通知给从库和客户端呢？ 这就是 Redis 的哨兵机制的作用。在 Redis 主从集群中，哨兵机制是实现主从库自动切换的关键机制，它有效地解决了主从复制模式下故障转移的这三个问题。\n基本流程 哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主和通知。\n监控指的是哨兵在运行时，会周期性地给所有的主从库发送 PING 命令，检测集群中的节点是否在正常运行。如果从库的响应超时，哨兵就会把它标记为“下线状态”；同样，如果主库没有在规定时间内响应哨兵的 PING 命令，哨兵就会判定主库下线，然后开始自动切换主库的流程。\n这也就会用到哨兵的第二个任务，选主。主库挂了之后，哨兵就需要从很多个从库里，按照一定的规则选择一个从库实例，把它作为新的主库。这一步完成后，集群中也有有了新的主库。\n然后，哨兵会执行最后一个任务：通知。在执行通知任务时，哨兵会把新主库的连接信息发送给其他从库，让它们执行 replicaof 命令，和新主库建立连接，并进行数据复制。同时，哨兵会把新主库的连接信息通知给客户端，让它们把请求操作发到新主库上。\n在上述的三个任务中，通知任务相对来说比较简单，哨兵只需要把新主库的信息发送给从库和客户端，让它们重新和新主库建立连接即可，并不涉及到决策的逻辑。但是，在监控和选主这两个任务重，哨兵需要做出两个决策：\n在监控任务中，哨兵需要判断主库是否处于下线状态； 在选择任务中，哨兵也需要决定选择哪一个从库实例作为新的主库。 主观下线和客观下线 先来看一下什么是“主观下线”。哨兵进程会使用 PING 命令检测它自己和主从库的网络连接情况，用来判断集群中各个实例的状态。如果某个节点的响应超时了，哨兵就会先把它标记为“主观下线”。\n这里对于主从库的后续处理会有所不同。如果检测的是从库，处理比较简单，只需要将其标记为“客观下线”就行了，因为从库的下线影响一般不会太大，集群对外的服务也就不会间断。\n但如果检测到的是主库响应 PING 命令超时，哨兵就不能简单地将其标记为“主观下线”，开启主从切换。因为很有可能存在这么一个情况：哨兵误判了，主库并没有故障。如果直接开始主从切换，后续的选主和通知任务都会带来额外的计算和通信开销。为了避免这些不必要的开销，就需要特别注意误判的情况。\n首先，得搞清楚误判是什么。简单来说，就是主库实际上并没有下线，但是哨兵误以为它挂了。误判通常会发生在集群网络压力较大、网络阻塞，或者是主库本身压力较大的情况下。\n一旦哨兵判断主库下线了，就会开始选择新主库，并让从库和新主库进行数据同步，这过程本身就会有开销，例如，哨兵要花时间选出新主库，从库也要花时间和主库建立连接，然后进行数据同步。而在误判的情况下，主库本身根本就不需要进行切换的，所以这个过程的开销是没有价值的。所以，我们要尽可能地减少误判。\n俗话说，一个好汉三个帮，我们可以采用多实例组成的哨兵集群来解决这个问题。引入多个哨兵实例一起来判断，就可以避免单个哨兵因为自身网络状况不好，而误判主库下线的情况。同时，多个哨兵的网络同时不稳定的概率比较小，通过哨兵集群一起做决策，误判率也会降低。\n在判断主库是否下线时，不能由一个哨兵说了算，只有大多数的哨兵实例，都判断主库已经“客观下线”了，主库才会被标记为“客观下线”。这个判断的原则是：少数服从多数。同时，这会进一步触发哨兵开始主从切换的流程。\n如下图所示，Redis 主从集群有一个主库、三个从库，还有三个哨兵实例。在图片的左边，哨兵 2 判断主库为“主观下线”，但哨兵 1 和 3 却判定主库是上线状态，此时，主库仍然被判断为处于上线状态。在图片的右边，哨兵 1 和 2 都判断主库为“主观下线”，此时，即使哨兵 3 仍然判断主库为上线状态，主库也被标记为“客观下线”了。\n简单来说，“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N/2+1 个哨兵实例都认为主库是“主观下线”了，才能最终将主库标记为“客观下线”。这样一来，就可以减少误判的概率，也能避免误判带来的主从切换。\n如何选主？ 一般来说，可以把哨兵选择新主库的过程称为“筛选 + 打分”。简单来说，在多个从库中，先按照一定的筛选条件，把不符合条件的从库去掉。然后，再按照一定的规则，给剩下的从库逐个打分，将得分最高的从库选为新主库，如下图所示：\n一般情况下，我们要先保证所选的从库仍然在线运行。不过，在选主时从库正常在线，这只能表示从库的现状良好，并不代表它就是最适合做主库的。比如，在选主时，一个从库正常运行，我们就把它选为新主库开始使用了。可是，没过一会它的网络出现了故障，这就导致不得不重新选主，是一件很糟糕的事情。\n所以，在选主时，除了要检查从库的当前在线状态，还要判断它之前的网络连接状态。如果从库和主库断连，而且断连的次数超过了一定的阈值，凭借这一点就可以说，这个从库的网络状况并不是很好，从而可以排除这个从库。\n具体怎么判断呢？可以使用配置项 down-after-milliseconds * 10。其中，down-after-milliseconds 是认定主从库断连的最大连接超时时间。如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从库的网络状况不好，不适合作为新主库。\n基于上述内容就可以过滤掉不适合做主库的从库，完成了筛选工作。\n接下来就需要给剩余的从库进行打分，可以分别按照三个规则依次进行三轮打分，这三个规则分别是从库优先级、从库复制进度以及从库 ID 号。只要在某一轮中，有从库得分最高，那么它就是主库了，选主过程到此结束。如果没有出现得分最高的从库，那么就继续进行下一轮。\n第一轮：优先级最高的从库得分高。\n用户可以通过 slave-priority 配置项，给不同的从库设置优先级。假设现在有两个从库，它们的内存大小不一样，就可以手动给内存大的实例设置一个高优先级。在选主时，哨兵会给优先级高的从库打高分，如果有一个从库优先级最高，那么它就是新主库了。如果从库的优先级相同，则哨兵会开始第二轮打分。\n第二轮：复制进度最高的从库得分高。\n这个规则的依据是，如果选择和旧主库同步最接近的从库作为主库，那么，这个新主库上就有最新的数据。如何判断从库和旧主库间的同步进度呢？\n在上一篇博客中有说到，主从库同步时有个命令传播的过程。在这个过程中，主库会使用 master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置，而从库会用 slave_repl_offset 这个值记录当前的复制进度。此时，想要找的从库，它的 slave_repl_offset 需要最接近 master_repl_offset。如果在所有从库中，有从库的 slave_repl_offset 最接近 master_repl_offset，那么它的得分就最高，可以作为新主库。\n就像下图所示，旧主库的 master_repl_offset 是 100，从库 1、2 和 3 的 slave_repl_offset 分别是 95、99 和 90，那么，从库 2 就应该被选为新主库。\n不过，有时候也会出现两个从库的 salve_repl_offset 的值大小是一样的，这种情况下，哨兵会继续进行第三轮打分。\n第三轮：ID 号最高的从库得分高。\n每个实例都会有一个 ID，这个 ID 类似于这里的从库编号。目前，Redis 在选主从库时，有一个默认的规定：在优先级和复制进度都相同的情况下，ID 号最小的从库得分最高，会被选为新主库。\n到这里，新主库就被选出来了，“选主”这个过程就完成了。\n简单总结如下：\n首先，哨兵会按照在线状态、网络状态，筛选过滤掉一部分不符合要求的从库，然后，依次按照优先级、复制进度、ID 号大小再对剩余的从库进行打分，只要有得分最高的从库出现，就把它选为新主库。\n总结 在这篇博客中，了解了哨兵机制，它是实现 Redis 不间断服务的重要保证。具体来说，主从集群的数据同步是数据可靠的基础保证；而在主库发生故障时，自动的主从切换时服务不间断的关键支撑。\nRedis 的哨兵机制自动完成了以下三大功能，从而实现了主从库的自动切换，可以降低 Redis 集群的运维开销：\n监控主库运行状态，并判断主库是否客观下线； 在主库客观下线后，选取新主库； 选出新主库后，通知从库和客户端。 为了降低误判率，在实际应用时，哨兵机制通常采用多实例的方式进行部署，多个哨兵实例通过“少数服从多数”的原则，来判断主库是否客观下线。一般来说，可以部署哨兵集群来进一步提升判断准确率。\n","description":"","tags":null,"title":"Redis05——哨兵机制","uri":"/tech/redis/redis05_sentinel/"},{"categories":null,"content":"Redis——数据同步：主从库实现数据一致 前言 在前面两篇博客，我们了解了 AOF 和 RDB，如果 Redis 发生了宕机，它们可以分别通过回放日志和重新读入 RDB 文件的方式恢复数据，从而尽可能地减少数据丢失，提升可靠性。\n不过，之前讨论的范围都是在单机 Redis 的场景下，如果 Redis 集群中存在多个节点，如果某个实例宕机了，它在恢复期间是无法服务新来的数据请求，那么该如何处理呢？\n我们经常会听到 Redis 具有高可靠性，这里指的主要是：数据尽量少丢失和服务尽量少中断。AOF 和 RDB 保证了前者，而对于后者，Redis 的做法是增加副本冗余量，说简单点就是，将一份数据同时保存在多个实例上。这样一来，即使有一个实例出现了故障，需要过一段时间才能恢复，其他实例也可以对外提供服务，不会影响业务使用。\n但这会引发出一个新的问题：这么多的副本，它们之间的数据如何保持一致呢？数据的读写操作可以发送给所有的实例吗？\n主从模式 Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。\n读操作：主库、从库都可以接收； 写操作：首先到主库执行，然后，主库将同步写操作给从库。 那么，为什么要这样设计呢？\n道理很简单，如果在上图中，不管是主库还是从库，都能接收客户端的写操作，就会带来这样一个问题：如果客户端对同一个数据（例如 k1）前后修改了三次，每一次的修改请求都发送到不同的节点上执行，那么，这个数据在这三个节点上的副本就不一致了（分别是 v1、v2 和 v3）。在读取这个数据的时候，就可能读取到旧的值。\n如果我们非要保持数据在这三个节点上是一致的，就要涉及到加锁、实例间协商是否完成修改等一系列操作，但这会带来巨额的开销，对于整个集群来说是较大的负担。\n而主从模式如果采用了读写分离，所有数据的修改只会在主库上进行，不用协调三个节点。主库有了最新的数据后，会同步给从库，这样主从库的数据就是一致的。\n那么，主从库同步是如何完成的呢？主库数据是一次性传给从库，还是分批同步？要是主从库间的网络断连了，数据还能保持一致吗？带着这些思考，继续看下去吧。\n第一次同步 首先，我们来看主从模式下的第一次同步是如何进行的，这也是 Redis 实例建立主从模式后的规定动作。\n当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof 命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。\n例如，现在有实例 1（IP：192.168.10.102）和实例 2（IP：192.168.10.103），在实例 2 上执行 replicaof 192.168.10.102 6379 命令，实例 2 就会变成实例 1 的从库，并从实例 1 上复制数据。\n关于主从数据第一次同步的三个阶段，具体可以看下图：\n第一阶段是主从之间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从之间就可以开始同步了。\n具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包括了主库的 runID 和复制进度的 offset两个参数。\nrunID：每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实力。当从库和主库第一次复制时，因为不知主库的 runID，所以将 runID 设为“?”。 offset：此时设为 -1，表示第一次复制。 主库收到 psync 命令后，会用 FULLRESYNC 响应命令并带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库接收到响应后，会记录下这两个参数。\n这里有个需要注意的地方，FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。\n在第二阶段，主库将所有数据同步给从库。从库接收到数据后，在本地完成数据加载。在这个过程依赖于内存快照生成的 RDB 文件。\n具体来说，主库执行完 bgsave 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。\n在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，就会把此时 replication buffer 中的修改操作发送给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。\n主从级联模式 通过分析主从库间第一次数据同步的过程，可以看到，一次全量复制中，对于主库来说，需要完成两个好事的操作：生成 RDB 文件和传输 RDB 文件。\n如果从库数据很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。\n针对上述产生的问题，我们就可以选用“主 - 从 - 从”模式来解决。\n在刚才介绍的主从模式中，所有的从库都是和主库连接，所有的全量复制也都是和主库进行的。现在，我们可以通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。\n简单来说，在部署主从集群的时候，可以手动选择一个从库，比如内存资源配置较高的从库，用于级联其他的从库。然后，可以再选择一些从库，在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。\n1 replicaof 所选从库的 IP 6379 这样一来，这些从库就会知道，在进行同步时，不用再和主库进行交互了，只要和级联的从库进行写操作同步就行，从而减轻了主库上的压力。\n到这里，我们了解了主从库间通过全量复制实现数据同步的过程，以及通过“主 - 从 -从”模式分担主库压力的方式。一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续收到的命令再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。\n网络断连 上面的过程看似一切顺利，但却有这不可忽视的风险点，那就是网络断连或阻塞。如果网络断连，主从库之间就无法进行命令传播了，从库的数据自然也就没办法和主库保持一致，客户端就可能在从库中读取到旧数据，\nRedis 提供的解决办法是，网络断了之后，主从库会采用增量复制的方式继续同步，增量复制只会把主从库网络断连期间主库收到的命令同步给从库。\n那么，增量复制时，主从库之间是怎么保持同步的呢？原因是 repl_backlog_buff 这个缓冲区。我们先来看看它是如何用于增量命令的同步的。\n当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。\n刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是 master_repl_offset。主库接收的新写操作越多，这个值就会越大。\n同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。\n主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距。\n在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset 会大于 slave_repl_offset。此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。\n就像刚刚示意图的中间部分，主库和从库之间相差了 put d e 和 put d f 两个操作，在增量复制时，主库只需要把它们同步给从库，就行了。\n不过，这里还有一个地方需要注意一下，因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖了之前写入的操作。如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致。\n因此，就需要想办法避免这一情况，通常来说，可以调整 repl_backlog_size 这个参数。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是：缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 repl_backlog_size = 缓冲空间大小 * 2，这也就是 repl_backlog_size 的最终值。\n举个例子，如果主库每秒写入 2000 个操作，每个操作的大小为 2KB，网络每秒能传输 1000 个操作，那么，有 1000 个操作需要缓冲起来，这就至少需要 2MB 的缓冲空间。否则，新写的命令就会覆盖掉旧操作了。为了应对可能的突发压力，我们最终把 repl_backlog_size 设为 4MB。\n这样一来，增量复制时主从库的数据不一致风险就降低了。不过，如果并发请求量非常大，连两倍的缓冲空间都存不下新操作请求的话，此时，主从库仍然可能会不一致。针对这种情况，就可以根据 Redis 所在服务器的内存资源继续增加 repl_backlog_size 的值。或者使用切片集群来分担单个主库的请求压力（关于切片集群留个坑）。\n总结 在这篇博客中，主要概括了 Redis 主从库同步的基本原理，总结起来，有三种模式：全量复制、基于长连接的命令传播，以及增量复制。\n全量复制虽然耗时，但对于从库来说，如果是第一次同步，全量复制是无法避免的，所以尽可能保证一个 Redis 实例的数据库不要太大，一个实例大小在几 GB 比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销。另外，为了避免多个从库同时和主库进行全量复制，给主库过大的同步压力，也可以采用“主 - 从 - 从”级联模式。来缓解主库的压力。\n长连接复制是主从库正常运行后的常规同步阶段。在这个阶段中，主从库之间通过命令传播实现同步。不过，这期间如果遇到了网络断连，增量复制就派上用场了。其中需要注意的点事 repl_backlog_size 这个配置参数。如果它配置得过小，在增量复制阶段，可能会导致从库的复制进度赶不上主库，进而导致从库重新进行全量复制。所以，通过调大这个参数，可以减少从库在网络断连时全量复制的风险。\n延伸 AOF 记录的操作命令更全，相比于 RDB 丢失的数据更少。那么，为什么主从库间的复制不使用 AOF 呢？\nRDB 文件是二进制文件，无论是要把 RDB 写入磁盘，还是要通过网络传输 RDB，IO 效率都比记录和传输 AOF 的高； 在从库进行恢复时，用 RDB 的恢复效率要高于 AOF。 ","description":"","tags":null,"title":"Redis04——主从数据同步","uri":"/tech/redis/redis04_sync/"},{"categories":null,"content":"《关于我爱你》 写在前面 可能是五月多放了几天假吧，就觉得这个月过的还是挺快的；也有可能是对于周末有了新的期待，所以每周就会感觉过的比较快；或者是有了想见的人，有了陪伴，让原本循规蹈矩的生活有了些许色彩。仔细一想，该死的调休，每周上六天班简直就是折磨😩，严格来说就没多放假。。所以最后的答案也就是后者咯。\n时常会觉得自己是个文青，但一到关键时刻，就大脑木讷、呆呆傻傻，不知该如何去表达自己。与其三言两语的朋友圈，我更想用这个月的博客来正式记录一下。\n五一假期 工作之后，特别期盼假期，但到假期真正到来之后，却又不知该做这些什么。如果只是宅在家里，把时间留给自己，看看书、打打游戏也是不错的。但就会想，好不容易放个假，如果不出门走走，太对不起自己了吧，下次放假还要再熬一个多月！可是，如果问想去哪，又开始犯难了。好像是自己刚步入社会，也好像是疫情放开之后，每逢节假日，或者什么一些活动，出个门，到处都是人从众，人挤人，也就不太想出门了。陷入矛盾之中。。。\n如果实在不知道去哪，那就回家吧。确实这是这样的，上了大学之后和家里人可能会渐行渐远，但当不知该往哪走的时候，就回家看看吧，回到父母身边，什么都不做，吃家里的饭也是很香的。当我们背上行囊，远赴他乡，不知到底为何要这么做，可能是为了生计、也许是为了未来、或许是看大家都这么做，如果自己不做的话，整天游手好闲，反而是个异类。也就有了故乡变成了他乡。\n似乎是在杭州过习惯了，再回到上海的时候，会感觉有点陌生。也更像是一名游客，去看看沪国的风土人情。到了虹桥，不用导航，坐上地铁，凭借直觉，随意选个站下，取下耳机，听听马路上的喧嚣声，不用选择方向，走到是哪，天黑前回家吃饭就好。漫步在路上也会感概，如果久居在上海，也许这些地方我是不会来的，因为没啥意义，很是无聊。但当转变了身份，再去看看，也是一种全新的体验。这一点在杭州也是同理，上 xhs 搜杭州的旅游攻略，就会有一种这些地方也没啥意思嘛，为啥有那么多人会挤过来呢。在现如今“网红打卡时代”这一点更是凸显出来，就一面墙稍微装饰几下，就会有一些博主来打卡，然后吸引更多的人，当自己去了实地之后，就觉得也就那么一回事，不免觉得会有点扫兴。所以尽可能要有自己的判断能力，有自己的选择，有些事情或者决定，是因为真正自己需要才去做，而不是随大流看着别人都在做，自己跟着去做。还有一点就是学会在信息的源头分析问题，当掌握一手资料，并有着敏锐的判断力，才知道哪些是自己想要的。emmmmmmm 又扯远了。\n随着父亲忙着生意上的事情，这几次回家，和爸爸妈妈相处的时间也不是很长，更多的还是在吃饭的时候有的没的聊上几句。有的时候确实会是这样，在一边获得的同时，也在失去，没办法的。也就导致我有时也不太想回家，因为在家也都是一个人，来回跑还是挺累的。这次也就早早的回杭了。但回去没几天，就听见我姐说，我爸因为长时间劳累出现了“眩晕”的症状，不过好在去医院检查都无大碍，希望可以借此机会让他戒酒。父母年纪慢慢大了，自己不在他们身边，还是有点担心的，只能说。所以也就习惯了报喜不报忧，事实上也没什么忧好说的，每天还是挺安逸的。\n假期的最后一天去了音乐节，第一次一个人去音乐节，不过不是很远，距离住的地方骑车也就十来分钟。音乐节这东西怎么说呢，我的观点是如果没有自己特别喜欢的歌手不太建议跟风去，因为真的有点坐牢。这次主要还是想看安溥的现场，也终于终于等到了！！！很值得！！！还有其他的歌手也不错，比如魏如萱的《香格里拉》听着就很舒服；陈珊妮的曲风太个性了，我很爱但暂时还欣赏不太来。还有赵雷的现场，可能我比较 i 吧，旁边的哥们蹦得挺欢的。听见了《朵》和《我记得》这两首算是比较喜欢的歌吧，就像歌词里面唱的“快来抱抱”，给人的感觉就是很温馨。最后的话，就是陈粒和安溥。当时还在纠结是前排安排，还是去隔壁舞台看陈粒呢，在犹豫不决的时候，就被人群推着到了前排。也只能透过屏幕看陈粒咯。听见了《小半》和《奇妙能力歌》，我还是更喜欢她的《清透》，可惜没有现场，呜呜。陈粒的现场还是很棒的，值得转粉。最后的话就是焦安溥女士了。由于某些原因，现场没有 talking，清唱了《如果你冷》，直接泪目了有没有😭。当唱到《最好的时光》的时候就觉得，一切都是值得的，“亲爱的你想念自己吗”，答案是“想”。最后是《关于我爱你》，也是这篇博客的标题。很喜欢。\n假期之后，紧跟其后的就是六天班！！！好讨厌！！\n遇见她 有时候就会觉得缘分这件事情很神奇。一次不经意的决定，便将故事写成了我们。\n起因在三月份的博客里面有写，对，就是打喷喷那一次。线下的时候也没有太注意，过了一段时间才发现。而且比较巧的是，她刚好坐我旁边，可能是余光效应，第一印象也就还不错。后来线上也就继续打游戏，应该是她带我上分，哈哈哈。起初来来回回拉扯的一段时间还是挺折磨的，明明自己目前各方面都还不错，面对她却还有点不太自信，就会有一种忽远忽近的感觉，还被她吐槽像个弟弟一样🥹。但好在及时止损，慢慢转变了过来。女生从某种程度上来说还是慕强的，所以还是该展现自己成熟的一面。\n也许自己是程序员的缘故，做事情都是讲逻辑，有强迫症的那种。但爱情这东西往往就是非理性因素决定，是不讲道理的。换做是之前的我，肯定会觉得现在我还需要进步，还有一堆知识需要学习，还需要沉淀，谈恋爱这种事情既浪费时间，又耗费精力。之前好像有说过，我暂时还没找到一个合适的人，值得我腾出太多的时间给对方。结果事实是很多道理都懂，但就是控制不住。不过也比较有意思，我和她性格和习惯各方面几乎完全相反，结果相处的还算是比较融洽，互相的感觉就像在一起好久了一样，可能主要的是坦诚相见吧。这也是我的特点吧，对于我在乎或者是比较重要的人，都会做到真诚相待，给予对方足够的安全感。她也是比较乖乖的那种，虽然时常说自己是个拽姐，明明就是个小妹妹，哈哈。所以在相处的过程中，就还比较舒适。她有足够的见识，我给她适当的安全感，不娇柔、不做作。大概就是我和她现在的状态吧。也有可能是刚在一起的热恋期，希望可以继续保持，健康积极地走下去。\n既然一切都挺好的，那么就从一束花🌹开始我们的关系吧。之前看一些表白或求婚的时候，就在想这都互相有好感了，表白岂不是水到渠成的事情，有什么好紧张的呢？真正到了自己，完了，脑子宕机了，心跳骤然加快，瞬间不知道说什么了。我也不知一场好的告白是什么样的，但可以的话，想说陪伴是最长情的告白。在 4.20 我和她第一次单独线下见面的时候就算是确定关系了吧，牵了手就算是约定。后来发朋友圈公开选择的是 5.20，还刚好是农历小满，寓意也还是挺好的。如果看整体的感情发展的话，或许还是会觉得有点快。毕竟是打游戏线下认识的，更多的还是网上聊天，然后就直接上头了。但有时爱情往往就需要一点点的冲动，我是一个比较相信感觉的人，最起码不想留下遗憾。\n有时候觉得自己还是挺幸运的，从事着自己不讨厌的职业，有着丰富的精神生活和自己的追求，现如今又有了喜欢的人，可以陪她“浪费”时间也是一种享受。想陪她一起慢慢进步，一起变好，一起躺平，然后吃吃喝喝，走走玩玩，不想被世俗所约束。\n你是非常可爱的人，\n真应该遇到最好的人，\n我也真希望我就是。\n珍惜当下 时常会“嘲笑”自己说，还是太菜了，很多事情做的还不够，要是再努力一点点可以做得更好。我不喜欢歌颂“苦难主义”，因为本身就是比较佛的类型。但我想的是保持进步，见贤思齐。有的时候不一定是和别人比，更重要的是看清楚自己需要的是什么。当自己做到一些事情的时候，就会更加珍惜现在所拥有的。\n有未完成的事情，有自己的想法，有想陪伴的人，如此，挺好～～\n我拥有的都是侥幸啊\n我失去的 都是人生\n当你不遗忘也不想曾经\n我爱你\n","description":"","tags":null,"title":"《关于我爱你》","uri":"/life/24_05-about_love/"},{"categories":null,"content":"Redis——RDB 内存快照 前言 上一篇内容，我们了解了 Redis 避免数据丢失的 AOF 方法。使用 AOF 的好处是，每次执行只需要记录操作命令，需要持久化的数据量不大。通常来说，只要不采用 Always 的持久化策略，都不会对性能造成太大的影响。\n但，也正因为记录的是操作命令，而不是实际数据，所以，用 AOF 方法恢复数据的时候，需要把记录的日志信息都逐一执行一遍。如果日志信息过多，那么在恢复的过程中也将会非常耗时，有可能会就影响到正常使用。那么，有没有什么办法既可以保证可靠性，还能在宕机时快速恢复的方法呢？\n答案就是——内存快照。按照里面意思来理解就是，指内存中的数据在某一时刻的状态记录。这就类似于照片，当按下快门的时候，就会将那一瞬间给记录下来。\n对 Redis 来说，它实现类似于照片记录效果的方式，就是把某一时刻的状态以文件的形式写到磁盘上，也就是快照。这样一来，即使宕机，快照文件也不会丢失，数据的可靠性也就得到了保证。这个快照文件就称为 RDB 文件，其中，RDB 就是 Redis DataBase 的缩写。\n和 AOF 相比，RDB 记录的是某一时刻的数据，并不是操作，所以，在做恢复数据的时候，可以直接把 RDB 文件读入内存，很快就可以完成恢复。但既然内存快照这么好，是不是就可以完全取代 AOF 了呢？肯定不是这样，我们可以尝试从以下两个方面进行考虑：\n对哪些数据做快照？ 做快照时，数据还能增删改吗？ 第一个问题，主要会牵涉到快照的执行效率；后一个则关系到 Redis 是否被阻塞，能否同时正常处理请求。\n这么说可能会感觉有点抽象，换个方式理解，还是以拍照的例子来看。\n如何取景构图？也就是说，照片中会有哪些元素； 按快门的时候，取景框中的元素有变化，对焦失败怎么办？ 下面就针对上面这两个关键问题来进行展开。\n数据快照的方式 Redis 的数据都在内容中，为了提供所有数据的可靠性保证，它执行的是全量快照，直接把内存中的所有数据记录到磁盘中，这就类似于给一整个班级的人拍合照，把每一个人都拍进照片里。这样做的好处是，一次性记录了所有数据，一个都不少。\n我们知道，当给一个人拍照时，只用注意这一个人就够了，但是，拍多个人合影的时候，就需要协调全部人的位置、状态等等，这也就会更耗时耗力。而且，全量数据越多，RDB 文件就越大，往磁盘上写数据的时间开销就越大。\n对于 Redis 而言，它的单线程模式就决定了要尽量避免所有会阻塞主线程的操作。所以，针对任何操作都要考虑：是否会阻塞主线程。这也就牵涉到 RDB 文件的生成是否会降低 Redis 的性能。\nRedis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave。\nsave：在主线程中执行，会导致阻塞； bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置。 看见 bgsave 的时候，心里就有底了。我们就可以通过 bgsave 命令来执行全量快照，这既保证了数据的可靠性，又避免了对 Redis 的性能造成影响。\n接下来，我们要关注的问题是，在对内存数据做快照时，这些数据还能被修改吗？这个问题非常重要，因为如果数据能被修改，那就意味着 Redis 还能正常处理写操作。否则所有写操作都得等到快照完了才能执行，性能会大打折扣。\n快照时数据修改？ 还是来看拍照这个例子，在给别人拍照的时候，如果对方在按快门的时候动了，那么这张照片也就拍糊，属于不可用的，就需要重拍。所以，我们当然希望对方保持不动，对于内存快照而言也是同理。\n举个例子。我们在时刻 t 给内存做快照，假设内存数据量是 4GB，磁盘的写入带宽是 0.2GB/s，简单来说，至少需要 20s（4/0.2 = 20）才能做完。如果在时刻 t+5s 时，一个还没有被写入磁盘的内存数据 A，被修改成了 A'，那么就会破坏快照的完整性，因为 A' 不是时刻 t 时的状态。因此，和拍照类似，我们在做快照时也不希望数据“动”，也就是不能被修改。\n但是，如果快照执行期间数据不能被修改，是会有潜在问题的。对于刚刚的例子来说，在做快照的 20s 时间里，如果这 4GB 的数据都不能被修改，Redis 就不能处理对这些数据的写操作，那无疑就会给业务服务造成巨大的影响。\n这个时候，你可能会说，不是有 bgsave 避免阻塞的嘛。这就是属于犯了一个经典的错误：避免阻塞和正常处理写操作并不是一回事。此时，主线程的确没有阻塞，可以正常接收请求，但是，为了保证快照完整性，它只能处理读操作，因为不能修改正在执行快照的数据。\n为了快照而暂停写操作，这明显是捡了芝麻丢了西瓜，是不能接受的。所以这个时候，Redis 就会借助操作系统提供的写时复制（Copy-On-Write, COW）技术，在执行快照的同时，正常处理写操作。\n简单来说，bgsave 子进程是有主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。\n此时，如果主线程对这些数据也都是读操作，比如图中的键值对 A，那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据，像图中的键值对 C，那么这块数据就会被复制一份，生成该数据的副本，也就是键值对 C'。然后，主线程在这个数据副本上进行修改。同时，bgsave 子进程可以继续把原来的数据（键值对 C）写入 RDB 文件。\n这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。\n看到这里，我们就解决了对“哪些数据做快照”以及“做快照时数据能否修改”这两大问题：Redis 会使用 bgsave 对当前内存中的所有数据做快照，这操作师子进程在后台完成的，这就允许主线程同时可以修改数据。\n快照频率 现在，我们再来看另外一个问题：多久做一次快照？我们在拍照的时候，有时候会使用“连拍”，可以记录人或物连续多个瞬间的状态。那么，快照也适合“连拍”吗？\n对于快照来说，所谓“连拍”就是指连续地做快照，这样一来，快照的间隔时间变得很短，即使某一时刻发生宕机，丢失的数据也不会太多。但我们都知道，凡事都有两面性，如果生成快照的频率过快，则会导致性能和存储资源的消耗。所以，快照时间间隔的选取也是很关键的。\n如下图所示，先在 T0 时刻做一次快照，然后又在 T0+t 时刻再做一次快照，在这期间，数据块 2 和 6 被修改了。如果在 t 这段时间内，机器宕机了，那么只能按照 T0 时刻的快照进行恢复。但由于数据快 2 和 6 的修改值没有快照记录，就无法恢复了。\n所以，要想尽可能避免数据丢失，t 值就要尽可能小。那么，t 值可以小到什么程度呢？是不是可以每秒做一次快照？毕竟，每次快照都是由 bgsave 子进程在后台执行，也不会阻塞主线程。\n但这种想法是错误的。虽然 bgsave 执行时不阻塞主线程，但是，如果频繁地执行全量快照，也会带来两方面的开销。\n一方面，频繁将全量数据写入磁盘，会给磁盘带来很大的 IO 压力，多个快照竞争有限的磁盘带宽，前一个快照还没有结束，后面的又来了，容易造成恶性循环。\n另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会阻塞主线程，但 fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，就会频繁阻塞主线程了。因为 Redis 中如果有一个 bgsave 在运行，就不会再启动第二个 bgsave 子进程。\n那么针对刚才这种情况，有什么比较好的解决办法呢？如果做过数据集成与同步业务的同学，可能已经想到答案了。既然每次全量同步快照的成本开销较大，那么我们可以这样做：做一次全量快照后，之后对于更新修改的数据进行增量快照记录，这样可以避免每次全量快照的开销。\n在第一次做完全量快照后，T1 和 T2 时刻如果再做快照，只需要将被修改的数据写入快照文件就行。但这么做的前提是，我们需要弄清楚哪些数据被修改了，这一步骤会使用额外的元数据信息去记录哪些数据被修改了，这也会带来额外的空间开销问题。如下图所示：\n如果每一个键值对的修改动作一个记录，那么，如果有 10w 个被修改的键值对，就需要有 10w 条额外的记录。而且，有的时候，键值对非常小，比如只有 32 字节，而记录它被修改的元数据信息，可能就需要 8 字节，这样一来，为了记录这些修改，引入的额外空间开销就会比较大。这对于非常重视内存资源的 Redis 来说，有些得不偿失。\n到这里，可以发现，虽然与 AOF 相比，快照的恢复速度快，但是，快照的频率不好把握，如果频率太低，两次快照间一旦宕机，就可能有比较多的数据丢失。如果频率太高，又会产生额外开销。那么，还有什么办法既能利用 RDB 的快速恢复，又能以较小的开销做到尽量少丢失数据呢？\n混合使用 AOF 日志和内存快照：简单来说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作。也就是说，不需要记录所有操作，也就不会出现文件过大，可以避免重写带来的开销。\n如下图所示，T1 和 T2 时刻的修改，用 AOF 日志记录，等到第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。\n这个方法既能利用 RDB 文件快速恢复的好处，又能使用到 AOF 只记录操作命令的简单优势。（小孩子才做选择，成年人肯定是“全都要”。）\n总结 在本篇博客中，主要讲解了 Redis 使用内存快照避免数据丢失的方法。这个方法的优势在于，可以快速恢复故障数据，也就是只需要把 RDB 文件直接读入内存，这就避免了 AOF 需要顺序、逐一重新执行操作命令带来的低效性能问题。\n不过，内存快照也有其局限性。如果每次都是全量同步快照信息，不可避免地会带来大量的资源消耗。虽然 Redis 设计了 bgsave 和写时复制方式，尽可能减少了内存快照对正常读写的影响，但是，频繁进行快照仍然是不太能接受的。而混合使用 AOF 和 RDB，正好可以取两者之长，以较小的性能开销保证数据可靠性和性能。\n最后，关于 AOF 和 RDB 的选择可以根据下面三条参考建议：\n数据不能丢失时，内存快照和 AOF 的混合使用是一个很好的选择； 如果允许分钟级别的数据丢失，可以只使用 RDB； 如果只用 AOF，优先使用 everysec 的配置选项，因为它在可靠性和性能之间取了一个平衡。 ","description":"","tags":null,"title":"Redis03——RDB 快照","uri":"/tech/redis/redis03_rdb/"},{"categories":null,"content":"杭漂一年 这是一篇流水账，没什么营养。\n前言 其实没想好这个月去写什么的，感觉什么都没发生，但隐隐约约有好像经历了挺多事情的。在回头看之前写的博客，回头发现原来我已经被流放在杭州一年了都。时间过的还是挺快的，这一年整体给我的感觉就是换个陌生的城市体验生活。说不上有什么好的，但好歹不算太差。\n这一年中经常会吐槽，“从小到大没受过这么大的苦！！！”，指的是上班。也确实如此，因为来到一个城市，首先要解决的就是衣食住行的问题，那么也就不得不上班。换句话来说，如果不是因为工作，我大概率也不会在杭州待这么长时间。至于能待到什么时候，我也不知道。反正目前来看，似乎有点安逸，没有刚来的时候那股劲儿了。也许是有点疲惫变成了自己所厌恶的社畜的模样。\n回想去年四月中上旬对爸妈说：我准备来杭州，去换个城市生活。上海因为 22 年疫情的措施，有点失望吧。起初，爸妈可能以为是开玩笑，毕竟在此之前已经拿到了上海那边的 Offer，随后一次偶然的机会抱着试一试的心态来到了现在这家公司，也就这样一个人背着包，拖着行李箱来到了杭州。\n初入职场 在我来杭州之前，已经有大学同学传琪在杭州工作快一年了，所以来的时候第一想到先去他那边，问问其情况，再决定自己这边的。他住在拱墅区，当时去他那边给我的感觉还是生活气息比较浓厚，每走一段距离就能看见小桥流水，小区门口也能看见独属于杭州的烟火气。随后，来到余杭这边租房，给我的感觉却是另外一番场景，出创景路站看见的就是高耸的写字楼，很是压抑。第一反应就是，过不了多久似乎自己也会变成这里的一份子，每日上下班拖着疲惫的身体。事实证明也确实如此。\n虽然之前有过实习经历，不过都是线上远程办公，当第一次线下入职还是有点点小紧张的。不过比较值得庆幸的就是，周围的同事至少在表面上看着还行，相处的也就还算不错。在入职没多久，还体验了一次出差的感觉，由于当时刚入职不久，而且还是去海南，所以更多的还是兴奋。原以为是公费出去旅游，但实际上还是挺累的。之后的话，感觉工作成为日常，很多内容都是毫无意义的，纯粹是为了公司的效益而做的事情。这种也就是我们俗称的“答辩”。\n从一身干劲的职场小白，到如今习惯摸鱼的半个老油条，在这其中，对于工作的厌恶是不断加深，也许是目前的工作不适合我吧。之前和朋友聊天，就提到如果考虑跳槽的话，想加入一家重视工程师文化的团队，而不是那么多条条框框。但目前来看，现在的工作最大的优点就是不怎么加班，整体上来说也比较轻松。现在这鬼环境，能找到安逸的工作躺着也是一种幸福。（但这其实是一种病态的，不加班不应该是正常的麽？为啥还成了有点呢？！！）\n工作态度的转变，在这个过程中，我不再去质疑工作内容的好与坏，开始有了自己的标准（有强迫症的那种），高于周围同事的水平。对于个人和公司来说，个人的技术栈能够给公司创造价值，公司给员工提供基本的收入来源就足矣，没有谁离不开谁。当然这个前提是自己没有房贷、没有娃要养，没有太大的家庭负担。前段时间在推上看见“优质员工”的说法，三十多岁，被房贷压着、有娃要养。这类员工就是可以被公司随意拿捏的。对于这类员工，先说个暴论，都三十多岁了，在当前的行业最起码有 10 年左右的工作经验，没混出点名堂来，靠着加班苟延残喘也是活该。（不想被打脸，看看十年后的自己咯。）这个时候肯定有人会说，你不懂，你还年轻之类的话。emmmm，我也确实不懂，但起码现在不想向生活低头。\n在工作大约三个月的时候，转变了工作的方式，会根据制定的 KPI，按量合理规划自己的任务，把工作当作学校时期的大作业，想办法提高自己的效率，尽可能快的去完成，这样一来省下的时间都是自己的。至于这部分时间干嘛呢？肯定是做自己的事情咯，也就是提升自己。也是在工作之后，感受到了基础知识的重要性，开始重新梳理分布式相关的论文，搞大数据的，如果连“三驾马车”都没看过，岂不是瞎搞么。再去选择一个自己感兴趣的方向去深入研究，因为问题是从实践中来，通过论文以及代码的实践，会一步一步发现更多有意思的事情，当回头看把整个过程给串起来的时候，也就形成了自己的知识体系。（虽然现在还半斤八两，还有很多要学习的。）\n在工作中和生活中，还有重要的一点就是拥抱变化，当下 LLM 大行其道，要学会思考“AI 时代的软件工程”这个命题。很多人担心 AI 会取代程序员这个行业，因为大部分人眼中自己就是搞技术写代码的，这部分的能力逐渐被 GPT 类的产品取代，那岂不是没了活路？\n从软件工程的角度来看，其实上述观点并不完全重要。在整个开发的过程中，我们要做的不仅仅是编写代码，甚至写代码在整个软件开发的周期也只是占很小的比例。在实际生产环境中，还涉及到问题解决、需求分析、系统设计、测试和维护等方面。所以我们要学会合理的使用工具去解决问题。借助 AI 工具，更重要是思考如何快速高效的给出我们想要的结果。这也是提升工作效率的一环，为了更好的摸鱼 哈哈哈。\n不再设限 当自己开始接触到另一个世界，也会感觉到自己的渺小与不足，也才能知道自己到底想要什么。而不是被困在信息茧房中出不来。摸鱼的时候，开始习惯逛外网，看一些互联网圈子的好人好事，也就是在这个过程中，开始不满足自己的现状，决定慢慢积累，从而打破。\n首当其冲的就是技术栈的选择，因为没有限制，可以了解更多，也就随之能够选择真正适合自己的。无论是在公司里面，还是一些线下技术相关的 meetup，都会听见有人提到自己是做 xx 开发的，然后干嘛干嘛的。有自己明确的定位是挺好的，但我还是更倾向于将自己定位成一个“开发者”。如果某个阶段新的问题，我会重新评估技术栈的选型，甚至是编程语言的选择。因为这些玩意都只是解决问题的工具和途径，并不是标准答案。当你有了一定的积累，自然而然能够做出对应的选择。\n但从公司的角度来说，就会选择稳妥一点，看看业界有哪些解决方案，照着抄一抄，改一改就能用。毕竟公司不是给你玩技术的地方，而且也不能保证每个同事都对技术有追求，更多的还只是将编程看作养家糊口的职业，巴不得自己的老本够吃到退休捏。最后防止被裁，表现的勤勤恳恳任劳任怨也是够了。\n吐槽结束，回到正文，在这个过程中给我带来最明显的感觉是以下两个：基础知识和信息的来源。因为很多内容放在底层来看是相通的，在思考问题的时候，就不要停留在表面，往里面走一走，看看有哪些类似的东西，会有意想不到的收获。由于国内的环境是封闭的，加上语言的限制（英语），很多人看不见或者不喜欢看英文文档，也就导致错失了很多一手的信息来源，这就导致了信息差。当积累的越多，就会发现自己与周围人的差距也会越来越大。所以我们要学会去问题的根源寻找答案，而不是嚼别人剩下的内容。\n谈谈生活 换个陌生的城市，总归来说还是想体验不一样的生活。\n首先来吐槽杭州的天气，第一次来杭州下雪！第二次来杭州下雨！入职第一天下雨！工作日经常到下班就开始下雨！春秋好短，夏天闷热，冬天温度还挺低，温度还习惯性的忽冷忽热！！！唉，和我以为的杭州不一样。小时候就听长辈们说：“上有天堂，下有苏杭”。结果实际上是这么一个天气情况，也很是无语。就导致了不知道该穿什么衣服合适。有时候走在路上会发现，路人的衣服可以贯穿一年四季。不过话说回来，最近两年华东地区的天气大都是这个样子，也没办法。\n杭州生活节奏上给人的感觉还是比较舒缓的，城市的基础设施建设、人文情怀也都是还行。可能和去年亚运会投入很多有关，但亚运会就像一阵风，吹完了什么都没留下，至少对我是这个感觉。对了，杭州这边的年轻人还是挺多的，有时候坐地铁，看见戴着眼镜背着双肩包的男生，就感觉十有八九是同行，哈哈哈哈。\n我是比较追求 WLB 的，受不了工作就是生活的态度，反对大小周、996 等劣势文化。经过这一年的了解会发现，不少人还是在大小周或者 996 的，换作是我可能早就发疯或者辞职了吧。我在工作中也是比较叛逆的，属于“坚持做正确的事，等着被开除”的那一类。前段时间公司的行政天天管着戴工牌，咱也是不想戴，反倒是不太理解为什么有些人出了公司门还喜欢把狗链戴在脖子上捏。\n比较值得庆幸的是杭州本身以及周边的山山水水比较多，而且都还不高，适合周末出去转一转。有时候就在想，上午爬个山，中午吃饭休息一会，下午在山脚下找个安静的地方写代码也是极好的。（肯定不是公司的业务代码咯。）\n在这一年中间还搬了一次家，住的距离公司更近了，社畜气息也就更加浓厚了。近的好处就是节省了上下班的通勤时间，不用担心迟到之类的问题。坏处就是周末了还在工作的范围圈内，有点麻木。而且房租也是挺贵的。但能够在家打卡还是挺好的，哈哈。\n从去年八月之后，开始重新看一些闲书，每天被技术充斥着也不好，糟糕来说还会阶段性陷入内耗。晚上睡前做到不带任何电子产品上床，床头放本书，睡前读一会，困了倒头就睡还挺好的。工作之后的身体状态变差，也可能是因为新冠阳了之后吧，大学四年没有感冒发烧的，结果这一年好几次。加上每天久坐，下意识摸了摸自己的肚肚，也是肉乎乎的，就想还是得自律一点，开始了健身。撸铁之后的好处就是，每天出出汗，洗完澡消除一天的班味。而且不担心长肉了。但最近这段时间体重一直在往下掉，就很离谱，在杭州待了一年体重掉了十来斤，美食荒漠实锤了！！！说起这个，每天工作最头疼的就是吃什么。和室友每天都得讨论哲学问题——今晚吃什么。附近的吃的店几乎给吃了个遍。也是挺头疼的。\n当每天的时间被工作占据太多之后，打主机游戏的时间也就少了，对游戏的态度也就变佛了。也很少有时间和精力去开一个新的游戏，因为上手一个全新的游戏成本还是挺高的，对于手残的我来说，不亚于上手一个新的技术，游戏本来就是放松的，如果学习成本过高，对于现如今快节奏的生活来说，反倒是负担。这一点就很佩服任天堂，可以说老任是懂玩家，游戏玩法上做减法，却并没有丢失趣味性，玩起来也很舒服。今年的话，希望能把去年吃灰的游戏给一个一个解决了吧。\n写在之后 就像关于过年🧨中最后写的一样，想去发现更多生活的乐趣，去看看技术以外的世界~~\n哦对了，还有一件事，就是 emmmmm 很开心你能看到这里。\n","description":"","tags":null,"title":"杭漂一年","uri":"/life/24_04-one_year/"},{"categories":null,"content":"Redis——AOF 日志 前言 聊起 Redis 的应用场景，大部分开发者第一反应可能会是：缓存，因为它可以把后端数据库中的数据存储在内存中，内存的访问效率要比硬盘高的多，所以直接从内存中读取数据，响应速度会非常快。\n这也是 Redis 目前在业务场景中的普遍使用案例，但其中也暴漏出一个不可忽视的问题：一旦服务器宕机，内存中的数据将会全部丢失。那么该怎么解决这个问题呢？\n比较容易想到的解决办法就是，既然 Redis 存储的数据是从后端数据库中来的，那么直接从数据库中恢复不就好了嘛。但这也会引发以下的问题：\n在恢复的过程中，可能需要频繁地访问数据库，会给数据库带来较大的 IO 压力； 这些数据是从数据库中读取出来，性能肯定比不上 Redis 中读取，会影响使用这些数据的应用程序。 由此可见，对于 Redis 来说，实现数据的持久化，避免从后端数据库进行恢复，是至关重要的。目前，Redis 的持久化主要有两种方式，分别是 AOF（Append Only File）日志和 RDB 快照。这篇博客先来看第一种——AOF 日志。\nAOF 日志 在传统的后端关系型数据库中对于日志的处理一般都是写前日志（Writer Ahead Log，WAL），简单来说，就是在实际写数据之前，先把修改的数据记录到日志文件中，如果后期数据库出现故障可以方便进行恢复。与此不同的是，AOF 日志刚好相反，它是写后日志，“写后”的意思是 Redis 先执行命令，把数据写入内存，然后才记录日志，如下图所示：\n看到这里，你可能会感到疑惑，为什么 AOF 要先执行命令再记录日志呢？回答这个问题之前，先来一起看看 AOF 里面记录了哪些内容。\n传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的。\n我们以 Redis 收到“set key1 value1”命令后记录的日志为例，看看 AOF 日志的内容。其中，*3 表示当前命令有三个部分，每部分都是由 $+ 数字 开头，后面紧跟着具体的命令、键或值。这里，“数字”表示这部分中的命令、键或值一共有多少字节。例如，$3 set 表示这部分有 3 个字节，对应的也就是 set 命令。\n不过，为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，如果记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。\n而写后日志这种方式，就是先让系统执行命令，只有命令被成功执行，才会被记录在日中，否则，系统就会直接向客户端报错。所以，Redis 使用写后日志这一方式的好处就是：可以避免出现记录错误命令的情况。除此之外，AOF 还有一个好处就是：它是在命令执行后才记录日志，所以不会阻塞当前线程的写操作。\n但我们知道凡事都有两面性，AOF 也有如下两个潜在的风险。\n首先，如果刚执行完一条命令，还没来得及记录日志服务器就宕机了，那么这个命令和相应的数据就会有丢失的风险。如果此时 Redis 是用作缓存，还可以从后端数据库重新读入数据进行恢复，但是，如果 Redis 是直接用作数据库的话，此时，因为命令没有记录日志，所有就无法通过日志进行恢复了。\n其次，AOF 虽然避免了对于当前命令的阻塞，但可能会给下一个操作带来阻塞风险。原因也很简单，AOF 日志也是在主线程中执行的，如果在把日志写入磁盘时，IO 压力较大，就会导致写盘很慢，进而导致后续的操作无法正常执行。\n诶，到这里如果细心一点，就会发现，刚才所描述的两个风险都是和 AOF 写回磁盘的时间点有关。这也意味着，如果我们能够控制一个写命令执行完 AOF 日志写回磁盘的时机，这两个问题也就迎刃而解咯。\n写回策略 其实，对于这个问题，AOF 机制给我们提供了三个选择，也就是 AOF 配置项 appendfsync 的三个可选值：\nAlways，同步写回：每个命令执行完成之后，立刻同步地将日志写回磁盘； Everysec，每秒写回：每个命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘； No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。 针对避免主线程阻塞和减少数据丢失问题，这三种写回策略都无法做到两全其美。我们来分析下其中的原因：\n“同步写回”可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能； “每秒写回”采用一秒写回一次的频率，避免了“同步写回”的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。所以，这也只能算是一种策略上的取舍； 虽然“操作系统控制的写回”在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在 Redis 把握之中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了； 配置项 写回策略 优点 缺点 Always 同步写回 可靠性高，数据基本不丢失。 每个写命令都要落盘，性能影响较大。 Everysec 每秒写回 性能适中。 宕机时丢失 1 秒内的数据。 No 操作系统控制的写回 性能好。 宕机时丢失数据较多。 到这里，我们就可以根据系统对高性能和高可靠性的要求，来选择使用哪种写回策略了。总结一下就是：想要获得高性能，就选择 No 策略；如果想要得到高可靠性保证，就选择 Always 策略；如果允许数据有一点丢失，又希望性能别受太大影响的话，那么就选择 Everysec 策略。\n但是，按照系统的性能需求选定了写回策略，并不是“以逸待劳”了。毕竟，AOF 是以文件的形式在记录接收到的所有写命令。随着接收到的写命令越多，AOF 文件也会越来越大。这也就意味着，一定要小心 AOF 文件过大带来的性能问题。\n这里的“性能问题”，主要在于以三个方面：\n文件系统本身对文件大小有限制，无法保存过大的文件； 如果文件太大，之后再往里面追加命令记录的话，效率也会变低； 如果服务器发生故障，如果日志文件过大，在恢复过程会非常缓慢，影响 Redis 正常使用。 所以针对以上问题，我们要采取一定的控制手段，那也就是 AOF 重写机制。\nAOF 重写机制 AOF 重写机制就是在重写时，Redis 根据数据库的现状创建一个新的 AOF 文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。emmm 这么说的话，可能觉得有点抽象，看个栗子：当读取了键值对 \"key1\": \"value1\" 之后，重写机制会记录 set key1 value1 这条命令。这样，当需要恢复时，可以重新执行该命令，实现 \"key1\": \"value1\" 的写入。\n为什么重写机制可以把日志文件变小呢？实际上，重写机制具有“多变一”的功能。简单来说就是，旧日志文件中的多条命令，在重写后的新日志中变成了一条命令。AOF 文件是以追加的方式，逐一记录接收到的写命令的。当一个键值对被多条写命令反复修改时，AOF 文件会记录相应的多条命令。但是，在重写的时候，是根据这个键值对当前最新的状态，为它生成对应的写入命令。这样一来，一个键值对在重写日志中只用一条命令就行了，而且，在日志恢复时，只用执行这条命令就可以直接完成键值对的写入了。\n不过，虽然 AOF 重写后，日志文件会缩小，但是，要把整个数据库的最新数据的操作日志都写会磁盘，也是非常耗时的，这个时候就带来新的问题——“重写会不会阻塞主线程？”\n和 AOF 日志由主线程写回不同，重写过程是由后台子进程 bgrewriteaof 来完成的，这也是为了避免阻塞主线程，导致数据库性能下降。\n对应过程主要如下：\n每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此时，fork 会把主线程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志。\n在这个过程中，由于主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复。\n还有一点就是新的 AOF 重写日志，这个操作也会被写到日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库最新状态的记录。这个时候，我们就可以使用新的 AOF 文件替代旧文件了。\n总结来说，每次 AOF 重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程并不会阻塞主线程。\n总结 在这篇博客中，简单介绍了 Redis 用于避免数据丢失的 AOF 方法。这个方法通过逐一记录操作命令，在恢复时再逐一执行命令的方式，保证了数据的可靠性。\n这个方法看似“简单”，但也是充分考虑了对 Redis 性能的影响。总结来说，它提供了 AOF 日志的三种写回策略，分别是 Always、Everysec 和 No，这三种策略在可靠性上是从高到低，而在性能上则是从低到高。\n此外，为了避免日志文件过大，Redis 还提供了 AOF 重写机制，直接根据数据库里数据的最新状态，生成这些数据的插入命令，作为新日志。这个过程通过后台线程完成，避免了对主线程的阻塞。\n其中，三种写回策略体现了系统设计中的一个重要原则，即 trade-off，或者称为“取舍”，指的就是在性能和可靠性保证之间做取舍。其实，放在生活中也是同理，我们总是在一边得到，一边失去。现如今这个时代，做好取舍，活得自洽就好~~\n","description":"","tags":null,"title":"Redis02——AOF 日志","uri":"/tech/redis/redis02_aof/"},{"categories":null,"content":"这个春天，等风来～ 可以听银河快递的《等风来》看这篇博客哦。\n说点什么来开场呢？ 哈哈，虽然想好了这个月的博客写什么，但感觉直奔主题会有点太突兀，就还是写点啥来暖个场吧。就简单聊聊这个月做了什么。\n随着三月的结束，2024 的第一个季度也正式告一段落，过得还挺快的。这个月心情还不错，开始慢慢尝试去拥抱新的生活。可能和最近听的歌有关吧————《等风来》。在 2023 年度总结中提到过这个乐队，是比较喜欢的。（虽然没抢到杭州场 live house 的票，呜呜🥹。但希望该遇见的总会遇见。\n这首歌听起来很舒服，旋律很舒缓，歌词也很阳光，刚好杭州最近的天气暖和了起来，一切也都契合的刚刚好。哦对了，这首歌的英文名是《Take Easy》。\n看了《Dune 2》，很不错，场面很大，画面感很强，配乐很震撼！！！是看了之后想二刷的电影。也正是这个原因，看完之后觉得意犹未尽，又买了原版的图书来看，希望能把原著早点啃完，哈哈。\n关于工作方面，还是保持我之前的特性，坚持做正确的事情。给团队重新规划了 GitHub Actions 的使用，优化了 CI/CD 的使用，最后也借此机会科普了一些开源有关的基础知识，比如开源 License 的选择。\nBTW 之前我一直以为大部分人写代码或者文档都会有洁癖，事实上我错了，在国内追求短平快的节奏下，大部分人都没有，看这种东西就宛如依托💩，对于一个强迫症晚癌来说太难受了😣 呜呜。\n这个月中旬去了姐姐家，看看小宝。隔一段时间去看看小宝，能明显地感觉到越来越有意思，稍微逗逗她就哈哈地笑，很治愈。但如果问我是否想生娃，暂时还不，偶尔看一次就挺好的，哈哈。和姐姐开玩笑说，咱对小宝好一点，以后也是我的闺女咯。不得不说，从怀孕、生娃到带娃，女性在这方面付出的要多得多。有时候在推上看见有些程序员奶爸分享带娃日常，是个好爸爸、好丈夫、好的开发者，也挺羡慕的。不过，刚开始过第二个本命年的我，还不想考虑这些事，尽可能过得自由一点就好，哈哈。\n虽然我不太喜欢币圈，但这个月还领了一笔空投。比较有意思的是这笔空投是从垃圾邮箱看见的，是一个收购空投的邮件，说愿意出大于 3200 软妹币的金额来收购。可以说我又不是傻子，既然你愿意出这些钱，肯定回报比这个要高的，不如自己动手操作一番咯，也算是真正感受一下币圈的流程。这次的流程比 StarkNet 的要复杂一点点，其中还涉及到 Proof、C2C 之类的，好在最后成功领到钱包里了，等着两月后变现咯，哈哈。从没想过混开源能够发家致富呐。\n捡起吃灰的 Splatoon3 由于我有点晕 FPS 类的游戏，以及网络原因，这游戏一直在吃灰。不过这个月 《Splatoon3》 从我的吃灰库中终终终于给拿了出来，不得不说老任的游戏还是有人联机一起玩比较有意思。这个月也参与了两次线下聚会，认识了一些新的朋鱿。线下一起玩游戏还是很快乐的，哈哈。其中还遇到了同行——lds 也是个程序员，听他说之前写过 Java，目前在做自动驾驶，还是挺佩服的。不过他竟然说 Emacs 是编辑器之神，这个我是不认可的！问就是咱菜菜，没用过 Emacs 🥹。其中还有来自 Panda 老师的8⃣️0⃣️，说真的他好像熊猫🐼 哈哈哈。还去了 Fejo，环境感觉挺不错的，本来打算周末去 coding 的，结果一直咕咕咯。有机会，下次一定！值的庆幸的是，lds 也喜欢听安溥，感觉五月的音乐节可以约起来，一起去听安溥麻麻 哈哈。\n聚会有好多大学生，真的好羡慕，也许是工作之后，有了“班味”，是一种肉眼可见的疲惫，唉。也就导致对于游戏没有以前那么爱玩，晚上撸完铁回到家，洗完澡之后躺在床上，一点都不想动 hhhh。看见好鱿在线，如果有车位的话，也会打上几局，权当是对工作的发泄吧。也感谢 ab大好き 带我打真格，让我成功从 C- 混到了 C 哈哈哈。感觉是一个挺有意思的小孩，不过喜欢听 emo 的音乐，如果有机会的话，得劝劝她多听点积极的音乐，《等风来》就很不错！（虽然自己听的也是 emo 的较多，可能天生比较丧吧。）不过最最最巧的是，她是 ESFP-A，和我 INTJ-J 完全相反，也是我第一个遇见和我完全相反的人，这应该也算是一种缘分吧，哈哈哈哈哈。虽然从理性上来说，咱不太信这鬼东西，但某种程度上也感觉挺符合的🤔️。\n说实在的，现在自己很少会主动打游戏了，总感觉时间不够用，目前这个阶段的自己还有很多需要学习、沉淀的。游戏和健身一样，是解压方式吧。\n重回开源 断断续续接触 Rust 七八个月了，但总感觉自己学的不到家，很多地方都不理解，听了持续集成的播客————Xuanwo 的开源世界大冒险 - 对话「OpenDAL」作者 Xuanwo。Xuanwo 大佬咱也是很佩服的！在播客中 Xuanwo 和 wayne 提到一个观点，那就是在用中学，简单来说就是 “get hands dirty”。刚好看见了 Xuanwo 的推文，是关于 Iceberg 的，刚好自己对于大数据领域的组件比较熟悉，就在 Issue 中找到了 Complete predicate builders for all operators，属于是 good first issue，从熟悉到上手编写也就四个多小时的工作量，抽了个周六很快就写完了。但这仅仅是个开始，自己平时接触的都是偏向于批处理的场景比较多，数据湖去年简单玩过一点点 Hudi，对于 Iceberg 也就是只闻其身，未曾动手使用过，又抽了点时间看看官网的 QuickStart，简单运行了几个案例，大体上知道了是怎么一回事。\n刚好在月底 PR 被成功 Merge，还是挺有成就感的，然后随手发了个推，表示庆祝。没想到了的有很多之前关注的大佬 follow back，其中还有 yihong0618，这真的是一种无以言表的开心，也许这就是开源的乐趣吧，所谓开源，也就是“开心的源头”。希望能够再接再厉，多做点力所能及的事情，make the lakehouse area rusty 🦀️。\n有时候往往一个不经意的决定或者动作，会带来意想不到的收获。这也符合我的佛系哲学观点：求而不得，往往不求而得。\n知识付费？ 在有了一定的知识和技术积累之后，针对某件事自然而然会有自己的判断。比如学 Rust 这件事，一开始可能仅仅出于好奇，大家都说难，我就想看看到底哪里难。然后就会去动手查找资料，再借助 LLM 的帮助，学习成本会小的很多。我感觉这也是学习编程的常规手段，就是先捋清楚基本概念，然后动手实践，写代码说到底还是手艺活，而且由于 Rust 语言本身的特性，一开始写起来不注重细节，就会有各种各样的错误。但有了一定量的练习之后，再去选择对应的方向，也就能真正用起来了。\n可就是这么正常的事情，却被一群所谓的技术博主给搞歪了。我们经常会看到“知识星球”、“独立开发者卖课”，但真的值得为这些内容付费吗？先说观点，我是提倡知识付费的，因为优质的内容是值得付费的。不过事实却是往往相反，很多教育机构、独立开发者开始割韭菜，稍微有个两三年编程经验的小鬼都开始乱跳，然后搞出各种面经八股文，就很恶心。这也从侧面反映出一些很水的面试官，只会问一些八股。这些人往往喜欢煽动情绪、制造焦虑。如果所有心思都放在挣快钱割韭菜，不去好好沉淀自己的技术，水平也是可想而知的。\n但从侧面来思考，对于小白来说，最重要的就是需要有人告诉该学什么，然后尽可能的多一点“陪伴”。现在很多大学生都喜欢说 B 站是个学习网站，之前我也是这么认为的。不可否认该视频平台是有很多优质内容的，但从本质来说娱乐软件就是娱乐软件，现如今不缺教育资源，缺的是一颗能够静下来的心。作为学习者要善于利用工具，就拿学 Java 来说，推荐的书是《Java 核心技术卷 1》，这本书可以当作经常翻阅的技术手册，用于入门和查漏补缺都是挺好的，而且看书是一个思考的过程。从我本人的角度来说，与看视频被一味地灌输来说，更喜欢看书+动手实践。此外，现在有 LLM 的帮助，遇见不同的问题向其讨论，也会得到不错的答案。万事开头难，只要成功入门，知识会带着读者继续寻找对应的知识。此外，在开源中学习也是个不错的选择。\n不过，说到底，很多人是没有辨别真伪的能力，甚至更有人会有一类人喜欢花钱买安慰。所以这也是那帮卖课割韭菜能存在的一部分原因。如果付费能够筛选出优质的内容，我觉得是挺值的。可惜现在的市场是鱼龙混在，劣币驱逐良币。反而导致获取有用知识的成本增加了。\n这部分过于主观，如果你杠就是你对，谢谢。\n还有啥呢？ Emmmmm，应该没有啥了。回顾这几年好像都没怎么好好感受过春天，今年在杭州看见樱花开，去寻找春天的脚步也挺不错的。有时候会陷入技术的内耗，合上电脑，做做其他的事情，认识有趣的人，多走走散散心也是不错的。如果连生活都过不好的人，多半也不会多么幸福。\n哦对了，还有就是，我挺期望看见五年后的自己。那个时候小宝应该在上幼儿园，如果她的父母说出，多向你舅舅学习，我还是挺自豪的，哈哈。\n我们一定要活\n在热爱里\n别人的话语\n没必要去在意\n迷雾中的森林下着大雨\n太阳照过头顶\n而我在等你\n","description":"","tags":null,"title":"等风来","uri":"/life/24_03-spring/"},{"categories":null,"content":"从 Redis 的数据结构开始聊起 前言 现如今提到 Redis，大众的第一印象应该就是“快”，也正是由于 Redis 的快的特性，使得其可以适用于分布式缓存、键值对数据存储等场景。但反过来想一下，为什么 Redis 能有如此突出的表现呢？它是如何在相关领域独占鳌头的呢？\n诶，这个时候可能懂点皮毛的程序员就会说，因为它是内存数据库，所有的操作都是在内存上完成的，内存的访问速度本身就比磁盘要快。这么回答当然没错，但是如果再深入一点的话呢？这样就要归功于 Redis 的数据结构。在 Redis 中键值对是按一定的数据结构来组织的，所以说用户对于键值对的操作，最终就是对数据结构进行增删改查的操作。\n如果上手使用过 Redis 的话，我们可以知道常见的有：String、List、Hash、Set 和 Sorted Set。不过，这些都只是 Redis 键值对中值的数据类型，说通俗点就是数据的保存形式。但在这篇博客中，我们来一起探究其底层的实现。\n简单来说，底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩列表、哈希表、跳表和整数数组。它们和数据类型的对应关系如下图所示：\n可以看到，String 类型的底层实现只有一种数据结构，也就是简单动态字符串。而 List、Hash、Set 和 Sorted Set 这四种数据类型，都有两种底层实现结构。通常情况下，我们会把这四种类型称为集合类型，它们的特点是一个键对应了一个集合的数据。\n看到这里，我们可以想一下，这些数据结构都是值的底层实现，键和值本身之间用什么结构组织呢？为什么集合类型有那么多的底层结构，它们之间有何区别呢？下面我们就这两个问题来展开讨论。\n键和值用什么结构？ 先说答案：Redis 的键和值之前使用哈希表来组织和存储。在 Redis 中，每个键都与一个值相关联，并且这些键值对都存储在哈希表中。一个哈希表，其实就是一个数组，数组的每个元素称为一个哈希桶，通过哈希函数将键映射到哈希桶中，从而快速地访问和检索数据。所以，我们常说，一个哈希表是由多个哈希桶组成，每个哈希桶中保存了键值对数据。\n这个时候可能有的读者就会想到：“如果值是集合类型的话，作为数组元素的哈希桶该怎么保存呢？”其实，这个答案很简单，哈希桶中保存的元素并不是这个值本身，而是指向这个值的指针。也就是说，不管值是 String 还是集合类型，哈希桶中的元素都是指向它们的指针。\n我们可以借助下图来理解：哈希桶的中 entry 元素中保存了 *key 和 *value 指针，分别指向了实际的键和值，这样做的好处是，即使值是一个集合，也可以通过 *value 指针被查找到。\n因为这个哈希表保存了所有的键值对，所以，可以将之称为全局哈希表。我们知道哈希表最大的优点是可以在 O(1) 的时间复杂度来快速查找对应的键值对。实现过程就是计算键的哈希值，从而得到对应的哈希桶的位置，然后就可以访问相应的 entry 元素。\n在这个查找过程主要依赖于哈希计算，和数据量的多少并没有直接关系。也就是说在理想状况下，不管哈希表里面有 10 万个键还是 100 万个键，我们只需要一次计算就能找到相应的键。\n但事实却并不是这样，当向 Redis 中写入大量数据后，就可能会发现有时候操作会突然变慢了。这是因为忽略了一个潜在的风险：服务器的资源并不是无限的，所以在存储过程中必定会有取舍，对于哈希表也是同理，也就有了哈希表的冲突问题和 rehash 可能带来的操作阻塞。\n哈希冲突 经过上面的分析，我们可以知道在有限的空间内，向哈希表中写入大量的元素时，哈希冲突是不可避免的问题。说简单点就是：当两个或两个以上的 Key 哈希值和哈希桶计算对应关系时，刚好落在了同一个哈希桶中。因为哈希桶的个数通常要少于 Key 的数据，这就导致了有一些 Key 的哈希值同时对应到了同一个哈希桶中。\n在 Redis 中解决哈希冲突的方式时链式哈希，是指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次使用指针连接。\n如下图所示：entry1、entry2 和 entry3 都需要保存在哈希桶 3 中，导致了哈希冲突。此时，entry1 元素会通过一个next 指针指向 entry2，同样，entry2 也会通过next 指针指向 entry3。这样一来，即使哈希桶 3 中的元素有 100 个，我们也可以通过 entry 元素中的指针，把它们连起来。这就形成了一个链表，也叫作哈希冲突链。\n但这么做也依然存在一个问题，哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就回导致某些哈希冲突链过长，也就会进一步导致这个链上的元素查找耗时较长，效率也会降低。这也越 Redis 的“快”相违背。\n所以，Redis 会对哈希表做 rehash 操作，也就是通过 rehash 增加现有的哈希桶的数量，让逐渐增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。具体做法如下：\nRedis 为了使 rehash 操作更高效，默认使用了两个全局哈希表：哈希表 1 和 哈希表 2.一开始，当插入数据的时候，会使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐渐增多，Redis 开始执行 rehash，这个过程分为三步：\n给哈希表 2 分配更大的空间，例如是当前哈希表 1 的两倍； 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中； 为了节省空间，释放哈希表 1 的空间。 当完成上述操作之后，就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多的数据，而原来的哈希表 1 释放空间之后，留作下一次 rehash 扩容备用。\n看到这里，有些读者可能会说，原来这么简单的呐。其实并不是，仔细思考一下，在第二步的时候会涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都迁移到过去，可能会造成 Redis 线程阻塞，无法服务于其他请求。此时，Redis 就无法快速访问数据叻。这就好比，既然一口吃不下，那就多分几口吃呗。是的，Redis 采用的是渐进式 Hash。\n说通俗点就是，在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。可以参考下图的内容来理解：\n这么做的好处是巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问。\n看到这里想必有可以理解 Redis 的键和值是怎么通过哈希表组织的了吧。对于 String 类型来说，找到哈希桶就能直接进行增删改查了，所以，哈希表的 O(1) 操作复杂度也就是它的复杂度了。但是，对于集合类型来说，即使找到哈希桶了，还要在集合中再进行一步操作。下面就一起来看看，在 Redis 中集合类型是怎么玩的。\n集合数据结构 和 String 类型不同的是，集合类型处理起来要复杂一点。对于集合类型的值来说，第一步是通过全局哈希表找到对应的哈希桶位置，第二步是在集合中再进行增删改查。下来我们就来分析一下集合的操作效率和哪些因素有关。\n首先可以想到的是，于集合的底层数据结构有关。例如，使用哈希表实现的集合，要比使用链表实现的集合访问效率更高。其次，操作效率和这些操作本身的执行特点也有关，比如读写一个元素的效率要比读写所有元素的效率高。\n接下来，我们就分别看一下集合类型的底层数据结构和操作复杂度。\n底层数据结构 在开篇我们提到了，集合类型的底层数据结构主要有 5 种：整数数组、双向链表、哈希表、压缩列表和跳表。\n其中，哈希表的特点刚才已经讲过；至于整数数组和双向链表也是比较常见，它们的操作都是顺序读写。也就是通过数组下标或者链表的指针逐个元素进行访问，时间复杂度基本是 O(N)，操作效率比较低；至于压缩列表和跳表我们平时接触的可能不是很多，但它们是 Redis 重要的数据结构，下面来重点解释一下。\n压缩列表比较类似于一个数组，数组中的每个元素都对应保存一个数据。和数组不同的是，压缩列表在表头有三个字段 zlbytes、zlail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数，在压缩列表的表尾还有一个 zlend，表示列表结束，如下图所示：\n在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，效率就没那么高了，只能逐个查找，此时的复杂度就是 O(N) 了。\n那么跳表呢？效率会不会高一点？\n有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现了数据的快速定位，如下图所示：\n如果我们要在链表中查找 26 这个元素，只能从头开始遍历链表，查找 6 次，直到找到该元素为止。此时，时间复杂度为 O(N)，查找效率很低。\n为了提高查找速度，我们来增加一级索引：从第一个元素开始，每两个元素选一个出来作为索引。这些索引再通过指针指向原始的链表。例如，从前两个元素中抽取元素 1 作为一级索引，从第三、四个元素中抽取 8 作为一级索引，依此类推。此时，我们只需要 4 次查找就能定位到元素 26 了。\n看到这里，聪明的你可能会想到，是不是能够再增加一个二级索引呢？从一级索引中再抽取部分元素作为二级索引。例如，从一级索引中抽取 1、19 和 45 三个元素作为二级索引，二级索引指向一级索引。这样，我们只需要 3 次查找，就能定位到元素 26 了。\n可以看到，这个查找过程就是在多级索引上跳来跳去，最后定位到元素。这也比较符合“跳表”这个名称，哈哈。当数据量很大时，跳表的查找复杂度就是好 O(logN)。\n到此为止，我们讲完了 Redis 中的底层数据结构类型，下面按照查找的时间复杂度总结如下：\n名称 时间复杂度 哈希表 O(1) 跳表 O(logN) 双向链表 O(N) 压缩列表 O(N) 整数数组 O(N) 不同操作的复杂度 在 Redis 中集合类型的操作有很多，有读写单个集合元素的，比如 HGET、HSET，也有操作多个元素的，例如 SADD，还有对整个集合进行遍历操作的，例如 SMEMBERS。这么多操作，它们的复杂度也各不相同。而复杂度的高低又是我们选择集合类型的重要依据。主要可以归纳为以下四类：\n第一，单元素操作，是指每一种集合类型对单个元素实现的增删改查操作。例如，Hash 类型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。这些操作的复杂度由集合采用的数据结构决定，例如 HGET、HSET 和 HDEL 是对哈希表做操作，所以他们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、SREM 和 SRANDMEMBER 的复杂度也是 O(1)。\n不过，这里有个地方需要注意一下，经过刚才介绍我们知道集合类型支持同时对多个元素进行增删改查，例如 Hash 类型的 HMGET 和 HMSET，Set 类型的 SADD 也支持同时增加多个元素。此时，这些操作的复杂度，就是由单个元素操作复杂度和元素个数决定的。例如，HMSET 增加 M 个元素时，复杂度就从 O(1) 变成 O(M) 了。\n第二，范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如 Hash 类型的 HGETALL 和 Set 类型的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免。\n上述问题作为 Redis 的维护者当然也知道这一点，所以 Redis 从 2.8 版本开始提供了 SCAN 系列操作（包括 HSCAN，SSCAN 和 ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于 HGETALL、SMEMBERS 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻塞。\n第三，统计操作，是指集合类型对集合中所有元素个数的记录，例如 LLEN 和 SCARD。这类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作。\n第四，例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作。\n总结 在这篇博客，主要介绍了 Redis 的底层数据结构，这既包括了 Redis 中用来保存每个键和值的全局哈希表结构，也包括了支持集合类型实现的双向链表、压缩列表、整数数组、哈希表和跳表这五大底层结构。\nRedis 之所以能快速操作键值对，一方面是因为 O(1) 复杂度的哈希表被广泛使用，包括 String、Hash 和 Set，它们的操作复杂度基本由哈希表决定，另一方面，Sorted Set 也采用了时间复杂度为 O(logN) 的跳表。不过，集合类型的范围操作，因为要遍历底层数据结构，复杂度通常是 O(N)。所以我们可以使用其他命令来替代，例如可以使用 SCAN 来代替，避免 Redis 内部产生费时的全集合遍历操作。\n当然，我们也不能忘了复杂度较高的 List 类型，它的两种底层实现结构：双向链表和压缩列表的复杂度都是 O(N)。因此，我们可以根据实际情况灵活地使用 List 类型。例如，既然它的 POP/PUSH 效率很高，那么就将它主要用于 FIFO 队列场景，而不是作为一个可以随机读写的集合。\n至于整数数组和压缩列表虽然在查找时间复杂度方面并没有很大的优势，但这二者在底层都是非常紧凑的数据结构，要比链表占用的内存要更少，Redis 本身定位又是内存数据库，大量数据存到内存中，所以需要尽可能地优化，提高内存的利用率。\nRedis 数据类型丰富，每个类型的操作繁多，如果第一次接触是很难记住所有操作的复杂度。单正所谓万变不离其宗，只要我们掌握其原理，就可以做到以不变应万变叻。\n","description":"","tags":null,"title":"Redis01——数据结构篇","uri":"/tech/redis/redis01_datastructure/"},{"categories":null,"content":"新年快乐啊 回家 不知从何时起，我开始变得讨厌回家，甚至变得有些讨厌自己。现在的我也是这种感觉，我不知道为何要回家，家对我而言意味着什么。如果是从我个人角度，自私点来说，“家”有可能是负担。其实这个观点不止一次在我的 blog 中提到过，真的，我也不知为何会这样。为何会如此厌恶这个生我养我的地方，我感觉就像一片孤叶，不知该飘向哪里，也不知何时能落地。\n可能是这些年来大部分事情都是一个人自己做的，父母的文化程度不高，上了大学之后，很多事情都是自己做决定，拿主意。在大学毕业的时候，虽然谈不上多有钱，但经济上已经相对自由了。在决定踏入社会之前，也做了不少违背父母的决定。因为我知道，只有当真正步入社会的那一刻起，我才能真正实现独立。也就造就了现在的我。这应该属于很正常，但也很病态的一种情况。我也知道这不对，但我却越陷越深。\n其实，不想回家的念头，在前两年就已经有了。但无奈拗不过我爸妈，他们是每年都要回家的，。再加上自己的心比较软，想了想爷爷奶奶在我上了大学之后，一年到头见不了几面，所以最后都是“笑脸”回家的。其实后面这一点占据主要原因吧。可现在的我，逐渐对感情变得麻木，其中也包括亲情。就感觉如果以自己为中心，只要自己过得好，其他都无所谓的了。这和最初的我变化是相当大，所以我不愿回家，可能是不愿面对以前的自己，也想进一步切断与过去的一切联系。。。但执行起来却不太能够做到。\n今年过年，我是想出去玩的，至于去哪，我也没想好。今天晚上和爸妈沟通说我不太想回家的时候，能够感觉他们虽然嘴上说的是随我，但能看见内心是十分不开心。主要是我习惯了一个人的生活，想做什么自己去做就好，没人管我的时间。和他们在一起，就不得不按照他们的节奏来，很难受。还有就是老家的人情世故，我很讨厌，对于有些所谓的亲戚的嘴脸，我越来约厌恶，现在的我，指不定会直接怼上去，因为我是不太想继续维护这层虚假的关系的。过着不同的生活，干嘛随意指指点点别人的生活，仅仅是因为多活了几年。而我老家那边的人都喜欢托大，感觉自己作为长辈，所做的所说的都是对的。就很离谱。大概是这样的吧。\n和爸妈的通话结束，过了一会，我又打电话给爷爷奶奶，简单说了一点。想了想今年还是回去吧。就想上一篇博客中所说的那样，我会回老家看看烟火气。我不该拿我的习惯去要求家里人，由于被压榨为社畜，做很多事情都是以目的为导向，尽可能地去提高效率，节约时间。但家里人做事，讲究的是“大而全”，简单来说就是面面俱到，走一步看一步，不会有那么多明确的结果，所以有时和他们沟通就会觉得很烦，因为最后得不出一个结果，没有想要的结果，对于我而言就不知下一步该怎么做。诸如此类的情况有很多，我也想了很久。我不应该把工作或者编码的习惯带到生活中去的，他们可能更多的是感受时间，而我往往是赶时间，所以就说嘛，慢一点，也挺好。\nemmm，怎么说呢，回家感觉对于我来说，是牺牲我自己的生活，去照顾家里人的情绪。但亲情这根线终归是割不断的。我真的很矛盾，也很痛苦，随着成长，自己与“家”的隔阂越来越大，我不想每次都是舍我求全，但我也知道现如今的生活没有想象的那么好。。。。\n很喜欢《稻香》里面的歌词，“回家吧，回到最初的美好”。\n回家只想带 Switch，这个假期想好好在海拉鲁大陆过一段时间。但社畜的本性会让我背着电脑回家。。\n除夕随感 比较庆幸的是回去的路上没有堵车，而且回到老家的时候，在路上看见了雪，在杭州的冬天只感受到了寒冷，虽然天气预报显示有雪当一只没看见，也是挺可惜的吧。其实在老家的生活没有自己想的那么糟糕吧，虽然近一年的时间没有回去，当在家的时候和周围的邻居、事物好像并没啥距离感，大概就像是出了个远门，我又回来了吧，也许这就是“根”所在的地方吧。在老家，看见爷爷奶奶的精神状态还是挺好的，他俩算是村子里年龄比较大的了，当整体来看，身体各方面都是很不错的。\n回到老家，一切的生活都慢了下来，虽然只过了四五天，给人的感觉是好久好久，直到我踏上高铁站的时候，才会发现，其实也没多久，下一次回来不知是什么时候呢？与老家周围的人相比，我家的长辈们在心态和认知上也比我预想的要好，更多的一种放下吧，没了周围人的争强好胜。这一点也给他们点个赞👍 哈哈。就像我之前说过的一样，家人之间最重要的是相互信任。\n成年了之后，所选择的路是一个新的世界，家里人也不能给过多的参考建议，久而久之也就养成了报喜不报忧的习惯，很多事情都喜欢一个人默默承担，其实在家里会发现自己确实还是个孩子。所以说，什么才是成长呢？？\n今年的除夕整体的体验还是一般般，其实很简单，我在家不怎么合群。他们说谈论的张家长李家短，对于我而言是极其无聊的，如果说到了自己，也就简单应付一下。过年的习俗之一就是打麻将，这个我也是不感兴趣的，感觉脑子不够用，玩不来这么复杂的东西吧。放烟花之类的不能说无感了，只能说声音挺吵的，也就导致有点反感。春节之后也只去了大舅家拜年，大舅说话是个“爹味”很重的人，虽然出发点是好的，听起来也就那样吧。这一点我爸妈就比较好，很多时候会主动询问我的想法，父母与孩子之间算是比较平等的关系。\n在老家虽然生活节奏慢了，但是晚上还是不能早睡，习惯性的熬夜是个病，但不知该这么改，很烦。\n王国之泪 假期闲下来之后，就是白天可以看看书写写代码，然后晚上打游戏。《王国之泪》虽然是首发入的，当一直没能抽出整段的世界来玩，这个假期就是个不错的选择。其实当时的《旷野之息》买了之后一开始也没玩进去，也是后来买了大师模式 DLC 才好好开始认真玩的。两款都是好游戏，不过我更喜欢野炊。。\n王泪整个玩下来，给我的感觉是危机四伏，没啥安全感，特别是前期，猪猪怪都是成群结队的，还有铠甲，林克时间根本打不死怪，我就被一刀带走，也就这样难度起来了，才有意思的嘛。开始慢慢琢磨游戏的机制，预料建造也就利用了起来，还有就是探索地底下，主线都打完了，地底地图还没开完，探索的过程很压抑，野炊第一次玩给我的感觉是生机勃勃，一个新鲜的海拉鲁大陆等着我去探索，王泪则是我去拯救世界。王泪我最喜欢的应该是“龙之泪”的主线任务吧，可能是年纪大了见不得这种场面😭😭。做完龙之泪之后，就一直推主线了。最后一幕也还不错，是优秀的游戏。\n玩《塞尔达传说》系列最有意思的点就是，当玩家设定一个目标，想做的时候。一路上会随机看见很多风景，遇见一些很有意思的事情，比如看见一群猪猪的老窝，我就想怎么去把他们的老窝给掀了 哈哈哈，紧接着就会出现更多意想不到的事情，其实主线也没那么重要。对于玩家来说，淡化目标，好好去享受沿途的风景，也是一种不错的选择。\n读书 这个月读完了《我在北京送快递》和《黑客与画家》，两本书都还不错，但我更喜欢第二本，这也许和我自身的职业属性有关吧。\n我也不知读书到底有什么用，大抵是为了填充内心的空虚吧，当不想打游戏、不想写代码、不想练球的时候，就会随手拿起一本书来看，可能是技术相关，也可能是闲书。读的时候感觉有道理，很不错。读完过一段时间之后，诶，这本书说什么的来着，有点记忆但不多。而且在现在这个被碎片化充斥的世界，读书需要集中大量的注意力，也是一种考验吧。其实写代码、打游戏、练球也是需要集中注意力，我也就养成了一段时间只做一件事，做的过程中尽可能去享受。如果不想做，发发呆也是不错的。\n关于《我在北京送快递》这本书，作者的文化程度不高，整本书看似是一个打工人的自述，实际上可以从字里行间感受到对生活的理解。就好比书中提到的：\n所谓的自由，实际上在于你能意识到什么，而不在于你享有什么。\n这一点随着年龄的增长深有体会，现在的生活能够满足小时候的大部分愿望，却感觉不到小时候的快乐，也没有自由。当一个人的文化程度越高、阅历越深、思维和意识越复杂，所看到的自由也就越少。作者也给出了答案，他想说的自由，是一种简历在高度发展的自我意识上的个人追求和自我实现，是一个真正区别于另一个人的精神内容。\n完全为了谋生而工作，就和坐牢一样可悲，所以很少人声称自己是完全为谋生而工作的。\n结合《黑客与画家》简单谈谈我对于工作的理解吧。从我个人的角度，对于编程和技术算不上热爱、喜欢的那种程度，也不排斥，久而久之就变成生活的一部分，毕竟现实和虚拟已经逐渐融为一体。如果懂点技术，能够从程序员的视角理解这个世界也是不一样的体验，所以也逐渐接纳了技术，有时候还会主动去折腾一点好玩的。而这些放在工作上是比较无聊的，也许是我比较讨厌公司的氛围，讨厌各种条条框框的限制，如果没有限制，我能做的应该会更多。目前的我认为，搞技术是一门手艺活，遇见合适的公司业务，能够实践自己的技术也是一种享受，既体现了自己的价值，又能给公司带来收益。可现实往往事与愿违，在落地过程中，总会遇见一些阻碍。就很无语。其实也正常，工作中，每个人都有自己的利益链条，保证自己的那一环正常运行就可以，你自己转的快了，可能会影响他人。耗子叔在《左耳听风》里面强调，坚持做正确的事，这件事只要是对公司和自己来说是有益的，就要尽可能地贯彻下去，遇见阻力，就要灵活一点换一种方式去实现。其余的，交给时间吧。\n在《黑客与画家》这本书我是真的很喜欢，读这本书的过程中，让我仿佛看见了以后的自己是什么样子的。那就是成为一名真正的黑客。我一直也强调，编程是一件很 🆒 的事情，也是一种艺术，就如同画家、作曲家一样，当现如今的短平快的生产方式，将这项工作的性质定义为搬砖，这类人群定义为“码农”，我是比较讨厌这个称号的。因为编程对于我而言，更多的是创造。这本书前面还谈到了教育，也是深有同感，所谓的教育就是把孩子送进“监狱”，然后大人们可以有时间去维护社会的正常运行。现在的学校老师，我是抱着怀疑的态度，很多人都是为人师表想着捞钱，师德败坏的事情也是层出不穷。而且最糟糕的是为了自己的利益，有些老师甚至会误人子弟。但这类人群，还享受着极高的社会地位，我是不能理解的。这本书在后面还提到了关于财富的定义，让我又有了新的思考，可以好好想想如何去变现自己的技术。最后的章节就是提到了一些黑客的习惯，这个可以说是影响于无形之中吧。咱就坚持 KISS 和 DRY 原则，哈哈哈。\n更多书中的内容三言两语讲不太清，还是值得反复去看。\n回杭 快乐的时光总是短暂的，还是得好好工作，要不然怎么养活自己呢 是不是。。🥹\n杭州这座城市算是我经历过的可以排在第一梯队的，总体上还是比较喜欢的，工作也尽可能的追求 WLB。有自己的时间，才能去做更多有趣的事情。\n今年如果可以的话，想尝试走去自己的舒适圈，认识更多有趣的人，做更多好玩的事情 哈哈。\n二月还是挺短的，算是给自己放了个假，技术博客一篇没写就过去了。三月如果不忙的话，开始恢复更新。\n","description":"","tags":null,"title":"关于过年🧨","uri":"/life/24_02-home/"},{"categories":null,"content":"你好啊，2024～～ 不知不觉，公历就已经迈入 2024 了。但我们老家那边更喜欢按农历来计算日期，所以我从小就有个疑惑，在元旦之后，除夕之前的这段时间我到底该说自己几岁了呢？？🤔️ 这一点，现在的我倒不是很会困惑。随着自己慢慢长大，不知从何时起开始有了年龄焦虑。家里的长辈往往都喜欢按虚岁来计算年龄，无形当中就虚了一岁多。现在我更习惯于对外说自己的周岁，也就自然而然不会有上面的这个问题咯。\n不过，2024 又是一个自己的本命年。上一次还是上初一的时候，一转眼十二年过去了。读书这么多年，给我印象最深的也大抵是初中那三年。如果仅仅只是从结果来看，我的初中应该是失败的，原因很简单并没有考上理想的高中；但从过程中来看，我还是有收获的。初中养成的一些习惯一直保留到高中、大学，甚至是现在，初中也算是自己思想刚刚启蒙，虽然但是还很幼稚 哈哈。但也正是这样，有了现在的我。\n人生第一个十二年，算是最开心的阶段。没啥压力，按时上下学，作业完成就行，考试完全看状态。考好一点的话，回家更容易交差 嘿嘿。不过这么一想，小学占了六年，如果当时条件好一点，完全可以空出两年出去到处走走，看看世界。所谓的上学考试，有点浪费时间诶，说白了就是小镇做题家。第二个十二年，经历了初中、高中、大学，到现在刚刚出身社会。这一个阶段对我来说是成长最多的，相信大部分人也是如此。但成长意味着一边得到、一边又在失去。儿时一起玩耍的伙伴，现在见面又能说几句话呢？？所以说嘛，向前走，别回头，迎接下一个阶段的自己。\n当舅舅啦 这个月最开心的就是，就是二夕当舅舅啦。emmmm，感觉自己好老了，呜呜呜。当时姐姐怀孕的时候，我就和她说，如果是个女孩子就很不错，到时候长大了，打扮的漂漂亮亮，多好。如果是个臭小子的话，我就可以带他一起打游戏 哈哈。最后，确实是个女孩，很不错！\n作为舅舅的话，希望她以后能够开心点，能够多思考，有自己的想法，然后尽可能活出自己想要的样子。也希望她爸妈，别给她那么大的压力，更多的是尊重孩子的想法，小孩子贪玩是天性，可以从玩的过程中起到教育作用，还有就是沟通，平等地沟通。当然，作为长辈也要起到表率作用，做个好的榜样。\n这一点希望别学我，我最近几年的状态有点吊不琅珰的，对啥事都提不起心来。\n不过，我也很期待当你长大，作为舅舅的我会变成什么样子了呢🤔️\nFXXK Work 咱就是说，为什么要工作呢？？？？？\n二十出头，大好的青春年华，没有房贷、没有娃要养。日复一日地熬在工作上，值得吗？\n最近公司裁员，压力还是有点，临近过年，事情好多，突然就好倦怠。这个月发现自己长了根白头发，😭\n心真的好累。\n所谓的追求技术、个人成长，最后还是为了工作服务，那不如躺平？\n但还是想做点什么的，还是想有个自己的代表作的。。。\n坚持做正确的事吧✊\n抢票回家 一个人在外地习惯了，突然不想回家了。回到老家的生活方式和现在的完全是两个样子，适应了现在，就不太想回去了。而且回安徽的票好难抢呐。\n回家过年，现在哪还有年味，除夕都不放假叻。\n不知是不是自己长大了，突然觉得老家的人戾气好重，攀比心理极强，而且还有点虚伪。小时候在老家那种串门子的感觉回不来了，以前的村子也找不到了。。所以我也就不太想回去。今年回去的话，带本书，带个 Switch，应该就够了。不想带电脑回家了，给自己放个假吧。\n留不住的他乡，回不去的故乡。\n写在之后，虽然标题充满希望，但内容还是挺丧的，就这样吧，早点睡。\n","description":"","tags":null,"title":"你好，2024","uri":"/life/24_01-hello/"},{"categories":null,"content":"关于分布式事务你知道哪些？ 前言 我们还是从电商系统开始谈起，确实有点俗套，但从业务场景的角度考虑可以更好地解释一些概念。在我们平时网购的过程中，创建的每一笔订单，对于电商平台来说都会涉及到两个核心步骤：一是订单业务采取下订单操作，二是库存业务采取减库存操作。\n在实际的后台中，这两个业务通常会运行在不同的服务器上，甚至是运行在不同区域的服务器上，在 2024 年听见“异地多活”已经不是什么新鲜的概念了。但是对于同一笔订单，当且仅当订单操作和减库存操作一致时，才能保证交易的正确性。也就是说一笔订单，只有当上述两个操作都完成，才能算处理成功，否则就是处理失败。\n这个问题放在分布式领域，对应的就是分布式事务，下面就一起来详细了解一些关于事务的基础知识。\n从事务开始谈起 在深入分布式事务之前，我们先来重新回顾一下什么是事务。\n事务（Transaction）提供一种机制，将包含一系列操作的工作序列纳入到一个不可分割的执行单元。只有所有操作均被正确执行才能提交事务；任意一个操作失败都会导致整个事务回滚（Rollback）到之前状态，即所有操作均被取消。简单来说，事务提供了一种机制，使得工作要么全部都不做，要么完全被执行，简单概括就是 all or nothing。\n通常情况下，我们所指的事务都是本地事务，也就是运行在单机上的事务。这类事务也就具备 ACID 四大特性，其具体含义如下：\nA：原子性（Atomicity），事务被视为一个不可分割的原子操作，即事务最终的状态只有两种，全部执行成功和全部不执行，不会停留在中间某个环节。若处理事务的任何一项操作不成功，就会导致整个事务失败。一旦操作失败，所有操作都会被取消（即回滚），使得事务仿佛没有被执行过一样。就好比买一件商品，购买成功时，则给商家付了钱，商品到手；购买失败时，则商品在商家手中，消费者的钱也没花出去。 C：一致性（Consistency），是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。比如，用户 A 和用户 B 在银行分别有 200 元和 100 元，总共 300 元。用户 A 给用户 B 转账 100 元，分为两个步骤，从 A 的账户扣除 100 元和对 B 的账户增加 100 元。一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 100 元，用户 B 有 200 元，总共 300 元，而不会出现用户 A 扣除了 100 元，但用户 B 未增加的情况（该情况，用户 A 和 B 均为 100 元，总共 200 元）。 I：隔离性（Isolation），事务之间的操作应该相互隔离，一个事务的执行不应该受到其他事务的干扰。并发执行的多个事务应该产生与串行执行相同的结果，以避免数据不一致性和冲突。比如说，消费者购买商品这个事务，是不影响其他消费者购买的。 D：持久性（Durability），也被称为永久性，是指一个事务被执行后，那么它对数据库所做的更新就永久地保存下来了。即使发生系统崩溃或宕机等故障，重新启动数据库系统后，只要数据库能够重新被访问，那么一定能够将其恢复到事务完成时的状态。就像消费者在网站上的购买记录，即使换了一台设备，也依然可以查到。 只有在数据操作请求满足上述四个特性的条件下，存储系统才能保证处于正确的工作状态。因此，无论是在传统的集中式存储系统还是在分布式存储系统中，任何数据操作请求都必须满足 ACID 特性。\n那么分布式事务是什么呢？顾名思义，就是在分布式系统中运行的事务，由多个本地事务所组成。在分布式系统中，对于事务的处理要复杂的多，这些事务可能来自于不同的机器，不同的地区，或者不同的操作系统。开头所提到的电商处理订单问题，就是一个比较典型的分布式事务。\n分布式事务由多个事务组成，因此基本满足 ACID，其中的 C 是强一致性，也就是所有操作均执行成功，才提交最终结果，以保证数据一致性或完整性。但随着分布式系统规模不断扩大，复杂度急剧上升，达成强一致性所需时间周期较长，限定了复杂业务的处理。为了适应复杂业务，出现了 BASE 理论，该理论的一个关键点就是采用最终一致性代替强一致性。\n梳理清楚上述的基本概念之后，接下来就一起看看如何实现一个简单的分布式事务。\n实现分布式事务 在探讨如何实现分布式事务之前，我们要了解为什么要有分布式事务？实际上，分布式事务主要是解决在分布式环境下，组合事务的一致性问题。实现分布式事务有以下 3 种基本方法：\n基于 XA 协议的二阶段提交协议方法； 三阶段提交协议方法； 基于消息的最终一致性方法。 其中，基于 XA 协议的二阶段提交协议方法和三阶段提交协议方法，采用了强一致性，遵从 ACID。基于消息的最终一致性方法，采用了最终一致性，遵从 BASE 理论。\n基于 XA 协议的二阶段提交方法 XA 是一个分布式事务协议，规定了事务管理器和资源管理器接口，使得应用程序能够通过事务管理器来管理分布式环境下的多个资源，通常是数据库。由此可以看出，XA 协议主要包括事务管理器和本地资源管理器两个部分。\nXA 实现分布式事务的原理，比较类似于分布式互斥博客中所介绍的集中式算法：事务管理器相当于协调者，负责各个本地资源的提交和回滚；而资源管理器就是分布式事务的参与者，通常由数据库实现，比如 Oracle、DB2 等商业数据库都实现了 XA 接口。\n基于 XA 协议的二阶段提交方法中，二阶段提交协议（Two-phase Commit Protocol，2PC），用于保证分布式系统中事务提交时的数据一致性，是 XA 在全局事务中用于协调多个资源的机制。\n那么 2PC 是如何保证分布在不同节点上的分布式事务的一致性呢？为了做到这一点，会需要引入一个协调者来管理所有的节点，并确保这些节点能够正确提交操作结果，若提交失败则放弃事务。接下来，我们看看两阶段提交协议的具体过程。\n两阶段提交协议的执行过程，分为投票（Voting）和提交（Commit）两个阶段。\n首先，我们看一下第一阶段投票：在这一阶段，协调者（Coordinator，即事务管理器）会向事务的参与者，也就是本地资源管理器，发起执行操作的 CanCommit 请求，并等待参与者的响应。参与者接收到请求后，会执行请求中的事务操作，将操作信息记录到事务日志中但不提交，也就是暂时不会修改数据库中的数据，待参与者执行成功，则向协调者发送“Yes”消息，表示同意操作；若不成功，则发送“No”消息，表示终止操作。\n当所有的参与者都返回了操作结果（Yes 或 No 消息）后，系统进入了第二阶段提交阶段（也可以称为，执行阶段）。在提交阶段，协调者会根据所有参与者返回的信息向参与者发送 DoCommit（提交）或 DoAbort（取消）指令。具体规则如下：\n若协调者从参与者那里收到的都是“Yes”消息，则向参与者发送“DoCommit”消息。参与者收到“DoCommit”消息后，完成剩余的操作（比如修改数据库中的数据）并释放资源（整个事务过程中占用的资源），然后向协调者返回“HaveCommitted”消息； 若协调者从参与者收到的消息中包含“No”消息，则向所有参与者发送“DoAbort”消息。此时投票阶段发送“Yes”消息的参与者，则会根据之前执行操作时的事务日志对操作进行回滚，就好像没有执行过请求操作一样，然后所有参与者会向协调者发送“HaveCommitted”消息； 协调者接收到来自所有参与者的“HaveCommitted”消息后，就意味着整个事务结束了。 这么说可能比较抽象，接下来我们以一个具体的案例来进行讲解。假设用户 A 想要在某宝上购买 100 件 T 恤，这中间可能会涉及到很多的业务流程，但重点聚焦于下单和减少库存这两个操作。\n第一阶段：订单系统接收到来自于用户 A 的下单操作，会将与用户 A 有关的订单数据库锁住，准备好增加一条关于用户 A 购买 100 件 T 恤的信息，并将同意消息“Yes”回复给协调者。但库存系统由于 T 恤库存不足，出货失败，因此向协调者回复了一个终止消息“No”。\n第二阶段：由于库存系统操作不成功，因此，协调者就会向订单系统和库存系统发送“DoAbort”消息。订单系统接收到“DoAbort”消息后，将系统内的数据退回到没有用户 A 购买 100 件 T 恤的版本，并释放锁住的数据库资源。订单系统和库存系统完成操作后，向协调者发送“HaveCommitted”消息，表示完成了事务的撤销操作。\n至此，用户 A 购买 100 件 T 恤这一事务已经结束，用户 A 购买失败。\n由上述流程可以看出，二阶段提交的算法思路可以概括为：协调者向参与者下发请求事务操作，参与者接收到请求后，进行相关操作并将操作结果通知协调者，协调者根据所有参与者的反馈结果决定各参与者是要提交操作还是撤销操作。\n虽然基于 XA 的二阶段提交算法尽量保证了数据的强一致性，而且实现成本低，但依然有些不足。主要有以下三个问题：\n同步阻塞问题：二阶段提交算法在执行过程中，所有参与节点都是事务阻塞型的。也就是说，当本地资源管理器占有临界资源时，其他资源管理器如果要访问同一临界资源，会处于阻塞状态。因此，基于 XA 的二阶段提交协议不支持高并发场景。 单点故障问题：该算法类似于集中式算法，一旦事务管理器发生故障，整个系统都处于停滞状态。尤其是在提交阶段，一旦事务管理器发生故障，资源管理器会由于等待管理器的消息，而一直锁定事务资源，导致整个系统被阻塞。 数据不一致问题：在提交阶段，当协调者向所有参与者发送“DoCommit”请求时，如果发生了局部网络异常，或者在发送提交请求的过程中协调者发生了故障，就会导致只有一部分参与者接收到了提交请求并执行提交操作，但其他未接到提交请求的那部分参与者则无法执行事务提交。于是整个分布式系统便出现了数据不一致的问题。 三阶段提交方法 三阶段提交协议（Three-phase Commit Protocol，3PC），是对二阶段提交（2PC）的改进。为了更好地处理两阶段提交的同步阻塞和数据不一致问题，三阶段提交引入了超时机制和准备阶段。\n与 2PC 只是在协调者引入超时机制不同，3PC 同时在协调者和参与者中引入了超时机制。如果协调者或参与者在规定的时间内没有接收到来自其他节点的响应，就会根据当前的状态选择提交或者终止整个事务，从而减少了整个集群的阻塞时间，在一定程度上减少或减弱了 2PC 中出现的同步阻塞问题。 在第一阶段和第二阶段中间引入了一个准备阶段，或者说把 2PC 的投票阶段一分为二，也就是在提交阶段之前，加入了一个预提交阶段。在预提交阶段尽可能排除一些不一致的情况，保证在最后提交之前各参与节点的状态是一致的。 于是，三阶段提交协议就有 CanCommit、PreCommit、DoCommit 三个阶段，下面我们来看一下这个三个阶段。\n第一，CanCommit 阶段 协调者向参与者发送请求操作，也就是 CanCommit 请求，询问参与者是否可以执行事务提交操作，然后等待参与者的响应；参与者收到 CanCommit 请求之后，回复 Yes，表示可以顺利执行事务；否则回复 No。\n3PC 的 CanCommit 阶段与 2PC 的 Voting 阶段相比：\n比较类似的点在于：协调者均需要向参与者发送请求操作（CanCommit 请求），询问参与者是否可以执行事务提交操作，然后等待参与者的响应。参与者收到 CanCommit 请求之后，回复 Yes，表示可以顺利执行事务；否则回复 No； 不同之处在于：2PC 中，在投票阶段，若参与者可以执行事务，会将操作信息记录到事务日志中但不提交，并返回结果给协调者。但在 3PC 中，在 CanCommit 阶段，参与者仅会判断是否可以顺利执行事务，并返回结果。而操作信息记录到事务日志，但不提交的操作由第二阶段预提交阶段执行 CanCommit 阶段不同节点之间的事务请求成功和失败的流程，如下所示：\n当协调者接收到所有参与者回复的消息后，进入预提交阶段，也就是 PreCommit 阶段。\n第二，PreCommit 阶段 协调者根据参与者的回复情况，来决定是否可以进行 PreCommit 操作。\n如果所有参与者回复的都是“Yes”，那么协调者就会执行事务的预执行； 协调者向参与者发送 PreCommit 请求，进入预提交阶段； 参与者接收到 PreCommit 请求后执行事务操作，并将 Undo 和 Redo 信息记录到事务日志中； 如果参与者成功执行了事务操作，则返回 ACK 响应，同时开始等待最终指令。 假如任何一个参与者向协调者发送了“No”消息，或者等待超时之后，协调者都没有收到参与者的响应，就执行中断事务的操作； 协调者会向所有参与者发送“Abort”消息； 参与者收到“Abort”消息之后，或超时后仍未收到协调者的消息，则会执行事务的中断操作。 预提交阶段，不同节点上事务执行成功和失败的流程，如下所示：\n预提交阶段保证了在最后提交阶段（DoCommit 阶段）之前所有参与者的状态是一致的。\n第三，DoCommit 阶段 DoCommit 阶段进行真正的事务提交，根据 PreCommit 阶段协调者发送的消息，进入执行提交阶段或事务中断阶段。\n执行提交阶段：\n若协调者接收到所有参与者发送的 Ack 响应，则向所有参与者发送 DoCommit 消息，开始执行阶段； 参与者接收到 DoCommit 消息之后，正式提交事务。完成事务提交之后，释放所有锁住的资源，并向协调者发送 Ack 响应； 协调者接收到所有参与者的 Ack 响应之后，完成事务。 事务中断阶段：\n协调者向所有参与者发送 Abort 请求； 参与者接收到 Abort 消息之后，利用其在 PreCommit 阶段记录的 Undo 信息执行事务的回滚操作，释放所有锁住的资源，并向协调者发送 Ack 消息； 协调者接接收到参与者反馈的 Ack 消息之后，执行事务的中断，并结束事务。 执行阶段不同节点上事务执行成功和失败、事务中断的流程，如下图所示：\n3PC 协议在协调者和参与者均引入了超时机制。即当参与者在预提交阶段向协调者发送 Ack 消息后，如果长时间没有得到协调者的响应，在默认情况下，参与者会自动将超时的事务进行提交，从而减少整个集群的阻塞时间，在一定程度上减少或减弱了 2PC 中出现的同步阻塞问题。\n但三阶段提交仍然存在数据不一致的情况，比如在 PreCommit 阶段，部分参与者已经接受到 ACK 消息进入执行阶段，但部分参与者与协调者网络不通，导致接收不到 ACK 消息，此时接收到 ACK 消息的参与者会执行任务，未接收到 ACK 消息且网络不通的参与者无法执行任务，最终导致数据不一致。\n基于消息的最终一致性方法 2PC 和 3PC 核心思想均是以集中式的方式实现分布式事务，这两种方法都存在两个共同的缺点，一是，同步执行，性能差；二是，数据不一致问题。为了解决这两种问题，通过分布式消息来确保事务最终一致性的方案便出现咯。\n最终一致性的思想就是：将需要分布式处理的事务通过消息或者日志的方式异步执行，消息或日志可以存到本地文件、数据库或消息队列中，再通过业务规则进行失败重试。这个案例，就是使用基于分布式消息的最终一致性方案解决了分布式事务的问题。\n基于分布式消息的最终一致性方案的事务处理，引入了一个消息中间件，用于在多个应用之间进行消息传递。比如可以采用 RocketMQ 机制来支持消息事务。\n基于消息中间件协调多个节点分布式事务执行操作的示意图，如下所示：\n仍然以网上购物为例。假设用户 A 在某电商平台下了一个订单，需要支付 50 元，发现自己的账户余额共 150 元，就使用余额支付，支付成功之后，订单状态修改为支付成功，然后通知仓库发货。\n在该事件中，涉及到了订单系统、支付系统、仓库系统，这三个系统是相互独立的应用，通过远程服务进行调用。\n根据基于分布式消息的最终一致性方案，用户 A 通过终端手机首先在订单系统上操作，通过消息队列完成整个购物流程。然后整个购物的流程如下所示。\n订单系统把订单消息发给消息中间件，消息状态标记为“待确认”； 消息中间件收到消息后，进行消息持久化操作，即在消息存储系统中新增一条状态为“待发送”的消息； 消息中间件返回消息持久化结果（成功 / 失败），订单系统根据返回结果判断如何进行业务操作。失败，放弃订单，结束（必要时向上层返回失败结果）；成功，则创建订单； 订单操作完成后，把操作结果（成功 / 失败）发送给消息中间件； 消息中间件收到业务操作结果后，根据结果进行处理：失败，删除消息存储中的消息，结束；成功，则更新消息存储中的消息状态为“待发送（可发送）”，并执行消息投递； 如果消息状态为“可发送”，则 MQ 会将消息发送给支付系统，表示已经创建好订单，需要对订单进行支付。支付系统也按照上述方式进行订单支付操作； 订单系统支付完成后，会将支付消息返回给消息中间件，中间件将消息传送给订单系统。若支付失败，则订单操作失败，订单系统回滚到上一个状态，MQ 中相关消息将被删除；若支付成功，则订单系统再调用库存系统，进行出货操作，操作流程与支付系统类似； 在上述过程中，可能会产生如下异常情况，其对应的解决方案为：\n订单消息未成功存储到 MQ 中，则订单系统不执行任何操作，数据保持一致； MQ 成功将消息发送给支付系统（或仓库系统），但是支付系统（或仓库系统）操作成功的 ACK 消息回传失败（由于通信方面的原因），导致订单系统与支付系统（或仓库系统）数据不一致，此时 MQ 会确认各系统的操作结果，删除相关消息，支付系统（或仓库系统）操作回滚，使得各系统数据保持一致； MQ 成功将消息发送给支付系统（或仓库系统），但是支付系统（或仓库系统）操作成功的 ACK 消息回传成功，订单系统操作后的最终结果（成功或失败）未能成功发送给 MQ，此时各系统数据可能不一致，MQ 也需确认各系统的操作结果，若数据一致，则更新消息；若不一致，则回滚操作、删除消息。 基于分布式消息的最终一致性方案采用消息传递机制，并使用异步通信的方式，避免了通信阻塞，从而增加系统的吞吐量。同时，这种方案还可以屏蔽不同系统的协议规范，使其可以直接交互。\n在不需要请求立即返回结果的场景下，这些特性就带来了明显的通信优势，并且通过引入消息中间件，实现了消息生成方（如上述的订单系统）本地事务和消息发送的原子性，采用最终一致性的方式，只需保证数据最终一致即可，一定程度上解决了二阶段和三阶段方法要保证强一致性而在某些情况导致的数据不一致问题。\n可以看出，分布式事务中，当且仅当所有的事务均成功时整个流程才成功。所以，分布式事务的一致性是实现分布式事务的关键问题，目前来看还没有一种很简单、完美的方案可以应对所有场景。\n总结 本节内容从事务的 ACID 特性出发，介绍了分布式事务的概念、特征，以及如何实现分布式事务。在关于如何实现分布式的部分，以网购为例，介绍了常见的三种实现方式，即基于 XA 协议的二阶段提交方法，三阶段方法以及基于分布式消息的最终一致性方法。\n二阶段和三阶段方法是维护强一致性的算法，它们针对刚性事务，实现的是事务的 ACID 特性。而基于分布式消息的最终一致性方案更适用于大规模分布式系统，它维护的是事务的最终一致性，遵循的是 BASE 理论，因此适用于柔性事务。\n在分布式系统的设计与实现中，分布式事务是不可或缺的一部分。可以说，没有实现分布式事务的分布式系统，不是一个完整的分布式系统。分布式事务的实现过程看似复杂，但将方法分解剖析后，就会发现分布式事务的实现是有章可循的。\n扩展：BASE 理论 在最后咱扩展一点关于 BASE 理论的基础知识。BASE 理论包括基本可用（Basically Available）、柔性状态（Soft State）和最终一致性（Eventual Consistency）。\n基本可用：分布式系统出现故障的时候，允许损失一部分功能的可用性，保证核心功能可用。比如，某些电商 618 大促的时候，会对一些非核心链路的功能进行降级处理。 柔性状态：在柔性事务中，允许系统存在中间状态，且这个中间状态不会影响系统整体可用性。比如，数据库读写分离，写库同步到读库（主库同步到从库）会有一个延时，其实就是一种柔性状态。 最终一致性：事务在操作过程中可能会由于同步延迟等问题导致不一致，但最终状态下，所有数据都是一致的。 BASE 理论为了支持大型分布式系统，通过牺牲强一致性，保证最终一致性，来获得高可用性，是对 ACID 原则的弱化。ACID 与 BASE 是对一致性和可用性的权衡所产生的不同结果，但二者都保证了数据的持久性。ACID 选择了强一致性而放弃了系统的可用性。与 ACID 原则不同的是，BASE 理论保证了系统的可用性，允许数据在一段时间内可以不一致，最终达到一致状态即可，也即牺牲了部分的数据一致性，选择了最终一致性。\n具体到今天的三种分布式事务实现方式，二阶段提交、三阶段提交方法，遵循的是 ACID 原则，而消息最终一致性方案遵循的就是 BASE 理论。\n","description":"","tags":null,"title":"分布式 006——事务","uri":"/tech/distributedsystem/ds006_transaction/"},{"categories":null,"content":"重新认识分布式锁 前言 在分布式系列的第三篇博客中，简单探讨了有关“分布式互斥”的相关知识，也从中领悟了”有你没我，有我没你“的设计精髓。分布式互斥算法主要是为了解决同一临界资源同一时刻只能被一个程序访问的问题。\n如果进一步思考可以发现，在之前介绍的算法中，主要讲了如何协调多个进程获取权限和根据权限有序访问共享资源，“获得访问权限的进程可以访问共享资源，其他进程必须等待拥有该权限的进程释放权限”。但是，并没有介绍在访问共享资源时，这个权限是如何设置或产生的，以及设置或产生这个权限的工作原理是什么。\n那么，就带着好奇心，一起来看看分布式锁是如何解决这个问题的。\n分布式锁的用途 首先，我们需要重新认识一下什么是“锁”。\n在单机系统中，经常会有多个线程访问同一种资源的情况，按照习惯，我们把这样的资源叫作共享资源，或者临界资源。为了维护线程操作的有效性和正确性，自然而就需要某种机制来减少低效率的操作，避免同时对相同的数据进行不一样的操作，要维护数据的一致性，防止数据脏读和数据丢失等。也就是说，我们需要一种互斥机制，按照某种规则对多个线程进行排队，依次、互不干扰地访问共享资源。\n这个机制指的是，为了实现分布式互斥，在某个地方做标记，这个标记每个线程都能看到，到标记不存在时可以设置该标记，当标记被设置后，其他线程只能等待拥有该标记的线程执行完成，并释放该标记后，才能去设置该标记和访问共享资源。这个标记也就是我们常常说的锁。\n简单来说，锁是多线程同时访问同一资源的场景下，为了让线程互不干扰地访问共享资源，从而保证操作的有效性和正确性的一种标记。\n与普通锁不同的是，分布式锁是指分布式环境下，系统部署在多个机器中，实现多进程分布式互斥的一种锁。为了保证多个进程能看到锁，锁被存在公共存储（比如 Redis、Memcached 等三方存储中），以实现多个进程并发访问同一共享资源，同一时刻只有一个进程可以访问共享资源，确保数据的一致性。\n哪些场景下需要使用分布式锁呢？\n比如，现在某电商网站正在售卖 NewBalacne 990V4（以下简称 ”990V4“），库存当前只有 2 双，但有 5 个来自不同地区的用户 {A, B, C, D, E} 几乎同时下单，那么这 2 双鞋子会花落谁家呢？\n这时，如果习惯于 CRUD 的开发者可能下意识会想到，这还不是小菜一碟，谁先提交订单请求，谁就购买成功呗。但实际业务中，为了高并发地接受大量用户订单请求，很少有电商网站真正实施那么简单的措施。\n有时候我们在思考问题的时候，多反问自己几个为什么，出于经验主义，很多时候第一反应都是需要打磨的。\n回到正题，对于订单的优先级，不同电商网站可能会采取不同的策略，比如有些电商根据下单时间判断谁可以购买成功，而有些会更偏向于付款时间来做出判断。但，无论采用什么样的规则去判断哪个用户可以下单成功，都必须要保证 990V4 在售出时，数据库中更新的库存是正确的。为了便于理解，我们以下单时间作为购买成功的判断依据。\n经过上面的提示，我们能想到最简单的方案就是，给 990V4 加一个锁。当有一个用户提交订单之后，后台服务器给库存数量加一个锁，根据该用户的订单修改库存。而其他用户则必须等到锁释放以后，才能重新获取库存数，继续购买。\n所以在当前这个案例中 990V4 的库存就是共享资源，不同的购买者对应着多个进程，后台服务器对共享资源加的锁就是告诉其他进程：“现在是我说了算，你们靠边站！”\n但问题就这么简单的解决了嘛？答案是否定的，继续往下分析。\n想象一下，用户 A 想买 1 双 990V4，用户 B 想买两双 990V4。在理想状态下，用户 A 网络质量稳定，率先下单买走了一双，这个时候库存也就还剩一双。此时应该提示用户 B 库存不足，用户 B 购买失败。但实际情况是，用户 A 和用户 B 同时获取到商品库存还剩 2 双，用户 A 买走 1 双，在用户 A 更新库存之前，用户 B 又买走了 2 双，此时用户 B 更新库存，商品还剩 0 双。这时，电商卖家就头大了，总共 2 双 990V4，却卖出去了 3 双。\n不难看出，如果只使用单机锁将会出现不可预知的后果。因此，在高并发场景下，为了保证临界资源同一时间只能被一个进程使用，从而确保数据的一致性，我们就需要引入分布式锁了。\n此外，在大规模分布式系统中，单个机器的线程锁无法管控多个机器对同一资源的访问，这时使用分布式锁，就可以把整个集群当作一个应用一样去处理，实用性和扩展性也就更好。\n分布式锁的三种实现方法 接下来，我带你看看实现分布式锁的 3 种主流方法，即：\n基于数据库实现分布式锁，这里的数据库指的是关系型数据库； 基于缓存实现分布式锁； 基于 ZooKeeper 实现分布式锁。 数据库实现分布式锁 实现分布式锁最直接的方式可以通过数据库进行实现，首先创建一张表用于记录共享资源信息，然后通过操作该表的数据来实现共享资源信息的修改。\n当我们要锁住某个资源时，就在该表中增加一条记录，想要释放锁的时候就删除这条记录。数据库对共享资源做了唯一性约束，如果有多个请求被同时提交到数据库的话，数据库会保证只有一个操作可以成功，操作成功的那个线程就获得了访问共享资源的锁，可以进行操作。\n基于数据库实现的分布式锁，是最容易理解的。但是，因为数据库需要落到硬盘上，频繁读取数据库会导致 IO 开销大，因此这种分布式锁适用于并发量低，对性能要求低的场景。对于电商系统双 11、双 12 等需求量激增的场景，数据库锁是无法满足其性能要求的。而在平日的购物中，我们可以在局部场景中使用数据库锁实现对资源的互斥访问。\n下面，我们还是以电商售卖 990V4 的场景为例。鞋子库存是 2 双，有 3 个来自不同地区的用户 {A, B, C} 想要购买，其中用户 A 想买 1 双，用户 B 想买 2 双，用户 C 想买 1 双。用户 A 和用户 B 几乎同时下单，但用户 A 的下单请求最先到达服务器。\n因此，该商家的产品数据库中增加了一条关于用户 A 的记录，用户 A 获得了锁，他的订单请求被处理，服务器修改 990V4 库存数，减去 1 后还剩下 1 双。当用户 A 的订单请求处理完成后，有关用户 A 的记录被删除，服务器开始处理用户 B 的订单请求。这时，库存只有 1 双了，无法满足用户 B 的订单需求，因此用户 B 购买失败。从数据库中，删除用户 B 的记录，服务器开始处理用户 C 的订单请求，库存中 1 双鞋子，刚好满足用户 C 的订单需求。所以，数据库中增加了一条关于用户 C 的记录，用户 C 获得了锁，他的订单请求被处理，服务器修改 990V4 数量，减去 1 后还剩下 0 双。\n可以看出，基于数据库实现分布式锁比较简单，关键在于创建一张锁表，为申请者在锁表里建立一条记录，记录建立成功则获得锁，消除记录则释放锁。该方法依赖于数据库，主要有两个缺点：\n单点故障问题：一旦数据库不可用，会导致整个系统崩溃。 死锁问题：数据库锁没有失效时间，未获得锁的进程只能一直等待已获得锁的进程主动释放锁。倘若已获得共享资源访问权限的进程突然挂掉、或者解锁操作失败，使得锁记录一直存在数据库中，无法被删除，而其他进程也无法获得锁，从而产生死锁现象。 缓存实现分布式锁 刚才说到，数据库的性能限制了业务的并发量，那么对于 6·18、双十一等需求量激增的场景是否有解决办法呢？\n这个时候，基于缓存实现分布式锁的方式，非常适合解决这种场景下的问题。所谓基于缓存，也就是说把数据存放在计算机的内存中，不需要写入磁盘，从而减少了 IO 带来的资源损耗。接下来，就以 Redis 为例展开这部分内容。\nRedis 通常可以使用 setnx(key, value) 函数来实现分布式锁。key 和 value 就是基于缓存的分布式锁的两个属性，其中 key 表示锁 id，value = currentTime + timeOut，表示当前时间 + 超时时间。也就是说，某个进程获得 key 这把锁后，如果在 value 的时间内未释放锁，系统就会主动释放锁。\nsetnx 函数的返回值有 0 和 1：\n返回 1，说明该服务器获得锁，setnx 将 key 对应的 value 设置为当前时间 + 锁的有效时间； 返回 0，说明其他服务器已经获得了锁，进程不能进入临界区。该服务器可以不断尝试 setnx 操作，以获得锁。 我们还是以电商售卖 990V4 的场景为例，来说明基于缓存实现的分布式锁，假设现在库存数量是足够的。\n用户 A 的请求因为网速快，最先到达 Server2，setnx 操作返回 1，并获取到购买鞋子的锁；用户 B 和用户 C 的请求，几乎同时到达了 Server1 和 Server3，但因为这时 Server2 获取到了 990V4 数据的锁，所以只能加入等待队列。\nServer2 获取到锁后，负责管理 990V4 的服务器执行业务逻辑，只用了 1s 就完成了订单。订单请求完成后，删除锁的 key，从而释放锁。此时，排在第一顺位的 Server1 获得了锁，可以访问鞋子的数据资源。但不巧的是，Server1 在完成订单后发生了故障，无法主动释放锁。\n于是，排在第三顺位的 Server3 只能等设定的有效时间（比如 10 分钟）到期，锁自动释放后，才能访问鞋子的数据资源，也就是说用户 C 只能到 00:10:01 以后才能继续抢购。\n总结来说，Redis 通过队列来维持进程访问共享资源的先后顺序。\nRedis 锁主要基于 setnx 函数实现分布式锁，当进程通过 setnx 函数返回 1 时，表示已经获得锁。排在后面的进程只能等待前面的进程主动释放锁，或者等到时间超时才能获得锁。\n相对于基于数据库实现分布式锁的方案来说，基于缓存实现的分布式锁的优势表现在以下几个方面：\n性能更好。数据被存放在内存，而不是磁盘，避免了频繁的 IO 操作。很多缓存可以跨集群部署，避免了单点故障问题。 使用方便。很多缓存服务都提供了可以用来实现分布式锁的方法，比如 Redis 的 setnx 和 delete 方法等。 可以直接设置超时时间（例如 expire key timeout）来控制锁的释放，因为这些缓存服务器一般支持自动删除过期数据。 这个方案的不足是，通过超时时间来控制锁的失效时间，并不是十分靠谱，因为一个进程执行时间可能比较长，或受系统进程做内存回收等影响，导致时间超时，从而不正确地释放了锁。\n为了解决基于缓存实现的分布式锁的这些问题，我们再来看看基于 ZooKeeper 实现的分布式锁吧。\nZookeeper 实现分布式锁 ZooKeeper 是基于树形数据存储结构实现分布式锁，来解决多个进程同事访问同一临界资源时，数据的一致性问题。ZooKeeper 的树形数据存储结构主要由 4 种节点构成：\n持久节点（PERSISTENT），这是默认的节点类型，一直存在于 ZooKeeper 中。\n持久顺序节点（PERSISTENT_SEQUENTIAL），在创建节点时，ZooKeeper 根据节点创建的时间顺序对节点进行编号命名。\n临时节点（EPHEMERAL），当客户端与 ZooKeeper 连接时临时创建的节点，与持久节点不同，当客户端与 ZooKeeper 断开连接后，该进程创建的临时节点会被删除。\n临时顺序节点（EPHEMERAL_SEQUENTIAL）。就是按时间顺序编号的临时节点。\n根据上述节点的特征，ZooKeeper 基于临时顺序节点实现了分布式锁。\n还是以电商售卖 990 V4 为例，假设用户 A、B、C 同时在 11 月 11 日的零点整提交了购买鞋子的请求，ZooKeeper 会采用如下方法来实现分布式锁：\n在与该方法对应的持久节点 shared_lock 的目录下，为每个进程创建一个临时顺序节点。如下图所示，990 V4 就是一个拥有 shared_lock 的目录，当有人买鞋子的时候，会为他创建一个临时顺序节点。\n每个进程获取 shared_lock 目录下的所有临时节点列表，注册 Watcher，用于监听子节点变更的信息。当监听到自己的临时节点是顺序最小的，则可以使用共享资源。\n每个节点确定自己的编号是否是 shared_lock 下所有子节点中最小的，若最小，则获得锁。例如，用户 A 的订单最先到服务器，因此创建了编号为 1 的临时顺序节点 LockNode1。该节点的编号是持久节点目录下最小的，因此获取到分布式锁，可以访问临界资源，从而可以购买鞋子。\n若本进程对应的临时节点编号不是最小的，则分为两种情况：\n本进程为读请求，如果比自己序号小的节点中有写请求，则等待； 本进程为写请求，如果比自己序号小的节点中有请求，则等待。 例如，用户 B 也想要购买 990 V4，但在他之前，用户 C 想看看鞋子的库存量。因此，用户 B 只能等用户 A 买完吹风机、用户 C 查询完库存量后，才能下单购买。\n根据上面的流程，我们可以看出，使用 ZooKeeper 实现的分布式锁，可以解决前两种方法提到的各种问题，比如单点故障、不可重入、死锁等问题。但该方法实现比较复杂，且需要频繁地添加和删除节点，所以性能可能不如基于缓存实现的分布式锁。\n小结 ","description":"","tags":null,"title":"分布式 005——锁","uri":"/tech/distributedsystem/ds005_lock/"},{"categories":null,"content":"关于 2023 我想说.. 今天是 2023-12-01，还有 30 天来想想这一年做了些哪些有趣的事情🤔️..\nemmmm，比较好笑的是写完上面的话，再次继续往下已经是二十多号了。但在中下旬就一直在想今年该写点啥呢？？建立 blog 以来，几乎每年都会写点什么，但是去年什么都没写，就是一张“白纸”，其实在某种程度上，不记录就是对去年最好的表达。那么今年呢？\n回顾前三年，也因为😷原因，不断经历了起起落落，经历过痛苦、希望、向阳、挣扎、失落、质疑，也有了现如今的我。不能站在现在的角度去评估那三年，也正是一个个小阶段的历练，才能一步步走下去吧。我一直主张人的一生从长远来看，最终有一个属于自己的归属，或坏或好，这中间的所有，都是某个阶段的自己，都将会过去，能做到的就是看开点，过好每一天呗。如果再读一遍，会发现其实这是一句废话 hhhhh。\n此外，不知从何时起，我开始担心自己会有白头发，可能看见同龄人以及周围的上班族年纪轻轻都有，就会有点怕。不过值得庆幸的是，我既没有秃头也没有白头发，所谓程序员秃头只是个段子罢了。今年也确实能够感觉到自己的身体大不如大学那几年，经常会的头疼脑热感冒之类的，也许是去年新冠的后遗症吧。也就这样在下半年开始了健身，emmm 去除“班味”也挺好的。\n简单来说，就是珍惜现在，活在当下。我喜欢用文字去记录自己的每个阶段，同样也相信文字的力量。当自己回过头来看的时候，应该会欣然一笑，也会为当时的自己感到骄傲吧。熟悉我的朋友，都知道我一直想当的是一个作家，可惜自己书读的太少，经历也不够丰富，写出的东西自然也就一般。也许是迫于无奈走上了写代码的道路吧。。但比较庆幸的是自己还不怎么讨厌。所以我选择尽量每一个月写一遍有关生活的博客，可能是一些日常生活的闲言碎语，也可能是最近做的事情、最近正在看的书、最近喜欢上的歌、最近入迷的游戏，如果还有自己对于当下的一点点思考，那就再好不过了。\n下面开始正文：\n发生了哪些事儿？ 先简单了罗列一下今年发生了哪些事情吧。\n阳了之后，终于能把口罩摘下咯，可身体素质大不如从前。。 捡起吃灰的《塞尔达：旷野之息》，果然是天！ 上半年去了一趟青岛，挺喜欢这个城市的建筑风格，让人值得回味，甚至好几次做梦都梦见了。应该会再去的吧～～ 大政来到杭州，开始正式工作啦，不要违背自己，做正确的事，继续打怪升级！ 姐姐今年结婚了，而且我马上也要当舅舅啦，哈哈～～ 体验了第一次出差，飞到了三亚，见识了另一种风土人情，也挺有意思的。 《怪猎猎人崛起：曙光》终盘更新，可惜有点烂尾，更新之后也没好好玩。 开始意识到基础知识的重要性，开始恶补。。出来混，总归是要还债的。 决定开始尝试 Rust，并参与了线下的技术讨论，用蹩脚的英文和国外的开发者沟通，5555😭 作为观众参与了 2023CYML，临近比赛前一周腱鞘炎也没谁了。。 线下音乐节听了许嵩的《有何不可》，听完眼眶有点湿哒哒的。 第一次看演唱会《张韶涵 寓言·杭州站》，是小时候磁带里面的声音～～ 组装了人生第一台海景房，今年上半年没买 4090 真的是亏麻了。。 听安溥，一起跨年～～✌️有时候错过也是一种缘分、（12.28 收到短信，因为不可抗力被取消了。。。） 一场新的抉择 在今年上半年我一直在思考自己想要的究竟是什么？面对抉择，该如何坚定自己的想法！不破不立，之前初三的时候很喜欢的一首歌的歌词里有写到“我曾经毁了我的一切，只想永远地离开”。我能做的也只是这样，在人工智能新的革命到来之际，我放弃了稳妥的选择，直接跳入这场浪潮之中。于是，我给自己放了三个月假，这三个月可以什么都做，也可以什么都不做，尽可能没有预期的浪费，当时间节点到了，那就该做点什么了。\n最后的选择，当个杭漂。杭州这个城市至少是我目前比较喜欢的城市，之前来过两次，那也是两个阶段的自己。第一次来杭州，是带着一点点不自信却对世界充满好奇，再一次就是认为自己有探索世界的能力，去尽情地享受拥抱新的事物。而今年大抵是，要不先这样吧。有点垂头下气呢。但也许这就是生活吧。当决定来到一个新的城市的时候，就会发现自己逐渐没有了根，我不知该往哪去。这可能就是“留不住的他乡，回不去的故乡”。\n说到故乡，就会觉得自己作为一个晚辈是不合格的，除了自己的爸爸妈妈和在老家的爷爷奶奶，其余的亲戚我都不太想联系。在我看来那是来自父母那一辈的关系网，是我出生所无法选择的。而我比较可悲的是多读了几年书，导致和他们观念上的冲突，包括我爸妈。这也是我选择一个来到陌生的城市的原因。我想尽可能的走远，斩断这一切。因为我想更好地活出自己的样子。他们没有错，我的观念在我看来也是再正常不过，但矛盾的是这个世界。我们这辈人往上数两三代，自己的长辈大都是农民出身。自古以来，农业社会主张的就是安稳，所以他们想的也就是尽可能早的结婚生子，如此反复一代一代。但这些在我看来都不是必选项，我不想要孩子（现在的想法，希望能保持下去），还恐婚，我已经不期望爱情，如果为了生活，勉强和一个不太喜欢的人在一起，我应该做不到的吧。这些观点，在他们看来就是大逆不道，经常会说我“读书读傻了”，随他们吧。今年过年又要斗智斗勇，我可没啥好怕的。至少我这个年龄做了他们孩子做不到的事情嘛。\n所以，这场抉择才刚刚开始，我希望 2024 还能继续坚定不移地走下去！\n游戏篇 原以为今年没给游戏投入太多的时间，但仔细想想玩了也不少游戏。\n首先是《女神异闻录 5：皇家版》，重新体验了一下高中生活。不愧是天下第一的游戏，整个游戏的画风也很喜欢，一整个爱住。第一章的鸭志田篇就给我惊到了，这真的是游戏里面可以说的嚒？要是放在国内，恐怖连上架的机会都没有吧。后面也是对社会的各种讽刺。但这款游戏的缺点也很明显，玩 RPG 类的游戏，我一般更注重主线的推进，所以就导致周可儿的雷达图点不满，很多有意思的场景解锁不了。。还有就是到后期，宫殿一个比一个复杂，加上自己有点路痴属性，会经常迷路。呜呜呜。玩这款游戏的时候，让我对日本的文化充满了好奇，就在想如果可以的话，想在日本的街头走一走，看一看外面的世界。游戏大约玩了 120h+，好像到了五月底六月初才完结。时间跨度也是够长的。\n《十三机兵防卫圈》终于打折了！！！等了好久好久，加上之前很多游戏博主都说移植在 Switch 上属于神优化，就毫不犹豫地入了，二十多个，花了半个月的时间，一口气打完。碎片化的叙述方式真的很棒！当时完结之后，第一想法就是快点失忆再玩一遍，不过现在回想起剧情，好像记不太清了，hhhh 不知道是好是坏呢，那就抽时间再来一遍哈～～谁能拒绝高中生开机甲拯救世界呢。\n《双人成行》大学同学在我的忽悠下也入了 Switch，然后我再一次通关了《双人成行》！最好的双人游戏没有之一，这一次是换了角色进行尝试的，也是船新的体验。不过和男生玩感觉怪怪的。。而且那个大裤衩飞机是真难开。\n《塞尔达传说》是天！！！虽然去年用任亏券换了旷野之息，但一直没有好好体验，就想着今年王国之泪发售，一起玩了吧。其实还有一部分原因是因为当时大师模式打折，又花了 100 块钱入了。就想着又砸钱了，不如岂不是很可惜。就这样重新踏上了海拉鲁大陆。关于这款游戏，不想多说任何评价。她就像家一样温暖，而且每次打开都会有新的发现。就我个人而言更喜欢野炊多一点。有时候晚上失眠，睡不着觉，就会打开 Switch，在海拉鲁走一走逛一逛，远远的听见驿站的 bgm，都会倍感亲切，宛如漂浮不定的心，找到了属于自己的港湾。\n《怪物猎人崛起：曙光》时隔一年多，终于引来了最终弹的更新。但随之而来的多多少少有点失望吧，不是说不好玩，但就真的觉得少了点什么。全部更新完之后，之前一起打猎的朋友也就许久没怎么上线了。四人一起狩猎也很难凑齐。今年重新开始玩怪猎，开始尝试接受新的武器，不再是斩斧一根筋咯。但曙光后期有点数值崩坏。游戏配装多多少少有点答辩，于是也就转了 PC。关于怪猎这款游戏又太多可以聊的了，对于我而言是值得写一篇博客来专门记录的。\n《异度神剑 2》很王道很热血很中二。去年玩 xb3 给我的感觉还不错，于是另一张任亏券就留给了 xb2。这款游戏优缺点很明显，先说缺点吧：地图糊，容易迷路，战斗系统上手存在门槛，支线太多了。除去这些全是优点，如果对胃口的话。剧情整体上更紧凑，美中不足的是当时雷克斯在焰被抓走之后，突然就放弃了。有点突兀，太生硬了。xb2 的 bgm 也很好听，最近一直在列表里循环。DLC 的内容也棒，可以直接给满分的。但是为了推主线，不得不做支线很痛苦。中间好几次想弃坑，好在有强迫症迫使自己坚持下来了。玩到最后，会发现做支线也是值得的，因为为了人和之力，已经无形中和伊拉的人民产生了羁绊。在玩黄金之国之前就已经料到了会有刀，最后结束的时候结果是大刀，太难受了。如果我是真，我会怎么做呢？\n抛出上面这些，还有很多游戏没有玩，比如《怪猎 GU》、《马里奥惊奇》、《马里奥制造 2》、《斯普拉顿》、《奥日》。唉 为什么买了游戏还要花时间啊 呜呜呜呜。\n今年考虑再三决定组了一台主机，可以是为了玩游戏，也可以是为了别的更有趣的事情。当时纠结 PS5 和 PC 哪个更适合自己。看见怪猎的下一作会直接上线 PC，也就没什么好犹豫的了。\n《霍格沃滋之遗》、《荒野大镖客 2》、《尼尔机械纪元》、《怪物猎人》系列，唉，好多游戏没玩。。。\n虽然为了玩游戏特地组装了一台主机，性能、画面与 Switch 相比都要更好，但是 Switch 的最大特点就是掌机，也是目前唯一一个合格的掌机。冬天在暖暖的被窝里玩游戏真的是太棒叻！也比较期待 NS2 吧。\n24 年希望能够抽多一点时间来玩游戏吧。\n书和音乐 好像从去年开始，对于闲书的阅读量突然就减少了，取而代之的更多是技术相关的书籍。今年八月有一次和同事们一起逛书店，才发现越来自己已经那么久没好好读过书了，也不知道自己想读什么类型的书籍了。以前逛书店的时候，给我的感觉是书能带着我去发现更多的书籍，现在这种感觉似乎找不回来了。痛定思痛，开始好好读写，多读好书，多读闲书。\n今年比较有成就感的一件事就是把《冰与火之歌》原著给啃完了，马丁老爷子长命百岁，还等着第六卷呢！当时密密麻麻的英文看着是真难受，还有很多的俚语在其中，读起来压力还是挺大的。最近《权利的游戏》上架 B 站了，而且还是 4K 画质，虽然阉割了很多，有时间的话还是想重温一遍的。\n今年的最后两个多月，我把《毛选》前四卷给读完了，因为目前市场上能买的版本只有这四卷了。如果把革命当作一个产品，毛他老人家则是最强的产品经理。更重要的是人心！不得不佩服毛当时的思想和格局。\n出于对道哥人格魅力的崇拜，买了他的新书《计算》。很遗憾的是今年没有看完，留作来年第一本咯。这本书可以算是现如今网络社会用户所必读的了。很多想不通的事情，道哥都从计算的视角给串起来了，有一种豁然开朗的感觉。\n《左耳听风》今年最后读完的一本书。今年也遗憾耗子叔离开了这个世界，虽然没有交集，但作为对技术崇拜的老一辈程序员还是很值得 respect 的。读这本书的时候，从最开始的“三观”就有一种深深的共鸣，这才是纯粹做技术的人该有的样子，而不是整天忽忽悠悠应付交差嘛。但由于自己的资历尚浅，很多内容并不能 Get 到相关的点，比如“编程范式”那一章。往好处来想，这等于是埋下一颗种子，以后工作中可以留意一点，以及下一阶段的自己该往哪个方向去努力咯。芝兰生于幽谷，不以无人而不芳。\n除此之外，还读了一些杂书，不想记流水账就没写。纯技术类的想了想也不写了吧。。\n今年听的歌中文歌占大多数，还是老样子，歌荒的时候总会去随便选一张周董的专辑，从头播放到底。今年下半年喜欢上了两位女歌手：安溥和刘莉旻。关于喜欢上安溥的歌这件事说起来比较神奇。当时去音乐节主要为了看房东的猫和许嵩，在他们演出中间还有安溥，由于不在同一个舞台就错过了安溥。但回来之后，无意间在 B 站刷到了《最好的时光》的现场，瞬间就被深深吸引了。所以说，有的时候错过也是另一种相遇，是不是呢？本来今年跨年打算去看南京看安溥的现场，结果受到消息取消了。离大谱。当时音乐日推有一首《嘉禾望岗》，粤语听起来很抓耳，以及刘莉旻的《再见你》听起来也很舒服。\n哦对，还留意到了一个乐队——银河快递。也可以试试看。也是日推发现的。\n牢骚话 最后我想和你谈谈 2023。今年算是重新回归生活的第一年，从经历来说，也有很多新的尝试，自己的视野逐渐扩展开来。有的时候，我就在想极度讨厌嫌恶现在自己的样子，但有时又比较欣赏现在的自己。挺说不清的。有的时候庆幸自己目前所过的生活比较安逸，但有时候又后怕年纪轻轻这么安逸真的好嘛？简单来说，即怕一眼望到头，更怕一眼望不到头。也许这个世界就是个矛盾的集合。\n经过今年，我似乎找到了自己想做的方向，但具体怎么做，该往哪走，需要多久？一点想法都没有，那就等等看咯，也许再过个几年就能搞出点名堂了呢。还有就是自己需要谦虚点，切勿心高气傲。年轻人很容易上头很正常，但要尽力的克制住自己。\n今年我的“三观”崩塌了，或者说之前的根本就没有建立。在学生时期，三观大多是来源于书本以及他们的讲授，但我自己有能力体验这个世界的时候，突然发现是截然不同的。我相信随着年龄的增长，三观这玩意会再次改变的。\n今年在技术上开始有了新的尝试，不再仅仅局限于工作的需求，我发现人由于惰性思维，经常会为自己找各种各样的借口。但我属于爱折腾的，需要把工作和生活剥离开，虽然工作的内容是大数据相关，但生活中我更愿意进一步去探索其底层的原理。于是就把分布式领域的一些经典论文又拿出来看了看，有的还自己动手实现了个简单的 demo。今年“锈”的事情就是接触到了 Rust，这是一门用过就爱上的编程语言。也正因为如此，让我变得更像是一名独立开发者。有时候描述自己“白天是社畜，晚上是开发者”哈哈哈。折腾起来，就很有意思。但其中不要为工具浪费太多的时间，先根据自己的能力选择一款适合自己的就行，如果真有工具上的需求，到了那个阶段自然是水到渠成的事情。如果前期花太多时间折腾工具有点本末倒置。\n2023 的到来，我没抱有任何预期，经历了去年，我只想说好好活着就行，可以的话，尽可能开心一点。\n那么 2024 呢？留一条吧，想发一次疯。。\n","description":"","tags":null,"title":"再见 23，写在最后","uri":"/life/23_12-summary/"},{"categories":null,"content":"漫长的十一月，重新认识计算 为何说漫长？？ 今年主观感受上，时间比较长的有上半年的三月下旬至四月份，然后就是这个月。好像经历了很多，但仔细想想每一天都是很普通的，似乎没有任何区别。\n普通的是周一到周五，白天当社畜，晚上是自由的。那么何为自由呢？？大抵是在有限的条件下，尽可能地做点自己想做的事情吧。可能是看书、可能是写点自己想写的代码或者博客，比如现在这篇；又或者是打打游戏、练练球。但当每天上班、健身结束，顶着疲惫的身体洗漱之后，也都晚上十点多了。所以属于自己的时间，也就两个小时左右，这就导致控制不住去熬夜。有的时候，还会纠结，这点时间我到底想做什么呢？？但往往是纠结着纠结着就该睡觉了，该死的拖延症。随性就想到什么做什么呗，不给自己定目标，just for fun。于是，这个月没读什么非技术的书籍，开始重新打游戏叻。等会再说说游戏 哈哈。\n再看看周末，第一个周末去看了音乐节，因为有许嵩和房东的猫！！！由于没经验，下午早早地就去了，熬了一下午。那天应该是杭州今年最后一天三十度以上的天气了吧，到目前为止，后面过冬了，除非天气反常。。逛了一圈，和浩哥找了个有阴凉的小角落打地铺在那等。真的好热！！条件还差！！呜呜呜🥹。到了傍晚的时候，听见了橘子海，诶对，就是一脚踢出盛夏的那个橘子海 哈哈。可能是太阳下山了，凉爽起来了，人也有了精神。下一个就是期待已久的房东的猫。音乐节比较好的一点，站位比较自由，我和浩哥就提前过去挤到稍微靠前的位置。但人还是好多，好在有身高优势 哈哈。说起房东的猫，大概是 18 年夏天听见《云烟成雨》，只感觉好温柔的声音，初印象也就不错。真正喜欢起来，是 21 年夏天，偶然刷到了一个音乐节小黑的片段，嗯，真好看😊。就开始重新认识了一下。也挺佩服她们的，在当时毕业已经有了稳妥且不错的工作，最后选择了音乐，没有被生活所妥协。那么回头看看自己呢？？刚刚步入社会，二十出头，已经是社畜的模样，唉。房东的猫下一场是马赛克乐队，之前听过《霓虹甜心》，但已经疲劳一下午，根本蹦不起来叻。最后一个出场的是许嵩。当用《有何不可》开场的时候，回来了，熟悉的开场回来了。如果只是这一首歌，熬了一天也是值得的！最后结尾的是《素颜》，全场合唱的感觉真是太棒了！第一次听见许嵩的歌，是当时五年级的时候。那时上初中的表哥，去网吧给 128M 的 SD 卡里面下的音乐，我还记得许嵩的分别是《城府》、《有何不可》以及《送你的独白》。其实还是挺怀念小时候的，但后来老家装修，老房子翻新，儿时的记忆也逐渐模糊了起来，不过有时却会在梦里出现。\n回头看看，没有追过什么星，从小喜欢到大的应该只有周杰伦了吧。与其说是喜欢听他们的歌，倒不如说是喜欢那个时候的回忆，因为人在回忆的时候，总会加滤镜的嘛。所以更多可能是用现在的能力给那个时候的自己补补票吧。\n之后的两个周末，见了很久没见的朋友。其中一个学姐是在开源社区认识的，前段时间从美团跳到淘天。当她说到工作时间的时候，在大厂加班几乎是家常便饭。然后我反问：这样的话 那自己的生活呢？她说：工作就是自己的生活。emmm 从我的角度来说，能理解，但不愿理解。理解的是因为在做有正反馈的、并且是自己所喜欢的事情，不在乎工作还是非工作时间，有主人翁意识，当出结果的时候，很有成就感，这么说可能有些人会觉得有点 PUA，确实是的，但开心也是真的。不愿理解，就是留点时间给自己，哪怕慢下来发发呆也是不错的尝试呢🤔️。还有一周和大学同学分别去了青山湖和玉鸟集，还狂炫了肉肉 哈哈。不过可惜的是，他要离开杭州，回家考公了。怎么说呢，也好也不好。从我的角度来说，我喜欢折腾，讨厌应酬，更不会妩媚，反对循规蹈矩，所以公务员在我看来是很无聊的职业。从反面来说，如果追求安逸平稳，却是最优解。最起码能回到自己的家乡，不用考虑在陌生城市的生存压力。加油吧。玉鸟集在 X 上看见“疯狂星期四”的活动，一群独立开发者围在一起 coding，还是挺向往的！\n十一月的最后一周，我选择了回家。其实在回上海前几天，因为一些私事还对父母发了脾气。年轻人上班哪有不发疯的呢。。随着自己的独立，也家人渐行渐远，总觉得他们不懂自己，虽然他们很多出发点都是为了我好。但反过来想，如果手里有一杯水，你会怎么做呢？？可能大多数人下意识的反应就是喝下它。我会反问我真的需要嘛，如果不是，我宁愿把杯子直接摔了，但碎玻璃可能还会割断一条条联系的线。之前我就和爸妈打趣地说，随着时间的推移，有可能会大吵一架。我还发现一个特别有趣的现象，很多孤身在外的子女，对父母都喜欢报喜不报忧。这次回家，妈妈和我说，一个人在外地是不容易，别想那么多，过好一天是一天，有什么不开心也可以说出来。我沉思了几秒，只能说，还行。没想象的那么好，但也不太差。送我去虹桥的时候，老爸问我下一次回来是什么时候。我说了一句废话，下一次回家应该就是下一次回家的时候了吧。拿起包，撒腿就跑，我可不想被骂。其实这么问，我也不知该怎么回答。再看看吧。\n所以看这几个周末，是不是挺漫长的呢？？\nXenoblade2 好像从五月中下旬就没怎么好好打过游戏了。每天晚上回到家里就是扎进技术的深渊里，最近学完了 6.1800，也就想着给自己放个假吧。在吃灰的游戏库中找到了奶刃 2。原因有以下几点：去年有一段时间陷入电子阳痿，不想学习，也不想玩游戏，刚好赶上《异度神剑 3》发售，抱着试一试的心态，就入了。emmm 算是第一次认真玩 jrpg 类的游戏，体验还不错，玩到后半期整个人心态就变了，特别是铁窗泪那一段（bushi。《A step away》。游戏前半部分有点赶进度，一直推主线，到了后半程更多的是想陪 Mio 看看艾欧尼翁这个大陆。当然结局也是有点🔪的，本以为之后的 DLC 是日后谈，结果不出意外的是都市六人转。在提前跳票的宣传片里出现了雷老板，就想着补补票吧。而且在玩 xb3 的时候，很多玩家都和 2 对比，说 3 做的不如 2。\n奶刃 2 是一款优点和缺点都很明显的游戏。先说说看缺点吧，得益于 NS “优秀的性能”，整个画面玩起来特别糊。。。然后就是没有良好的跑图指引，导致经常迷路，有的地方地图显示距离很近，结果一绕就半个小时过去了。。。。最后一点也算是优点吧，那就是复杂的战斗系统。当时打到第三章的时候，因为模式选择了是普通模式，一直卡在灭那里，卡了两晚！！还去看了战斗系统教程，结果一个头两个大 呜呜。后来发现可以调整难度的选项，果断选择简单模式。诶 就这样一把过 哈哈哈哈。当然之后又去补了课，才发现战斗系统的趣味所在。画质糊，其实大冬天能捧在手里在暖暖被窝里玩游戏，也没什么不能接受的是吧。但是后两点真的有点劝退。要不是我个人比较执拗，有强迫症估计早就弃坑了 呜呜呜。除去以上，可以说整个游戏全是优点。\n整个游戏玩下来，剧情方面很紧凑，抓的很近。虽然有十章，但主线设置的都很合理。而且越深入玩到后期，越燃，特别是配上中二的台词 哈哈哈哈。这一点相比 xb3 剧情安排要合理的多。但也许是心境的原因，我个人更喜欢 xb3.。也许是每天快节奏、碎片化的生活，对于一个大体量的内容接受起来比较难。也就很难深挖其中的韵味所在。比如玩游戏的时候，只想着快点推主线，支线几乎都放一边，这对于游戏内容来说是一个较大的损失。奶刃 2 最喜欢的角色应该是真，喜欢他的执念，更想了解在其身上发生的事情。到底是什么原因，导致他变成这样。其实这句话也是在反问我自己咯。\n再谈谈我对于游戏的观点吧。属于愿意接受的那一种，特别是主机游戏。在现如今快节奏的社会，能够沉下心来认真玩一个游戏的门槛是比较高的。一款好的游戏不亚于一本好书，而且是从更主观的视角去接受一个新的世界。虽然这个月没看闲书，但体验了《异度之刃 2》也算是一样的吧。下一个月打算先把《黄金之国：伊拉》给速速完结，看看真的故事！\n重新认识计算 十一月的第一天就调休去了“云栖大会”。大学时期因为受😷影响都是远程看看有啥好玩的东西，今年还不错有机会去线下体验一番。上一次去云栖小镇还是 21 年 “2050 大会”的时候，一转眼两年半过去了。今年的主题是“计算，为了无法计算的价值”。整个大会会看见很多大模型的论坛，不过我更喜欢 infra 那一块 哈哈哈。然后就去大数据以及数据库方向逛了逛。看见 DataWorks 的时候，我就想如果这鬼东西深度接入通义千问，岂不是可以实现 SQL 自由，从此以后就可以自己来当产品，把指标输入给工具就行。但想象是美好的，事实应该还有段路要走。如果这样的话，那么也将会有大把的 SQLBoy 面临失业的危机。下午的话就去看了看一些感兴趣的论坛，比如 Redis、Paimon 这类，只能说有技术有吹水吧。\n这个月还收到了一本书——道哥写的《计算》，这是一本很有意思的书籍，细细读下来有点颠覆我对传统计算机的理解。第一次线下见到道哥，也是 21 年的时候，当时所讲的 topic 是《计算的未来 30 年》。由于当时的经历优先，而且知识面比较浅，然后主观上受《头号玩家》的影响，总喜欢把观点往上面靠，就有点走偏。还好有了《计算》这本书，让我重新认识这个世界。\n有时候觉得自己挺幸运的，无意间做了一点小事，紧接着能遇见一群人，然后能够做出更多有意思的事情。\n那么到底什么是计算呢？\n这个概念，从某种程度上来说现如今生活的人们都需要理解。毕竟按照发展趋势，计算终将会成为公共服务，也就是 “Computing as Utility”，成为一种普世价值，虽然一定程度上说这是一个美好的愿景。当然作为一名合格的开发者，就更有义务去搞清楚。就好比经常有人会说，什么是码农？什么又是程序员呢？在我的认知里，程序员至少是一个创造性的职业，也就是懂程序、懂架构设计的，并在此基础上还要理解计算的本质才行。至于“码农”可以是自嘲，但是你要给我扣这个帽子，就不太喜欢叻。但事实却是，很多程序员其实是不懂计算的，有些人写代码就是无脑 CV，或者说从开源项目里面扒拉出来改改，然后变成自己的东西。这是搬砖、搭积木的活，这种流程也就和计算没有关系了。\n在书中，有说到计算的起源是莱布尼茨，他在 250 年前提出了两个想法：一个叫做人类思想字母表，是对人类思维规律的一种直接反映。他可以用这个字符去描绘世间的万事万物。站在今天的视角来看，这不就是编码的思想嘛。他希望通过这个共同的字符解决人与人之间的沟通障碍。另一个想法叫做普遍语言。莱布尼茨其实是想解决巴别塔难题，不同的人和人之间之所以有分歧，是因为语言不通，所以他希望发明一种非常规范的普遍语言。这个普遍语言是由特定的字符组成的，以后所有人有争端的时候，坐下来，算一算，用纸和笔算一算，争端就解决了，所有人就不会再有分歧。现在来看似乎也不太现实。但这种思想是有启蒙意义的。\n这个思想进而影响了很多人，比如希尔伯特、哥德尔和图灵等。1936 年的图灵恰恰在研究哥德尔和希尔伯特的一些理论，就受到启发，写了篇论文《论可计算数及其在判定问题上的应用》，定义清楚了什么是图灵机。可以说，图灵机是基于前面的这些理论诞生的。图灵机是想干什么呢？是希望模拟人类计算者的心理活动。简单来说，就是人类的一个计算者拿笔在纸上去写写画画、做数学公式推导的时候，这个人的心理活动是什么样的？这个心理活动，图灵想用图灵机来描述，或者说可以用机械驱动。\n到目前为止，计算所有的发展基本上就是在模拟人类的心理活动、思维规律，或者说到了模拟人类大脑的阶段。计算就是这件事情，今天我们无非是用电子计算机来驱动这样的一个计算过程。这里面，图灵机是一个非常重要的、里程碑式的理论模型。图灵之前，计算的定义是不清晰的。人类可能从 3000 年前就发明了加、减、乘、除，不过在古代，我们只能做一些机械式的计算机，效率很低。但是直到图灵，才把计算的概念定义清楚。有了这个基础，才有了后面所有通过机械的装备和装置来制造计算机的可能性，提高计算的效率。\n中间还有香农对于逻辑电路的贡献。1946 年冯·诺伊曼他们去做世界上第一台电子计算机的时候，有了图灵机作为理论基础，有香农的贡献，所有的东西就这么结合到了一起。可以说冯·诺伊曼只是在图灵的理论模型上面做了一个实现，做出了世界上第一台真空管电子计算机。后来过了一二十年又有了晶体管，晶体管又取决于量子力学的进展。\n当把这些都串在一起的时候，我们可以重新思考计算到底要干什么？\n计算机如果从理论模型上来讲，其实还是在实现当年图灵和莱布尼茨的梦想，就是**用一个机械化的过程模拟人类思维的规律。**计算从本质上来说，是从数字出发，模拟世界万物的结构。如果再大一点，那就是通过数字编码世间万物，世间万物所有的规律就能通过机械化的方式来推导。\n写在最后 又啰里八嗦说了一堆，前半段是生活，后半段是思考。更多的是把《计算》书中的内容给拎出来了，不得不佩服道哥的思想深度。最后用书封底的三句话作为结尾：\n我希望同路人铭记先辈们攀登过的高峰，\n我们将以此为起点继续前行。\n我希望亲朋好友们理解我们努力的目标，\n我们还将为此继续奋斗。\n我希望孩子们知道他们会继承什么，以及\n还有哪些留待他们去开拓。\n","description":"","tags":null,"title":"重新认识计算","uri":"/life/23_11-compute/"},{"categories":null,"content":"分布式选举 前言 既然提到了分布式，集群就是绕不开的话题。简单来说，集群一般是由两个或两个以上的服务器组建而成，每个服务器都是一个节点。我们经常会听到数据库集群、管理集群等概念，也知道数据库集群提供了读写功能，管理集群提供了管理、故障恢复等功能。\n那么问题，对于一个集群来说，多个节点到底是怎么协同，怎么管理的呢。比如，数据库集群如何保证写入的数据在每个节点都一致呢？比如上一篇博客中谈到的分布式各个服务之间可能会打架——互斥。\n这个时候，你也许会说，这还不简单，选一个”领导“来负责调度和管理其他节点不就可以了嘛。诶，很不错。这就是我们常说的”主从“架构设计。这个”领导“在分布式叫做主节点，而选”领导“的过程在分布式领域中叫作分布式选举。\n关于如何选主这个过程，就是我们本篇的重点咯。\n为什么要有分布式选举？ 主节点，在一个分布式集群中负责对其他节点的协调和管理，也就是说，其他节点都必须听从主节点的安排。主节点的存在，就可以保证其他节点的有序运行，以及需要保证写入每个节点的数据一致性。这里的一致性是指，数据在每个集群节点中都是一样的，不存在不同的情况。\n当然，如果主节点发生故障，集群就会处于一个混乱的状态，比如数据库集群中主节点故障后，可能导致每个节点上的数据一致性得不到保证。就好比，某个公司的 CEO 突然被辞退了，公司短时间可能就会出现人心不稳的情况。\n**这，就应那句话“国不可一日无君”，对应到分布式系统中就是“集群不可一刻无主”。**总结来说，选举的作用就是选出一个主节点，由它来协调和管理其他节点，以保证集群有序运行和节点间数据的一致性。\n分布式选举的算法 那么，如何在集群中选出一个合适的“领导者”呢？目前常见的选主方法有基于序号选举的算法，比如 Bully 算法、多数派算法，比如 Raft 算法、ZAB 算法等。下面的内容，我们一个一个来看。\nBully 算法 Bully 算法是一种极为主观的集群选主算法，为什么说是非常主观呢？因为它的选举原则是“长者”为大，简单来说，就是在所有活着的节点中，选取 ID 最大的节点作为主节点。\n在 Bully 算法中，节点的角色有两种，分别是普通节点和主节点。初始化时，所有节点都是平等的，都是普通节点，并且都有资格成为领导者。但是，当选主成功后，有且仅有一个节点成为主节点，其他所有节点都是普通节点。当且仅当主节点故障或与其它节点失去联系后，才会重新选主。\nBully 算法在选举过程中，需要用到以下 3 种消息：\nElection 消息，用于发起选举； Alive 消息，对 Election 消息的应答； Victory 消息，竞选成功的主节点向其他节点发送的宣誓主权的消息。 Bully 算法选举的原则是“长者为大”，意味着它的假设条件是，集群中每个节点均知道其他节点的 ID。在此前提下，其具体的选举过程是：\n集群中每个节点判断自己的 ID 是否为当前活着的节点中 ID 最大的，如果是，则直接向其他节点发送 Victory 消息，宣誓自己的主权； 如果自己不是当前活着的节点中 ID 最大的，则向比自己 ID 大的所有节点发送 Election 消息，并等待其他节点的回复； 若在给定的时间范围内，当前节点没有收到其他节点回复的 Alive 消息，则会判定自己成为主节点，并向其他节点发送 Victory 消息，宣誓自己成为主节点；若接收到来自比自己 ID 大的节点的 Alive 消息，则等待其他节点发送 Victory 消息； 若该节点收到比自己 ID 小的节点发送的 Election 消息，则回复一个 Alive 消息，告知其他节点，我比你大，重新选举。 Bully 算法的选择是比较霸道直接的。谁活着且谁的 ID 最大谁就是主节点，其他节点必须无条件服从。这种算法的优点是：选举速度快、算法复杂度低，而且实现起来比较简单。缺点也很明显，主要在于：需要每个节点有全局的节点信息，就造成存储了大量的重复数据；其次，任意一个比当前节点 ID 大的新节点或节点故障后恢复加入集群的时候，都可能会触发重新选举，成为新的主节点，如果该节点频繁退出、加入集群，就会导致集群频繁换主。\nRaft 算法 Raft 算是是典型的多数派投票选举算法，其选举机制有点类似于我们日常生活中的民主投票机制，其核心思想是“少数服从多数”。简单来说就是，Raft 算法中，获得投票最多的节点成为主节点。\n采用 Raft 算法选举，集群节点的角色有 3 种：\nLeader，即主节点，同一时刻只有一个 Leader，负责协调和管理其他节点； Candidate，即候选者，每一个节点都可以成为 Candidate，节点在该角色下才可以被选为新的 Leader； Follower，Leader 的跟随者，不可以发起选举。 Raft 选举的流程，可以分为以下几步：\n初始化时，所有节点均为 Follower 状态； 开始选主时，所有节点的状态由 Follower 转化为 Candidate，并向其他节点发送选举请求； 其他节点根据接收到的选举请求的先后顺序，回复是否同意成为主。这里需要注意的是，在每一轮选举中，一个节点只能投出一张票； 若发起选举请求的节点获得超过一半的投票，则成为主节点，其状态转化为 Leader，其他节点的状态则由 Candidate 降为 Follower。Leader 节点与 Follower 节点之间会定期发送心跳包，以检测主节点是否存活； 当 Leader 节点的任期到了，即发现其他服务器开始下一轮选主周期时，Leader 节点的状态由 Leader 降级为 Follower，进入新一轮选主。 请注意，每一轮选举，每个节点只能投一次票。这种选举就类似人大代表选举，正常情况下每个人大代表都有一定的任期，任期到后会触发重新选举，且投票者只能将自己手里唯一的票投给其中一个候选者。对应到 Raft 算法中，选主时周期进行的，包括选主和任值两个时间段，选主阶段对应投票阶段，任值阶段对应节点成为主之后的任期。但也有例外的时候，如果主节点故障，会立马发生选举，重新选出一个主节点。\nGoogle 开源的 Kubernetes，擅长容器管理与调度，为了保证可靠性，通常会部署 3 个节点用于数据备份。这 3 个节点中，有一个会被选为主，其他节点作为备。Kubernetes 的选主采用的是开源的 etcd 组件。而，etcd 的集群管理器 etcds，是一个高可用、强一致性的服务发现存储仓库，就是采用了 Raft 算法来实现选主和一致性的。\nRaft 算法具有选举速度快、算法复杂度低、易于实现的优点；缺点是，它要求系统内每个节点都可以相互通信，且需要获得过半的投票数才能选主成功，因此通信量大。该算法选举稳定性比 Bully 算法好，这是因为当有新节点加入或故障恢复后，会触发选主，但不一定会真正切主，除非新节点或故障后恢复的节点获得投票数过半，才会导致切主。\nZAB 算法 ZAB（Zookeeper Atomic Broadcast）选举算法是 Zookeeper 实现分布式协调功能而设计的。相较于 Raft 算法的投票机制，ZAB 算法增加了通过节点 ID 和数据 ID 作为参考进行选主，节点 ID 和数据 ID 越大，表示数据越新，优先成为主。相比较于 Raft 算法，ZAB 算法尽可能保证数据的最新性。所以，ZAB 算法可以说是对 Raft 算法的改进。\n使用 ZAB 算法选举时，集群中每个节点拥有 3 种角色：\nLeader，主节点； Follower，跟随者节点； Observer，观察者，无投票权。 选举过程中，集群中的节点拥有 4 个状态：\nLooking 状态，即选举状态。当节点处于该节点时，它会认为当前集群中没有 Leader，因此自己进入选举状态； Leading 状态，即领导者状态，表示已经选出主，且当前节点为 Leader； Following 状态，即跟随者状态，集群中已经选出主后，其他非主节点状态更新为 Following，表示对 Leader 的追随； Observeing 状态，即观察者状态，表示当前节点为 Observer，持观望态度，没有投票权和选举权。 投票过程中，每个节点都有一个唯一的三元组（server_id，server_zxID，epoch），其中 server_id 表示本节点的唯一 ID；server_zxID 表示本节点存放的数据 ID，数据 ID 越大表示数据越新，选举权重越大；epoch 表示当前选取轮数，一般用逻辑时钟表示。\nZAB 选举算法的核心是“少数服从多数，ID 大的节点优先成为主”，因此选举过程中通过 vote_id，vote_zxID 来表明投票给哪个节点，其中 vote_id 表示投票节点的 ID，vote_zxID 表示被投票节点的服务器 zxID。ZAB 算法选主的原则是：server_zxID 最大者成为 Leader；若 server_zxID 相同，则 server_id 最大者成为 Leader。\n下面就以 3 个 Server 的集群为例，此处每个 Server 代表一个节点，来介绍 ZAB 选主的过程。\n第一步：当系统刚启动时（三个服务器同时启动），3 个服务器当前投票均为第一轮投票，即 epoch = 1，且 zxID 均为 0。此时每个服务器都会优先推选自己，并将投票信息 \u003cepoch, voted_id, vote_zxID\u003e 广播出去。\n第二步：根据判断规则，由于 3 个 Server 的 epoch、zxID 都相同，因为比较 server_id，较大者即为推选对象，因此 Server1 和 Server2 将 vote_id 改为 3，更新自己的投票信息，并重新广播自己的投票。\n第三步：此时系统内所有的服务都推选 Server3，超过半数，因此 Server3 当选 Leader，处于 Leading 状态，向其他服务器发送心跳包并维护连接；Server1 和 Server2 处于 Following 状态。\n简单来说，ZAB 算法性能高，对系统无特殊要求，采用广播方式发送信息，若节点中有 n 个节点，每个节点同时广播，则集群中信息量为 n*(n-1) 个消息，同意出现广播风暴；且除了投票，还增加了对比节点 ID 和数据 ID，这就意味着还需要知道所有节点的 ID 和数据 ID，所以选举时间相对较长。但该算法选举稳定性比较好，当有新节点加入货节点故障后，出触发选主，但不一定真正切主，除非新节点或故障后恢复的节点数据 ID 和节点 ID 最大，且获得投票数过半，才会导致切主。\n小结 本篇内容讲解了什么是分布式选举，以及为什么需要分布式选举。然后走马观花地介绍了 Bully 算法、Raft 算法以及 ZooKeeper 中的 ZAB 算法，并通过实例展示了各类方法的选举流程。\n最后聊一聊为什么“多数派”选主算法通常采用奇数节点，而不是偶数节点呢？\n多数派选主算法的核心是少数服从多数，获得投票多的节点胜出。想象一下，如果现在采用偶数节点集群，当两个节点均获得一半投票时，到底应该选谁为主呢？\n答案是，在这种情况下，无法选出主，必须重新投票选举。但即使重新投票选举，两个节点拥有相同投票数的概率也会很大。\n因此，多数派选主算法通常采用奇数节点。这，也是大家通常看到 ZooKeeper、 etcd、Kubernetes 等开源软件选主均采用奇数节点的一个关键原因。\n","description":"","tags":null,"title":"分布式 004——选举策略","uri":"/tech/distributedsystem/ds004_election/"},{"categories":null,"content":"写在 2023 立冬之后，不想再谈 Web 3.0 和我走的比较近的朋友都知道，我最近对于 Rust 比较感兴趣，关于这门系统级编程语言有哪些优点这里不想多说，但其中最关键的一点是安全，这也就造就了她独有的魅力。\n八月底参加了 GTR@Hangzhou 也是第一次参与 Rust 技术相关的 meetup，以及九月下旬去上海看了 GOSIM，其中会有不少开发者都是做 Web 3.0 这一块的。我第一次听 Web 3.0 是在 20 年年底的时候，当时大概的印象就是去中心化。只会觉得很有发展前景，但却很难普及。\n最近立冬，天变冷了，闲着无聊，不如开始重新认识一下 Web 3.0。\n互联网的诞生 如果想要弄清楚 Web 3.0 的诞生，先来纵向梳理一下互联网的发展历程和现状。\n不言而喻的是，互联网的发展是人类发展步入到信息社会的前提，一方面，大量信息可以被低成本的记录和传播，因为随着硬件技术的发展，存储成本是不断下降的；另一方面，当这些信息内容的总量达到一定量级之后，会对社会和经济活动产生巨大的影响。人们常说的大数据，就是在这种情况下发展的产物，数据变成资源，哪家公司掌握的用户数据越多，可操作的空间就越大。\n在上个世纪 90 年代，互联网的诞生可以说是在纸质媒体之外创造了一个全新的传播渠道，诞生了一批专业的内容生产平台 PGC，此时的互联网是一个只读网络，所有网站的内容都由运营者提供，用户只能观看，是静态互联网。其中代表性的企业包括雅虎、新浪、搜索等门户网站，各网媒雇佣大批编辑，将图文并茂的内容发布为网页。对于读者来说，能做的只有访问网站，浏览数字内容，但读者不能写，无法参与内容的操作。这一时期的互联网是单向的，互联网产生的数据和用户的关系不大。这就是 Web 1.0 时代。\n接着，随着时间的推移，用户开始不满足“只有输入没有输出”的状态了，于是在用户渴望表达自己想法的诉求下，催生出了一大批可以为用户提供创作和表达的平台，比如 Twitter、微博 等。除此之外，还有就是需要用户参与的电商平台、视频网站，以及为这些服务提供终端可基础设施的科技公司，比如微软和苹果，也纷纷涌现。这个阶段，我们在这过渡到 Web 2.0 时代。\n数据资源 在这一时期，用户的各种行为产生了大量数据，但这些数据的特点是存储即拥有，而不是谁创造谁拥有。这样一来，就会导致如下问题：互联网公司凭借收集的数据和掌握数据资源的优势，可以随便操纵分析用户的数据，为企业谋取利益最大化，也就有了所展示出来的私人立场和公共利益的冲突日益变大。\n我们可以看一下 Meta 这家公司（也就是 Facebook），截止 2021 年末最高市值达到 1 万亿美元，如果按照这个数值参与当年各国 GDP 排名的话，大概可以排进全球前十五的位置。就其背后原因，是 19 亿日活用户和 29 亿月活用户，月活用户在全球人口中占比高达 36%。但在 Facebook 主导的互联网里面，你就必须得遵守它所设定的规则，方面的例子就是当年追求连任的川建国同志一样，被“社交性死亡”。\n由此及彼，现如今的互联网服务差不多都是这个样子，其他领域也是同理。比如，在国内我们常用的沟通工具就是微信，随着网络技术的普及，无线网的覆盖面积越来越大，运营商的流量相较以往也在降价，所以作为用户，是以极低的代价使用这些工具。而作为公司来说，肯定是想盈利的。他们为用户提供了沟通的服务，也随之掌握了用户的信息。通过信息变现，会向用户投送广告，作为用户，是不太愿意看见这些广告的。\n这就是事情的关键，你在互联网上获得了很多服务，但你在互联网上的每一步，其实都离不开某一个互联网巨头的“陪伴”。每个互联网巨头又都为他们的产品设计了一整套的制度，在这套制度面前，用户就像一个孩子在面对家长或者老师，几乎没有任何讨价还价的能力和空间。这一时期互联网功能可谓非常强大，但用户离开互联网公司，可谓是“寸步难行”。\n这个时期，我们感受到了互联网服务的强大，但也深陷离开互联网公司就“寸步难行”的困境！互联网公司利用用户对自己产品的依赖，正在像“灰犀牛”一样，把私人机构的价值诉求，变成某种社会规则。\nWeb 3.0：互联网的革命？ 那么有的人可能会说，如果数据归用户自己所有，不就可以了嘛。这也就是 Web 3.0 要做的事情！把互联网打开，从技术层面让互联网实现一种开放性，再通过技术逻辑的再造去改变它的“精神气质”。\n不过，关于 Web 3.0 还没有形成一个大家公认的定义。比如以太坊的前 CTO，Polkadot 创始人加文·伍德（Gavin Wood）就提出，Web 3.0 是一组包容性协议，可为应用程序构建模块；这些模块取代了传统的 Web 技术，如 HTTP 和 MySQL 等，同时可以提供一种全新的创建应用程序的方式。再比如著名硅谷风投机构 A16Z，将 Web 3.0 定义为“一组包含区块链、加密协议、数字资产、去中心化金融和社交平台的技术”。\n简单来说可以这样理解，Web 3.0 即是互联网功能的协议化，协议仅按照代码体现的有限规则运行，既没有更多的利益诉求，也没有更多地投射到社会层面的价值主张；协议之间可以通过相互组合实现功能的叠加，并体现出一种开放和协作的精神。\n举个例子，支付宝的诞生对于电商的兴起来说，是发挥了基础性的作用的，因为在没有支付宝的情况下，买家和卖家互不相识且互不信任，卖家担心发货之后收不到货款，买家担心付款之后收不到货，交易几乎无法完成。而支付宝就在买家和卖家之间，发挥了一种“担保交易”的功能，来组织资金结算，进而促进了贸易的达成。但支付宝的想法并没有到此为止，而是在支付的基础上继续绑定借贷业务，通过推出交易金额越大，信用额度也就越大的激励政策，推荐自己的借贷业务，这就是 Web 2.0 的典型模式。但我们要注意一点，支付业务和借贷业务的绑定，其实会对借贷市场的其他金融机构形成一种排斥效果，这明显对于金融市场扩大供给、促进市场竞争是不利的。\n那么，在 Web 3.0 网络中，支付宝的作用就不再由某一家机构承担了，而是由一个协议来承担，这样就算没有第三方机构作为中介，不信任的双方仍可以安全地进行交易结算，这种协议就叫 HTLC，全名叫哈希时间锁协议，它还可以为其他金融机构创造一种更加公平的竞争环境。\n功能的协议化仅仅是 Web3.0 建设的第一步，在这些协议的背后，还需要一个作为“硬件系统”的支撑协议运行的分布式计算网络，和一个作为“软件系统”的通用的、围绕用户的身份验证、数据记录以及如何使用授权和激励的经济系统。\n硬件系统 “硬件系统”为协议执行提供技术支撑，从底层到应用层分别实现通信、计算、存储和交互等功能，并且在每个环节中都体现出一种“可替代性”，也就是说这些功能并不是依赖于某个特定的机构或者组织才能实现的，但是功能的逻辑是准确而可信的，这种特性又被称为是“去信任的信任”，即 Trustless Trust。\n比如，在目前互联网中，我们所有的程序在执行计算任务的时候，都要自行解决输入的可用性、可靠性以及相互之间的授权问题，还需要因此花费额外的资源，去解决各种不兼容和安全风险等问题。而定位于“互联网计算机”的 IC 协议，就提供了一种 Web 3.0 的解决方案。\nIC 协议是基于区块链共识机制，在 TCP/IP 协议和应用层之间构建了一个包括多个物理节点的虚拟子网；子网内部的节点对输入输出达成共识，可以相互验证计算结果；多个子网之间可以通信，并且可以通过相互组合，实现计算能力的大幅提升。\n其实，类似于 IC 的设计理念，在通信、计算、存储等领域也有类似的探索，这些协议通过相互组合为数据的产生、存储、调用以及隐私保护创造了一个不依赖于任何特定机构的，且功能完整的链条，从而使得互联网具备了一种克服“单点故障”的基本架构。\n经济系统 而在“硬件系统”之外，围绕用户还需要一套针对身份认证、数据记录以及使用授权和激励的经济系统。这套系统需要内嵌到协议的执行过程，协议的实施无需任何第三方机构的参与和帮助。基于这套经济系统，不同的协议就可以相互叠加和组合，并实现经济利益的协调。\n那么，从“硬件和软件”系统的功能来看，区块链就是 Web 3.0 发展高度依赖的一项技术，区块链不仅可以不依赖任何第三方机构实现去信任的协作，还可以通过代币系统对系统成员进行激励。但是，区块链并不是 Web 3.0 的全部，因为区块链的主要作用是建立一套可信共享账本，而不能为 Web 3.0 需要解决的全部问题提供解决方案；Web 3.0 还将通过区块链、隐私计算，人工智能甚至物联网技术的结合获得更大的发展空间。\n但需要注意的是，虽然前面讲了很多“硬件和软件”的组合，但从用户使用的角度看，Web 3.0 与 Web 2.0 可能没有什么太大的区别。Web 3.0 通过分布式技术架构和经济系统的打造，将创造一个全新的商业模式，一个高度联系、无国界的数字经济体，并产生大量的自下而上的创新机会。\nWeb 3.0 的出现反映了一种底层技术的变革在产业链层面带来的新的职能分工，而新的职能分工往往就意味着新的业务模式和新的产业机会。所以，Web 3.0 就是基于技术的方式，对现有互联网进行的一次“破坏性创新”。\n写在之后 Web 3.0 从技术的角度赋予了互联网开放的精神气质，通过分布式技术架构和经济系统的打造，将创造一个全新的商业模式，一个高度联系、无国界的数字经济体。\n但基于目前的环境，我想说 Web 3.0 只能说是一个美好的愿景，实现起来很难很难，触及到的利益链条太多了。但朝这个方向发展是大势所趋，只不过会比较漫长。\n有的时候很喜欢从技术的角度，去解读现如今的世界，倒不如说技术是为了更好地服务。比如说，在 Web 3.0 的概念中，计算将会变成一种通用服务，这一点我是认可的，毕竟让数据回归到创造数据的人手里才是终点，从而就能摆脱数据垄断。这也就提出“公链”这个概念，大家常说的以太坊就是这样一种提供通用计算服务的基础设施。\n所以如果可以的话，我想回归重新去做 infra。还是拿以太坊来继续往下写一点吧。以太坊是在比特币的基础上，实现了图灵完备的智能合约，它理论上可以支持任何形式的去中心化应用，但毕竟是理论上。事实上，以太坊只能支持有限数量的去中心化应用。就其主要原因就是著名的 CAP 不可能三角定理。也就是说，一个分布式系统中，在一致性、可用性和分区容错性三项特征中，最多只能存在其中两个。\n好好好。打住！，啰里八嗦的写了一堆。整理这些资料的时候，也让自己对于技术的发展有了一个重新的认识，也算是一个科普向的文章，并未涉及到了技术方面的知识，毕竟现如今这个社会上，懂不懂技术都可以好好生活，不是嘛。\n写得比较片面，也比较主观。。\n","description":"","tags":null,"title":"不想再谈 Web3","uri":"/tech/web3/web3-001_introduce/"},{"categories":null,"content":"聊聊分布式互斥 前言 在之前的两篇博客中，完成了分布式的基础入门，也就是知道了什么是分布式，以及分布式有哪些指标。下面一个篇章，将会聚焦于分布式协调与同步的内容。简单来说就是，如何让程序通过协作共同去达成一个业务目标。\n什么是分布式互斥？ 假设如下的场景，你正在吃自选餐，刚刚寻找到你想吃的菜品，突然在这时有一个抠脚大汉过来，把你挤到一边。看着他那体型，你只好耐着性子等他打完菜，再继续打自己的菜。结果你夹菜到一半他又回来中断了你的过程。如果这样反复来几次，你肯定会想，这老几就是来找茬的，马上就会来一场“有你没我，有我没你”的格斗了。\n上述的场景，也同样存在于分布式集群环境。就像我们在选菜过程中不希望被打断一样，对于同一共享资源，一个程序正在使用的时候也不希望被其它程序进程所打扰。这就要求在同一时刻只能有一个程序能够访问这种资源。\n在分布式系统里，这种排他性的资源访问形式，叫作分布式互斥，而这种被互斥访问的共享资源叫作临界资源。\n接下来，一起看看如何才能让分布式系统中的程序互斥地访问临界资源。\n集中式算法 对于前文提到的打菜问题，是不是可以增加一个“协调者”来约束大家文明就餐，从而避免强行插入打断别人进程的问题。\n那么，按照这种方式，我们可以在分布式集群中，引入一个协调者程序，得到一个分布式互斥算法。每个程序在需要访问临界资源时，先给协调者发送一个请求。如果当前这个资源处于空闲状态，也就是没有程序正在使用，协调者直接授权请求程序访问；否则，可以按照先来后到的顺序为请求程序“排一个号”。如果有程序使用完资源，则通知协调者，协调者从“排号”的队列里面取出排在最前面的请求，并给它发送授权消息。拿到授权消息的程序，可以直接去访问临界资源。\n这就是 FIFO 的模式，这个互斥算法，就是我们常说的集中式算法。之所以这么称呼，是因为协调者代表着集中程序，如下图所示：\n程序 1、2、3、4 为普通运行的程序，另一个程序为协调者。当程序 2 和 程序 4 需要使用临界资源时，会先向协调者发送申请，请求协调者授权。\n不巧的是，程序 3 正在使用临界资源。这时，协调者会根据程序 2 和 4 的申请顺序，依次将它们放入等待队列。比如当前的案例是，程序 4 的申请时间早于程序 2，因此排在程序 2 的前面。\n程序 3 使用完临界资源后，通知协调者释放授权。此时，协调者从等待队列中通知程序 4，并给它发放授权。这时，程序 4 就可以使用临界资源了。依次类推，直到所有申请结束。\n基于上述流程可以看出，一个程序完成一次临界资源访问，需要如下几个流程和信息交互：\n向协调者发送请求授权信息，1 次消息交互； 协调者向程序发放授权信息，1 次消息交互； 程序使用完临界资源后，向协调者发送释放授权，1 次信息交互。 因此，每个程序完成一次临界资源访问，至少需要进行 3 次信息交互。\n集中式算法的优点在于直观、简单、信息交互量少、易于实现，并且所有程序只需和协调者通信，程序之间无需通信。但缺点也很明显，就是在协调者自身，原因如下：\n一方面，协调者会成为系统的性能瓶颈。假设如果有 200 个程序要访问临界资源，那么协调者要处理 200*3=600 条消息。也就是说，协调者处理的消息数量会随着需要访问临界资源的程序数量线性增加； 另一方面，容易引发单点故障。当协调者的受到的请求访问量过大，如果某一进程特别重，可能会引发协调者故障，就会导致所有程序都无法访问临界资源，可能会进一步造成系统处于不可用状态。 因此，在使用集中算法的时候，一定要选择性能好、可靠性高的服务器来运行协调者。\n分布式算法 既然引入协调者会带来一些问题，那不用协调者是否可以实现对临界资源的互斥访问呢？比如试试看，能不能协商着来。在访问某块资源之前，先征求其他人的意见，在确认其他人都没有意向使用的时候，就属于来到自己的主场了。\n同理，我们可以把这种方式用于分布式系统。当一个程序要访问临界资源时，先向系统中的其他程序发送一条请求信息，在接受到所有程序返回的同意消息后，才可以访问临界资源。其中请求消息需要包含请求的资源、请求者的 ID，以及发送请求的时间。这就是民主协商法。\n如图所示，程序 1、2、3 需要访问资源 A。在时间戳为 8 的时刻，程序 1 想要使用资源 A，于是向程序 2 和 3 发起使用资源 A 的申请，希望得到它们的同意。在时间戳为 12 的时刻，程序 3 想要使用资源 A，于是向程序 1 和 2 发起访问资源 A 的请求。\n如果此时程序 2 暂时不访问资源 A，因此同意了程序 1 和 3 的资源访问请求。对于程序 3 来说，由于程序 1 提出请求的实践更早，因此同意程序 1 先使用资源，并等待程序 1 返回用以消息。\n程序 1接收到其他所有程序的同意消息之后，开始用资源 A。当程序 1 使用完资源 A 后，释放使用权限，向请求队列中需要使用资源 A 的程序 3 发送同意使用资源的消息，并将程序 3 从请求队列中删除。此时，程序 3 收到了其他所有程序的同意消息，获得了使用资源 A 的权限，开始用临界资源 A。\n从上述流程可以看出，一个程序完成一次临界资源的访问，需要进行如下的信息交互：\n向其他 n-1 个程序发送访问临界资源的请求，总共需要 n-1 次消息交互； 需要接收到其他 n-1 个程序回复的同意消息，方可访问资源，总共需要 n-1 次消息交互。 可以得出以下结论，一个程序要成功访问临界资源，至少需要 2*(n-1) 次消息交互。假设，现在系统中的 n 个程序都要访问临界资源，则会同时产生 2(n-1) *n 条消息。总结来说，在大型系统中使用分布式算法，消息数量会随着需要访问临界资源的程序数量呈指数级增加，容易导致高昂的“沟通成本”。\n从上述分析不难看出，分布式算法根据“先到先得”以及“投票全票通过”的机制，让每个程序按时间顺序公平地访问资源，简单粗暴、易于实现。但，这种算法可用性很低，主要包括以下两个方面：\n当系统内需要访问临界资源的程序增多时，容易产生“信令风暴”，也就是程序收到的请求完全超过了自己的处理能力，从而导致自己正常的业务无法继续开展； 一旦某一程序发生故障，无法发送同意消息，那么其他程序均除以等待回复的状态中，使得整个系统处于停滞状态，导致整个系统不可用。所以，相对于集中算法的协调者故障，分布式算法的可用性更低。 针对可用性低的一种改进办法是，如果检测到一个程序故障，则直接忽略这个程序，比如网络阻塞，长时间接收不到返回的消息，既然等不到那么就无需再等咯。\n这就好比在自助餐厅，一个人离开了餐厅，你想选某个菜品也就无需再征求他的建议。但这样的话，每个程序都需要对其他程序进行故障检测，这无疑带来了更大的复杂性。\n因此，分布式算法适合节点数目少且变动不频繁的系统，且由于每个程序均需通信交互，因此适合 P2P 结构的系统。比如，运行在局域网中的分布式文件系统。\n令牌环算法 既然集中式算法、分布式算法都存在一定的缺陷，那么还有什么方法可以实现分布式互斥嘛？答案是肯定的。比较方法总比问题多。轮值 CEO 其实就给了我们一个很好的启示：在轮值 CEO 体系里，CEO 就是临界资源，同时只能有一个人担任，由多名高管轮流出任 CEO。\n类似的，程序访问临界资源问题也可以按照轮值 CEO 的思路实现，如下图所示，所有程序构建一个环结构，令牌按照指定的顺序（顺时针或逆时针）方向在程序之间传递，收到令牌的程序有权访问临界资源，访问完成后将令牌传送给下一个程序；若该程序不需要访问临界资源，则直接把令牌传送给下一个程序。\n在分布式领域，通常将这个算法叫作令牌环算法。为了便于理解记忆，可以形象地称之为轮值 CEO 算法。\n因为在使用临界资源前，不需要像分布式算法那样挨个征求其他程序的意见了，所以相对而言，在令牌环算法里单个程序具有更高的通信效率。同时，在一个周期内，每个程序都能访问到临界资源，因此令牌环算法的公平性很好。\n但是，不管环中的程序是否想要访问资源，都需要接收并传递令牌，所以也会带来一些无效通信。假设系统中有 100 个程序，那么程序 1 访问完资源后，即使其它 99 个程序不需要访问，也必须要等令牌在其他 99 个程序传递完后，才能重新访问资源，这就降低了系统的实时性。\n综上，令牌环算法的公平性高，在改进单点故障后，稳定性也很高，适用于系统规模较小，并且系统中每个程序使用临界资源的频率高且使用时间比较短的场景。\n总结 在这篇博客中，我们介绍了分布式互斥的概念和几种实现方法，包括集中式算法，分布式算法和令牌环算法。\n集中式算法引入了一个协调者程序，每个程序在需要访问临界资源时，先给协调者发送一个请求。协调者根据请求的顺序，决定哪个程序可以访问资源。集中式算法的优点是简单和易于实现，但是协调者可能会成为系统的性能瓶颈，或者引发单点故障。\n分布式算法的思路是，一个程序在访问临界资源时，先向其他程序发送请求。只有当所有程序都同意之后，该程序才可以访问资源。这种方式可以避免单点故障的问题，但是可能会产生大量的消息交互，导致“信令风暴”。此外，如果某个程序发生故障，那么整个系统可能会处于停滞状态。\n令牌环算法则是所有程序构成一个环，令牌按照一定的顺序在程序之间传递。只有拿到令牌的程序才能访问资源。这种方法避免了无效的通信，提高了通信效率。同时，由于在一个周期内，每个程序都能访问到资源，因此令牌环算法的公平性很好。但是，不论程序是否需要访问资源，都需要接收并传递令牌，这可能会降低系统的实时性。\n总的来说，每种算法都有其适用的场景和局限性。在实际使用中，需要根据系统的规模，程序的数量，以及临界资源的使用频率和使用时间等因素，选择最合适的算法。同时，也可以考虑使用混合的方式，结合多种算法的优点，以满足不同的需求。\n","description":"","tags":null,"title":"分布式 003——互斥","uri":"/tech/distributedsystem/ds003_mutex/"},{"categories":null,"content":"分布式系统有哪些指标？？ 前言 经过上一篇博客，我们简单了解了分布式的起源，对于分布式技术有了一个整体的印象。这篇内容将会回归理性，一起来看看可以用哪些指标来具体地衡量一个分布式系统。\n从分布式技术的起源可以看出，分布式系统的出现就是为了用廉价的、普通的机器解决单个服务器处理复杂、大规模数据和任务所存在的性能问题、资源瓶颈问题，以及可用性和可扩展性问题。因为我们知道如果要想使得一台机器能兼顾所有的性能，成本是非常昂贵的。简单来说，分布式的目的就是用尽可能低的成本，处理更多的数据和更复杂的任务。\n由此可以看出，性能、资源、可用性和可扩展性是分布式系统的重要指标。接下来，就详细来逐个来了解一下。\n性能（Performance） 谈起性能指标，主要是用于衡量一个系统处理各种任务的能力，无论是分布式系统还是单机系统，都会对性能有所要求。\n不同的系统、服务要达成的目的不同，所以各自对于性能的要求也就会有所区别，甚至是相互矛盾的。这里我们来看几个常见的性能指标，分别是吞吐量、响应时间和完成时间。\n吞吐量指的是，单位时间内系统能够处理的请求或事务，能够表示系统的处理能力和效率。\n吞吐量的衡量可以根据具体应用场景而有所不同。例如，在网络通信中，吞吐量可以表示单位时间内传输的数据量；在数据库系统中，吞吐量可以表示每秒钟执行的查询数量；在并发用户访问网站时，吞吐量则可以表示每秒钟处理的请求数量。\n常见的吞吐量指标有 QPS（Queries Per Second）、TPS（Transaction Per Second）和 BPS（Bits Per Second）。\nQPS，即查询数每秒，用于衡量一个系统每秒处理的查询数，需要注意的是离开响应时间的要求是无法衡量 QPS 的。这个指标通用用于读操作，越高说明对读操作的支持越好。比如刚才我们所举的数据库的查询操作，就会用这个指标来表示。所以，我们在设计一个分布式系统的时候，如果主要都是偏向于读的操作，那么就需要重点考虑如何提高 QPS，来支持高频的读操作。 TPS，即事务数每秒，用于衡量一个系统每秒处理的事务数。这个指标通常对应于写操作，越高说明对写操作支持越好。那么如果需要设计一个以写请求的分布式系统，对于 TPS 的支持是需要关心的，从而达到支持高频的写操作； BPS，即比特数每秒，用于衡量一个系统每秒处理的数据量。对于一些网络系统、数据管理系统，我们不能简单的按照请求数或事务数来衡量其性能。因为请求与请求、事务与事务之间也存在着很大的差异，比如说，有的事务因为要写入更多的数据，所以比较大。那么在这种情况下，BPS 更能客观地反映系统的吞吐量。 响应时间指的是，系统响应一个请求或输入需要花费的时间。响应时间直接影响到用户体验，对于时延敏感的业务非常重要。比如我们出门时都会用到导航，如果响应时间过长，很容易带错路。\n完成时间指的是，系统真正完成一个请求或处理需要花费的时间。任务并行模式出现的其中一个目的，就是缩短整个任务的完成时间。特别是需要计算海量数据或处理大规模任务时，系统对完成时间的感受非常明显。\n资源占用（Resource Usage） 资源占用指的是，一个系统在正常运行时需要占用的硬件资源，比如 CPU、内存和硬盘等。\n一个系统在没有任何负载时的资源占用，叫作空载资源占用，体现了这个系统自身的资源占用情况。比如，我们手机上在安装一款新的 APP 的时候，在软件的详情页面都会标注出软件的大小，比如多少 KB。这就是该 APP 的空载硬盘资源占用。对于同样的功能，空载资源占用越少，说明系统设计的越整洁，往往也会更容易被用户所接受。\n一个系统满额负载时的资源占用，叫作满载资源占用，体现了这个系统全力运行时占用资源的情况，也体现了系统的处理能力。同样的硬件配置上，运行的业务越多，资源占用越少，说明这个系统设计的越好。\n可用性（Availability） 可用性，通常来说是指系统在面对各种异常时可以正确提供服务的能力。可用性是分布式系统的一项重要指标，衡量了系统的 Robustness，是系统容错能力的体现。\nRobustness 也就是中文翻译的“鲁棒性”，我是不太喜欢这个翻译的，让人不知所以然。主要指的是系统在面对异常、错误或不符合预期输入时的稳健性和能力。\n我们经常会在分布式系统中看见高可用这个词，也就是 7*24 不间断连续工作。那么系统的可用性可以用系统停止服务的时间与总的时间之比衡量。假设一个网站总的运行时间是 24 小时，在 24 小时内，如果网站故障导致不可用的时间是 6 个小时，那么系统的可用性就是 6/24=0.25，也就是有四分之一的时间处于不可用阶段。\n除此之外，系统的可用性还可以用某功能的失败次数与总的请求次数之比来衡量，比如给网站发送 1000 次请求，其中有 10 次请求失败，那么可用性就是 99%。\n提到了可用性，有的同学可能会疑惑，诶 这个和可靠性（Reliability）有何区别呢？\n可靠性通常用来表示一个系统完全不出故障的概率，更多地用在硬件领域。而可用性则更多的是指在允许部分组件失效的情况下，一个系统对外仍能正常提供服务的概率。\nJeff Dean 曾在 Google I/O 大会上透露：谷歌一个基于 1000 台通用计算机的集群，一年之内就有 1000+ 硬盘会出现故障。由于现在比较常见的分布式系统基本上都是基于通用计算机的，这就意味着在这些系统中无法实现真正的可靠，所以我们也会在一些场合见到可靠性和可用性交换使用的情况。\n可扩展性（Scalability） 可扩展性，指的是分布式系统通过扩展集群机器规模提供系统性能（吞吐量、响应时间、完成时间）、存储容量、计算能力的特征，是分布式系统的特有性质。\n分布式系统的设计初衷，就是利用集群多机的能力处理单机无法解决的问题。然而，完成某一具体任务所需要的集群规模，取决于单个机器的性能和任务的要求。\n当任务的需求随着具体业务不断提高时，除了升级系统的性能做垂直 / 纵向扩展外，另一个做法就是通过增加机器的方式去水平 / 横向扩展系统规模。\n这里垂直 / 纵向扩展指的是，增加单机的硬件能力，比如 CPU 增强、内存增大等；水平 / 横向扩展指的就是，增加计算机数量。好的分布式系统总是在追求“线性扩展性”，也就是说系统的某一指标可以随着集群中的机器数量呈线性增长。\n衡量系统可扩展性的常见指标是加速比（Speedup），也就是一个系统进行扩展后相对扩展前的性能提升。\n如果扩展的目标是为了提高系统吞吐量，则可以用扩展后和扩展前的系统吞吐量之比进行衡量。 如果目标是为了缩短完成时间，则可以用扩展前和扩展后的完成时间之比进行衡量。 总结 这篇内容读起来可能比较无聊，更偏向于科普类的介绍了一些常用的专业术语。需要注意的是，使用这些指标衡量一个分布式系统不能教条化。\n按照不同维度，分布式系统的指标可以分为性能、资源占用、可用性、可扩展性这四大类。我们当然也希望自己开发或者使用的系统，是高性能、高可用、可扩展和低资源同时占用的，但考虑到硬件成本、开发效率等因素，对于不同的系统和业务，必须在设计时做出取舍。\n","description":"","tags":null,"title":"分布式 002——分布式系统的指标","uri":"/tech/distributedsystem/ds002_norm/"},{"categories":null,"content":"分布式该从何谈起？？ 前言 现如今做开发，写代码出门和人聊天，动不动就会提起分布式，而且很多使用的框架、中间件都会采用分布式的设计。所以开阔自己的眼界，别做个 API Boy(Girl)。想了想开始试水写点相关的文章，一来梳理一下自己的学习心得，再者编写博客的过程中，也是对知识加强的一种途径。BTW 如果能帮助有些人就再好不过啦～～\n作为第一篇文章，先来看看分布式到底是什么。抛去那些抽象的的技术名词，该如何阐述这个概念呢？？\n注：为了更好地理解分布式的发展过程，默认每个计算机或服务器都是单核、单处理器的。\n分布式起源 从第一台计算机开始聊聊 世界上第一台通用计算机是在 1946 年情人节发布的 ENIAC，由于当时硬件水平的限制，就如大家所说的那样，占地面积大，还显得特别笨重，但在那个时候已经做到了每秒可进行 5000 次加法或者 400 次乘法运算，标志着单机模式的开始。\n从这方面来看，电脑的出现就是为了计算，其实现如今也不例外，如果有时间可以简单来谈谈计算，试着从莱布尼茨开始说起 哈哈。回归正题，所谓单机模式简单来说是指，所有应用程序和数据均部署在一台电脑或服务器上，由一台设备完成所有的处理。\n最近“双十一”，就以电商网站系统为例，删繁就简，只关注以下几个模块，分别是：用户管理、商品管理和订单管理。数据也就包括用户数据、商品数据和订单数据等。如果使用单机模式，那么所有的模块和数据均会部署在同一台计算机上，也就是说数据存储、请求处理均有同一个服务器来完成。这种模式的好处是功能、代码和数据更加集中，便于维护、管理和执行。\n单机模式的示意图，如下所示：\nEvery coin has two sides. 那么单机部署的缺点是什么呢？？单个计算机的处理能力取决于 CPU 和内存等，但硬件的发展速度和性能是有限的（可以看看摩尔定律），而且升级硬件的成本也比较高，可以说硬件的性能是单机模式的瓶颈。还有就是如果当前将所有的任务都交给一台服务器，可能会承受较大的负载压力，或者受到攻击挂了的话，所有的服务也就不能正常运行了，这也就将所有鸡蛋放到一个篮子里的风险，也就是单点失效问题。\n顺着这个思路往下走，既然单机模式存在性能的瓶颈，也就会导致会存在可用性的问题，有没有更好的解决办法呢？\n数据并行 为解决单机模式的问题，并行计算得到了发展，也就是我们常说的 MapReduce，并进一步出现了数据并行模式，也有的人喜欢称之为数据分布式模式。并行计算采用消息共享模式使用多台计算机并行运行或执行多项任务，核心原理是每台服务器上执行相同的程序，将数据进程拆分到不同的服务器上进行计算。\n需要注意的是，并行计算强调的是对数据进行拆分，任务程序在每台机器上运行。要达到这个目的，首先要做的是把单机模式中的应用和数据分离，才可能实现对数据的拆分。这里的应用就是执行任务的程序，任务就是提交的请求。还是来看上面的这个例子，运行在服务器上的用户管理、商品管理和订单管理等程序都是应用，用户提交的查询浏览商品、购买商品的请求就是任务。\n在单机模式中，应用和数据均在一台计算机或服务器上，要实现数据的并行，必须先将应用和数据分离以便将应用部署到不同的计算机或服务器上；然后，对同类型的数据进行拆分，比如说，不同计算机或服务器上的应用可以到不同的数据库上获取数据执行任务。\n这么讲可能比较抽象，来看看图：\n第一步，将应用与数据分离，分别部署到不同的服务器上。\n第二步，对数据进行拆分，比如把同一类型的数据拆分到两个甚至更多的数据库中，这样应用服务器上的任务就可以针对不同数据并行执行了。\n对于电商销售系统，根据商品类型将用户、商品和订单数据拆分到不同的数据库中，部署到不同的服务器上，比如运动鞋服类的数据放在数据库服务器 1 上，电脑数据的数据放在数据库 2。\n这种模式的好处是，可以利用多台计算机并行处理多个请求，使得我们可以在相同的时间内完成更多的请求处理，解决了单机模式的计算效率瓶颈问题。但这种模式仍然存在如下几个问题，在实际应用中，我们还需要进行相对应的优化：\n相同的应用部署到不同的服务器上，当大量用户请求过来时，如何能比较均衡地转发到不同的应用服务器上呢？这也就是我们常说的“负载均衡”的问题，等后期有时间再展开聊聊； 当请求量较大时，对数据库的频繁读写操作，会导致数据库的 IO 访问成为瓶颈。这种就可以使用“读写分离”的模式，也就是“主从库”的方式来解决，主数据库负责读写操作，然后再同步数据给从库，从而可以做到读数据库只接收读请求，写数据库只接收写请求，需要注意的是保证数据一致性； 当有些数据成为热点数据时，会导致数据库访问频繁，压力增大。解决这个问题的方法是引入缓存机制，将热点数据加载到缓存中，一方面可以减轻数据库的压力，另一方面也可以提高查询效率。 由此我们可以看出，数据并行模式实现了多请求并行处理，但如果单个请求特别复杂，比如说需要几个小时甚至几天的时候，这种模式的整体计算效率还是不够高。其主要问题是：对提升单个任务的执行性能及降低时延无效。\n任务并行 既然数据并行是存在一定缺陷的，我们就可以想是不是可以提高单个任务的执行性能，或者缩短单个任务的执行时间呢？也就出现了任务并行的模式，有的人可能喜欢称之为“任务分布式”，都是一个概念。\n任务并行指的是，将单个复杂的任务拆分为多个子任务，从而使得子任务可以在不同的计算机并行执行。\n我们仍以电商销售系统为例，任务并行首先是对应用进行拆分，比如按照领域模型将用户管理、商品管理、订单管理拆分成多个子系统分别运行在不同的计算机或服务器上。简单来说就是，原本包括用户管理、商品管理和订单管理的一个复杂任务，被拆分成多个子任务在不同的服务器上执行。\n可以看出，任务并行模式完成一项复杂任务主要有两个核心步骤：首先将单任务拆分成多个子任务，然后让多个子任务并行执行。我们可以这样类比，任务拆分对应于部门领导，不同子系统对应不同的开发人员，不同子程序执行不同任务就像不同的程序员使用不同的技术栈一样，并且运行子系统或者子任务的计算机又可以组成一个服务。\n在这种模式中，由于多个子任务可以在多台服务器上运行，因此通过将同一任务待处理的数据分散到多个服务器上，在这些服务器上同事进行处理，就可以加快任务执行的速度。因为，只要一个复杂任务拆分出的任意子任务执行时间变短了，那么这个任务整体的执行时间也就相对而言变短咯。\n当然，任务分布式也存在一定的缺点，它在提供了更好的性能、扩展性、可维护性的同时，也带来了设计上的复杂性问题。毕竟对一个大型的复杂业务进行拆分并不是一件轻松的事情。从长远收益来看，这个短期设计上的阵痛是值得的。我们在平时也要注意多积累，有些技术可能仅仅是自己感兴趣，但不要因为短期内或公司的业务用不上就放弃不去学习，要有长远目标，慢慢多学一点点，回头来看会有不一样的感悟噢～～\n分布式是什么？？ 看到这里，有些人就可能会觉得，啰里八嗦讲了一堆，诶 分布式到底是什么呢？\n用大白话说来说分布式就是，将相同或相关的程序运行在多台服务器上，从而实现特定目标的一种计算方式。\n从这个角度来看，数据并行、任务并行其实都可以算作是分布式的一种形态。从这些计算方式的演变中不难看出，产生分布式的最主要原因是，数据量的暴增，如何更有效地追求高性能、可用性以及可扩展性。。\n总结 这篇博客，简单聊了分布式的起源，从最初的单机模式到数据并行，再到任务并行。起初我是想从 GFS 和 MapReduce 的角度来阐述，但脱离业务，从数据出发可能会让不懂大数据的同学来说有点抽象，分布式文件系统和分布式计算引擎等后期有时间再拎出来单独唠唠（开始挖坑叻。。。）\n单机模式指的是，所有业务和数据均部署到同一台机器上。这种模式的好处是功能、代码和数据集中，便于维护、管理和执行，但计算效率是瓶颈。也就是说单机模式性能受限，也存在单点失效的问题。\n数据并行（也叫作数据分布式）模式指的是，对数据进行拆分，利用多台计算机并行执行多个相同任务，通过在相同的时间内完成多个相同任务，从而缩短所有任务的总体执行时间，但对提升单个任务的执行性能及降低时延无效。\n任务并行（也叫作任务分布式）模式指的是，单任务按照执行流程，拆分成多个子任务，多个子任务分别并行执行，只要一个复杂任务中的任意子任务的执行时间变短了，那么这个业务的整体执行时间也就变短了。该模式在提高性能、扩展性、可维护性等的同时，也带来了设计上的复杂性问题，比如复杂任务的拆分。\n在数据并行和任务并行这两个模式的使用上，用户通常会比较疑惑，到底是采用数据并行还是任务并行呢？一个简单的原则就是：任务执行时间短，数据规模大、类型相同且无依赖，则可采用数据并行；如果任务复杂、执行时间长，且任务可拆分为多个子任务，则考虑任务并行。在实际业务中，通常是这两种模式并用。\n","description":"","tags":null,"title":"分布式 001——聊聊分布式的起源","uri":"/tech/distributedsystem/ds001_introduce/"},{"categories":null,"content":"十月杂谈——人生海海，愿有岸有帆 关于假期 十月的开始，是在放假诶，真的很棒！调休了一天，提前回家，没有什么比放假更开心的事情啦～～\n回上海之后，顺路去看了一下 KubCon，emmm 可能是去的比较晚了吧，收摊收的比较早，就简单地逛逛转转就回父母那边了。也许是比较累了，早上起的有点早。作为一名云原生小白，会感到自己有很多知识需要去补，先从基础知识抓起吧。\n与国庆相邻的是中秋🎑，之前读大学的时候，对于中秋的定位是比较尴尬的，因为假期时间短，也就很少回父母身边，本应该是团圆的日子，结果却发出“如果很想念的话，就抬头看看月亮吧”的感叹。这两年倒还不错，能和家人团聚在一起。但随之而来的就是长辈们的“亲切问候”。细节就不想说了，也就是大家所常聊的那些，但对我来说，不太喜欢。我放弃了很多看似很好的选择，只想活成我想要的样子，我也不知对或错，我也不知该往哪走，但我知道自己想要的是什么，也大概知道下一个目标在哪，二十刚出头，走点弯路很正常的嘛。\n我一直提倡的一个观点，就是要想自己完全独立，首先需要做的就是经济独立，从而才能保证人格独立。所以，从大学阶段我就几乎“断奶”了。目前工作的收入，也差不多够日常的支出，再通过技术变现，积累点小的财富。我也不知从何开始，突然觉得，如果手里的余额低于某个数，很会不安全感。多备一点，以防不时之需嘛。而且，我也感觉到自己的观点与长辈们相冲突，但至少我独立了，他们也无可奈何我。随着时间的推移，矛盾终会爆发，但我不想向生活低头，emmm 至少现在还不想。\n假期中，还和朋友吃了烤肉，最后又去逛了逛卡普空周边店，只是单纯想看看怪猎 IP 的周边，不由的想说二次元的钱真好赚，虽然很多东西看着就有买的欲望，对我来说，只要不是“强需求”就没必要。我也就逛逛而已了嘛。\n假期的最后，去了无锡看 2023CYML，受“口罩😷”的影响，好久没见过这么热闹的线下比赛了。本来准备参赛的，一分钟都排好了，结果最后半个月发生了腱鞘炎，可能是练球练多了，也可能是打游戏打的，总不能说是写代码写的吧，呜呜呜呜，天朝苦命打工人😭。其实，反过来想，单纯的做一名观众也挺舒服的，没有比赛的负担，可以更轻松地去看比赛。其中，也不得不感叹，很多新面孔，很刷，但预赛看起来很容易审美疲劳，差不多的音乐，差不多的穿搭，玩着差不多的招。决赛的话，我最喜欢的应该是 shy 的“青鸟”，完成度很高，编排看起来也很舒服。\n然后就假期结束，回杭州躺一天，准备上班叻。\n身体状态 自从去年阳了之后，会感觉到身体素质大不如从前，也可能是年纪大了（bushi。。\n有假期就有补班，吐槽一句调休是什么勾八政策，直接多给几天假期不就得了，今年除夕不放假，把老祖先的传统都给丢咯。\n回归正题，回来上班之后，突然头疼难受，然后还发热🥵 就觉得该不会是自己又阳了吧，至于是几阳，我也不知道，反正只要我不测，我就没阳，是不是这个道理。。。实在无语，三年防疫，最后依托答辩呢。过去的事情就不提了，但仔细一想，如果后半辈子都是这种状态，当社畜上着班，然后隔段时间给你来一下，唉 生活没了盼头。买药的时候，也会想着，现在是不是穷人都不配生病了？？现实就是结结实实的灰色幽默。\n身体差了肯定是要练的嘛， 然后就和室友去开始尝试撸铁。第一周说不好的痛苦，练哪哪疼，一疼疼几天，以至于周六和朋友干饭的时候，走路都一歪一歪的。到了第二周的时候，身体慢慢习惯了，虽然有点酸痛，但都属于能够接受的范围，也开始逐渐接受这个强度，开始慢慢喜欢上了。写这篇博客的时候是第三周，也还是好累啊。\n总体来说，虽然有点累，但还是挺享受的，工作避免不了久坐，还喜欢下意识的喜欢跷二郎腿，这都是不好的，要改。每天下班，撸完铁，做好有氧，回到家里，洗个澡。属于自己的夜生活也正式开始咯。可能是看看书，可能是打打游戏 写写代码，最后顶着疲惫不堪的身体入睡。\n还是想看看健身两个月之后的样子，虽然目前看起来没啥效果，也可能是自己比较偏瘦，身体显得不是很壮，但还是挺怕吃重了之后，万一不健身了的时候，身体变得臃肿可咋办呢，hhhh。\n哦对了，还有点想买 iWatch，算了，不是强需求没必要买。不是为了健身而买手表，更不会为了买手表而健身，只会徒增烦恼罢了。\n读书 这个月读了两本书，第一本是《长安的荔枝》，属于畅销网文小说类型的，本来对于这类书籍是不太喜欢的，但同事推荐说挺好看的，然后假期往返途中，在高铁上用 iPad 看完的，好久没用 iPad 看过书了，随着想扩宽自己的技术路线，对于闲书读的是越来越少，大不如从前几年。这本书讲还是比较浅显易懂的，侧面反应的是人心，里面比较好的点大概是几处转折。虽然最后完成了任务，但却失去了很多，我们不也正是这样嘛，一边在得到，一边在失去，得到了之后，会发现不如自己当时所期待的，失去了的，有可能是再也无法挽回的。知足常乐就好～～\n第二本是麦家老师的《人生海海》，这本书越读到后面，越没有勇气往下读，就很难受。也许就像是书里所阐述的观点：真正的英雄主义，不是勇敢地去死，而是勇敢地选择活着。谈谈几个印象比较深的点吧。首先是老巫头，从“我”的角度代入故事，自然对于一肚子大道理的爷爷很敬佩，但也恰恰是这些繁文缛节，被条条框框所限制，被周围人的看法所影响，从而选择告密。“我”多么希望这是假的啊，但却是事实。。当时老保长说上校当兵在前线的事情，我甚至一度怀疑，老保长说的是假的，毕竟印象不太好，谎话连篇也不足为奇，一个英雄的故事，结果却从他口中来阐述，总觉得有点别扭。还有就是林阿姨和上校的爱情故事。一开始觉得上校有点吊不琅珰的，读到后面发现，真的 emmm 说不好的难受。不知以这种方式安排他俩在一起，是不是算是相互救赎呢🙏。最后就是，小瞎子学会上网之后，污蔑“我”的父亲是鸡奸犯，“我”的内心也是很痛的，不相信、不理解、埋怨、愤恨都有，后期父亲还想着给小瞎子找大夫，结果却因为“这层原因”，让我觉得很脏。比较庆幸的是在林阿姨家看见上校的“金子”，也就放下心来。我现在大概率是不会同情小瞎子这类人，反而该死，最好是死的透透的，可怜之人，必有可恨之处。\n我小时候，心是比较软的，看不得任何苦难，随着自己的成长，慢慢没了这种感觉，或者是把这种想法深深藏了起来，不想让别人看见，显得自己是无懈可击的。也有可能是，自己的现状是靠自己一步一步熬过来的，所以看见碌碌无为的人，总会觉得是他们自身造成的，也就不值得同情。\n写在最后 这个月算是又开始了新的尝试——健身，但牺牲的是自己的时间。近期会感觉有点力不从心，需要进一步提高效率，把更多的时间放在基础知识的学习上。还有就是开始尝试读读《毛泽东选集》，察势者明，趋势者智。\n","description":"","tags":null,"title":"人生海海，愿有岸有帆","uri":"/life/23_10-life/"},{"categories":null,"content":"集群：如何构建分布式的消息队列集群（下） 我们接着上一讲的内容，继续来看如何构建集群。先来看元数据存储服务的设计选型。在消息队列的集群架构中，元数据存储服务的选型和实现是整个架构设计的核心，其他模块的设计都是围绕着元数据存储服务来展开的。\n元数据存储服务设计选型 如果博客一路看到这篇的话，想必对于下面的内容并不会感觉到陌生。我们知道业界主要有基于第三方存储引擎和集群内部自实现元数据存储两种方案。先来分析一下这两种方案的具体实现。\n基于第三方存储引擎 这个方案最重要的一件事就是组件选型。\n从技术上来看，一般只要具备可靠存储能力的组件都可以当作第三方引擎。简单的可以是单机维度的内存、文件，或者单机维度的数据库、KV 存储，进一步可以是分布式的协调服务 Zookeeper、etcd 等等。\n正常来说，在设计的时候，结合自身的业务需求选择一中存储引擎就行。但是也有如 Pulsar 支持插件化的元数据存储服务，用来简化不同场景下的部署成本，比如单机运行、集成测试、线网部署等等。\n从分布式的角度来看，单机维度的存储能满足的场景有限，也会有单机风险。所以处于实际生产需求考虑，一般都会选用分布式的协调服务，比如使用 Zookeeper、etcd 等来当集群的元数据存储服务。所以基于第三方存储引擎的集群架构图一般如下所示：\n在这个架构图中，如果把元数据服务替换成 Zookeeper，也就成了 Kafka 和 Pulsar 的架构了。\n如图所示，这是一个有单独的元数据存储集群和多台 Broker 节点组成的消息队列集群。Broker 连接上 Metadata Service 完成节点发现、探活、主节点选举等功能。其中 Controller 的角色是由某一台 Broker 兼任的。\n细心的小朋友可能已经发现，图中 Controller 和 Metadata Service 是分开的，各自都承担着不同的职责。Controller 是无状态的，因为它不负责保存数据，只负责计算逻辑。所以在这种情况下，一般就会让集群中的某台 Broker 来承担 Controller 的功能。当这台 Broker 挂了后，可以依赖元数据存储服务把 Controller 切换到新的 Broker。因为它是无状态的，所以切换是非常快的。\n但使用这种方案，集群中最少得有 6 个节点，这会导致部署成本、运维复杂度变高。那有没有可能简化架构呢？？我们继续啊来看集群内部实现元数据存储的方案。\n集群内部自实现元数据存储 简单来说，可以通过在多台 Broker 的进程中实现分布式的元数据存储，从而解决依赖第三方组件的一些弊端。整体架构如下图所示：\n从技术实现上来看，主要有三种思路：\n直接在 Broker 内部构建一个小型的元数据存储集群来提供服务； 通过某些可以内嵌到进程的小型的分布式存储服务来完成元数据的存储； 通过某些可以内置的单机持久化的服务，配合节点间的元数据同步机制来完成元数据的存储。 第一种方案需要在 Broker 中实现一个元数据集群。这个元数据集群和 Broker 集群最大的差别在于它只需要承担单个集群的元数据管理存储，数据量和规模很小，集群一般不需要扩容。所以这个集群适合使用“通过配置发现节点的方案”来构建集群。Kafka 的 KRaft 架构用的就是这种方案。\n第二种方案是利用某种可以内嵌到进程的存储服务来存储元数据，比如 Mnesia 或 RocksDB。如果是单机的存储引擎，比如 RocksDB，那么主要适用于单机部署的场景。单机存储引擎的方案如果要实现元数据的集群化，那么就得在节点之间实现相互同步数据的机制，这个就相对复杂许多。而如果是分布式的存储引擎，如 Mnesia，那么就简单许多，几乎没有工作量，直接调用存储引擎的接口存储元数据即可。\n第三种方案是在节点上部署一个持久化的单机存储引擎，如 RocksDB 等。然后在 Broker 内维护节点间的元数据数据的一致性。这种方式也是一种实现比较简单的方案，开发难度低于第一种方案，高于第二种方案。\n从业界实现来看，目前第一种和第二种方案都有在使用。第三种方案主要用在单机模式下，问题是要维护多个节点的存储服务之间的数据一致性，有一定的开发工作量，并且保持数据强一致比较难。\n总结来看，在集群中实现元数据服务的优点是，后期架构会很简洁，不需要依赖第三方组件。缺点是需要自研实现，投入研发成本比较高。而如果使用独立的元数据服务，产品成型就会很快。这也是当前主流消息队列都是依赖第三方组件来实现元数据存储的原因。\n接下来，我们就用实际案例结合前面这些基础知识点，来看一下 Zookeeper、Kafka 是如何构建集群的。\nZookeeper 的集群构建 Zookeeper 是一个分布式的数据协调服务，本质上是一个简单的、分布式、可靠的数据存储服务。核心操作就是数据的写入、分发、读取和 Hook。从客户端看，主要操作就是写入喝读取。从服务端看，主要操作就是集群构建、数据接收、存储、分发和 Hook。\n在集群构建上，它会事先在配置中定义好集群中所有节点的 IP 列表。然后集群启动时，会在这些几点之间进行选举，经过多数投票机制，选举出一个 Leader 节点，从而构建成为集群。在单节点上，集群构建相关的配置一般如下所示，配置中会包含所有节点信息。\n1 2 3 server.0=hadoop102:2888:3888 server.1=hadoop103:2888:3888 server.2=hadoop104:2888:3888 在节点启动的时候，节点之间就会两两进行通信，触发投票。然后根据票数的多少，基于多数原则，选举出一个 Leader 出来。当 Leader 节点发生宕机或者增加节点时，就出重新触发选举。\n多数投票是一个经常用到的投票机制，即某个节点获得票数超过可投票的节点的一半后，就可以当选为 Leader。从实现角度，一般是通过集群中节点之间的通信和间隔随机投票的机制来完成投票，以保证能够在短时间内完成选举。\n当选举完成后，Leader 会主动给各个 Follower 节点发送 ping-pong 请求，以确定节点是否还活着。当 Follower 心跳异常时，就会剔除该节点，当集群中可用的节点数少于总节点数的一半，就会选举不出 Leader，从而导致集群异常。\n因为 ZooKeeper 只是一个数据存储服务，并没有很多管控操作，Leader 节点就负责数据的写入和分发，Follower 不负责写入，只负责数据的读取。当 Leader 收到操作请求时，比如创建节点、删除节点、修改内容、修改权限等等，会保存数据并分发到多个 Follower，当集群中有一半的 Follower 返回成功后，数据就保存成功了。当 Follower 收到写入请求时，就把写入请求转发给 Leader 节点进行处理。\n因为功能和定位上的差异，ZooKeeper 上是没有 Controller 和元数据存储的概念的。它是比较典型的基于固定配置构建集群的方式。\nKafka 的集群构建 之前我们有说过，目前主流消息队列的集群主要是基于第三方组件来构建的。而 Kafka 正是这种方案的典型实现，接下来我们就看一下 Kafka 基于 Zookeeper 和基于 KRaft 构建集群的两种实现方式。\n基于 Zookeeper 的集群 在这种架构中，Kafka 将 Zookeeper 作为节点发现和元数据存储的组件，通过在 Zookeeper 上创建临时节点来完成节点发现，并在不同的节点上保持各种元数据信息。\nBroker 在启动或重连时，会根据配置中的 Zookeeper 地址找到集群对应的 Zookeeper 集群。然后会在 ZooKeeper 的 /broker/ids 目录中创建名称为自身 BrokerID 的临时节点，同时在节点中保存自身的 Broker IP 和 ID 等信息。当 Broker 宕机或异常时，TCP 连接就会断开或者超时，此时临时节点就会被删除。\n注册完这些信息后，节点发现就算完成了。节点之间的探活依赖 ZooKeeper 内置的探活机制，前面讲过，这里不再赘述。接下来来看一下 Kafka 中的 Controller。\n在 Kafka 中，Controller 是一个虚拟概念，是运行在某台 Broker 上的一段代码逻辑。集群中需要确认一台 Broker 承担 Controller 的角色，那 Controller 是怎么选出来的呢？我们来看一看。\nKafka 的 Controller 选举机制非常简单，即在 ZooKeeper 上固定有一个节点 /controller。每台 Broker 启动的时候都会去 ZooKeeper 判断一下这个节点是否存在。如果存在就认为已经有 Controller 了，如果没有，就把自己的信息注册上去，自己来当 Controller。集群每个 Broker 都会监听 /Controller 节点，当监听到节点不存在时，都会主动去尝试创建节点，注册自己的信息。哪台节点注册成功，这个节点就是新的 Controller。\nController 会监听 ZooKeeper 上多个不同目录，主要监听目录中子节点的增加、删除，节点内容变更等行为。比如会通过监听 /brokers/ids 中子节点的增删，来感知集群中 Broker 的变化。即当 Broker 增加或删除时，ZooKeeper 目录中就会创建或删除对应的节点。此时 Controller 通过 Hook 机制就会监听到节点发生了变化，就可以拿到变化节点的信息，根据这些信息，触发后续的业务逻辑流程。\nKafka 集群中每台 Broker 中都有集群全量的元数据信息，每台节点的元数据信息大部分是通过 Controller 来维护的，比如 Topic、分区、副本。当这些信息发生变化时，Controller 就会监听到变化。然后根据不同的 Hook（如创建、删除 Topic 等），将这些元数据通过 TCP 调用的形式通知给集群中其他的节点，以保持集群中所有节点元数据信息是最新的。\n可以看下图，我们用 Topic 的创建流程，来串联集群中的 Controller 的集群管理和元数据存储。\n如图所示，Kafka 创建 Topic 有两种形式（图中 1 和 2），即通过 Broker 来创建和通过 ZooKeeper 来创建。当调用 Broker 创建 Topic 时，Broker 会根据本地的全量元数据信息，算出新 Topic 的分区、副本分布，然后将这些数据写入到 ZooKeeper。然后 Controller 就会 Hook 到创建 Topic 的行为，更新本地缓存元数据信息，通知对应的 Broker 节点创建分区和副本。 所以，也可以通过直接生成计划然后、写入到 ZooKeeper 的方式来创建 Topic。\n基于 KRaft 的集群 从架构的角度，基于 KRaft 实现的 Kafka 集群做的事情就是将集群的元数据存储服务从 Zookeeper 替换称为内部实现的 Metadata 模块。这个模块会同时完成 Controller 和元数据存储的工作。\n我们前面讲过，集群元数据需要分布式存储才能保证数据的高可靠。所以 Kafka KRaft 架构的 Metadata 模块是基于 Raft 协议实现的 KRaft，从而实现元数据可靠存储的。\n因为 Kafka 的 Metadata 模块只需要完成元数据存储，所以它的设计思路和 ZooKeeper 是一样的，是主从架构。即通过在配置文件中配置节点列表，然后通过投票来选举出 Leader 节点。这个节点会承担集群管控、元数据存储和分发等功能。\nMetadata 模块的配置如下所示。即通过配置项 controoler.quorum.votes 配置允许成为 Controller 的节点列表，然后这些节点之间会通过投票选举出 Leader 节点，这个 Leader 会完成 Controller 和元数据存储的工作。这个 Leader 相当于基于 ZooKeeper 版本中的 Controller 和 ZooKeeper 的 Leader。\n1 2 process.roles=broker,controller controller.quorum.voters=1@localhost:9093 所以在这个版本架构的实现中，就只有 Controller 了，然后 Controller 自带了元数据存储的功能。Broker 之间通过投票选举出来的 Leader 节点就是 Controller。此时，所有 Broker 都会和 Controller 保持通信，以维护节点的在线状态，从而完成节点发现。当 Controller 发现 Broker 增加或异常时，就会主动执行后续的操作。\n所以，从链路来看，这个架构简化了通过监听 ZooKeeper 来发现节点变更的流程，链路更短，稳定性更高。和基于 ZooKeeper 的架构一样，每台 Broker 依旧有集群全量的元数据信息，这些元数据信息的维护也是通过 Controller 完成的。\n接下来，我们来看一下 KRaft 架构下创建 Topic 的流程，来看下图：\n这里因为没有 ZooKeeper，所以创建 Topic 只有通过 Broker 创建的方式。通过 Admin SDK 调用 Broker 创建 Topic，如果 Broker 不是 Controller，这个请求就会转发到当前的 Controller 上。Controller 会根据本地的元数据信息生成新 Topic 的分区、副本的分布，然后调用对应的 Broker 节点完成分区和副本数据的创建，最后会保存元数据。\n其他的操作，比如删除 Topic、修改配置、创建 ACL 等流程是一样的。更多细节如果感兴趣的话，可以去看一下官方的 KIP。\n讲到这里，你会发现基于 KRaft 的 Kafka 架构比基于 Zookeeper 架构简单清晰非常多，操作链路也短很多。这样可以解决基于 Zookeeper 架构中一些难以解决的问题，如集群可承载分区数量上限较低，缓存不一致等等。\n总结 目前，消息队列的主流实现方式都是依赖第三方组件来完成数据存储，常见的有 ZooKeeper、etcd 等。为了简化架构，我们还可以通过在集群内自建元数据存储服务来替代第三方组件，虽然需要研发投入，但从架构长期演进的合理性来看，我是推荐这种方式的，毕竟后期架构会很简洁。\nZooKeeper 集群的组件，是基于配置文件中指定集群中其他节点的 IP 地址和端口来实现节点发现的，属于单播发现机制。这种方式的缺点就是扩容需要修改配置、重启集群。所以，还有一种通过配置多播地址和端口来实现集群发现的方式，其好处是可以动态发现节点，属于单播的一种升级，目前 Elasticsearch 和消息队列 RabbitMQ 都属于多播的实现。从 Kafka 的集群构建来看，基于独立的元数据存储服务，会导致架构复杂和引入缓存不一致等问题。集群内部实现元数据存储，可以简化架构，避免不一致。从技术合理性来看，或许尝试内置元数据存储是个不错的方案。\n","description":"","tags":null,"title":"MQ010——分布式消息队列（下）","uri":"/tech/bigdata/bigdata_mq010/"},{"categories":null,"content":"集群：如何构建分布式的消息队列集群？（上） 有状态服务和无状态服务 在正式讲解如何构建一个分布式的消息队列集群之前，我们可以先来了解一下什么是有状态服务，以及什么是无状态服务。\n这两个词在我们日常开发中也是经常遇到的，这二者之间最重要的一个区别在于：是否需要在本地存储持久化数据。简单来说就是，需要在本地存储持久化数据的就是有状态服务，反之就是无状态服务。\n说这两个，主要是因为有状态服务和无状态服务构建集群的思路完全是不一样的。HTTP Web Server 就是典型的无状态服务。在搭建 HTTP Web 集群的时候，我们经常会使用 Nginx 或者其他网关后面挂一批 HTTP 节点，此时后端的这批 HTTP 服务节点就是一套集群。\n如上图所示，因为 HTTP Web 是无状态的服务，不同的节点不需要知道其他节点的存在。Nginx 认为后端所有的节点的功能是一样的，所以请求经过 Nginx 后，只需要根据一定转发策略，如轮询、加权轮询、按 Key Hash 等将请求转发给后端的 Web 服务节点即可。然后在节点增减的时候，Nginx 会感知到节点的增减。执行转发或者不转发就可以咯。\n至于消息队列通常来说都是有状态服务。消息是和分片绑定，分片是和节点绑定。所以，当需要发送一个消息后，就需要发送到固定的节点，如果把消息发送到错误的节点，就会失败。所以，为了将消息发送到对的节点和从对的节点削峰数据，消息队列在消息的收发上，就有服务端转发和客户端寻址两种方案。\n所以，消息队列集群应该是按照有状态来设计的。接下来，我们就看看如何设计出一个集群化的消息队列服务。\n消息队列的集群设计思路 当前业界主流的分布式集群，一般都是基于主从（Master/Slave）思想来设计的。即通过一个组件来管理整个集群的相关工作，比如创建和删除 topic、节点上下线等等。这个组件一般叫做 Master 或 Controller。\n然后还需要有一个组件来完成集群元数据（比如节点信息、Topic 信息等等）的存储，这个组件一般叫做元数据服务。当然还有一批数据流节点来完成数据的读写和存储工作，这个组件一般叫做 Broker。\n元数据存储 我们先来看一下集群中的元数据是如何存储的。\n消息队列集群元数据是指集群中 Topic、分区、配置、节点和权限等信息。元数据必须保证可靠、高校的存储，不允许丢失。因为一旦元数据丢失，其实际的消息数据也会变得没有意义。\n从技术上看，业界主要有第三方存储引擎和集群内部自实现存储两种方案。\n依赖第三方存储引擎是指直接使用第三方组件来完成元数据信息的存储，比如 Zookeeper、etcd、单机或分布式数据库等等。这种方案的优点是拿来即用，无需额外的开发成本，产品成型快，稳定性较高。缺点是需要依赖第三方组件，会增加额外的部署维护成本，并且受限于第三方组件的瓶颈和稳定性，也可能会有数据一致性问题。像 Kafka、Pulsar 基于 Zookeeper 都是用的这种方式。\n集群内部自实现存储是指在消息队列应用内部自定义实现元数据存储服务，相当于在消息队列集群中实现一个小型的 Zookeeper。这种方案的优点是集群内部集成了这部分能力，部署架构就很简单轻量，应用自我把控性高，不会有第三方以来问题。缺点是开发成本较高，从头开始自研，相对于成熟组件而言，稳定性上短期内会比较弱，需要投入时间打磨。Kafka 去 Zookeeper 后的 KRaft 架构中的元数据存储，就是基于这个思路实现的。\n节点发现 接下来，我们一起看看看如何完成节点发现。我们知道集群是由多个节点组成的，此时组成集群的最基本要求就是：所有节点知道对方的存在或者有一个组件知道所有节点的存在，这样才能完成后续的集群管理和调度。这个过程就是节点发现的过程。\n从技术上看，当前业界主要有配置文件、类广播机制、集中式组件三种手段来完成节点发现。\n配置文件：通过指定文件配置所有节点 IP，然后节点启动后根据配置文件去找到所有的节点，从而完成节点发现。 类广播机制：通过广播、DNS 解析等机制，自动去发现集群中所有节点。比如通过解析 DNS 域名，得到域名绑定的所有 IP，从而发现集群中所有节点。 集中式组件：所有节点都向集中式组件去注册和删除自身的节点信息，此时这个组件就会包含所有节点的信息，从而完成节点发现。 第一种方案的好处是实现简单，在节点发现这块几乎不需要额外的开发成本，缺点就是集群扩容需要修改配置文件，水平扩容不方便，需要重启。比如 Zookeeper 和 KRaft 就是用的这种方案。\n第二种方案好处是可以自动发现新节点，自动扩容集群。缺点是开发成本很高，需要通过广播或者类似的机制发现集群中的其他节点。\n第三种的好处是可以动态地感知节点的变更，水平扩容非常方便，实现也简单。所以当前主流消息队列都是用的这种方案。Kafka 基于 Zookeeper 的版本，RocketMQ 和 Pulsar 都是用的这种方案。\n完成节点后，接下来就需要能够感知节点的变更，以便在节点故障时及时将其踢出集群。而这种动作就得依靠节点探活来实现。\n节点探活 从实现角度来看，一般需要有一个角色来对集群内所有节点进行探活或者保活，这个角色一般是主节点或第三方组件。\n如下图所示，技术上一般分为主动和定时上探测两种，这两种方式的主要区别在于心跳探活发起方的不同。从技术和实现上看，差别都不大；从稳定性来看，一般推荐主动上报。因为由中心组件主动发起探测，当节点较多时，中心组件可能会有性能瓶颈，所以目前业界主要的探活实现方式也是主动上报。\n从探测策略上看，基础都是基于 ping-pong 的方式来完成探活。心跳发起一般会根据一定的时间间隔发起心跳探测。如果保活组件一段时间没有接收到心跳或者主动心跳探测失败，就会提出这个节点。比如每 3 秒探测一次，连续 3 次探测失败就剔除节点。探测行为一般会设置较短的超时时间，以便尽快完成探测。\n以 Kafka 为例，它是基于 Zookeeper 提供的临时节点和 Hook 机制来实现节点保活的。即节点加入集群时会创建 TCP 长连接并创建临时节点，当 TCP 连接断开时就会删除临时节点。临时节点的变更会触发后续的相关操作，比如将节点加入集群、将节点剔除集群等等。\n所以基于 Zookeeper 实现节点发现和保活就很简单，只要通过 SDK 创建临时节点即可，只要 TCP 连接存活，临时节点就会存在。那么怎样确认连接存活呢？底层还是通过 ping-pong 机制、客户端主动上报心跳的形式实现的。\n因为 Zookeeper 具备这两个机制且组件相对成熟、稳定性较高，所以很多消息列队都会用 Zookeeper 来实现节点发现和探活。完成节点探活后，接下来我们看看集群的主节点是怎么选举出来的。\n主节点选举 从技术上看，理论上只要完成了节点探活，即节点健康的情况下，这批节点就都是能被选为主节点的。当然，有的集群可以配置哪些节点可以被选举为主节点，哪些节点不能被选举主节点，但是这点不影响后续的选举流程。\n主节点的选择一般有相互选举和依赖第三组件争抢注册两种方式。\n相互选举是指所有节点之间相互投票，选出一个得票最多的节点成为 Leader。投票的具体实现可以参考 Raft 算法，这里就不展开。目前业界 Zookeeper、ElasticSearch、Kafka KRaft 版本等都是用的这种方案。\n依赖第三方组件争抢注册是通过引入一个集中式组件来辅助完成节点选举。比如可以在 Zookeeper、etcd 上的某个位置写入数据，哪个节点先写入成功它就是 Leader 节点。当节点异常时，会触发其他节点争抢写入数据。依此类推，从而完成主节点的选举。\n在消息队列中，这个主节点一般称为 Controller，Controller 主要是用来完成集群管理相关的工作，集群的管理操作一般指创建和删除 Topic、配置变更等等行为。\n所以抽象来看，一般情况下消息队列的集群结构如下所示：\n其中，Metadata Service 负责元数据的存储，Controller 负责读取、管理元数据信息，并通过集群中的 Broker 执行各种操作。此时从实际架构实现的角度来看，Broker 的元数据上报可以走路径 1，通过 Controller 上报元数据到 Metadata Service，也可以直连 Metadata Service 走路径 2 上报元数据。两条路径没有明显的优劣，一般根据实际的架构实现时的选型做考虑。\n当完成元数据存储、节点发现、节点探活、主节点选举后，消息队列的集群就创建完成了。接下来我们通过集群启动、创建 Topic、Leader 切换三个动作来分析一下集群的运行机制。先来看一下集群启动的流程。\n消息队列的集群构建流程 集群启动 集群启动其实就是节点启动的过程，可以看下图：\n节点启动大致分为以下四步：\n节点启动时在某个组件（如图中的 Controller 或 Metadata Service）上注册节点数据，该组件会保存该节点的元数据信息； 节点注册完成后，会触发选举流程选举出一个主节点（Controller）； 节点会定期向主节点（或 Metadata Service）上报心跳用来确保异常节点能快速被剔除； 当节点异常下线或有新节点上线时，同步更新集群中的元数据信息。 从运行的角度看，完成这一步，集群就算已经构建完成了。接下来我们看看如何创建 Topic。\n创建 Topic 创建 Topic 大致分为以下四步：\n客户端指定分区和副本数量，调用 Controller 创建 Topic； Controller 根据当前集群中的节点、节点上的 Topic 和分区等元数据信息，再根据一定的规则，计算出新的 Topic 的分区、副本的分区，同事选出分区的 Leader（主分片）； Controller 调用 Metadata Service 保存元数据信息； Controller 调用各个 Broker 节点创建 Topic、分区、副本。 再来看看删除 Topic 和扩容分区是如何执行的。\n如果要删除 Topic，首先依旧要先往 Controller 发送一个删除 Topic 的指令；然后 Controller 会通知 Topic 分区所在的节点，删除分区和副本数据，删除 Topic；最后再删除 Metadata Service 中的 Topic 元数据/扩容分区的操作也是类似的，Controller 接收到扩容分区的指令，根据逻辑计算出新分区所在的节点，然后通知对应的节点创建分区，同时保存相关元数据。\nLeader 切换 Leader 切换的流程可以分为以下四步：\nController 会持续监听节点的存活状态，持续监控 Broker 节点是否可用； 根据一定的机制，判断节点挂掉后，开始触发执行 Leader 切换操作； Controller 通过 RPC 调用通知存活的 Broker2 和 Broker3，将对应分区的 Follower 提升为 Leader； 变更保存所有元数据。 从客户端的视角来看，服务端是没有机制通知客户端 Leader 发生切换的。此时需要依靠客户端主动更新元数据来感知已经发生 Leader 切换。客户端一般会在接收到某些错误或者定期更新元数据来感知到 Leader 的切换。\n总结 集群构建的思路分为有状态服务和无状态服务，两种类型服务的构建思路是不一样的。有状态服务需要解决元数据存储、节点发现、节点探活、主节点选举等四部分。\n元数据存储主要有依赖第三方组件实现和集群内自定义实现元数据存储两个思路。第三方组件主要有 ZooKeeper、etcd 等，依赖第三方组件是当前主流的选择，因为其实现较为简单，前期稳定性较高。自定义实现元数据存储是指在消息队列 Broker 集群内实现元数据存储服务，从而简化架构，实现虽较为复杂，但长期来看相对更合理。\n节点发现主要有静态发现和动态发现两个思路。静态发现是指通过配置文件配置好集群的所有节点，各个节点之间通过配置内容来发现对方，从而组建成一个集群。动态发现是指依赖一个中心组件或者类广播机制来动态完成节点之间的相互发现，即当节点上线或下线的时候，及时感知到变化，从而将节点加入到集群或者从集群中剔除。\n节点探活主要分为主动上报和定时探测两种，业界主要使用主动上报的实现形式。\n主节点在消息队列中一般叫做 Controller，一般通过节点间选举或者依赖第三方组件争抢注册来完成选举。Controller 主要用来完成集群内的管理类操作，如节点上下线、Topic 创建 / 删除 / 修改、Leader 切换等等。Controller 由集群中的某个 Broker 担任。\n","description":"","tags":null,"title":"MQ009——分布式消息队列（上）","uri":"/tech/bigdata/bigdata_mq009/"},{"categories":null,"content":"九月杂谈——置身事内的大梦 《西江月·世事一场大梦》〔宋〕苏轼\n世事一场大梦，人生几度秋凉？夜来风叶已鸣廊。看取眉头鬓上。\n酒贱常愁客少，月明多被云妨。中秋谁与共孤光。把盏凄然北望。\n标题名取之于这个月的的一本书《置身事内》和这几天最近在循环的一首歌《大梦》。\n随着“一个叫木头，一个叫马尾”，到“我看到人们漫步在路上”。九月也就随之结束了。这个月过的整体上还不错，似乎慢慢找到了自己的方向，并不断去奔向。这个过程很神奇，也是不断质疑自己，不断肯定自己的过程。\n谈谈生存 上个月和同事去过书店之后，就想着还是得读点闲书的嘛。于是在推荐下，选择了《置身事内》，jd 上买的，加上有京豆的折扣到手也就十几块钱，不由地感叹，在中国读书的成本真的是比较低的，可能也就是因为这样，导致很多人不珍惜读书的机会。\n《置身事内》这本书是从宏观与微观上来，讲解中国的经济变化，而且通读下来，很多内容都是自己刚好经历过的，或者说是未来可能要面对的。这本书写的比较通俗易懂，可以当作经济学科普类的读物来看，但写的也比较无聊，好几次看着看着就想睡觉。。。在现如今的环境下，如果有时间的话，还是值得一读的。\n简单说几个对我而言印象比较深的点吧。在说到京东方和合肥的故事，那一段只能说双方是互相成就彼此。当京东方选择定址的时候，接二连三被夏普插足。但合肥也是一个敢于“豪赌”的城市，面对前来搅局的夏普，当地政府给出“绝不动摇”的回复。并且给予大力的支持，从而得到发展。后来合肥选择蔚来也是如此。这不得不佩服合肥政府的魄力。大学是在合肥读的，但合肥给我的整体感觉是有冲劲，有目标，但实际在做的过程却似乎有点一塌糊涂，大学四年读完，整个城市没有发生什么实际性的变化。反观杭州，待了半年多，由于亚运会，真的是“造了一座城”。这也是体现书中所说的的一个观点，土地是一样的，但是所处的地理位置不同，价值也就不一样。那么这个观点是否可以来类比人呢？？这样想是不是有点太讽刺了。在华东地区，江浙沪属于房价比较高的城市，但在后疫情时代，大环境不稳定，经济下沉，房价也随之波动。拿余杭的房价来举例吧，未来科技城互联网行业比较多，但是现在裁员风波此起彼伏，人人自危，如果没有稳定的收入来源，谁敢轻易买房呢？？而且，如果买个房，按 500w 的预算，普通家庭夫妻双方每个月在经济条件允许的情况下，假设一共还 5w 的房贷，除去首付，还得还将近 10 年，这十年还得保证没有什么意外开支，如果有了小孩，又是一笔支出。在这个环境下，是否还有必要买房呢？？\n工作的“劣”与“良” 最近的工作挺无聊的，几乎不用写代码，总之似乎显得都不像是搞技术的，有点本末倒置。\n现在的市场，简单概括就是劣币驱逐良币，快速上线迭代，赚快钱，是目前国内大部分互联网企业都默认的选择。我一直认为好的作品是需要投入成本，花费时间和精力慢慢打磨的，但随之而来的问题就是，谁来为这个买单？？客户嘛，从甲方的角度来说，一般都是既要又要，当你生产内容的成本上去了，客户会真的觉得值得花这个钱嘛？？如果更便宜的，整体上大差不差的呢？？肯定会选择后者的。\n其实，在生活中来说，很简单。比如像现在国内的电商平台，一开始我极度反感 pdd 的，买东西都是天猫、京东居多。但后来，其他的平台要是想同等的优惠，还需要做活动，领券、拼单之类的操作，为了卷价格、用户留存率，运营方也是用尽了手段。从我的角度来说，是比较懒的，与其让我东拼西凑的，还不如直接原价购买，有一次偶然使用了 pdd，价格确实低一点，质量好像也没自己想要的那么糟糕，生活用品也会考虑从 pdd 下单。今年上半年，发现京东也发起了“百亿补贴”的活动，而且京东的服务和售后都是比较放心的，电子商品或者大件还是会考虑京东，多花钱少一点焦虑是值得的。再来看看淘宝，服务比不上京东，价格打不过 pdd。所以主流的电商平台，都最后价格都会逐渐趋同，上下肯定会有波动，但不太夸张。但是各个优惠策略都会不同，最后留住的用户也就不同。有的时候 pdd 某个物品对比其他平台特别便宜，买之前可以先问问自己，你敢买吗？？\n放在工作中也是同理，如果一切为了迎合市场，生产出来一堆垃圾，有必要吗？？可能自己是接触过顶级的开源项目，以及有强迫症，是个偏执狂，对这一切都比较排斥。之前看过一个段子说的是“每天的工作就是在一坨💩山上继续拉答辩”，这个例子虽然有点恶心，但很生动形象。既然自己有代码洁癖，就好好要求自己呗。如果能保持住就继续坚持咯。\n尝试“解耦”手机 不知从何时起，开始想摆脱手机的束缚。先来想一下手机在我日常生活中的作用。回复微信、购物、外卖、接打电话和听歌，还有就是照相。如果不考虑这些软件的使用场景，电脑和 iPad 完成可以替代，但如果在工作中，想点个外卖呢？iPad 体积就显得有点大。回复微信、听歌这些使用电脑可以替代。购物使用 iPad 也可以。仅仅是屏幕大小不同，结果却导致不同的用户体验和适用场景。\n一开始想到的就是使用 Apple Watch，这玩意我一开始就感觉很鸡肋，对我而言用处不大。而且苹果的宣传片总显得有点 CPU 用户，强行把健康和一款产品绑定在一起，这是不合理的。但如果蜂窝版的 Watch 支持了微信、听歌、接打电话，是不是就意味着在日常出门可以不用手机了呢？但随之而来的是，现在不带手机出门，或者说低电量出门，会莫名有点觉得缺失安全感。因为手机已经极大程度融入进日常生活了。再加上 eSIM 卡貌似不再支持中国大陆的运营商，整个流程就直接作废。\n后来想想，手机只是个工具，融合的更多是为了更方便用户的使用。简单来说，想摆脱的不是手机，而是浪费在手机上的时间，于是我对于每个 App 的屏幕使用时长进行了限制，并卸载了知乎、小红书等软件，这类软件本质来说都是一样，都是为了吸引用户使用。最后只对手机保留其最基础的功能。这样一通操作下来，手机屏幕的平均使用时间被压在了两个小时以内。争取下一个阶段控制在一小时左右。\n有的时候，最怕的就是给自己创造需求，从而陷入痛苦之中。。\n总结 这个月初去了桐庐，爬山比较友好（没有难度），爬到山顶有个瀑布，虽然不算太高，但离近一点看，还是挺不错的。下午的话去看了“破房子”，这种乡村建筑，让我想起了小时候老家的环境。可惜的是现在老家再也没有小时候的那种味道，大多是二层的小平房，没有乡土气息。。\n参与了 GOSIM 和 KubCon，第一场是周日到的，里面有五个论坛，比较有意思的是无论是“元宇宙和游戏”，还是“人工智能”都有提到 Rust，看来 Rust 必将是大势所趋。KubCon 则有点赶，到会场的时候，都已经开始清场，只能到处瞎逛逛就回家叻。两个大会给我的感觉是，自己对于底层的基础知识掌握的还不够，英语交流可以听得懂，但想流畅的说出来，还需要一段时间锻炼，也是因为没有说的氛围和环境的缘故。还有一点比较有意思，国外的开发者大多数都有大肚腩，这也给自己提个醒，保持锻炼，防止成为油腻男开发。\n开始补《哈利波特》系列，虽然是“儿童文学”，但看起来还是比较有意思的。比较遗憾的是，邓布利多的扮演者——米高·约翰·甘邦 也于近日离开了人间，去了魔法世界🙏 R.I.P 🕯️\n收藏了两首喜欢的音乐：康士坦的变化球——《美好的事可以不可以发生在我身上》和瓦依那——《大梦》，也因为这两首歌开始看《乐队的夏天 3》。\n九月也开始认真对待 Rust，但有点越学越痛苦的感觉，希望能早日渡过瓶颈期～～\n哦对，今天是中秋🥮，别忘了抬头看看月亮啊，如果能看得见的话。\n","description":"","tags":null,"title":"置身事内的大梦","uri":"/life/23_09-moon/"},{"categories":null,"content":"Kafka 系统架构 首先来看一下 Kafka 的架构图：\n如上图所示，Kafka 由 Producer、Broker、Zookeeper 和 Consumer 四个模块组成。其中，Zookeeper 用来存储元数据信息，集群中所有元数据都持久化存储在 Zookeeper 中。之前的内容，我们有讲过，使用 Zookeeper 作为元数据存储服务会带来额外的维护成本、数据一致性和集群规模限制（主要是分区数）等问题。所以 Kafka3.0 使用内置的 Raft 机制替代 Zookeeper。\nKafka 有 Topic 和分区的概念，一个 Topic 可以包含一个或多个分区。消费方面，通过 Group 来组织消费者和分区的关系。\n从消息的生命周期来看，生产者也需要通过客户端寻址拿到元数据信息。客户端通过生产分区分配机制，选择消息发送到哪个分区，然后根据元数据信息拿到分区 Leader 所在的节点，最后将数据发送到 Broker。Broker 收到消息并持久化存储。消费端使用消费分组或直连分区的机制去消费数据。如果使用消费分组，就会经过消费者和分区的分配流程，消费到消息后，最后项服务端提交 Offset 记录消费进度，用来避免重复消费。\n讲完基础概念和架构，我们继续围绕着前面所提到的五个模块来分析一下 Kafka，先来看一下协议和网络模块。\n协议和网络模块 Kafka 是自定义的私有协议，经过多年发展目前有 V0、V1 和 V2 三个版本，稳定在 V2 版本。官方目前没有支持其他协议，比如 HTTP，但是商业版的 Kafka 都会支持 HTTP 协议，主要原因还是 HTTP 协议使用的便携性。\nKafka 协议从结构上看包含协议头和协议体两部分，协议头包含基础通用的信息，协议体由于每个接口的功能参数不一样，内容结构上差异很大。\nKafka 协议的细节在通信协议中已经讲过，这里就不做过多的赘述。关于协议的更多详细信息还可以参考 官方文档。\nKafka 服务端的网络层是基于 Java NIO 和 Reactor 来开发的，通过多级的线程调度来提供性能。Kafka 网络层细节在网络模块 也有讲过，可以自己翻回去看。。\n数据存储 下面，我们继续来看 Kafka 1的存储层，Kafka 同样分为元数据存储和消息存储两部分。\n元数据存储 上面我们说过，Kafka 的元数据是存储在 Zookeeper 里面的。元数据信息包括 Topic、分区、Broker 节点和配置信息等。Zookeeper 会持久化存储全量元数据信息，Broker 本身不存储任何集群相关的元数据信息。在 Broker 启动的时候，需要连接 Zookeeper 读取全量元数据信息。\nZookeeper 是一个单独的开源项目，它自带了集群组网、数据一致性、持久化存储和监听机制等完整的能力。它的底层是基于 Zab 协议组件集群，有 Leader 节点和 Slave 节点的概念，数据写入全部在 Leader 节点完成，Slave 负责数据的读取工作。\n从 Zookeeper 的角度来看，Kafka 只是它的一个使用者。Kafka 用 Zookeeper 的标准使用方式向 Zookeeper 集群上写入、删除和更新数据，以完成 Kafka 的元数据管理、集群构建等工作。所以每台 Broker 启动时，都会在 Zookeeper 注册、监听一些节点信息，从而感知集群的变化。\n另外，Kafka 集群的一些如消费进度信息、事务信息，分层存储元数据，以及 3.0 后的 Raft 架构相关的元数据信息，都是基于内置 Topic 来完成存储的。把数据存储在内置 Topic 中，算是一个比较巧妙的思路了，也是一个值的借鉴的技巧。Kafka 中存储不同功能的元数据信息的 Topic 列表如下所示：\n数据类型 Topic 名称 消费进度 _consumer_offsets 事务消息 _transaction_state Kafka Raft 版本的元数据 _cluster_metadata 分层存储元数据 _remote_log_metadata 消息数据 在消息数据存储方面，Kafka 的数据是以分区为维度单独存储的。即写入数据到 Topic 后，根据生产分区分配关系，会将数据分发到 Topic 中不同的分区。此时底层不同分区的数据是存储在不同的“文件“中的，即一个分区一个数据存储“文件“。这里提到的“文件“也是一个虚指，在系统底层的表现是一个目录，里面的文件会分段存储。\n如下图所示，当 Broker 收到数据后，是直接将数据写入到不同的分区文件中的。所以在消费的时候，消费者也是直接从每个分区读取数据。\n在底层数据存储中，Kafka 的存储结构是以 Topic 和分区维度来组织的。一个分区一个目录，目录名称是 TopicName + 分区号。每个分区的目录下，都会有 .index、.log、.timeindex 三类文件。其中，.index 是偏移量（offset）索引文件，.log 是消息数据的存储文件，.timeindex 是时间戳索引文件。两个索引文件分别根据 Offset 和时间检索数据。\n在节点维度，也会持久存储当前节点的数据信息（如 BrokerID）和一些异常恢复用的 Checkpoint 等数据。由于每个分区存储的数据量会很大，分区数据也会进行分段存储。分段是在 .log 进行的，文件分段的默认数据大小也是 1G，可以通过配置项来修改。\nKafka 提供了根据过期时间和数据大小清理的机制，清理机制是在 Topic 维度生效的。当数据超过配置的过期时间或者超过大小的限制之后，就会进行清理。清理的机制也是延时清理的机制，它是根据每个段文件进行清理的，即整个文件的数据都过期后，才会清理数据。需要注意的是，根据大小清理的机制是在分区维度生效的，不是 Topic。即当分区的数据大小超过设置大小，就会触发清理逻辑。\n在存储性能上，Kafka 的写入大量依赖顺序写、写缓存、批量写来提高性能。消费方面依赖批量读、顺序读、读缓存的热数据、零拷贝来提高性能。在这些技巧中，每个分区的顺序读写诗高性能的核心。\n接下来，我们看一下 Kafka 的客户端关于生产者和消费者的实现。\n生产者和消费者 Kafka 客户端在连接 Broker 之前需要经过客户端寻址，找到目标 Broker 的信息。在早期，Kafka 客户端是通过连接 Zookeeper 完成寻址操作的，但是因为 Zookeeper 性能不够，如果大量的客户端都访问 Zookeeper，那么就会导致 Zookeeper 超载，从而导致集群异常。\n所以在新版的 Kafka 中，客户端是通过直连 Broker 完成寻址操作的，不会直接和 Zookeeper 进行交互。即 Broker 与 Zookeeper 进行交互，在本地缓存全量的元数据信息，然后客户端通过连接 Broker 拿到元数据信息，从而避免对 Zookeeper 造成太大负载。\n生产者 生产者完成寻址后，在发送数据的时候可以将数据发送到 Topic 或直接发送到分区。发送到 Topic 时会经过生产分区分配的流程，即根据一定的策略将数据发送到不同的分区。\nKafka 提供了轮询和 KeyHash 两种策略 轮询策略是指按消息维度轮询，将数据平均分配到多个分区。Key Hash 是指根据消息的 Key 生成一个 Hash 值，然后和分区数量进行取余操作，得到的结果可以确定要将数据发送到哪个分区。生产消息分配的过程是在客户端完成的。\nKafka 协议提高了批量（Batch）发送的语义，所以生产端会在本地先缓存数据，根据不同的分区聚合数据之后，在根据一定的策略批量将数据写入到 Broker。因为这个 Batch 机制的存在，客户端和服务端的吞吐性能会提高很多。\n客户端批量往服务端写有两种方式：一种是协议和内核就提供了 Batch 语义，一种是在业务层将一批数据聚合成一次数据发送。这两种虽然都是批量发送，但是它们的区别在于：\n第一种批量消息中的每条数据都会有一个 Offset，每条消息在 Broker 看来就是一条消息。第二种批量消息是在这批量消息就是一条消息，只有一个 Offset。 在消费端看来，第一种对客户端是无感的，一条消息就是一条消息。第二种需要消费者感知生产的批量消息，然后解析批量，逐条处理。 消费者 Kafka 的消费端只提供了 Pull 模式的消费。即客户端是主动不断地去服务端轮询数据、获取数据，消费则是直接从分区拉取数据的。Kafka 提供了消费分组消费和直连分区消费两种模式，这两者的区别在于，是否需要进行消费者和分区的分配，以及消费进度谁来保存。\n大部分情况下，都是基于消费分组消费。消费分组创建、消费者或分区变动的时候会进行重平衡，重新分配消费关系。Kafka 默认提供了 RangeAssignor（范围）、RoundRobinAssignor（轮询）、 StickyAssignor（粘性）三种策略，也可以自定义策略。消费分组模式下，一个分区只能给一个消费者消费，消费是顺序的。\n当客户端成功消费数据后，会往服务端提交消费进度信息，此时服务端也不会删除具体的消息数据，只会保存消费位点信息。位点数据保存在内部的一个 Topic（__consumer_offset）中。消费端同样提供了自动提交和手动提交两种模式。当消费者重新启动时，会根据上一次保存的位点去消费数据，用来避免重复消费。\n最后我们来看一下 Kafka 对 HTTP 协议和管控操作的支持。\nHTTP 协议支持和管控操作 Kafka 内核是不支持 HTTP 协议的，如果需要支持，则需要在 Broker 前面挂一层代理。\n管控的大部分操作是通过 Kafka Protocol 暴露的，基于四层的 TCP 进行通信。还有部分可以通过直连 Zookeeper 完成管控操作。\n在早期很多管控操作都是通过操作 Zookeeper 完成的。后来为了避免对 Zookeeper 造成压力，所有的管控操作都会通过 Broker 再封装一次，即客户端 SDK 通过 Kafka Protocol 调用 Broker，Broker 再去和 Zookeeper 交互。\nKafka 命令行提供了管控、生产、消费、压测等功能，其底层就是通过客户端 SDK 和 Broker 进行交互的。我们在代码里面也可以通过客户端 SDK 完成相应的操作，不用必须通过命令行。\n因为历史的演进，在一些命令行里面，还残留着直连 Zookeeper 的操作。而我们也可以通过直接操作 Zookeeper 中的数据完成一些操作，比如更改配置、创建 Topic 等等。\n总结 最后，我们再来总结一下 Kafka。\n协议层只支持私有的 Kafka Protocol 协议； 网络层是基于原生的 Java NIO 开发，底层也是通过多路复用、异步 IO、Reactor 模型等技术来提高网络模块的性能； 存储层是每个分区对应一份具体的存储文件，分区文件在底层会分段存储，同时支持基于时间和大小的数据过期机制； 元数据存储是通过 Zookeeper 来实现的，所有的元数据都存储在 Zookeeper 中； 客户端的访问同样也需要经过客户端寻址机制。老版本可以通过 Zookeeper 获取元数据信息，新版本只能通过 Broker 拿到元数据信息。拿到所有元数据信息后，才会直连 Broker； 生产端支持将数据写入到 Topic 或指定写入某个分区，写入 Topic 时需要经过生产分区分配操作，选择出最终需要写入的分区，同时支持批量写入的语义； 消费端也有消费分组的概念，消费时需要在多个消费者和消费分组之间进行消费的负载均衡，同时也支持指定分区消费的模式。 Kafka 从生产到消费的全过程：\n在生产端，客户端会先和 Broker 建立 TCP 连接，然后通过 Kafka 协议访问 Broker 的 MetaData 接口或渠道集群的元数据信息。接着生产者会向 Topic 或分区发送数据，如果是发送到 Topic，那么客户端会有消息分区分配的过程。因为 Kafka 协议具有批量发送语义，所以客户端会先在客户端缓存数据。然后根据一定的策略，通过异步线程将数据发送到 Broker； Broker 收到数据之后，会根据 Kafka 协议解析出请求内容，做好数据校验，然后重整数据结构，将数据按照分区的维度写入到底层不同的文件中。如果分区配置了副本，则消息数据会被同步到不同的 Broker 中进行保存； 在消费端，Kafka 提供了消费分组和指定分区消费两种模式。消费端也会先经过寻址拿到完整的元数据信息，然后连接上不同的 Broker。如果是消费分组模式消费，则需要经过重平衡、消费分区分配流程，然后连接上对应分区的 Leader，接着调用 Broker 的 Fetch 接口进行消费。最后一步则是需要提交消费进度来保存消费信息。 ","description":"","tags":null,"title":"MQ008——剖析 Kafka 架构设计","uri":"/tech/bigdata/bigdata_mq008/"},{"categories":null,"content":"消费端：消费者客户端 SDK 有哪些设计？ 前言 上一篇内容讲了生产端，这次继续来聊聊有关消费端的内容。从技术上看，消费端 SDK 和生产端 SDK 一样，主要包括客户端基础功能和消费相关功能两部分。客户端基础功能之前已经讲过，这里也就不做过多的赘述。\n从实现上看，消费相关功能包括消费模型、分区消费模型、消费分组（订阅）、消费确认和消费失败处理五个部分。我们一个一个来看。\n消费模型的选择 为了满足不同场景的业务需求，从实现机制上来看，主流消息队列一般支持 Pull、Push 和 Pop 三种消费模型。\nPull 模型 Pull 模型是指客户端通过不断轮询的方式想服务端拉取数据。它是消息队列中使用最广泛和最基本的模型，主流的消息队列一般也都支持这个模型。\n它的好处是客户端根据自身的处理速度去拉取数据，不会对客户端和服务端造成额外的风险和负载压力。缺点是可能会出现大量无效返回的 Pull 调用，另外消费及时性不够，无法满足一些需要全链路低耗时的场景。\n为了提供消费性能，Pull 模型都会支持批量读，即在客户端指定需要拉取多少条数据或者拉取多大的数据，然后传递给服务端。客户端拉取到数据并处理完成后，再重复拉取数据处理。如前面讲的，这种拉取模式的缺点是可能会出现长时间轮询到空数据的情况，从而浪费通信资源，提高服务端的负载。\n比如下面这个场景，当 Topic1 数据已经被消费完，此时如果消费者频繁来拉取数据并立即返回结果，客户端就会不停地重复请求服务端。当空数据请求特别多的时候，就会造成资源损耗，不利于提高吞吐，也有可能导致负载问题。\n为了解决这个问题，正常的思路是在客户端根据一定策略进行等待和回避。这样做的话，就会出现如何设置等待时间的问题，客户端等待时间设置不合理就会出现消费不及时的情况。\n为了解决空请求带来的问题，一般服务端会协助处理，有如下两种思路：\n1. 服务端 hold 住请求 当客户端根据策略拉取数据时，如果没有足够的数据，就先在服务端等一段时间，等有数据后一起返回给客户端。这种方案的好处是，可以尽量提高吞吐能力，不会有太多的空交互请求。缺点则是如果长时间不给客户端回包，会导致客户端请求超时，另外当数据不够时，hold 住请求的时间太长就会提高消费延时。\n2. 服务端有数据的时候通知客户端 当服务端不 hold 住请求，立刻返回空数据，客户端收到空数据时则不再发起请求，会等待服务端的通知。当服务端有数据的时候，再主动通知客户端来拉取。这种方案的好处是可以及时通知客户端来拉取数据，从而降低消费延时。缺点是因为客户端和服务端一般是半双工的通信，此时服务端是不能主动向客户端发送消息的。\n所以在 Pull 模型中，比较合适的方案是客户端告诉服务端：最多需要多少数据、最少需要多少数据、未达到最小数据时可以等多久三个信息。然后服务端首先判断是否有足够的数据，有的话就立即返回，否则就根据客户端设置的等待时长 hold 住请求，如果超时，无论是否有数据，都会直接给客户端返回当前的结果。\n这种策略可以解决频繁不可控的空轮询请求。即使全是空轮询，对单个消费者来说，其 TPS 也是可以预估的，即总时间 / 等待时长 = 总轮询次数。而如果需要降低消费延时，可以通过降低最小获取的数据大小和最大等待时长来提高获取的频率，从而尽量降低延时。通过这种方案，我们可以把理想的消费延迟时间降低到两次 Pull 请求之间的时间间隔。\n在一些业务消息的场景中，因为应对的场景规模有限，可以将最大等待时长设置为 0，此时消费模型就变成了“请求—返回”的模式，当没有数据的时候就会立即返回数据，其余逻辑交给客户端自己处理。\nPush 模型 Push 模型是为了解决消费及时性而提出来的。这个模型的本意是指当服务端有数据时会主动推给客户端，让数据的消费更加及时。理想中的思路如下图所示，即当服务端由数据以后，会主动推给各个消费者。在实际的 Push 模型的实现上，一般有 Broker 内置 Push 功能、Broker 外独立实现 Push 功能的组件、在客户端实现伪 Push 功能三种思路。\n1. Broker 内置 Push 功能 第一种，Broker 内置 Push 功能是指在 Broker 中内置标准的 Push 的能力，由服务端向客户端主动推送数据。\n这种方案的好处是 Broker 自带 Push 能力，无需重复开发和部署。Broker 内部可以感知到数据堆积情况，可以保证消息被及时消费。缺点是当消费者很多时，内核需要主动维护很多与第三方的长连接，并且需要处理各种客户端异常，比如客户端卡住、接收慢、处理慢等情况。这些推送数据、异常处理、连接维护等工作需要消耗很多的系统资源，在性能上容易对 Broker 形成反压，导致 Broker 本身的性能和稳定性出现问题。所以这种方案在主流消息队列中用得较少，为了保证消息投递的高效及时（比如全链路的毫秒级耗时），才会采用这种方案。\n2. Broker 外独立实现 Push 功能的组件 第二种，Broker 外独立实现 Push 功能的组件是指独立于 Broker 提供一个专门实现 Push 模型的组件。通过先 Pull 数据，再将数据 Push 给客户端，从而简化客户端的使用，提高消费数据的及时性。\n这种方案的好处是将 Push 组件单独部署，解决了 Broker 的性能和稳定性问题，也能实现 Push 的效果。缺点是虽然实现了 Push 的模型，但其本质还是先 Pull 再 Push，从全链路来看，还是会存在延时较高的问题，并且需要单独开发独立的 Push 组件，开发和运维成本比较高。\n从实际业务上来讲，这种模型的使用场景较为有限，主要用在回调、事件触发的场景，在实际的流消费场景用的不是很多。主要是因为通过第三方组件的 Push 灵活性不够，性能会比 Pull 第。\n3. 客户端实现伪 Push 功能 **第三种，在客户端实现伪 Push 功能是指在客户端内部维护内部队列，SDK 底层通过 Pull 模型从服务端拉取数据存储到客户端的内存队列中。**然后通过回调的方式，触发用户设置的回调函数，将数据推送给应用程序，在使用体验上看就是 Push 的效果。\n这种方案的好处在于通过客户端底层的封装，从用户体验看是 Push 模型的效果，解决用户代码层面的不断轮询问题，降低了用户的使用复杂度。缺点是底层依旧是 Pull 模型，还是得通过不断轮询的方式去服务端拉取数据，就会遇到 Pull 模型遇到的问题。\n在客户端实现伪 Push，是目前消息队列在实现 Push 模型常用的实现方案，因为它解决了客户体验上的主动回调触发消费问题。虽然底层会有不断轮询和消费延时的缺点，但是可以通过合理的编码设计来降低这两个问题的影响。\n因为 Push 模型需要先分配区和消费者的关系，客户端就需要感知分区分配、分区均衡等操作，从而在客户端就需要实现比较重的逻辑。并且当客户端和订阅的分区数较多时，容易出现需要长时间的重平衡时间的情况。此时为了解决这个问题，于是就有了 Pop 模型。\nPop 模型 Pop 模型想解决的是客户端实现较重，重平衡会暂停消费并且可能时间较长，从而出现消费倾斜的问题。\n它的思路是客户端不需要感知到分区，直接通过 Pop 模型提供的 get 接口去获取到数据，消费成功后 ACK 数据。这就像发起 HTTP 请求去服务端拉取数据一样，不用感知服务端的数据分布情况，只需要拉到数据。这种方案的好处是简化了消费模型，同时服务端可以感知到消费的堆积情况，可以根据堆积情况返回哪些分区的数据给客户端，这样也就简化了消息数据的分配策略。\n从实现上来看，它将分区分配的工作移到了服务端，在服务端完成了消费者的分区分配、进度管理，然后暴露出新的 Pop 和 ACK 接口。客户端调用 Pop 接口去拿去数据，消费成功后调用 ACK 去确认数据。可以类比 HTTP 中的 Request 和 Response 使用模型。\n分区消费模式 我们知道，消息队列的数据是在 Partition/Queue 维度承载的，所以消费过程中一个重要的工作就是消费者和分区的消费模式问题，即分区的数据能不能被多个消费者并发消费，一条数据能不能被所有消费者消费到，分区的数据能不能被顺序消费等等。\n从技术上看，在数据的消费模式上主要有独占消费、共享消费、广播消费和灾备消费四种思路\n独占消费 **独占消费是指一个分区同一个时间只能被一个消费者消费。**在消费者启动时，会分配消费者和分区之间的消费关系。当消费者数据和分区数量都没有变化的情况下，两者之间的分配关系不会变动。当分配关系变动时，一个分组也只能被一个消费者消费，这个消费者可能是当前的，也可能是新的。如果消费者数量大于分区数量，则会有消费者被空置；反之，如果分区数量大于消费者数量，一个消费者则可以同时消费多个分区。\n独占消费的好处是可以保证分区维度的消费是有序的。缺点是当数据出现倾斜、单个消费者出现性能问题或 hang 住时，会导致有些分区堆积严重。Kafka 默认支持的就是独占消费的类型。\n共享消费 **共享消费是指单个分区的数据可以同时被多个消费者消费。**即分区的数据会依次投递给不同的消费者，一条数据只会投递给一个消费者。\n这种方式的好处是，可以避免单个消费者的性能和稳定性问题导致分区的数据堆积。缺点是无法保证数据的顺序消费。这种模式一般用在对数据的有序性无要求的场景，比如日志。\n广播消费 **广播消费是指一条数据要能够被多个消费者消费到。**即分区中的一条数据可以投递给所有的消费者，这种方式是需要广播消费的场景。\n实现广播消费一般有内核实现广播消费的模型、使用不同的消费分组消费和指定分区消费三种技术思路。\n内核实现广播消费的模型，指在 Broker 内核中的消息投递流程实现广播消费模式，即 Broker 投递消息时，可以将一条消息吐给不同的消费者，从而实现广播消费。 使用不同的消费分组对数据进行消费，指通过创建不同的消费者组消费同一个 Topic 或分区，不同的消费分组管理自己的消费进度，消费到同一条消息，从而实现广播消费的效果。 指定分区消费，是指每个消费者指定分区进行消费，在本地记录消费位点，从而实现不同消费者消费同一条数据，达到广播消费的效果。 三种方案的优劣对比：\n广播消费类型 优点 缺点 内核实现 客户端成本低，无多余工作 服务端开发工作量大 消费分组实现 统一消费模型，无需服务端开发 需要创建很多消费分组 指定分区消费 统一消费模型，避免创建很多消费分组 客户端编码工作较重，使用相对复杂 灾备消费 灾备消费是独占消费的升级版，在保持独占消费可以支持顺序消费的基础上，同时加入灾备的消费者。 当消费者出现问题的时候，灾备消费者加入工作，继续保持独占顺序消费。\n好处是既能保持独占顺序消费，又能保证容灾能力。缺点是无法解决消费倾斜的性能问题，而且还需要准备一个消费者来做灾备，使用成本比较高。\n消费分组 消费分组是用来组织消费者、分区、消费进度关系的逻辑概念。为什么需要消费分组呢？\n在没有消费分组直接消费 Topic 的场景下，如果希望不重复消费 Topic 中的数据，那么就需要有一个标识来标识当前的消费情况，比如记录进度。这个唯一标识就是消费分组。\n在一个集群中可以有很多消费分组，消费分组间通过名称来区分。消费分组自身的数据是集群元数据的一部分，会存储在 Broker 的元数据存储服务中。消费分组主要有管理消费者和分区的对应关系、保存消费者的消费进度、实现消息可重复被消费三类功能。\n消费分组和 Topic 是强相关的，它需要包含 Topic 才有意义，一个空的消费分组是没有意义的。消费分组内有很多个消费者，一个消费分组也可以订阅和消费多个 Topic，一个 Topic 也可以被多个消费分组订阅和消费。\n因为 Topic 不存储真实数据，分区才存储消息数据，所以就需要解决消费者和分区的分配关系，即哪个分区被哪个消费者消费，这个分配的过程就是消费重平衡。\n从流程上来看，当新建一个消费分组的时候，就需要开始分配消费者和分区的消费关系了。分配完成后，就可以正常消费。如果消费者和分区出现变动，比如消费者挂掉、新增消费者、订阅的 Topic 的分区数发生变化等等，就会重新开始分配消费关系，否则就会存在某些分区不能被订阅和消费的情况。\n协调者 从实现上来看，如果要对消费者和分区进行分配，肯定需要有一个模块拥有消费分组、所有的消费者、分区信息三部分信息，这个模块我们一般命名为协调者。协调者主要的工作就是执行消费重平衡，并记录消费分组的消费进度。\n在消费分组创建、消费者变化、分区变化的时候就会触发重新分配。分区分配的操作可以在协调者内部或消费者上完成。\n在协调者完成，即协调者首先获取消费者和分区的信息，然后再协调者内部完成分区分配，最后再把分配关系同步给所有消费者。 在消费者完成，即负责分配的消费者获取所有消费者和分区的信息，然后该消费者完成分区分配操作，最后再把分配关系同步给其他消费者。 从技术上来看，这两种形式的优劣区别并不大，取决于代码的实现。一般在创建消费分组和消费者 / Topic 分区变化的时候，会触发协调者执行消费重平衡。\n从实现的角度来看，协调者一般是 Broker 内核的一个模块，就是一段代码或者一个类，专门用来完成上述的工作。当有多台 Broker 时，协调者的实现有多种方式，比如 Kafka 集群每台 Broker 都有协调者存在。通过消费分组的名称计算出来一个 hash 值和 _consumer_offset 的分区数，取余计算得出一个分区号。最后这个分区号对应的 Leader 所在的 Broker 节点就是协调者所在的节点。客户端就和计算出来的这台 Broker 节点进行交互，来执行消费重平衡的相关操作。\n当有了协调者后，就需要确认哪个分区给哪个消费者了，此时就需要一个分配策略来执行，这就是消费分区分配策略。\n消费分区分配策略 再具体实现上，一般内核会默认提供几种分配策略，也可以通过定义接口来支持用户自定义实现分区分配策略。分区分配策略的制定一般遵循以下三个原则：\n各分区的数据能均匀地分配给每个消费者，保证所有消费者的负载最大概率是均衡的，该原则最为常用； 在每次重新分配的时候，尽量减少陪去和消费者之间的关系变动，这样有助于加快重新分配的速度，并且保持数据处理的连续性，降低处理切换成本； 可以运行灵活地根据业务特性指定分配关系，比如根据机房就近访问最近的分区、某个 Topic 的奇数分区分配给第一个消费者等等。 所有消息队列的默认策略都是相对通用的，一般都会包含有轮询、粘性、自定义三种策略。\n轮询 轮询就是指用轮询的方式将分区分配给各个消费者，保证每个消费者的分区数量是尽量相同的，从而保证消费者的负载最大概率上是均衡的。思路是拿到所有主题的所有分区和所有消费者，根据拿到的顺序（实际实现中可能会先全部打乱，以确保随机性）将分区逐个分配给消费者。分配到最后的效果是，每个消费者所分到的分区数是一样的，最多相差 1 个分区。比如 tp0 有 3 分区，tp1 有 2 分区，tp2 有 3 分区，分配后效果如下。\n消费者 1：tp0-0、tp2-1、tp1-1\n消费者 2：tp2-2、tp0-1、tp2-0\n消费者 3：tp1-0、tp0-2\n因为 Topic 一般会有多个分区，默认情况下写入大部分是均匀的。这个方案的优点是，从随机性的原理来看，打乱分区后再分配给每个消费者，消费者的负载大概率是均匀的。但是也有可能出现不均衡，比如当消费组同时订阅多个分区时，有可能会将同一个 Topic 的多个分区都分配给一个消费者，从而出现消费者的负载倾斜。\n在轮询的基础上，为了解决随机轮询的情况，某些流量搞的 Topic 可能会分配给同一个消费者。为了解决这种情况，就可以调整一下轮询的策略，比如在随机的基础上，将 Topic 的不同分区尽量打散到不同的消费者，从而保证整体消费者之间的分区是均衡的，如下所示：\n消费者1：tp0-0、tp2-1、tp1-1\n消费者 2：tp0-1、tp2-0、tp1-0\n消费者 3：tp0-2、tp2-2\n主要的核心思路都是为了消费者更加均衡，避免消费倾斜。\n粘性 粘性是指尽量减少分区分配关系的变动，进而减少重平衡所耗费的时间和资源损耗。即当已经分配好消费者和分区的消费关系后，当消费者或者分区出现变动，就会触发重平衡。从底层来看，可能就是一个消费者掉了或者新增分区。此时需要重新进行分配的消费者和分区其实是有限的，大部分的分配关系可以不动。而此时，如果使用轮询算法，则要全部打算重来，耗时就会非常长，并且浪费资源，即把原先不需要重新分配的关系都重新分配一遍。\n粘性的效果如下，比如当上面的消费者 3 挂了后，只需要将 tp1-0、tp0-2 平均分给消费者 1 和 2 即可，消费者 1 和 2 原先分配的分区不用动。\n消费者1：tp0-0、tp2-1、tp1-1、tp1-0\n消费者 2：tp0-1、tp2-0、tp1-0、tp0-2\n在实际的实现中，为了减少重新分配关系，有一个非常常用的算法是一致性哈希。一致性哈希的算法经常用在负载均衡中。用一致性哈希实现粘性分配策略的优点是，当节点或者分区变动时，只需要执行少量的分区再分配即可。\n自定义策略 在一些消息队列中，也会提供一些与自己相关的特色的分区分配策略。比如 Kafka 就提供了轮询策略改进版的 RoundRobinAssignor 分配策略。这些策略的核心出发点，都是为了解决消费者和分区之间的分配均衡、重平衡耗时、业务场景需要等诉求。\n自定义分区分配算法，和生产端数据的分区分配策略是一样的，内核会提供接口，用户可以根据自身需求自定义算法，然后指定配置生效即可。比如 Kafka 提供了 org.apache.kafka.clients.consumer.internals.PartitionAssignor 接口来提供自定义分区分配策略。\n消费确认 那么当数据被消费成功后，就必须进行消费确认操作了，告诉服务端已经成功消费了这个数据。消费确认就是我们在消息队列中常说的 ACK。一般情况下，消费确认分为确认后删除数据和确认后保存数据两种形式。\n确认后删除数据是指集群的每条消息只能被消费一次，只要数据被消费成功，就会回调服务端的 ACK 接口，服务端就会执行数据删除操作。在实际开发过程中，一般都会支持单条 ACK 和 批量ACK 两种操作。这种方式不利于回溯消费，所以用得比较少。\n消费成功保存消费进度是指当消费数据成功后，调用服务端的消费进度接口来保持消费进度。这种方式一般都是基于配合消费分组一起用的，服务端从消费分组维度来保存进度数据。\n为了保证消息的回溯消费和多次消费，消息队列大多数用的是第二种方案。数据的删除交由数据过期策略去执行。\n保存消费进度一般为服务端保存和客户端自定义保存两种机制实现。\n服务端保存是指当消费端消费完成后，客户端需要调用一个接口提交信息，这个接口是由服务端提供的”提交消费进度“接口，然后服务端会持久保存进度。当客户端断开重新消费时，可以从服务端读取这个进度进行消费。服务端一般会通过内置的 Topic 或者文件来持久保存该数据。这种方式的优点是客户端会封装好这些逻辑，使用简单，无序管理进度相关的信息，缺点就是不够灵活。服务端保存一般是默认的方案。\n在提交位点信息的时候，底层一般支持自动提交和手动提交两种实现。\n自动提交一般是根据时间批次或数据消费到客户端后就自动提交，提交过程客户端无感知； 手动提交：是指业务根据自己的处理情况，手动提交进度信息，以避免业务处理异常导致的数据丢失。 提交方式 优点 缺点 自动提交 实现简单，业务无感知，使用成本低 可能会漏消费数据，导致数据丢失 手动提交 安全可控 需要代码提交，使用成本较高 如果想避免数据丢失的情况下，优先考虑手动提交的方式。\n客户端自定义保存是指当消费完成后，客户端自己管理保存消费进度。此时就不需要向服务端接口提交进度信息了，自定义保存进度信息即可，比如保存在客户端的缓存、文件、自定义的服务中，当需要修改和回滚的时候就比较方便。这种方案的的优点是灵活，缺点是会带来额外的工作量。\n消费失败处理 我们知道，一个完整的消费流程包括消费数据、本地业务处理、消费进度提交三部分。那么从消费失败的角度来看，就应该分为从服务端拉取数据失败、本地业务数据处理失败、提交位点信息失败三种情况。下面我们逐一来看。\n从服务端拉取数据失败，和客户端的错误逻辑处理是一致的，根据可重试错误和不可重试错误的分类，进行重复消费或者向上抛错。\n本地业务数据处理失败，处理起来就变囧复杂了。如果是偶尔失败，那么在业务层做好重试处理逻辑，配合手动提交消费进度的操作即可解决。如果是一直失败，即使重试多次也无法被解决，比如这条数据内容有异常，导致无法被处理。此时如果一直重试，就会出现消费卡住的情况，这就需要配合死信队列等功能，将无法被处理的数据投递到死信队列中，从而保存异常数据，并保证消费进度不阻塞。\n提交位点信息失败，其处理方法通常是一直重试，重复提交，如果持续失败就向上抛错。因为如果提交进度失败，即使再从服务端拉取数据，还是会拉到同一批数据，出现重复消费的问题。\n总结 在消费端，为了提高消费速度和消息投递的及时性，需要选择合适的消费模型，目前主流有 Pull、Push 和 Pop 三种模型。\n这三种模型的应用场景都不一样。目前业界主流消息队列使用的都是 Pull 模型。但为了满足业务需求，很多消息队列也会支持 Push 模型和 Pop 模型。其中，Push 模型的及时性更高，实现较为复杂，限制也比较多。Pop 模型本质上是 Pull 模型的一种，只是在实现和功能层面上，与 Push 的实现思路和使用场景不一样。所以在模型的选择上来看，因为场景复杂，三种模型都是需要的。\n常用的消费模式一般有独占消费、共享消费、广播消费和灾备消费四种。为了避免堆积，保证消息消费顺序，一般需要选择分区独占的消费模式。从单分区的维度，共享消费的性能是最高的。广播消费主要是通过创建多个消费分组、指定分区消费来实现的。灾备消费的场景用的则相对较少。\n从设计上看，消费端要解决的问题依次分为三步：\n满足基本的消费需求，能消费到数据，确认数据； 满足稳定性和性能的需求，能快速稳定地消费到数据； 支持功能方面的需求，比如回溯消费、消费删除、广播消费等等。 为了能满足基本的消费需求，服务端会提供消费和确认接口，同时在客户端封装消费和确认操作中，底层通过网络层和服务端建立、维护 TCP 连接，然后通过协议完成基本的消费操作。\n如果要回溯消费，则需要单独记录消费进度。这样就能抽象出消费分组的概念，用来管理消费者、分区和消费进度的关系。通过消费分组来记录消费进度，从而实现数据的多次分发。另外，消费分组机制也可以用在广播消费的场景。\n在消费确认的过程中，一般需要客户端回调服务端提供的确认接口。确认接口分为确认删除和确认记录消费进度两种模式。主流方式是在确认的时候记录消费进度。\n异常处理主要是为了保证数据能被正常消费，重点关注不丢数据、不重复消费、不阻塞住消费三个问题，我们需要针对不同的问题做不一样的处理。\n","description":"","tags":null,"title":"MQ007——剖析消费者 SDK","uri":"/tech/bigdata/bigdata_mq007/"},{"categories":null,"content":"生产端：生产者客户端 SDK 有哪些设计要点？？ 前言 大部分开发者在使用某个组件或框架的时候，都希望能够做到开箱即用，作为一款成熟的产品来说，也确实应该做到。那么，在使用的过程中是否会有疑问，这些框架的 SDK 底层是如何工作的呢，由哪些功能模块所组成的呢？消息队列的客户端主要包含生产、消费、集群管控三类功能。我们先用 MQ 中的生产者为例，来进行一个浅层次的设计分析。。从客户端 SDK 实现的角度来看，生产模块包含客户端基础功能和生产相关功能两部分，其中基础功能是客户端所有功能共有的。如下图所示：\n基础功能是蓝色部分，包括请求连接管理、心跳检测、内容构建、序列化、重试、容错处理等等。生产功能是黄色部分，包括客户端寻址、分区选择、批量发送、生产错误处理、SSL、幂等和压缩等等。\n客户端基础功能 连接管理 在网络模块，讲过客户端和服务端之间基本都是通过各自语言的网络库，创建 TCP 长连接进行通信的。在大部分实现中，为了避免连接数膨胀，每个客户端实例和每台 Broker 只会维护一条 TCP 连接。\n建立一条 TCP 连接是简单的，关键的是，什么情况下建立连接呢？？一般来说有初始化创建连接和使用时创建连接两种方式。\n初始化创建连接：指在实例初始化时就创建到各个 Broker 的 TCP 连接，等待数据发送。好处是提前创建好可以避免发送的时候冷启动；缺点是需要提前创建好所有的连接，可能导致连接空跑，会消耗一定的资源。 使用时创建连接：指在实例初始化时不建立连接，当需要发送数据时再建立。好处是发送时再连接，连接的使用率会较高；缺点是可能出现连接冷启动，会增加一点本次请求的耗时。 因为客户端会有空闲连接回收机制，创建连接的耗时一般较短，所以在实际的架构实现中，两种方式都会有用到，优劣区别并不是很明显。不过，从资源利用率的角度考虑，建议使用晚建立连接的方式。\n因为连接并不是任何时候都有数据，可能出现长时间连接空闲。所以连接都会搭配连接回收机制，连接建立后如果连接长时间空闲，就会被回收。连接回收的策略一般是判断这段时间内是否有发送数据的行为，如果没有就判断是空闲，然后执行回收。\n因为单个 TCP 连接发送性能存在上限，就需要在客户端启动多个生产者，提高并发读写的能力。一般情况下，每个生产者会有一个唯一的 ID 或唯一标识来标识客户端，比如 ProduceID 或客户端的 IP+Port。\n单个 TCP 的瓶颈和很多因素有关，比如网路带宽、网络延迟、客户端请求端的 socketbuff 的配置、TCP 窗口大小、发送速率导致本地数据反压堆积、服务端请求队列的堆积情况、收包和回包的速度等等。\n接下来继续看看客户端和服务端之间的心跳检测。\n心跳检测 心跳检测是客户端和服务端之间保活的一种机制，检测服务端或者客户端的一方不可用时，另一方可以及时回收资源，避免资源浪费。一般都是通过 ping-pong 的方式来发起探测。之前的内容有提到过，消息队列一般都是基于 TCP 协议通信的。所以客户端和服务端之间的心跳机制的实现，一般有基于 TCP 的 KeepAlive 保活机制和应用层主动探测两种形式。\n基于 TCP 的 KeepAlive 保活机制：是 TCP/IP协议层内置的功能，需要手动打开 TCP 的 KeepAlive 功能。通过这种方案实现心跳检测，优点是简单，缺点是 KeepAlive 实现是在服务器侧，需要 Server 主动发送检测包，此时如果客户端异常，可能出现很多不可用的 TCP 连接。这种连接会占用服务器内存资源，导致服务器端的性能下降。\n应用层主动探测：一般是 Client 向 Server 发起的，主要解决灵活性和 TCP KeepAlive 的缺陷。探测流程一般是客户端定时发送保活心跳，当服务端连续几次没收到请求，就断开连接。这样做的好处是，可以将压力分担到各个客户端，避免服务端的过载。\n错误处理 从请求的角度，有些错误是重试可以恢复的，比如连接断开、Leader 切换、发送偶尔超时和服务端某些异常等；有些错误是不可恢复的，比如 Topic / 分区不存在、服务端 Broker 不存在、集群和 Broker 长时间无响应等。所以，在客户端的处理中，也会将错误分为可重试错误和不可重试错误两类。\n因为网络环境、架构部署的复杂性，集群可能出现短暂网络抖动、Leader 切换等异常，可重试错误就是这类通过一次或多次重试可能恢复的异常；不可重试的错误，就是不管如何重试都无法恢复的异常。\n虽然实现思路很直接、很简单，但在客服端 SDK 的实现过程中，错误处理是一个包含很多细节的工作，一般需要考虑下面几个常见的点：\n如何定义可恢复错误和不可恢复错误； 完整的错误码的定义和枚举，如何定义一个好的错误码从而提高排查问题的效率； 错误后重试的代码实现方式是否合理高效； 判断哪些情况需要停止客户端，向上抛出异常，以免一些错误信息一直在 SDK 内空转，提高上层感知异常和排查异常的难度； 日志信息打印 debug、info 以及 error 日志时，是否包含了完整的内容。 发生错误后，客户端一般会提供重试策略，接下来一起看看重试机制的实现，\n重试机制 重试策略一般会支持重试次数和退避时间的概念。当消息失败，超过设置的退避时间后，会继续重试，当超过重试次数后，就会抛出消息或者将消息投递到配置好的重试队列中。\n退避时间是可以配置的，比如 1s、10s 或者 60s 等。当出现错误时，就会按照退避策略进行退避，再尝试写入。一般情况下，重试是有次数上限的，当然如果想的话也也可以配置无限重试。\n退避策略影响的是重试的成功率，因为网络抖动一般来说是 ms 级，某些严重的情况下可能会抖动十几秒。此时，如果退避策略设置的太短，在退避策略和重试次数用完后，可能消息还没生产成功；反过来，如果退避时间设置太长，可能导致客户端发送堵塞消息堆积。所以消息队列生产者的重试次数和退避策略的设置都是比较讲究的，需要结合业务的场景仔细设计。\n另外，客户端为了满足安全传输、性能和功能方面的需求，客户端都会支持传输加密、压缩、事务、幂等等功能。\n生产相关基础功能 客户端寻址机制 MQ 作为一个分布式系统，分区会分布在集群的不同节点上。所以从客户端的角度看，往服务端写入数据的时候，服务端有那么多台节点，请求该发送給台节点呢？？\n看见这个问题，可能大部分开发者都会觉得这并不是什么难题，类似我们发送 HTTP 请求，手动指定目标 Broker 的 IP 就行了。就是说在生产者写数据到 Broker 的时候，在代码里面手动指定分区对应的对端的 Broker 地址，然后将数据写到目标 Broker。\n这个思路没问题，但是我们手动指定对端 Broker 地址的时候，怎么知道这个分区在这台 Broker 上的对应关系存在哪里呢？？为了解决这个问题，就从而提出了 Metadata 寻址机制和服务端内部转发两个思路。\n1.Metadata 寻址机制 服务端会提供一个获取全量的 Metadata 的接口，客户端在启动时，首先通过接口拿到集群所有的元数据信息，本地缓存这部分数据信息。然后，客户端发送数据的时候，会根据元数据的内容，得知服务端的地址是什么，要发送的分区在哪台节点上。最后根据这两部分信息，将数据发送到服务端。\n消息队列的元数据是指 Topic、分区、Group、节点、配置等集群维度的信息。比如 Topic 有几个分区，分区的 Leader 和 Follwer 在哪些节点上，节点的 IP 和端口是什么，有哪些 Group 等等。\n在 Metadata 寻址机制中，元数据信息主要包括 Topic 及其对应的分区信息和 Node 信息两部分。可以看一下 Kafka 的元数据信息结构；\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 主题分区元数据： { \"test1\": { \"Topic\": \"test1\", \"Partitions\": [ { \"ID\": 0, \"Error\": {}, \"Leader\": 101194, \"Replicas\": [ 101194, 101193 ], \"Isrs\": [ 101194, 101193 ] } ], \"Error\": {} } } 节点元数据： [ { \"ID\": 101195, \"Host\": \"9.130.62.0\", \"Port\": 6097 }, { \"ID\": 101194, \"Host\": \"9.130.62.1\", \"Port\": 6096 }, { \"ID\": 101193, \"Host\": \"9.130.62.2\", \"Port\": 6095 } ] 客户端一般通过定期全量更新 Metadata 信息和请求报错时更新元数据信息两种方式，来保证客户端的元数据信息是最新的。目前 Kafka 也是用的这个方案。\n2. 服务端内部转发机制 另外一种服务端内部转发机制，客户端不需要经过寻址的过程，写入的时候是随机把数据写入到服务端任意一台 Broker。具体思路是服务端的每一台 Broker 会缓存所有节点的元数据信息，生产者将数据发送给 Broker 后，Broker 如果判断分区不在当前节点上，会先找到这个分区在哪个节点上，然后把数据转发到目标节点。\n这么做的好处是，分区寻址在服务端完成，客户端的实现成本比较低。但是生产流程多了一跳，耗时增加了。另外服务端因为转发多了一跳，会导致服务端的资源损耗多一倍，比如 CPU、内存、网卡，在大流量的场景下，这种损耗会导致集群负载变高，从而导致集群整体性能降低。所以这种方案不适合大流量、高吞吐的消息队列。\n解决了请求要发送給哪个节点，下面就要思考消息数据要写入到哪个分区呢。\n生产分区分配策略 我们知道，数据可以直接写入分区或者写入对应的 Topic。写入 Topic 时，最终数据还是要写入到某个分区。这个数据选择写入到哪个分区的过程，就是生产数据的分区分配过程。过程中的分配策略就是生产分区分配策略。\n一般情况下，消息队列默认支持轮询、按 Key Hash、手动指定和自定义分区分配这四种分区分配策略。\n轮询是所有消息队列的默认选项。消息通过轮询的方式依次写到各个分区中，这样可以保证每个分区的数据量是一样的，不会出现分区数据倾斜。\n分区数据倾斜是指一个 Topic 的每个分区的存储的数据量不一样，有的分区数据量大，有的小，从而导致硬件的负载不均，集群性能出现问题。\n既然能解决数据倾斜，那是不是使用轮询就是最优解了呢？？答案是否定的，因为如果我们需要保证数据的写入是有序的，轮询就满足不了。因为在消费模型中，每个分区的消费是相互独立的，如果数据依次写入多个分区，在消费的时候就无法保持顺序。所以若要想数据有序，就需要保证 Topic 只有一个分区。这也是另外两种分配策略的思路。\n按 Key Hash 是指根据消息的 Key 算出一个 Hash 值，然后与 Topic 分区数取余数，算出一个分区号，将数据写入到这个分区中。公式参考：\n1 partitionSeq = hash(key) % partitionNum; 这种方案的好处是可以根据 Key 来保证数据的分区有序。比如某个用户的访问轨迹，以客户的 AppID 为 Key，按 Key Hash 存储，就可以确保客户维度的数据分区有序。缺点是分区数量不能变化，因为变化后 Hash 值就会变，导致消息乱序。并且因为每个 Key 的数据量不一样，容易导致数据倾斜。\n手动指定很好理解，就是在生产数据的时候，手动指定数据写入哪个分区。这种方案的好处就是灵活，用户可以在代码逻辑中根据自己的需要，选择合适的分区，缺点是业务需要感知分区的数量和变化，代码实现相对复杂。\n除了这三种默认策略，消息队列也支持自定义分区分配策略，让用户灵活使用。通常会在内核提供 interface 机制，用户如果需要指定自定义分区的分区分配策略，可以实现对应的接口，然后配置分区分配策略。比如 Kafka 可以通过实现 org.apache.kafka.clients.producer.Partitioner 接口实现自定义分区策略。\n批量语义 为了提高写入性能，有的生产者客户端会提供批量（Batch）写入的语义。客户端支持批量写入数据的前提是，需要在协议层支持批量的语义。否则就只能在业务中自定义将多条消息组成一条消息。\n批量发送的实现思路一般是在客户端内存中维护一个队列，数据写入的时候，先将其写入到这个内存队列，然后通过某个策略从内存队列读取数据，发送到服务端。\n批量发送数据的策略和存储模块的刷盘策略很像，都是根据数据条数或时间聚合后，汇总发送到服务端，一般是满足时间或者条数的条件后触发发送操作，也会有立即发送的配置项。\nKafka 是按照时间的策略批量发送的，提供了 linger.ms、max.request.size、batch.size 三个参数，来控制数据批量发送。\nlinger.ms：设置消息延迟发送的时间，这样可以等待更多的消息组成 Batch 发送。默认为 0 表示立即发送。\nmax.request.size：生产者能够发送的请求包大小上限，默认为 1MB。\nbatch.size：生产者会尝试将业务发送到相同的 Partition 的消息合包后再进行发送，它设置了合包的大小上限。\n为了支持对于性能和可靠性有不同需求的业务场景，客户端一般会支持多种数据发送方式。\n数据发送方式 消息队列一般也会提供同步发送、异步发送和发送即忘三种形式。\n同步和异步更多是语言语法的实现，同步发送主要解决数据发送的即时性和顺序性，一步发送主要考虑性能。下面，我们来重点看一下发送即忘（这个不太好理解）。\n发送即忘指消息发送后不关心请求返回的结果，立即发送下一跳。这种方式因为不用关心发送结果，发送性能会提升很多。缺点是当数据发送失败时无法感知，可能会有数据丢失的情况，所以通常适用在发送不重要的日志等场景。Kafka 提供了 ack = 0 来支持这种模式。\n讲完了发送相关的功能设计，接下来我们看一下管控操作在客户端中的实现方式。\n集群管控操作 集群管控操作一般是用来完成资源的创建、查询、修改和删除等集群管理动作。资源主要包括主题、分区、配置以及消费分组等等。\n命令行工具是最基础的支持方式。如下图所示，它的底层主要通过包装客户端 SDK 和服务端的相关功能接口进行交互。程序编码上一般由命令行、参数包装和底层 SDK 调用三部分组成。主要流程是接收参数、处理参数和调用 SDK 等相关操作。\n有的消息队列也会支持 HTTP 接口形式的管控操作。好处是因为 HTTP 协议的通用性，业务可以从各个环节发起管控的调用，不是强制使用 admin SDK。另外客户端封装 HTTP 接口实现命令行工具的成本也比较低。\n总结 消息队列生产者客户端的设计，主要关注下面三个部分：\n网络模块的开发和管理。这部分是为了完成和服务端的通信，比如请求和返回的构建、心跳检测、错误处理和重试机制等； 根据服务端提供的各个接口的协议结构，构建请求，完成序列化和反序列化后，通过网络模块发起请求并获得返回； 在前面两步的基础上，添加各个业务层面的功能，比如生产、消费、事务、幂等和 SSL 这类。 客户端和服务端交互的过程中，一般要经过元数据寻址，以正确找到分区所在的 Broker。如果我们想避免客户端寻址，只能在服务端内进行转发，但有性能和资源的损耗。所以在主打吞吐的消息队列组件中，转发的方案用的很少。\n从生产者的的角度来看，需要重点关注分区分配策略、批量语义和发送方式三个方面。请求内容构建和序列化属于协议设计的内容，主要取决于协议的具体设计和序列化 / 反序列化框架的选择。\n","description":"","tags":null,"title":"MQ006——剖析生产者 SDK","uri":"/tech/bigdata/bigdata_mq006/"},{"categories":null,"content":"二十三，九局下半 何为成长，也许是有了选择的能力，但却发现没有选择的权利。。\n有的时候，或者说大部分时候，做的事情都是身不由己。就在想啊，人如果不能做自己想做的事情，那么还有什么意思呢？？emmm 或者换个角度来说，现在所有的过渡是为了以后自己想做的事情嚒？？又或者真的有想清楚自己想做什么了嘛？？还是说，仅仅是因为目前做的事情比较无聊，而导致说，现在做的是自己不太喜欢的呢。。\n学会选择放弃 从我的角度来说，学会选择是想做的事情，学会放弃是极难的事情，如果二者综合在一起呢？？该如何才能做到学会选择放弃。。上一次独立选择是高考填志愿选择了计算机，再一次是现在。\n我是一个喜欢在质疑中成长的，在被别人看扁的时候，心里骂一句你懂个 der，然后按照自己的长远规划来慢慢实现，事实证明，也确实做到咯。这一次，我相信也是一样。一定的！！\n如果说是放弃了自己曾经所想追求的事情呢？？心里有矛盾，会不甘，会难受，但更多的是怕，怕自己后悔，怕让家人失望，怕一切的一切都不会如自己所料。\n我也不知现在的生活是否真的好或不好，或者是否真的适合自己，现在好像真的不知道自己想要变成什么样子，有点陷入舒适区，不肯挪动半步，有时候会想想，自己累了那么久，真的好想好想停下脚步，歇歇啊。。如果真的选择停下会有莫名的焦虑感，这种焦虑感不知从何而来，也许来自于天生的不自信吧，也有一部分是 peer pressure。人，只有站的足够高，才会明白自己是多么想要触碰到天空。鹰，不会留恋地平线！再加上自己是比较喜欢折腾的那一类人，所以，走下去吧，别回头，至于终点在哪？？我还在想，我还在找，我也许还在迷茫。。\n当自己选择放弃的想法涌入脑海的那一瞬间，后背不自觉的发出冷汗。。甚至有点不可思议，为什么自己是这么想的，后来想着想着也就释怀了吧。至少有始有终，属于给自己了一个交代，也算是弥补了遗憾。同龄人，很多是没得选择，我却有点一手王炸，打得稀烂的感觉，至少从他人视角来说确实如此。放弃读研，放弃大厂的 offer，孤身一人流放杭州，选择了一个有点养老的工作，也许是真的累了，想给自己喘口气的时间，\n但换个角度思考，现在的工作能够养活自己，工作上能发挥自己的所长，下班了有自己的时间。虽然有时候也有点糟心，但好在，这些也不重要。虽然还不知下一步该走向哪，那就厚积薄发，当作是场过渡咯～～\n意外的收获 既然喜欢折腾，那么就适当的搞搞破坏吧，也许是目前的技术栈总觉得很窄，而且所学的大部分技术都是为了满足生存，是真的自己所喜欢的吗？？并不是吧，既然不是那为何不去学呢！！学点看似无用，但自己感兴趣的。\n先从扩展一下自己的语言开始吧，首选的是 Go，因为还想体验一下传说中的 MIT6.824 这门课，里面的实验也都是使用 Go 完成的，不想懂分布式的悠悠球手不是好的游戏玩家嘛。学习 Go 的时候总觉得它的编程范式有点别扭，意外地看了一篇关于 Rust 和 Go 的对比，emmmm，要不然试试 Rust，难才有意思的嘛。\n就这样入了 Rust 的坑，也让我真正体验到了如何做一名合格的程序员。起初各种不适应，定义一个变量还需要考虑其是放在堆上还是栈上，以及所有权的机制、生命周期等这些都是什么玩意，慢慢在不断入门中，有点适应之后，再回来看看其它语言，不好意思，真的不熟！！学习 Rust 之后，开始习惯逛推，也关注了很多有意思的大佬，看他们分享的折腾记录，为何不自己动手试试呢。先打造个 IDE 吧，Vim 也算是在不断入门中放弃的，那段时间刚好天天都看见 NeoVim 的推送，可能这都是安排好的吧，于是就开始折腾了起来，自己配置了 nvim，lua 之前制作游戏 mod 用过，所以上手也比较快。 所以说，有时候仅仅出兴趣出发，往往会有意想不到的收获。折腾完 nivm 又看见关于 terminal 的配置，iTerm2 崩溃过几次之后，也决定换到 Kitty 或者 Alcritty，最终的选择是 Kitty，没人能拒绝自己的 macOS 多一个猫猫的图标，不是吗 哈哈哈哈。。\n在我从事这个行业之前，特别佩服那些能够独立折腾的玩家，后来入行之后，干的事情，很多都是比较乏味，有点循规蹈矩，现在算是找到了自己当初想要的模样了吧。而且，特别感谢自己遇见了开源，也正是这股黑客文化，能够促使我不断接触新的东西～～\n上一次认真对待一件事情，又是什么时候呢？？持续了多久？？\n逛书店 回想一下自己有多久没逛过书店了呢？？\n去年受疫情影响，似乎没怎么去过书店，沉迷于 Switch，再加上个人状态也不是特别好，就没读过几本书。而且大都是泛泛而读，没有啥实质性的收获。今年突然开始重新陷入技术学习的苦海，看的也都是技术相关的书籍，就突然感觉有点文化沙漠了。。\n前段时间，去书店，虽说书店不是很大，逛了一圈下来，却并没有发现自己想要的书，这是一件很可怕的，至少对我而言。以往逛书店，看见某个感兴趣的，可以牵连着找出许多想要的书，因为书会带着你去探索更多有意思的事情。这次没有，因为我不知道自己喜欢看什么类型的，历史相关的、哲学相关的、传记、心理学以及金融学，比较大众化的都有涉及，但却没有一个能够真正提取我阅读兴趣的。最后在一个拐角看见了《蛤蟆先生去看心理医生》，听名字就知道是关于心理学的，自己也该看看了。\n从九月开始，给自己定个小目标吧，每个月至少一篇纸质书，读完之后或多或少写点什么，留个记录。\n一个人 不知从何开始，感觉到每个人都是孤独的个体；不知从何开始，接受了一个人的状态；也不知从何开始，慢慢开始享受一个人的生活。。\n或好或糟，凡事都是两面性。有的时候想找人，说说话，吐槽最近的生活。可翻了一页列表，貌似没有适合倾诉的对象。于是，带上耳机，看看书、练练球、打打游戏，或者写写代码，也就过去了。也许就是这样的次数多了，也就习惯了吧。\n有可能我天生就是个浑身带刺的人，从小到大就不喜欢别人碰我，有点洁癖，有强迫症，不喜欢无意义的合群，所以有的时候的群体活动，我都会感觉到可能是在浪费时间，这段时间留给我自己发发呆也是蛮不错的，总好过强颜欢笑。但人总归来说还是群居动物，不是不懂社交，只是不想，或者感觉意义不是很大。\n还有就是，不知从何时起，我开始慢慢意识到原生家庭是一种负担，他们的亲朋好友，对我嘘寒问暖也好，指指点点也罢，我都不太喜欢，可能是真的关心我，也有的可能就是吃瓜的心态。有的时候总觉得自己作为晚辈，很多地方做的都很差劲，emmm 对亲戚来说，我不太喜欢去刻意维护，毕竟生活的环境不一样，每个人对生活的理解也不一样，你说的他们未必听得懂，他们说的，我也会或多或少觉得有点无聊。小时候，去舅舅家都会觉得格外亲切，随着他们的孩子先结婚生娃，他们的重心都会转变的嘛。我一直提倡的都是，当我们这一代有能力之后，我们的父母那一辈可以早点休息，他们那个年代是吃过苦的，现在作为他们的子女有能力，可以试着去享受生活。但从他们的角度来说，总会觉得自己做的还不够，还想着为子女多做点什么。他们是伟大的，但同时也是自私的，他们做的越多，往往会导致对子女的依赖性越大，也就越舍不得子女离开自己身边，我感觉这是病态的。。所以，我想靠着自己的能力，吃吃苦，从一无所有，到想去看看世界。\n现在回头看看自己，有能力、有自己的思想、有自己的认知，还有自己想做的事情。总体而言，是挺享受一个人目前的状态，但也会越来越孤僻。家里人，催着找对象，总想着各种理由推脱掉。如果遇不到合适的，那就算了吧。。应该是吧。因为就现在的情况来看，我不太想浪费自己的时间，去陪伴一个没那么喜欢的人。有的人可能会说，感情都是慢慢培养的嘛，也许吧。。\n简单来说，就是走一步看一步了，如果站在更高的角度，看现在的我，也没啥好烦心的。\n期待 对下一个阶段的自己有啥期待的呢？？\n多读点闲书，早睡，可以抽点时间打打游戏，多运动，多看看山山水水，还有就是坚持去学你想做的技术。\n最重要的一点就是，心理素质再强大一点咯。\n","description":"","tags":null,"title":"二十三，九局下半","uri":"/life/23/"},{"categories":null,"content":"如何设计元数据和消息数据的存储模块？？ 前言 存储模块作为 MQ 高吞吐、低延时、高可靠性的基础保证，可以说是最核心的模块。从技术架构的来看，存储模块主要包含功能实现和性能优化两个方面，这篇 blog 就重点来看一下其是如何实现的。\nMQ 的存储模块的主流程是数据的写入、存储、读取、过期。写入和持久化存储是基本功能，但因为消息队列独有的产品特性，主要被用来当缓冲分发，它的数据存储是临时的，数据持久化存储后，在一定的时间或操作后，需要能自动过期删除。\n而且 MQ 中的数据一般分为元数据和消息数据。元数据指的是 Topic、Group、User、ACL 和 Config 等集群维度的资源数据信息，消息数据是指客户端写入的用户的业务数据。\n元数据信息的存储 元数据信息的特点是数据量比较小，不会经常读写，但是需要保证数据的强一致和高可靠，不允许出现数据的丢失。同时，元数据信息一般需要通知到所有的 Broker 节点，Broker 会根据元数据信息执行具体的逻辑。比如创建 Topic 并生成元数据后，就需要通知对应的 Broker 执行创建分区、创建目录等操作。\n所以元数据信息的存储，一般有两个思路：\n基于第三方组件来实现元数据的存储； 在集群内部实现元数据的存储。 基于第三方组件来实现元数据的存储是目前业界的主流选择。比如 Kafka Zookeeper 版本、RocketMQ 和 Pulsar 用的都是这个思路。其中 Kafka 和 Pulsar 的元数据存储在 Zookeeper 中。\n这个方案最大的优点是集成方便，开发成本低，能满足消息队列功能层面的基本要求，因为可以直接复用第三方组件已经实现的一致性存储、高性能的读写和存储、Hook 机制等能力，而且在后续集群构建规划的过程中也可以继续复用这个组件，能极大程度降低开发难度和工作成本。\n但凡事都有利弊。其缺点也很明显，那就是引入第三方组件会增加集群系统部署和运维的成本，而且第三方组件自身的稳定性问题也会增加系统风险，第三方组件和多台 Broker 之间可能会出现数据信息不一致的情况，导致读写异常。\n另外一种思路，集群内部实现元数据的存储是指在集群内部完成元数据的存储和分发。也就是在集群内部实现类似第三方组件一样的元数据服务，比如 Raft 协议实现内部的元数据存储模块或依赖一些内置的数据库。目前 Kafka 去 Zookeeper 版本用的就是这个思路。\n这个方案的优缺点刚好与第一个相反。优点是部署和运维成本低，不会因为依赖第三方服务导致稳定性问题，也不会有数据不一致的问题。但是缺点是开发成本高，前期要投入大量的开发成本。\n消息数据的存储 与元数据的存储相比，消息数据的存储要复杂一点。一般情况下，MQ 的存储主要是指消息数据的存储，分为存储结构、数据分段、数据存储格式和数据清理四个部分。\n数据存储结构设计 我们先看数据存储目录结构设计。在消息队列中，与存储有关的主要是 Topic 和分区两个维度。用户可以将数据写入 Topic 或直接写入到分区。\n不过如果写入 Topic，数据也是分发到多个分区去存储的。所以从实际数据存储的角度来看，Topic 和 Group 不承担数据存储功能，承担的是逻辑组织的功能，实际的数据存储是在分区维度完成的。\n从架构角度上看，数据的落盘也有两种思路：\n每个分区单独一个存储“文件” 每个节点上所有分区的数据都存储在同一个“文件” 需要注意的是，这里的“文件”是一个虚指，即表示所有分区的数据是存储在一起，还是每个分区的数据分开存储的意思。在实际的存储中，这个“文件”通常以目录的形式存在，目录中会有多个分段文件。\n先来看第一个思路，每个分区对应一个文件的形式去存储数据。具体实现时，每个分区上的数据顺序写到同一个磁盘文件，数据的存储是连续的。因为消息队列在大部分情况下的读写是有序的，所以这种机制在读写性能上的表现是最高的。\n但如果分区太多，会占用太多的系统 FD 资源，极端情况下有可能把节点的 FD 资源耗完，并且硬盘层面会出现大量的随机读写情况，导致写入的性能下降很多，另外管理起来也相对复杂。目前 Kafka 在存储数据的组织上用的就是这种思路。\n具体的磁盘的组织结构一般有“目录+分区二级结构”和“目录+分区一级结构”地两种形式。不过从技术上来看，二者并没有太大的优劣区别。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 目录+分区二级结构： ├── topic1 │ ├── partrt0 │ ├── 1 │ └── 2 └── topic2 ├── 0 ├── 1 目录+分区一级结构： ├── topic1-0 ├── topic1-1 ├── topic1-2 ├── topic2-0 ├── topic2-1 └── topic2-2 再来看第二种思路，每个节点上所有分区的数据都存储在同一文件中，需要为每个分区维一个对应的索引文件，索引文件里会记录每条消息在 File 里面的位置信息，以便快速定位到具体的消息内容。\n因为所有文件都在一份文件上，管理简单，也不会占用过多的系统 FD 资源，单机上的数据写入都是顺序的，写入的性能会很高。缺点是同一个分区的数据一般会在文件中的不同位置，或者不同的文件段中，无法利用到顺序读的优势，读取的性能会收到影响，但是随着 SSD 技术的发展，随机读写的性能也越来越高。最简单的体现就是固态越来越便宜咯。如果使用 SSD 或高性能 SSD，一定程度上可以缓解随机读写的性能损耗。\n那么该如何选择呢？核心考虑是对读写的性能要求。\n第一种思路，单个文件读和写都是顺序的，性能最高。但是当文件很多且都有读写的场景下，硬盘层面就会退化为随机读写，性能会严重下降； 第二种思路，因为只有一个文件，不存在文件过多的情况，写入层面一直都会是顺序的，性能一直很高。但是在消费数据的时候，因为多个分区数据存储在同一个文件中，同一个分区的数据在底层存储上是不连续的，硬盘层面会出现随机读的情况，导致读取的性能降低。 不过随机读写带来的性能问题，可以通过给底层配备高性能的硬件来缓解。所以当前比较多的 MQ 选用的是第二种方案，但是 Kafka 为了保证更高的吞吐性能，选用的是第一种方案。\n但是不管是方案一还是方案二，在数据存储过程中，如果单个文件过大，在文件加载、写入和检索的时候，性能就会有问题，并且 MQ 有自动过期机制，如果单个文件过大，数据清理时会很麻烦，效率很低。所以，我们的消息数据都会分段存储。\n消息数据的分段实现 数据分段的规则一般是根据大小来进行的，比如默认 1G 一个文件，同时会支持配置项调整分段数据的大小。当数据段达到了规定的大小后，就会创建一个新的文件来保存数据。如果进行了分段，消息数据可能分布在不同的文件中。所以我们在读取数据的时候，就需要先定义消息数据在哪个文件中。为了满足这个需求，技术上一般有根据偏移量定位或根据索引定位两种思路。\n根据偏移量（Offset）来定位消息在哪个分段文件中，是指通过记录每个数据段文件的起始偏移量、中止偏移量、消息的偏移量信息，来快速定位消息在哪个文件。\n当消息数据存储时，通常会用一个自增的数值型数据（比如 Log）来表示这条数据在分区或 commitlog 中的位置，这个值就是消息的偏移量。\n在实际的编码过程中，记录文件的起始偏移量一般有两种思路：单独记录每个数据段的起始和结束偏移量，在文件名称中携带起始偏移量的信息。因为数据是顺序存储的，每个文件都记录了其对应的起始偏移量，那么下一个文件的起始偏移量就是上一个文件的结束偏移量。\n如果用索引定位，会直接存储消息对应的文件信息，而不是通过偏移量来定位到具体的文件。具体是通过维护一个单独的索引文件，记录消息在哪个文件和文件的哪个位置。读取消息的时候，先根据消息 ID 找到存储的信息，然后找到对应的文件和位置，读取数据。RocketMQ 用的就是这个思路。\n这两种方案所面临的的场景不一样。根据偏移量定位数据，通常用在每个分区各自存储一份文件的场景；根据索引定位数据，通常用在所有分区的数据存储在同一份文件的场景。因为前一种场景，每一分数据都属于同一个分区，那么通过位点来二分查找数据的效率是最高的。第二种场景，这一份数据属于多个不同分区，再使用二分查找就不是那么明智咯，可以选择使用哈希查找。\n数据消息存储格式 消息数据存储格式一般包含消息写入文件的格式和消息内容的格式两个方面。\n消息写入文件的格式指消息是以什么格式写入到文件中的，比如 JSON 字符串或二进制。从性能和空间冗余的角度来看，消息队列中的数据基本都是以二进制的格式写入到文件的。这部分二进制数据，我们不能直接用 vim/cat 等命令查看，需要用专门的工具读取，并解析对应的格式。\n消息内容的格式是指写入到文件中的数据都包含哪些信息。对于一个成熟的消息队列来说，消息内容格式不仅关系功能维度的扩展，还牵涉性能维度的优化。\n如果消息格式设计的不够精简，功能和性能都会大打折扣。比如冗余字段会增加分区的磁盘占用空间，使存储和网络开销变大，性能也会下降。如果缺少字段，则可能无法满足一些功能上的需求，导致无法实现某些功能，又或者是实现某些功能的成本较高。所以在数据的存储格式设计方面，内容的格式需要尽量完整且不要有太多冗余。\n这么说可能会感觉比较抽象，我们分析一下 Kafka 的消息内容格式设计来直观的感受一下。\n字段名 含义 baseOffset 用在 Batch 中，该批次消息的起始 offset lastOffset 用在 Batch 中，该批次消息的结束 offset count 表示该行记录包含了多少条信息 baseSequence 用在 Batch 中，起始序号，用来支持幂等和事务 lastSequence 用在 Batch 中，结束序号，用来支持幂等和事务 producerId PID，用来支持幂等和事务 producerEpoch 分区 leader 纪元，可以看作分区 leader 的版本号或更新次数 isTransactional 是否事务信息 isControl - position 该行记录在本文件的偏移量 size 该行记录的总大小 magic 当前数据存储格式的版本，kafka 有 v0、v1 和 v2 三种格式 compresscodec 压缩格式，NONE 表示不压缩 crc CRC 校验码，用来校验数据在传输过程中的准确性 isvalid 表示数据是否可用，比如是否被删除 offset 该行记录的在这个分区的偏移量 LogAppendTime 数据写入到文件的时间 keysize key 长度 valuesize payload 长度 sequence 序号，用来支持幂等和事务 headerKeys 消息 header 的内容 key 消息的 key payload 消息的内容 可以看到，Kafka 的消息内容包含了业务会感知到的消息的 Header、Key 和 Value，还包含了时间戳、偏移量、协议版本、数据长度和大小、校验码等基础信息，最后还包含了压缩、事务、幂等 Kafka 业务相关的信息。\n需要注意的是，因为 kafka 支持 Batch 特性，所以消息格式中还包含 base 和 last 等 Batch 相关信息。\n消息数据清理机制 前文提到过，消息队列的数据在持久化存储后，需要在一定策略后自动过期删除。那么数据过期机制是如何实现的呢？\n消息队列中的数据最终都会删除，时间周期短的话几个小时、甚至几分钟，正常情况一天、三天、七天，长的话可能数个月，基本很少有场景需要再消息队列中存储一年的数据。\n消息队列的数据过期机制一般有手动删除和自动删除两种形式，从实现上看主要有三种思路：\n消费完成执行 ACK 删除数据 根据时间和保留大小删除 ACK 机制和过期机制相结合 消费完成执行 ACK 删除数据，技术上的实现思路一般是：当客户端完成消费数据后，回调客户端的 ACK 接口，告诉服务端数据已经消费成功，服务端就会标记删除该行数据，以确保消息不会被重复消费。ACK 的请求一般会有单条消息 ACK 和批量消息 ACK 两种形式。\n因为消息队列的 ACK 一般是顺序的，如果前一条消息无法被正确处理并 ACK，就无法消费下一条数据，导致消费卡住。此时就需要死信队列的功能，把这条数据先写入到死信队列，等待后续的结果。然后 ACK 这条消息，确保消费正确进行。\n这种方案，优点是不会出现重复消费，一条消息只会被消费一次。缺点是 ACK 成功后消息被删除，无法满足需要消息重放的场景。\n根据时间和保留大小删除指消息在被消费后不会被删除，只会通过提交消费位点的形式标记消费进度。\n实现思路一般是服务端提供偏移量提交的接口，当客户端消费成功数据后，客户端会回调偏移量接口，告诉服务端这个偏移量的数据已经消费成功了，让服务端吧偏移量记录起来。然后服务端会根据消息保留的策略，比如保留时间或保留大小来清理数据。一般通过一个常驻的异步线程来清理数据。\n这个方案，一条消息可以重复消费多次。不管有没有被成功消费，消息都会根据配置的时间规则或大小规则进行删除。优点是消息可以多次重放，适用于需要多次进行重放的场景。缺点是在某些情况下（比如客户端使用不当）会出现大量的重复消费。\n结合前两个方案，就有了 ACK 机制和过期机制相结合的方案。实现的核心逻辑和方案二比较类似，但保留了 ACK 的概念，不过 ACK 是相对于 Group 概念的。\n当消息完成后，在 Group 维度 ACK 消息，此时消息不会被删除，只是这个 Group 也不会再重复消费到这个消息，而新的 Group 可以重新消费订阅这些数据。所以在 Group 维度避免了重复消费的情况，也可以运行重复订阅。\n前面我们虽然反复提到“删除”，但数据实际怎么删除也有讲究。我们知道消息数据是顺序存储在文件中的，会有很多分段数据，一个文件可能会有很多行数据。那么在 ACK 或者数据删除的时候，一个文件中可能既存在可删除数据，也存在不可删除数据。如果我们每次都立即删除数据，需要不断执行“读取文件、找到记录、删除记录、写入文件”的过程，即使批量操作，降低频率，还是得不断地重复这个过程，会导致性能明显下降。\n当前主流的思路是延时删除，以段数据为单位清理，降低频繁修改文件内容和频繁随机读写文件的操作。\n只有该段里面的数据都允许删除后，才会把数据删除。而删除该段数据中的某条数据时，会先对数据进行标记删除，比如在内存或 Backlog 文件中记录待删除数据，然后在消费的时候感知这个标记，这样就不会重复消费这些数据。\n总结 消息队列的存储分为元数据存储和消息数据存储两方面。\n元数据的存储主要依赖第三方组件实现，比如 ZooKeeper、etcd 或者自研的简单元数据存储服务等等。在成熟的消息队列架构中，基于简化架构和提升稳定性的考虑，都会考虑在集群内部完成元数据的存储和管理。\n消息数据的存储在功能层面包含数据存储结构设计、数据分段存储、数据存储格式、数据清理机制四个方面。\n消息数据的存储主要包含 Topic 和分区两个维度。Topic 起逻辑组织作用，实际的数据存储是在分区维度完成的。所以在数据存储目录结构上，我们都以分区为最小粒度去设计，至于选择每个分区单独一个存储文件，还是将每个节点上所有分区的数据都存储在同一个文件，方案各有优劣，你可以根据实际情况去选择。\n因为大文件存在性能和资源占用、数据清理成本等问题，一般情况下，我们都需要对数据文件进行分段处理，分段的策略一般都是按照文件大小进行的。\n数据存储格式可以分为基础信息和业务信息两个维度，数据格式需要遵循极简原则，以达到性能和成本的最优。数据的过期策略一般有三种，ACK 删除、根据时间和保留大小删除数据、两者结合。目前业界的实现比较多样，从选择上来看，两者结合的方案更合理。\n","description":"","tags":null,"title":"MQ005——元数据和消息数据的存储设计","uri":"/tech/bigdata/bigdata_mq005/"},{"categories":null,"content":"如何设计一个高性能的网络模块？？ 前言 这篇博客我们来扒一下有关消息引擎系统的第二个基础知识点——网络模块。对 MQ 来说，网络模块是核心组件之一，网络模块的性能很大程度上决定了消息传输的能力和整体性能。\n对于 Java 后端的开发人员来说，如果谈到网络模块的开发，大概率都会想到 Netty。Netty 作为 Java 网络编程中最出名的类库，可以说是独当一面的存在。那既然都这么说了的话，关于 MQ 的网络模块选型是不是直接使用 Netty 就可以了？？\n带着这份好奇心，继续往下看看吧。\n选型之前，我们得先知道要解决什么问题。消息引擎系统是需要满足高吞吐、高可靠、低延时，并支持多语言访问的基础软件，网络模块最需要解决的是性能、稳定性、开发成本三个问题。接下来就围绕这三点来思考消息队列网络模块应该怎样设计。\n网络模块的性能瓶颈分析 这里就基于最基础的 MQ 访问链路图进行分析。\n对于单个请求来说，请求流程是：客户端（生产者 / 消费者）构建请求后， 向服务端发送请求包 —\u003e 服务端接收包后，将包交给业务线程处理 —\u003e 业务线程处理完成后，将结果返回给客户端。其中可能消耗性能的有三个点：\n编解码的速度：见上一篇博客——MQ003—通信协议 网络延迟：即客户端到服务端的网络延迟，这一点取决于网络链路的性能，在软件层面几乎无法优化，与网络模块无关 服务端 / 客户端网络模块的处理速度：发送 / 接收请求包后，包是否能及时被处理，比如当逻辑线程处理完成后，网络模块是否及时回包。这一点属于性能优化，也是网络模块设计的核心工作，有机会的话会深入探究一下咯。 对于并发请求来说，在单个请求维度问题的基础上，还需要处理高并发、高 QPS 和高流量等场景带来的性能问题，主要包括以下三个方面：\n高效的连接管理：当客户端和服务端之间的 TCP 连接过多，如何高效处理、管理连接； 快速处理高并发请求：当客户端和服务端之间的 QPS 很高，如何快速处理（接收、返回）请求； 大流量场景：当客户端和服务端之间的流量很高，如何快速吞吐（读、写）数据。 大流量场景，某种意义上是高并发处理的一种子场景。因为大流量分为单个请求包大并发小、单个请求包小并发大两种场景，前者的瓶颈主要在于数据拷贝、垃圾回收、CPU 占用等方面，主要依赖语言层面的编码技巧来解决。第二种场景就是我们主要解决的对象。\n高性能网络模块的设计实现 知道了瓶颈在哪里，就具体来看一下如何设计出一个高性能的网络模块。从技术上看，高性能的网络模块设计可以分为如何高效管理大量的 TCP 连接、如何快速处理高并发的请求以及如何提高稳定性和降低开发成本等三个方面。\n基于多路复用技术管理 TCP 连接 从技术原理角度思考，高效处理大量 TCP 连接，在消息引擎系统中主要有单条 TCP 连接的复用和多路复用两种技术思路。\n1. 单条 TCP 连接的复用 这是在一条真实的 TCP 连接中，创建信道（channel，可以理解为虚拟连接）的概念。通过编程手段，把信道当做一条 TCP 连接使用，做到 TCP 连接的复用，避免创建大量 TCP 连接导致系统资源消耗过多。\n这种实现的缺点是在协议设计和编码实现的时候有额外的开发工作量，而且近年随着异步 IO、IO 多路复用技术的发展，这种方案有点多余。不过因为语言特性、历史背景等原因，像 RabbitMQ 用的就是这种方案。\n2. IO 多路复用 像现在主流的 Kafka、RocketMQ、Pulsar 的网络模块都是基于 IO 多路复用的思路开发的。\nIO 多路复用技术，是指通过把多个 IO 的阻塞复用到同一个 selector 的阻塞上，让系统在单线程的情况下可以同时处理多个客户端请求。这样做最大的优势是系统开销小，系统不需要创建额外的进程或者线程，降低了维护的工作量也节省了资源。\n目前支持 IO 多路复用的系统调用有 Select、Poll、Epoll 等，Java NIO 库底层就是基于 Epoll 实现的。\n不过，即使使用了这两种技术，单机能处理的连接数还是有上限的。\n第一个上限是操作系统的 FD 上限，如果连接数超过了 FD的数量，连接会创建失败。第二个上限是系统资源的限制，主要是 CPU 和内存。频繁创建、删除或者创建过多连接会消耗大量的物理资源，导致系统负载过高。\n所以可以发现，每个消息队列的配置中都会提到连接数的显示和系统 FD 上限调整。Linux 中可以通过命令查看系统的 FD 信息：\n1 2 3 4 5 6 // 查看能打开 FD 的数量 ulimit -n // 用户级限制 cat /proc/sys/fs/file-max // 系统级限制 // 临时修改最大数量 ulimit -n 100000 // 将最大值改为 100000 解决了第一个问题连接处理，下面来看如何快速处理高并发请求。\n基于 Reactor 模型处理高并发请求 先看单个请求的处理。\n我们都知道，两点之间直线最短。对于单个请求来说，最快的处理方式就是客户端直接发出请求，服务端接收到包后，直接丢给后面的业务线程处理，当业务线程处理成功后，直接返回给客户端。\n这种处理是最快的，但是还有两个问题需要解决：\n如何第一时间拿到包交给后端的业务逻辑处理？？ 当业务逻辑处理完成后，如何立即拿到返回值返回给客户端？？ 可能比较直观的思路就是阻塞等待模型，不断轮询等待请求拿到包，业务逻辑处理完，直接返回结果给客户端。这种处理是最快的。但是阻塞等待模型因为是串行的处理机制，每个请求需要等待上一个请求处理完才能处理，处理效率会比较低。所以，单个请求，最合理的方式就是异步的事件驱动模型，可以通过 Epoll 和异步编程来解决。\nOk，继续再来看看看高并发请求的情况。在高并发的情况下会有很多连接、请求需要处理，核心思路就是并行、多线程处理。那么如何并行处理呢？？这个时候就需要用到 Reactor 模型了。\nReactor 模型是一种处理并发服务请求的事件设计模式，当主流程收到请求后，通过多路分离处理的方式，把请求分发给相应的请求处理器处理。如下图所示，Reactor 模式包含 Reactor、Acceptor、Handler 三个角色。\nReactor：负责监听和分配时间。收到事件后分派给对应的 Handler 处理，事件包括连接建立就绪、读就绪、写就绪等； Acceptor：负责处理客户端新连接。Reactor 接收到客户端的连接事件后，会转发给 Acceptor，Acceptor 接收客户端的连接，然后创建对应的 Handler，并向 Reactor 注册此 Handler； Handler：请求处理器，负责业务逻辑的处理，即业务处理线程。 从技术上看，Reactor 模型一般有三种实现方式：\n单 Reactor 单线程模型（单 Reactor 单线程） 单 Reactor 多线程模型 （单 Reactor 多线程） 主从 Reactor 多线程模型 (多 Reactor 多线程） 我们具体分析一下，看消息队列更适合哪一种。\n单 Reactor 单线程模型，特点是 Reactor 和 Handler 都是单线程的串行处理。\n优点是所有处理逻辑放在单线程中实现，没有上下文切换、线程竞争、进程通信等问题。缺点是在性能与可靠性方面存在比较严重的问题。\n性能上，因为是单线程处理，无法充分利用 CPU 资源，并且业务逻辑 Handler 的处理是同步的，容易造成阻塞，出现性能瓶颈。可能性主要是因为单 Reactor 是单线程的，如果出现异常不能处理请求，会导致整个系统通信模块不可用。\n所以单 Reactor 单进程模型不适用于计算密集型的场景，只适用于业务处理非常快速的场景。\n相比起来，单 Reactor 多线程模型，业务逻辑处理 Handler 变成了多线程，也是就说，获取到 IO 读写事件之后，业务逻辑是同一批线程在处理。\n优点是 Handler 收到响应后通过 send 把响应结果返回给客户端，降低 Reactor 的性能开销，提升整个应用的吞吐。而且 Handler 使用多线程模式，可以充分利用 CPU 的性能，提高了业务逻辑的处理速度。\n缺点是 Handler 使用多线程模式，带来了多线程竞争资源的开销，同时涉及共享数据的互斥和保护机制，实现比较复杂。另外，单个 Reactor 承担所有事件的监听、分发和响应，对于高并发场景，容易造成性能瓶颈。\n在此基础上，主从 Reactor 多线程模型，是让 Reactor 也变成了多线程。\n当前业界主流 MQ 的网络模型，比如 Kafka、RocketMQ 为了保证性能，都是基于主从 Reactor 多线程模型开发的。\n这种方案，优点是 Reactor 的主线程和子线程分工明确。主线程只负责接收新连接，子线程负责完成后续的业务处理。同时主线程和子线程的交互也很简单，子线程接收主线程的连接后，只要负责处理其对应的业务即可，无须过多关注主线程，可以直接在子线程把处理结果返回给客户端。所以，主从 Reactor 多线程模型适用于高并发场景，Netty 网络通信框架也是采用了这种实现方式。\n缺点是如果基于 NIO 从零开发，开发的复杂度和成本都是比较高的。另外，Acceptor 是一个单线程，如果挂了，如何处理客户端新连接是一个风险点。\n为了解决 Acceptor 的单点问题，有些组件为了保证高可用性，会对主从 Reactor 多线程做一些优化，把 Acceptor 也变为多线程的模式。如下图：\n到此为止，基于 IO 多路复用技术和 Reactor 模型，我们已经可以解决网络模块的性能问题了，接下来继续深入探究如何提高网络模块的稳定性和降低开发成本。\n基于成熟网络框架提高稳定性并降低开发成本 这里的“稳定性”主要指代码的稳定性。因为网络模块的特点是编码非常复杂，要考虑的细节和边界条件非常多，一些异常情况的处理也很细节，需要经过长时间的打磨。但相对而言，一旦开发完成，稳定后，代码几乎不需要再改动，因为需求相对固定的。\n在 Java 中，网络模块的核心是一个基础类库——Java NIO 库，它的底层是基于 Unix / Linux IO 复用模型 Epoll 实现的。\n如果我们要基于 Java NIO 库开发一个 Server，需要处理网络的闪断、客户端的重复接入、连接管理、安全认证、编解码、心跳保持、半包读写、异常处理等等细节，工作量非常大。所以在消息队列的网络编程模型中，为了提高稳定性或者降低成本，选择现成的、成熟的 NIO 框架是一个更好的方案。\n而 Netty 就是这样一个基于 Java NIO 封装的成熟框架。所以大部分 Java 开发者一提到网络编程，自然而然会想到 Netty。\nKafka 网络模型 Kafka 的网络层没有用 Netty 作为底层的通信库，而是直接采用 Java NIO 实现网络通信。在网络模型中，也是参照 Reactor 多线程模型，采用多线程、多 Selector 的设计。\n看整个网络层的结果图，Processor 线程和 Handler 线程之间通过 Request Channel 传递数据，Request Channel 中包含一个 Request Queue 和多个Response Queue。每个 Processor 线程对应一个 Response Queue。\n具体流程上：\n一个 Acceptor 接收客户端建立连接的请求，创建 Socke 连接并分配给 Processor 处理； Processor 线程把读取到的请求存入 RequestQueue 中，Handler 线程从 RequestQueue 队列中取出请求进行处理； Handler 线程处理请求产生的响应，会存放到 Processor 对应的 ResponseQueue 中，Processor 线程对其对应的 ResponseQueue 中取出响应信息，并返回给客户端。 NIO 编程和 RPC 框架 其实，要想不关心底层的调用细节（比如底层的网络协议和传输协议等），可以直接调用 RPC（Remote Procedure Call）框架来实现。\n因为 RPC 调用的是一个远程对象，调用者和被调用者处于不同的节点上，想完成调用，必须实现 4 个能力。\n网络传输协议：远端调用底层需要经过网络传输，所以需要选择网络通信协议，比如 TCP。 应用通信协议：网络传输需要设计好应用层的通信协议，比如 HTTP2 或自定义协议。 服务发现：调用的是远端对象，需要可以定位到调用的服务器地址以及调用的具体方法。 序列化和反序列化：网络传输的是二进制数据，因此 RPC 框架需要自带序列化和反序列化的能力。 细心的话，可以发现 RPC 框架完成的工作等于同学协议和前文提到的网络模块设计两部分的工作。在当前的微服务框架中，RPC 已经是我们很熟悉、很常用且很成熟的技术了。\n那 RPC 框架作为消息队列中的网络模块会有哪些优缺点呢？我们以 gRPC 框架举例分析。gRPC 是 Google 推出的一个 RPC 框架，可以说是 RPC 框架中的典型代表。主要有以下三个优点：\ngRPC 内核已经很好地实现了服务发现、连接管理、编解码器等公共部分，我们可以把开发精力集中在消息队列本身，不需要在网络模块消耗太多精力。 gRPC 几乎支持所有主流编程语言，开发各个消息队列的 SDK 可以节省很多开发成本。 很多云原生系统，比如 Service Mesh 都集成了 gRPC 协议，基于 HTTP2 的 gRPC 的消息队列很容易被云原生系统中的其他组件所访问，组件间的集成成本很低。 但是当前主流的消息队列都不支持 gRPC 框架，这是因为如果支持就要做很大的架构改动。而且，gRPC 底层默认是七层的 HTTP2 协议，在性能上，可能比直接基于 TCP 协议实现的方式差一些。但是 HTTP2 本身在性能上做了一些优化，从实际表现来看，性能损耗在大部分场景下是可以接受的。\n所以如果是一个新设计的消息队列或者消息队列的新架构，通过成熟的 RPC 框架来实现网络模块是一个蛮不错的方案。\n总结 MQ 的网络模块主要解决的是性能、稳定性和成本三个方面的问题。\n性能问题，核心是通过 Reactor 模型、IO 多路复用技术解决的。Reactor 模式在 Java 网络编程中用得非常广泛，比如 Netty 就实现了 Reactor 多线程模型。即使不用 Netty 进行网络编程（比如 Kafka 直接基于 Java NIO 编程）的情况下，网络模块也大多是参考或基于 Reactor 模式实现的。因为 Reactor 模式可以结合多路复用、异步调用、多线程等技术解决高并发、大流量场景下的网络模块的性能问题。\n在 Java 技术栈下，网络编程的核心是 Java NIO。但为了解决稳定性和开发成本的问题，建议选择业界成熟的网络框架来实现网络模块，而不是基于原生的 Java NIO 来实现。成熟的框架分为成熟的 NIO 框架（如 Netty）和成熟的 RPC 框架（如 gRPC）。\n目前业界主流的消息队列都是基于 Java NIO 和 Netty 实现的。Netty 是我们网络模块编程的常用选型，大部分情况下，可能还是我们的最终选择。但是 Netty 好用并不意味着所有的 Java 网络编程都必须选择 Java NIO 和 Netty。\n当需要构建一个组件的网络模块的时候，要先知道这个组件的业务特点是什么，需要解决哪些问题，再来考虑使用什么技术。比如在客户端连接数不多、并发不高，流量也很小的场景，只需要一个简单的网络 Server 就够了，完全没必要选择 Java NIO 或 Netty 来实现对应的网络模块。随着技术架构的迭代，基于 RPC 框架的方案也是一个不错的选择。\n","description":"","tags":null,"title":"MQ004——网络模块","uri":"/tech/bigdata/bigdata_mq004/"},{"categories":null,"content":"2023.07 杂记——聊聊所谓的“价值” 前言 其实从我个人角度来说，是不太喜欢聊“理想”、聊“价值”这类假大空的名词，因为不接地气，往往会给人虚假的感觉。尤其这几年互联网行业在招人的时候都喜欢来考察那所谓的“价值观”，以及动不动就喊一些“集体荣誉感”、“使命感”、“责任感”等废话口号，但往大了说是不是整个国家都在喊口号呢？？\n所以说嘛，与其让别人来整天嚷嚷，不如先自己来吐槽一波咯。最近，怎么说呢。可能和自己的预期不太符，也可能是这才是真正的样子，又和几个朋友唠唠他们的近况，聊的多了，想的多了，就会产生自我怀疑，再严重点会有精神内耗。何必让它耗呢，对吧。\n我这个是比较“佛”的，对于名声啊之类的都不屑于顾，更多的是想做自己。当然对于“价值”也认为是虚名，无非是给自己套个圈，变得不自在咯。\n这篇文章内容会极其主观（其实自己的博客大部分都会很主观咯），某些内容可能会引起一些玻璃心的不适应，如果你看着比较膈应，趁早退出，哈哈哈哈。\n谈谈 22 年的毕业生 就业环境 因为我自己也是从 22 本科毕业，总体来说周围很多人也较多是。上周末和大学同学聊天的时候忽然感慨道：我们才毕业一年，为何有一种脱离学生身份好多年的错觉。\n江湖上都流传着“00 后整顿职场”的烂梗，但实际上却是：“没整顿职场，现实先教会做人”。事实上，没有选择的机会，很多时候只能咬着牙忍下去。因为你并不是不可替代的，一个公开的职位，毫不客气地说会有大把的应聘者，你不愿意干，自然会有人做。所以有的时候，能遇见一家比较人性化的公司也不是很容易。（随便扯了一点，下面看看大环境：\n这一年毕业的人，去年上半年赶上疫情，无论是找工作，还是考公、考研复试，都有着一定的影响。最💩的是去年一年反反复复的封了差不多一年，年底直接大家一起喜🐑🐑，zczh！！笑死。哈哈哈哈。\n所以 22 届毕业生，到目前为止，真正就业的到底有多少呢？？近三年受疫情影响，抛弃一些宏观上的数据来说，经济下沉已成事实。所以对于整个社会的影响都是有的。加上 20 年研究生扩招，有的专硕是两年毕业，然后会发现近两年的应届生（韭菜）格外的多，而且差距特别大。所以我更偏向于 22 年毕业生真的不容易。。\n原生家庭 基于上述的环境，我见过有不少同龄人还在伸手向父母要钱，其中有继续读书的、也有在家备考的、甚至还有无所事事的，相信大多数的家长都有着“别人家”孩子的思想，“别人都可以你怎么就不行”这句话似乎不经意间就会随口而出，这句话也是最容易刺痛孩子的内心，因为这是来自于他们最亲近的人的质疑与不信任。\n比较庆幸的是，至少我爸妈不会这么对我说吧。我个人虽然谈不上优秀，但却足够独立，首先保证经济独立，才能进一步在思想上取得独立！！所以我就会和爸妈说：放在同龄人里面，我至少不是最差的，也就马马虎虎能够得过且过吧。但我这种其实属于个例，很多人是找不到一份说得过去的工作，而且一大部分人是没有工作能力的。之前看过一个笑话但也是事实，招个三千左右的体力工，求职者还会考虑考虑，但拿着三千却可以轻轻松松招个大学实习生。现实即是灰色幽默。。\n我们的上一代，上上一代都有很深的社会、文化以及历史的创伤，这些原生家庭的创伤可能会代代遗传。当风平浪静、岁月静好的时候，这些都会被隐藏起来，或者表现的不太明显。但是当形势一旦紧张，大环境不怎么光明，人受到挤压，就很容易被激发。而在传统的中国家庭中，家长经常说的一句话就是“我是为你好”。孩子很少被看作一个有独立意识的主体，他们的自我往往是不被看见的。儒家文化和集体主义也强调人际关系的和谐，把人放在群体中。\n很多中国孩子承载了家长过多的期待，他们从小接受的爱就是有条件的——“只有我这样做，爸爸妈妈才会爱我。”有的好学生被妈妈不断数落着长大，妈妈的理由是“我希望你完美”。她的缺点，是不被妈妈接受的。但“追求完美”是一场让人精疲力尽的夸父逐日游戏。这个好学生后来成为了工作狂，一闲下来就有罪恶感。因为没有接受过无条件的爱，好学生小时候迎合父母，长大后迎合领导，即使离开了家，他们内化了的严苛父母还会继续批判自己，对内攻击。\n那么这类人，当不努力工作的时候，还能是谁？？过去三十年里，中国社会的基调就是高大猛好，要创造，要发展，要向上，人们相信的是明天会更好，一分耕耘一分收获，好学生的人格也是在这样的环境中形成的。但当在职场“大杀四方”的愿望遇到收缩的环境，好学生就很容易产生自尊体系的崩塌。然后有的就开始选择卷。。。我是比较讨厌“内卷”这个词的，没啥意思，真的没意义。你能熬，还有比你更能熬的。而且我一直在强调在绝对的实力面前，内卷就纯纯的小丑，都是徒劳。尽可能去寻找自己的闪光点，去发挥自己的优势，而不是跟风去熬。\n孤身杭漂 在意识到上述的问题之后，我开始尝试离开家人身边，流放在异地，孤身一人当个杭漂，有的时候会觉得长这么大终于能够自己独立面对生活，比较自由。但还是挺怕家里人担心的。来杭州的时候，很多人都很费解，手里有更好的选择，为何还选择现在的公司呢。。emmmm 怎么说呢。从某种意义上来说，现如今的工作无论是技术上，还是薪资上都不是最优的。但从我个人角度来说，是比较适合自己的。刚出学校门，加上自己喜欢瞎折腾，学的技术比较杂，很多都不精，需要时间去沉淀。而且从主观上来说，上海和杭州这两个城市，我更喜欢后者。经过去年那么一折腾，前者太失望了。。。简单来说，就是想换个城市独立地生活，然后尽可能选择有自己时间的工作啦。\n来杭三个多月，新鲜劲也慢慢消散，仿佛自己也逐渐变成社畜的样子。回头想想，在学校的时候评价一个学生的好与坏往往是看成绩；在公司里动不动就提绩效，搞些形式主义，透漏着一股 cpu 味；进入社会评判一个人的成功与否，直接关系到是否有车有房。这不对吗？？这是对的。这也是目前这个社会的风气。但如果拿这些或者这类标准来决定价值的话，我大概率是不及格。目前自己所想的大部分事情都与之背道而驰，有的人问我，你有认真考虑过以后吗？？有的吧，指的是我只想过以后某个阶段的自己是什么状态，但具体到在哪做什么事情就不得而知了。我不想被生活所约束，更想成为我自己。\n我本身对于技术，虽然谈不上热爱，但至少是不排斥。曾几何时，刚遇见“开源”的时候，原以为找到了值得自己付出一辈子为之努力的方向，但随之了解的越深入，接触到背后的逻辑，开源社区的运作、开源圈子以及开源商业化之后，开始有点质疑自己所做的事情是否真的有价值，虽然心里明白开源确实是大势所趋。参与开源，也算是成就了自己。\n不过，反过来想，投入自己的时间去学习去探索去钻研技术，虽然提升的是自己，但最后给到的反馈还是公司，所以真的有必要吗？？\n日子就这样过吧 工作是为了生活，那为何不直接选择生活呢？？互联网的发展，无形中将焦虑放大了。名校论、学历论、金钱论、车房论本质上没啥区别，没有谁比谁高级，对于自身的认知不同，看重的自然而然也就不一样咯。大部分人都在想着要过得比“别人”好。其实没必要，都一样。\n那么，我选择和自己和解、和生活和解🙏。\n有时候我就会想啊，也许最好的状态就是，意识到“我的存在本身就是价值，哪怕什么都不做，只是呼吸，我都是有价值的”。我的价值，不需要外界来定义！！这种状态，也就是自由。。\n","description":"","tags":null,"title":"杂记——聊聊所谓的‘价值’","uri":"/life/202307_value/"},{"categories":null,"content":"如何为消息引擎系统设计一个好的通信协议？ 前言 经过上面两篇博客的梳理，已经了解了 MQ 的基本概念。从功能上看，一个最基础的消息引擎系统应该具备生产、存储和消费的能力。也就是能够完成“生产者把数据发送到 Broker，Broker 收到数据后，持久化存储数据，最后消费者从 Broker 消费数据”的整个流程。\n从整个流程来拆解技术架构，最基础的消息引擎系统应该具备五个模块：\n通信协议：用来完成客户端（生产者和消费者）和 Broker 之间的通信，比如生产和消费； 网络模块：客户端用来发送数据，服务端用来接收数据； 存储模块：服务端用来完成持久化数据存储； 生产者：完成生产相关的功能； 消费者：完成消费相关的功能。 其实消息引擎系统，本质上讲就是个 CS 模型，即通过客户端和服务端之间的交互完成生产、消费等行为。那么客户端和服务端之间的通信流程是如何实现的呢？？\n这就是今天的重点——通信协议。为了完成交互，我们第一步就需要确定服务端和客户端是如何通信的。而通信的第一步就是确定使用哪种通信协议进行通信。\n通信协议基础 所有协议的选择和设计都是根据需求来的，我们知道 MQ 的核心特性是高吞吐、低延时、高可靠，所以在协议上至少需要满足：\n协议可靠性要高，不能丢数据； 协议的性能要高，通信的延时要低； 协议的内容要精简，带宽的利用率要高； 协议需要具备可扩展能力，方便功能的增减。 那没有没现成的满足这四个要求的协议呢？\n目前业界的通信协议可以分为公有协议和私有协议两种。公有协议指公开的受到认可的具有规范的协议，比如 JMS、HTTP、STOMP 等。私有协议是指根据自身的功能和需求设计的协议，一般不具备通用性，比如 Kafka、RocketMQ、Puslar 的协议都是私有协议。\n其实 MQ 领域是存在公有的、可直接使用的标准协议的，比如 AMQP、MQTT、OpenMessaging，它们设计的初衷就是为了解决因各个消息队列的协议不一样导致的组件互通、用户使用成本高、重复设计、重复开发成本等问题。但是，公有的标准协议讨论制定需要较长时间，往往无法及时赶上需求的变化，灵活性不足。\n因此大多数消息队列为了自身的功能支持、迭代速度、灵活性考虑，在核心通信协议的选择上不会选择公有协议，都会选择自定义私有协议。那私有协议要怎么设计实现呢？从技术上来看，私有协议设计一般需要包含三个步骤。\n网络通信协议选型，指计算机七层网络模型中的协议选择。比如传输层的 TCP/UDP、应用层的 HTTP/WebSocket 等； 应用通信协议设计，指如何约定客户端和服务端之间的通信规则。比如如何识别请求内容、如何确定请求字段信息等； 编解码（序列化 / 反序列化）实现，用于将二进制的信息的内容解析为程序可识别的数据格式。 网络通信协议选型 从功能需求出发，为了保证性能和可靠性，几乎所有主流的 MQ 在核心生产、消费链路的协议选择上，都是基于可靠性高、长连接的 TCP 协议。\n四层的 UDP 虽然也是长连接，性能更高，但是因为其不可传输的特性，业界几乎没有消息引擎系统用它通信。\n七层的 HTTP 协议每次通信都需要经历三次握手、四次关闭等步骤，并且协议结构也不够精简。因此在性能（比如耗时）上的表现比较差，不适合高吞吐、大流量、低延时的场景。所以主流协议在核心链路上很少使用 HTTP。\n应用通信协议设计 从应用通信协议构成的角度，协议一般会包含协议头和协议提两部分。\n协议头包含一些通用信息和数据源信息，比如协议版本、请求标识、请求 ID、客户端 ID 等等； 协议体主要包含本次通信的业务数据，比如一个字符串、一段 JSON 格式的数据或者原始二进制数据等等。 从编解码协议的设计角度来看，需要分别针对“请求”和“返回”设计协议，请求协议结构和返回协议结构一般如下图：\n设计的原则是：请求维度的通用信息放在协议头，消息维度的信息就放在协议体。下面结合 Kafka 协议来详细分析一下：\n协议头的设计 协议头的设计，首先要确认协议中需要携带哪些通用的信息。一般情况下，请求头要携带本次请求以及源端的一些信息，返回头要携带请求唯一标识来标识对应哪个请求。\n所以，请求头一般需要携带协议版本、请求标识、请求的 ID、客户端 ID 等信息。而返回头，一般只需要携带本次请求的 ID、本次请求的处理结果（成功或失败）等几个信息。\n接下来，我们分析一下 Kafka 协议的请求头和返回头的内容，以便于对协议头的设计有个更直观的认识。如下图所示，Kafka V2 协议的请求头中携带了四个信息。\n用来标识请求类型的 api_key，如生产、消费、获取元数据； 用来标识请求协议版本的 api_version，如 V0、V1、V2； 用来唯一标识该请求 correlation_id，可以理解为请求 ID； 用来标识客户端的 client_id。 Kafka V0 协议的返回头只携带了一个信息，即该请求的 correlation_id，用来标识这个返回是哪个请求的。\n这里有个细节你可能注意到了，请求协议头是 V2 版本，返回协议头是 V0 版本，会不会有点问题呢？\n其实是没有的。因为从协议的角度，一般业务需求的变化（增加或删除）都会涉及请求内容的修改，所以请求的协议变化是比较频繁的，而返回头只要能标识本次对应的请求即可，所以协议的变化比较少。所以，请求头和返回头的协议版本制定，是建议分开定义的，这样在后期的维护升级中会更加灵活。\n协议体的设计 协议体的设计就和业务功能密切相关了。因为协议体是携带本次请求 / 返回的具体内容的，不同接口是不一样的，比如生产、消费、确认，每个接口的功能不一样，结构基本千差万别。\n不过设计上还是有共性的，注意三个点：极简、向后兼容、协议版本管理。如何理解呢？\n协议在实现上首先需要具备向后兼容的能力，后续的变更（如增加或删除）不会影响新老客户端的使用；然后协议内容上要尽量精简（比如字段和数据类型），这样可以降低编解码和传输过程中的带宽的开销，以及其他物理资源的开销；最后需要协议版本管理，方便后续的变更。\n同样为了让你直观感受协议体的设计，我们看 Kafka 生产请求和返回的协议内容：\nKafka 生产请求协议如下：\nKafka 生产返回协议如下：\nKafka 生产请求的协议体包含了事务 ID、acks 信息、请求超时时间、Topic 相关的数据，都是和生产操作相关的。生产返回的协议体包含了限流信息、分区维度的范围信息等。这些字段中的每个字段都是经过多轮迭代、重复设计定下来的，每个字段都用用处。\n所以在协议体的设计上，最核心的就是要遵循“极简”原则，在满足业务要求的基础上，尽量压缩协议的大小。\n接下来我想讨论一下数据类型，在协议设计里，我们很容易忽略的一个事就是数据类型，比如上面 throttle_time_ms 是 INT32，error_code 是 INT16。\n数据类型很简单，用来标识每个字段的类型，不过为什么会有这个东西呢，不能直接用 int、string、char 等基础类型吗？这里有两个原因。\n消息队列是多语言通信的。不同语言对于同一类型的定义和实现是不一样的，如果使用同一种基础类型在不同的语言进行解析，可能会出现解析错乱等错误。 需要尽量精简消息的长度。比如只需要 1 个 byte 就可以表示的内容，如果用 4 个 byte 来表示，就会导致消息的内容更长，消耗更多的物理带宽。 所以一般在协议设计的时候，我们也需要设计相关的基础数据类型（如何设计可以参考 Kafka 的协议数据类型或者 Protobuf 的数据类型）。\n编解码实现 编解码也称为序列化和反序列，就是数据发送的时候编码，收到数据的时候解码。\n为什么要编解码呢? 如下图所示，因为数据在网络中传输时是二进制的形式，所以在客户端发送数据的时候就要将原始的格式数据编码为二进制数据，以便在 TCP 协议中传输，这一步就是序列化。然后在服务端将收到的二进制数据根据约定好的规范解析成为原始的格式数据，这就是反序列化。\n在序列化和反序列化中，最重要的就是 TCP 的粘包与拆包。TCP 是一个“流”协议，是一串数据，没有明显的界限，TCP 层面不知道这段数据的意义，只负责传输。所以应用层就要根据某个规则从流数据中拆出完整的包，解析出有意义的数据，这就是沾包和拆包的作用。\n沾包 / 拆包的基本思路：\n消息定长； 在包尾增加回车换行符进行分割，例如 FTP 协议； 将消息分为消息头和消息体，消息头中包含消息总长度，然后根据长度从流中解析出数据； 更加复杂的应用层协议，比如 HTTP、WebSocket 等。 早期，消息队列的协议设计几乎都是自定义实现编解码，如 RabbitMQ、RocektMQ 4.0、Kafka 等。但从 0 实现编解码器比较复杂，随着业界主流编解码框架和编解码协议的成熟，一些消息队列（如 Pulsar 和 RocketMQ 5.0）开始使用业界成熟的编解码框架，如 Google 的 Protobuf。Protobuf 是一个灵活、高效、结构化的编解码框架，业界非常流行，很多商业产品都会用，它支持多语言，编解码性能较高，可扩展性强，产品成熟度高。这些优点，都是我们在设计协议的时候需要重点考虑和实现的，并且我们自定义实现编解码的效果不一定有 Protobuf 好。所以新的消息队列产品或者新架构可以考虑选择 Protobuf 作为编解码框架。\n如果想关注如何在 MQ 中实现自定义编码，可以去深入了解 RocketMQ，它是目前业界唯一一个既支持自定义编解码，又支持成熟编解码框架的消息引擎系统。RocketMQ 5.0 之前支持的 Remoting 协议是自定义编解码，5.0 之后支持的 gRPC 协议是基于 Protobuf 编解码框架。用 Protobuf 的主要原因是它选择 gRPC 框架作为通信框架。而 gRPC 框架中默认编解码器为 Protobuf，编解码操作已经在 gRPC 的库中正确地定义和实现了，不需要单独开发。所以 RocketMQ 可以把重点放在 Rocket 消息队列本身的逻辑上，不需要在协议方面上花费太多精力。\n总结 无论是做业务开发，还是数据开发，都或多或少和 MQ 打过交道，很多程序员可能只停留在如何使用上，其实慢慢尝试往下走一步会有不一样的收获～～\n这篇博客也只是浅谈 MQ 底层关于通信协议设计的讨论。从功能支持、迭代速度、灵活性上考虑，大多数消息队列的核心通信协议都会优先考虑自定义的私有协议。私有协议的设计主要考虑网络通信协议选择、应用通信协议设计、编解码实现三个方面。\n网络通信协议选型，基于可靠、低延时的需求，大部分情况下应该选择 TCP。 应用通信协议设计，分为请求协议和返回协议两方面。协议应该包含协议头和协议体两部分。协议头主要包含一些通用的信息，协议体包含请求维度的信息。 编解码，也叫序列化和反序列化。在实现上分为自定义实现和使用现成的编解码框架两个路径。 其中最重要的是应用通信协议部分的设计选型，这部分需要设计协议头和协议体。重要的是要思考协议头和协议体里面分别要放什么，放多了浪费带宽影响传输性能，放少了无法满足业务需求，需要频繁修改协议内容。\n另外，每个字段的类型也有讲究，需要尽量降低每次通信的数据大小。所以应用通信协议的内容设计是非常考验技术功底或者经验的。有一个技巧是，如果需要实现自定义的协议，可以去参考一下业界主流的协议实现，看看都包含哪些元素，各自踩过什么坑。总结分析后，这样一般能设计出一个相对较好的消息队列。\n思考？？ 为什么业界的消息引擎系统有多种标准的协议呢？？\n业界的消息队列有多种标准的协议，如 MQTT、AMQP、OpenMessaging。主要是因为业务场景不一样，一套协议标准无法满足多种场景需要。\nMQTT 是为了满足物联网领域的通信而设计的，背景是网络环境不稳定、网络带宽小，从而需要极精简的协议结构，并允许可能的数据丢失。 AMQP 是主要面向业务消息的协议，因为要承载复杂的业务逻辑，所以协议设计上要尽可能丰富，包含多种场景，并且在传输过程中不允许出现数据丢失。因为 AMQP 协议本身的设计具有很多局限，比如功能太简单，所以不太符合移动互联网、云原生架构下的消息需求。 OpenMessaging 的设计初衷是设计一个符合更多场景的消息队列协议。 ","description":"","tags":null,"title":"MQ003——通信协议","uri":"/tech/bigdata/bigdata_mq003/"},{"categories":null,"content":"消息引擎系统的基本概念 前言——什么时候会用 MQ？？ 经过上一节 blog 的内容，以及了解了有关 MQ 的前置知识。那么是否会有想过 MQ 会用在哪些场景呢？\n在现如今的系统架构中，MQ 的定位就是总线和管道，主要起到解耦上下游系统、数据缓存的作用，通俗点就是“削峰填谷”。这个时候肯定会有人会想到 Redis 之类的数据库，与之不同的是它的主要操作就是生产和消费，而不太会关注计算、聚合和查询的逻辑。所以，在业务中不管使用哪款 MQ，其核心的操作永远是生产和消费数据。\n上次提到的订单下单流程就是一个典型的系统解耦、消息分发的场景，一份数据需要被多个下游系统处理。在大数据领域中，比较经典的就是日志采集流程，一般日志数据都很大，而且是实时产生的，直接发到下游，下游系统可能会扛不住崩溃，所以会把数据先缓存到 MQ 中。实际现如今的数仓，不仅仅是日志文件写入 Kafka 之类的消息引擎系统，有时候也会选择被存储在数据库中的业务数据，通过增量同步的方式传入到 MQ，然后再统一采集到 HDFS 上。\n针对以上场景，一款优秀的消息引擎系统必须满足：高性能、高吞吐和低延时等基本特性。\n架构层面的基本概念 Topic：在大部分 MQ 中，topic 都是指用来组织分区关系的一个逻辑概念。通常情况下，一个 topic 会包含多个分区。在 Kafka 中，发布订阅的是 topic，可以为每个业务、每个应用甚至是每类数据都创建专属的 topic；\nProducer（生产者）：向 topic 发布消息的客户端应用程序称为生产者，生产者程序通常会持续不断地向一个或多个主题发送消息。简单来说就是：指消息的发送方，发送消息的客户端；\nConsumer（消费者）：订阅这些主题消息的客户端应用程序称为消费者，和生产者类似，消费者也能够同时订阅多个注意的消息。说通俗点就是，指消息的接收方，即接收消息的客户端；\nBroker：Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。Broker 本质上是一个进程。Kafka 的服务器端由被称为 Broker 的服务进程构成，即一个 Kafka 集群由多个 Broker 组成。虽然多个 Broker 进程能够运行在同一台机器上，但更常见的做法是将不同的 Broker 分散运行在不同的机器上，这样如果集群中某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也依然能够对外提供服务。这其实就是 Kafka 提供高可用的手段之一；\nConsumerGroup/Subscription（消费分组 / 订阅）：一般情况下，消息队列中消费分组和订阅是同一个概念，后面统一用消费分组来称呼。它是用来组织消费者和分区关系的逻辑概念，也有保存消费进度的作用。\nMessage（消息）：指一条真实的业务数据，消息队列的每条数据一般都叫做一条消息。\nOffset/ConsumerOffset/Cursor（位点 / 消费位点 / 游标）：指消费者消费分区的进度，即每个消费者都会去消费分区，为了避免重复消费进度，都会保存消费者消费分区的进度信息。\nACK/OffsetCommit（确认 / 位点提交）：确认和位点提交一般都是指提交消费进度的操作，即数据消费成功后，提交当前的消费位点，确保不重复消费。\nLeader/Follower（领导者 / 追随者，主副本 / 从副本）：Leader 和 Follower 一般是分区维度副本的概念，即集群中的分区一般会有多个副本。此时就会有主从副本的概念，一般是一个主副本配上一个或多个从副本。\nSegment（段 / 数据分段）：段是指消息数据在底层具体存储时，分为多个文件存储时的文件，这个文件就叫做分区的数据段。即比如每超过 1G 的文件就新起一个文件来存储，这个文件就是 Segment。基本所有的消息队列都有段的概念，比如 Kakfa 的 Segment、Pulsar 的 Ledger 等等。\nStartOffset/EndOffset（起始位点 / 结束位点）：起始位点和结束位点是分区维度的概念。即数据是顺序写入到分区的，一般从 0 的位置开始往后写，此时起始位点就是 0。因为数据有过期的概念，分区维度较早的数据会被清理。此时起始位点就会往后移，表示当前阶段最早那条有效消息的位点。结束位点是指最新的那条数据的写入位置。因为数据一直在写入分区，所以起始位点和结束位点是一直动态变化的。\nACL（访问控制技术）：ACL 全称是 Access Control List，用来对集群中的资源进行权限控制，比如控制分区或 Topic 的读和写等。\n功能层面的基础概念 讲完了架构层面的基本概念，我们来看看功能层面的基本概念。\n相比于数据库的基本操作是增删改查，消息队列的基本操作就是生产和消费，即读和写。消息队列一般是不支持客户端修改和删除单条数据的。接下来我们就从功能的角度，来了解一些常见的基本概念。\n顺序消息：是指从生产者和消费者的视角来看，生产者按顺序写入 Topic 的消息，在消费者这边能不能按生产者写入的顺序消费到消息，如果能就是顺序消息。 延时消息 / 定时消息：都是指生产者发送消息到 Broker 时，可以设置这条消息在多久后能被消费到，当时间到了后，消息就会被消费到。延时的意思就是指以 Broker 收到消息的时间为准，多久后消息能被消费者消费，比如消息发送成功后的 30 分钟才能被消费。定时是指可以指定消息在设置的时间才能被看到，比如设置明天的 20:00 才能被消费。从技术上来看，两者是一样的；从客户端的角度，功能上稍微有细微的差别；从内核的角度，一般两种消息是以同一个概念出现的。 事务消息：消息队列的事务因为在不同的消息队列中的实现方式不一样，所以定义也不太一样。正常情况下，事务表示多个操作的原子性，即一批操作要么一起成功，要么一起失败。在消息队列中，一般指发送一批消息，要么同时成功，要么同时失败。 消息重试：消息重试分为生产者重试和消费者重试。生产者重试是指当消息发送失败后，可以设置重试逻辑，比如重试几次、多久后重试、重试间隔多少。消费者重试是指当消费的消息处理失败后，会自动重试消费消息。 消息回溯：是指当允许消息被多次消费，即某条消息消费成功后，这条消息不会被删除，还能再重复到这条消息。 广播消费：广播听起来是一个主动的，即 Broker 将一条消息广播发送给多个消费者。但是在消息队列中，广播本质上是指一条消息能不能被很多个消费者消费到。只要能被多个消费者消费到，就能起到广播消费的效果，就可以叫做广播消费。 死信队列：死信队列是一个功能，不是一个像分区一样的实体概念。它是指当某条消息无法处理成功时，则把这条消息写入到死信队列，将这条消息保存起来，从而可以处理后续的消息的功能。大部分情况下，死信队列在消费端使用得比较多，即消费到的消息无法处理成功，则将数据先保存到死信队列，然后可以继续处理其他消息。当然，在生产的时候也会有死信队列的概念，即某条消息无法写入 Topic，则可以先写入到死信队列。从功能上来看，死信队列的功能业务也可以自己去实现。消息队列中死信队列的意思是，消息队列的 SDK 已经集成了这部分功能，从而让业务使用起来就很简单。 优先级队列：优先级队列是指可以给在一个分区或队列中的消息设置权重，权重大的消息能够被优先消费到。大部分情况下，消息队列的消息处理是 FIFO 先进先出的规则。此时如果某些消息需要被优先处理，基于这个规则就无法实现。所以就有了优先级队列的概念，优先级是消息维度设置的。 消息过滤：是指可以给每条消息打上标签，在消费的时候可以根据标签信息去消费消息。可以理解为一个简单的查询消息的功能，即通过标签去查询过滤消息。消息过滤主要在消费端生效。 消息过期 / 删除（TTL）：是指消息队列中的消息会在一定时间或者超过一定大小后会被删除。因为消息队列主要是缓冲作用，所以一般会要求消息在一定的策略后会自动被清理。 消息轨迹：是指记录一条消息从生产端发送、服务端保存、消费端消费的全生命周期的流程信息。用来追溯消息什么时候被发送、是否发送成功、什么时候发送成功、服务端是否保存成功、什么时候保存成功、被哪些消费者消费、是否消费成功、什么时候被消费等等信息 消息查询：是指能够根据某些信息查询到消息队列中的信息。比如根据消息 ID 或根据消费位点来查询消息，可以理解为数据库里面的固定条件的 select 操作。 消息压缩：是指生产端发送消息的时候，是否支持将消息进行压缩，以节省物理资源（比如网卡、硬盘）。压缩可以在 SDK 完成，也可以在 Broker 完成，并没有严格限制。通常来看，压缩在客户端完成会比较合理。 多租户：是指同一个集群是否有逻辑隔离，比如一个物理集群能否创建两个名称都为 test 的主题。此时一般会有一个逻辑概念 Namespace（命名空间）和 Tenant（租户）来做隔离，一般有这两个概念的就是支持多租户。 消息持久化：是指消息发送到 Broker 后，会不会持久化存储，比如存储到硬盘。有些消息队列为了保证性能，只会把消息存储在内存，此时节点重启后数据就会丢失。 消息流控：是指能否对写入集群的消息进行限制。一般会支持 Topic、分区、消费分组、集群等维度的限流。 总结（扩展） 看完了上面的基础概念，下面就以 Kafka 为例，整体来看一下～～\nKafka 的三层消息架构：\n第一层是主题层，每个主题可以配置 M 个分区，而每个分区又可以配置 N 个副本。\n第二层是分区层，每个分区的 N 个副本中只能有一个充当领导者角色，对外提供服务；其他 N-1 个副本是追随者副本，只是提供数据冗余之用。\n第三层是消息层，分区中包含若干条消息，每条消息的位移从 0 开始，依次递增。\n最后，客户端程序只能与分区的领导者副本进行交互。\nKafka Broker 如何持久化数据？？\n总的来说，Kafka 使用消息日志（Log）来保存数据，一个日志就是磁盘上一个只能追加写（Append-only）消息的物理文件。因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。不过如果你不停地向一个日志写入消息，最终也会耗尽所有的磁盘空间，因此 Kafka 必然要定期地删除消息以回收磁盘。怎么删除呢？简单来说就是通过日志段（Log Segment）机制。在 Kafka 底层，一个日志又进一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。Kafka 在后台还有定时任务会定期地检查老的日志段是否能够被删除，从而实现回收磁盘空间的目的。\n谈谈消费者\n这里再重点说说消费者。上一篇博客中提到过两种消息模型，即点对点模型（Peer to Peer，P2P）和发布订阅模型。这里面的点对点指的是同一条消息只能被下游的一个消费者消费，其他消费者则不能染指。在 Kafka 中实现这种 P2P 模型的方法就是引入了消费者组（Consumer Group）。\n所谓的消费者组，指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它。为什么要引入消费者组呢？**主要是为了提升消费者端的吞吐量。**多个消费者实例同时消费，加速整个消费端的吞吐量（TPS）。BTW 这里的消费者实例可以是运行消费者应用的进程，也可以是一个线程，它们都称为一个消费者实例（Consumer Instance）。\n消费者组里面的所有消费者实例不仅“瓜分”订阅主题的数据，而且更牛掰的的是它们还能彼此协助。假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个 Failed 实例之前负责的分区转移给其他活着的消费者。这个过程就是 Kafka 中大名鼎鼎的“重平衡”（Rebalance）。嗯，其实既是大名鼎鼎，也是臭名昭著，因为由重平衡引发的消费者问题比比皆是。事实上，目前很多重平衡的 Bug 社区都无力解决。每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上，这个字段就是消费者位移（Consumer Offset）。\n注意，这和上面所说的位移完全不是一个概念。上面的“位移”表征的是分区内的消息位置，它是不变的，即一旦消息被成功写入到一个分区上，它的位移值就是固定的了。而消费者位移则不同，它可能是随时变化的，毕竟它是消费者消费进度的指示器嘛。另外每个消费者有着自己的消费者位移，因此一定要区分这两类位移的区别。我个人把消息在分区中的位移称为分区位移，而把消费者端的位移称为消费者位移。\n","description":"","tags":null,"title":"MQ002——消息引擎系统的基本常识","uri":"/tech/bigdata/bigdata_mq002/"},{"categories":null,"content":"开发者的落日？？ 前言 这篇文章，早就想写，但又怕自己资历太浅，见识不够，会的太少，写出来或多或少有点泛泛而谈，或者说蹭热度，毕竟最近遇上互联网寒冬，各个大厂裁员，这也是事实。\n熬过了💩一样的 2022，原以为今年会好那么一丢丢，但实际发现也就那么回事，整个行业危机似乎在某种程度上来说可以进一步加剧了。那么互联网的红利期是真的过去了吗？\n这是一切的开始，这也是人类的落日。\n谈谈程序员 从我的角度来说，我一直很喜欢程序员这个行业，从本质上来说，开发的本质是创造，而创造的过程中是连接着未来的。但不知从何时起出现了“码农”这个称呼，因为 CRUD 的操作，这一点从我接触这个行业开始就早已存在，我是极其特别讨厌这个称呼。因为它将整个行业形容成做的东西就是重复劳动，没有意义可言。\n那么这类人可以称之为程序员嚒？至少在我是不认可的，或者说不能当“职业的程序员”。GPT 的出现，可以说是划时代的产品，它将颠覆以往的编程方式，只会这种 CRUD 的操作人，也会进一步被淘汰，因为从本质上来说就没必要存在。但这却是这个行业的普遍现状，又有几个能做中间件开发呢？？\n所以普通的开发者要深刻理解一件事情，如今你暂时拿在手里的看似高薪不是个人能力的体现，是行业带动的结果，那么行业带动的结果。你要感谢两家公司微软和 Google。\n如果整个互联网行业只有 2 家公司可以存活的话，除了微软和Google，任何其他企业都没有资格，只能去死。\n微软大幅降低了编程的门槛，围绕操作系统诞生一整套的生态，把编程变成了一种普通人可以当成工作的玩意儿。从这角度来看，那怕你不懂编程，能读懂英文，也能七七八八理解一段简单的代码。\nGoogle 站在巨人的肩膀上，从提出分布式这个概念开始，几乎重塑了整个计算机行业。此后，Google 不满足于此，不仅疯狂制定顶层标准，而且在科技界的贡献持续造福全人类。\n可以这么说，互联网行业这些年的高光完全是行业热潮带动普通开发人员受益，而不是个人本身。我们都是风口上的猪而已。\n技术本身门槛的大幅降低导致【技术通货膨胀】，更多的人参与就代表每个人分到更少的蛋糕。回归公司的本质，一个专注于技术但是对业务 0 贡献的开发者为什么能拿高薪趴在电脑前？存量市场的竞争白热化，躺着赚钱的时代终结。不懂业务，疯狂跳槽，盲目转行，仅仅追逐技术能力的提升脱离商业本身的开发者最终会被弃之如敝履。\n综上所述，简单来说就是普通的技术越来越不值钱。\n人人皆可编程：Low Code Low Code Development Platform 是指无需编码（0 代码）或通过少量代码就可以快速生成应用程序的开发平台。\n低代码在干什么？我们直接引用行业大佬的一句话：\n低代码是基于可视化和模型驱动理念，结合云原生与多端体验技术，它能够在多数业务场景下实现大幅度的提效降本，为专业开发者提供了一种全新的高生产力开发范式。另一方面，低代码能够让不懂代码的人，通过“拖拉拽”开发组件，就能完成应用搭建。从意义上讲，低代码可以弥补日益扩大的专业技术人才缺口，同时促成业务与技术深度协作的终极敏捷形态。 看到了么？低代码是让不懂的人可以进行完成相关开发任务。这个领域的发展会迅速淘汰掉企业中的某些混子，然后向外蔓延开来。\n下面以大数据方面来举例（Java 后端开发的脚手架太多了 都是些烂梗 没意思），现如今无论公司规模大小，很多企业都想要整个大数据平台，可能会面临的问题就是，没有专业大数据开发者。如何在节省人力成本的情况下解决这个难题呢？？\n因为大数据的组件框架众多，搭建一套高可用能够落地的集群系统就存在着不小的难度，那么有没有可以一键部署安装的平台呢？？又该如何管理这些大数据组件呢？如果有的话，是否就可以让后端工程师通过写 SQL 完成大数据的工作呢？？还有一点就是各个工作流之间的上下游关系以及整个集群的任务调度是否可以通过“拖拉拽”的方式完成呢？？答案是肯定的。\n显而易见，后端开发写 SQL 算是基本功，只需了解各个大数据组件的用途，再看些行业大牛的分享就足以完成一个低代码版的大数据集群。是否可以进一步来说，其他领域也很难独善其身。\n丧钟为谁而鸣？\nFaaS 和 PaaS 关于云计算时代的一些名词不做过多解释，可以自行去查资料。\n从 2021 年开始，其实从 2020 年下半年就初露端倪。FaaS 重新被推上风口浪尖，普通开发者应该感到危机。\nFaaS 是 Functions as a Service 的简称，它往往和无服务架构（Serverless Architecture）一同被提起。PaaS 是 Platform as a Service 的简称，是一种云模型，你提供源码，平台将打包、发布、部署、运行、监控和扩缩微服务。\n为了好理解就拿 FaaS 举例。\n大家注意，FaaS 自上而下，和上文的低代码自下而上对普通开发者形成了双重挤压，对普通开发者的生存空间造成了严重影响。\nFaaS 在干什么？FaaS 抛弃了原来大型复杂应用的架构，将整个架构中的单元进行拆分，将各种软、硬件资源等抽象为一种服务提供给开发者使用，让他们不再担心基础设施、资源需求、中间件等等，专注于具体逻辑实现。\n看到了么？FaaS 已经将整个开发者最需要脑子和开发量的工作吃掉了。基础设施和中间件乃至服务器资源的管理，不需要开发者介入。这会导致什么后果？\n大批量【填鸭式】进入这个行业的开发者你们应该感到危机。因为 FaaS 正把你们变成实实在在的【工具人】。\n所谓工具人，就是低成本、易替换。\n谈谈对于大数据的影响 再次声明，只是个人的思考。我也希望未来几年回过来看自己使劲打自己脸。\n数据领域进入平台期，门槛降低，湖仓一体，批流结合。这一点可以看看 Apache 和数据领域的顶级项目和孵化器中的项目。\n未来低代码盛行，类 SQL、拖拉拽大行其道，会导致开发者们离原理越来越远，不懂底层设计，不懂顶层架构，结合上文拿大数据低代码举的例子，这一点应该不难理解，像阿里的 DataWorks 对于用户来说只要会写 SQL 就可以。数据领域天然 Low Code。\n愚者还在窃喜，智者却在悲伤。\n因为而致力于低代码和云计算领域的行业推动者正是微软、Google、阿里云这些行业引领者。\n它们成就了开发者盛世，也会亲手毁掉开发者。\n所谓，成也萧何败也萧何。\n不破不立 懂原理 目前数据领域还处于上升期，每过一段时间就会蹦出几个新概念。这些新概念势必会带动一些基础架构部门的发展，因为基础架构部门不向前跑，就会变成运维专家，变成答疑专家，就会自己干掉自己。\n所以，作为引领公司甚至行业的基础开发者，基于业务大胆启用新的技术方案前，只有对原理足够熟悉，才能做到顺利转型。盲目上马，不做出充分调研，技术能力不足会被其他领跑者拖死。可以想一下 MQ 之类的框架，微服务在用，大数据中也是必不可少，那么区别在哪呢？？又有多少用户仅仅是只掌握几条常用命令呢？？\n顶层架构设计 这一点我是比较佩服顶级的运维，很多开发者嘲笑运维不会写代码，也有可能只是个梗，一个好的运维是可以看见整个集群全貌的，这一部分仅仅只做开发是很难做到的。那么一个好的架构设计，尤其是基于业务系统的合理技术选型和正确的架构设计，这对开发者提出了相当高的要求，技术栈足够深入，场景足够丰富的情况下才能游刃有余。对于那些技术 Leader，这更是巨大的挑战。否则，一将无能，累死千军。要么你足够优秀可以当做火把给全队把路照亮，要么就要有足够的魅力发现和吸引那些是火把的人。\n懂业务 业务才是开发者的立足根本，对业务足够熟悉，才能最终站稳脚跟。随着开发门槛的不断降低，业务人员，尤其是一些专业的熟悉业务的且可以做分析的业务人员，它们对于开发会逐渐降低依赖，在低代码和套件化足够成熟的未来，只懂开发的开发者会被边缘化。\n参与开源 参与开源，拥抱未来，这一点不想再解释了。。\n所以，2023 年是一切的开始，也是开发者的落日？？\n","description":"","tags":null,"title":"2023，不想再谈技术？？","uri":"/tech/2023_mid/"},{"categories":null,"content":"关于消息引擎系统 一、前言 看见标题写的是“消息引擎系统”，咋一看是不是觉得比较陌生，那么换个说法呢，比如“消息队列”、“消息中间件”这些无论是在后端开发还是在大数据中想必都是耳熟能详的啦。但从我的角度来说，更喜欢称呼其为“消息引擎系统”。因为消息队列给出了一个不太明确的暗示，仿佛类似 Kafka 之类的框架是利用队列的方式构建的；而消息中间件的提法有过度夸张“中间件”之嫌，让人搞不清楚这个中间件到底是做什么用途的。\n像 Kafka 这一类的系统国外有专属的名字叫 Messaging System，国内很多文献将其简单翻译成消息系统。我个人认为并不是很恰当，因为它片面强调了消息主体的作用，而忽视了这类系统引以为豪的消息传递属性，就像引擎一样，具备某种能量转换传输的能力，所以我觉得翻译成消息引擎反倒更加贴切。\n讲到这里，说点题外话。我觉得目前国内在翻译国外专有技术词汇方面做得不够标准化，各种名字和提法可谓五花八门。我举个例子，比如大名鼎鼎的 Raft 算法和 Paxos 算法。了解它的人都知道它们的作用是在分布式系统中让多个节点就某个决定达成共识，都属于 Consensus Algorithm 一族。如果你在搜索引擎中查找 Raft 算法，国内多是称呼它们为一致性算法。实际上我倒觉得翻译成共识算法是最准确的。我们使用“一致性”这个字眼太频繁了，国外的 Consistency 被称为一致性、Consensus 也唤作一致性，甚至是 Coherence 都翻译成一致性。\n二、用途 根据维基百科的定义，消息引擎系统是一组规范。企业利用这组规范在不同系统之间传递语义准确的消息，实现松耦合的异步式数据传递。\n常见的官网不说人话系列，读起来云里雾里的。其实简单来说就是：系统 A 发送消息给消息引擎系统，系统 B 从消息引擎系统中读取 A 发送的消息。\n最基础的消息引擎就是做这点事的！不论是上面哪个版本，它们都提到了两个重要的事实：\n消息引擎传输的对象是消息； 如何传输消息属于消息引擎设计机制的一部分。 三、传输信息 既然消息引擎是用于在不同系统之间传输消息的，那么如何设计待传输消息的格式从来都是一等一的大事。试问一条消息如何做到信息表达业务语义而无歧义，同时它还要能最大限度地提供可重用性以及通用性？稍微停顿几秒去思考一下，如果是你，你要如何设计你的消息编码格式。\n一个比较容易想到的是使用已有的一些成熟解决方案，比如使用 CSV、XML 亦或是 JSON；又或者你可能熟知国外大厂开源的一些序列化框架，比如 Google 的 Protocol Buffer 或 Facebook 的 Thrift。这些方法借助开源框架实现都是不错的选择，那么像 Kafka 这种事如何实现的呢？答案是：它使用的是纯二进制的字节序列。当然消息还是结构化的，只是在使用之前都要将其转换成二进制的字节序列。\n消息设计出来之后还不够，消息引擎系统还要设定具体的传输协议，即用什么方法把消息传输出去。常见的有两种方法：\n点对点模型：也叫消息队列模型。说通俗点就是，系统 A 发送的消息只能被系统 B 接收，其他任何系统都不能读取 A 发送的消息。日常生活的例子比如电话客服就属于这种模型：同一个客户呼入电话只能被一位客服人员处理，第二个客服人员不能为该客户服务。 发布 / 订阅模型：与上面不同的是，它有一个主题（Topic）的概念，你可以理解成逻辑语义相近的消息容器。该模型也有发送方和接收方，只不过提法不同。发送方也称为发布者（Publisher），接收方称为订阅者（Subscriber）。和点对点模型不同的是，这个模型可能存在多个发布者向相同的主题发送消息，而订阅者也可能存在多个，它们都能接收到相同主题的消息。生活中的报纸订阅就是一种典型的发布 / 订阅模型。 而像现在主流的 MQ 大部分都是同时支持这两种消息引擎模型。好了，现在我们了解了消息引擎系统是做什么的以及怎么做的，但还有个重要的问题是为什么要使用到这类框架呢？\n四、削峰填谷 写这篇博客的时候，我查询了很多资料和文献，最常见的就是这四个字。所谓的“削峰填谷”就是指缓冲上下游瞬时突发流量，使其更平滑。特别是对那种发送能力很强的上游系统，如果没有消息引擎的保护，“脆弱”的下游系统可能会直接被压垮导致全链路服务“雪崩”。但是，一旦有了消息引擎，它能够有效地对抗上游的流量冲击，真正做到将上游的“峰”填满到“谷”中，避免了流量的震荡。消息引擎系统的另一大好处在于发送方和接收方的松耦合，这也在一定程度上简化了应用的开发，减少了系统间不必要的交互。\n说了这么多，可能你对“削峰填谷”并没有太多直观的感受。接下来用 Kafka 举个例子来说明一下在这中间是怎么去“抗”峰值流量的吧。回想一下，你在某宝是如何购物的。看见想要的商品点击立即购买。之后会进入到付款页面。这个简单的步骤中就可能包含多个子服务，比如点击购买按钮会调用订单系统生成对应的订单，而处理该订单会依次调用下游的多个子系统服务 ，比如调用支付宝的接口，查询你的登录信息，验证商品信息等。显然上游的订单操作比较简单，它的 TPS 要远高于处理订单的下游服务，因此如果上下游系统直接对接，势必会出现下游服务无法及时处理上游订单从而造成订单堆积的情形。特别是当出现类似于秒杀这样的业务时，上游订单流量会瞬时增加，可能出现的结果就是直接压跨下游子系统服务。\n解决此问题的一个普通的做法是我们对上游系统进行限速，但这种做法对上游系统而言显然是不合理的，毕竟问题并不出现在它那里。所以更常见的办法是引入像 Kafka 这样的消息引擎系统来对抗这种上下游系统 TPS 的错配以及瞬时峰值流量。\n还是这个例子，当引入了 Kafka 之后。上游订单服务不再直接与下游子服务进行交互。当新订单生成后它仅仅是向 Kafka Broker 发送一条订单消息即可。类似地，下游的各个子服务订阅 Kafka 中的对应主题，并实时从该主题的各自分区（Partition）中获取到订单消息进行处理，从而实现了上游订单服务与下游订单处理服务的解耦。这样当出现秒杀业务时，Kafka 能够将瞬时增加的订单流量全部以消息形式保存在对应的主题中，既不影响上游服务的 TPS，同时也给下游子服务留出了充足的时间去消费它们。这就是 Kafka 这类消息引擎系统的最大意义所在。\n五、结束语 其实从广义上讲，消息引擎系统是有缓冲作用、具备类发布和订阅能力的存储引擎。关于 MQ 的演进，无论是从需求发展路径上看是：消息 —\u003e 流 —\u003e 消息和流融合，还是从架构发展角度的单机 —\u003e 分布式 —\u003e 云原生 /Serverless，本质上走的都是降低成本的方向。\n为了降低成本，弹性是最基础的要求。所以消息引擎系统在技术上，对计算弹性的需求提出了计算存储分离架构，对低存储成本的需求提出了分层存储的概念，对资源复用的需求提出了多租户的概念。\n为了吸引用户，现如今常见的消息引擎系统都在尽量提高自己的竞争力，围绕着功能、容灾、多架构、生态建设展开。\n不过要注意，消息和流只是业界的趋势，不是我们作为使用者必然的非此即彼的选择。在开发者实际使用的时候，我也发现很多人会将 Kafka 当做一个业务消息总线在用，也有人使用 RocketMQ 传递大流量的日志，当做大数据架构中的管道在用。\n所以要学会变通，学技术做框架没有现成的，更不会一成不变，要有敏锐的洞察力，才不会被淘汰。\n补充：什么是消息和流？\n消息，就是业务信息，在业务机构（比如微服务架构）中用来做信息传递，做系统的消息总线，比如用户提交订单的流程。 流，就是在大数据框架中用来做大流量时的数据削峰，比如日志的投递流转。 ","description":"","tags":null,"title":"MQ001——消息引擎系统入门篇","uri":"/tech/bigdata/bigdata_mq001/"},{"categories":null,"content":"Rust--02 ｜ 编程开发中，必须掌握的基本概念 牢骚话😩 上一讲我们了解了内存的基本运作方式，简单回顾一下：栈上存放的数据是静态的，固定大小，固定生命周期；堆上存放的数据是动态，不固定大小，不固定生命周期。\n这一讲，来梳理一下编程开发过程中一些常见的基础概念。按照习惯，我会将其分为四大类：数据（值和类型、指针和引用）、代码（函数、方法、闭包、接口和虚标）、运行方式（并发并行、同步异步和 Promise / async / await），以及编程范式（泛型编程）。\n有的时候，很多人都说在搞开发，写代码。从某种程度上来说确实如此。如果说，仅仅是把需求翻译成代码也算程序员的话，那么什么才是职业的程序员呢？？怎么做才是职业的程序员呢？？我的答案是从基础做起，夯实软件开发相关的基础知识，而 Rust 恰恰是可以从一定程度上反应程序员是否合格的标准，比如所有权、动态分派以及并发处理等。\n说了点废话，下面开始正片～～\n数据 数据是程序操作的对象，不进行数据处理的程序是没有意义的，我们先来重温和数据有关的概念，包括值和类型、指针和引用。\n值和类型 严谨地说，类型是对值的区分，它包含了值在内存中的长度、对齐以及值可以进行的操作等信息。一个值是符合一个特定类型的数据的某个实体。比如 64u8，它是 u8 类型，对应一个字节大小、取值范围在 0～255 的某个整数实体，这个实体是 64。\n值以类型规定的表达方式（representation）被存储成一组字节流进行访问。比如 64，存储在内存中的表现形式是 0x40，或者 0b 0100 0000。\n这里需要注意的是，值是无法脱离具体的类型讨论的。同样是内存中的一个字节 0x40，如果其类型是 ASCII char，那么其含义就不是 64，而是 @ 符号。\n不管是强类型的语言还是弱类型的语言，语言内部都有其类型的具体表述。一般而言，编程语言的类型可以分为原生类型和组合类型两大类。\n原生类型（primitive type）是编程语言提供的最基础的数据类型。比如字符、整数、浮点数、布尔值、数组（array）、元组（tuple）、指针、引用、函数、闭包等。所有原生类型的大小都是固定的，因此它们可以被分配到栈上。\n组合类型（composite type）或者说复合类型，是指由一组原生类型和其它类型组合而成的类型。组合类型也可以细分为两类：\n结构体（structure type）：多个类型组合在一起共同表达一个值的复杂数据结构。比如 Person 结构体，内部包含 name、age、email 等信息。用代数数据类型（algebraic data type）的说法，结构体是 product type。 标签联合（tagged union）：也叫不相交并集（disjoint union），可以存储一组不同但固定的类型中的某个类型的对象，具体是哪个类型由其标签决定。比如 Haskell 里的 Maybe 类型，或者 Swift 中的 Optional 就是标签联合。用代数数据类型的说法，标签联合是 sum type。 另外不少语言不支持标签联合，只取其标签部分，提供了枚举类型（enumerate）。枚举是标签联合的子类型，但功能比较弱，无法表达复杂的结构。\n指针和引用 在内存中，一个值被存储到内存中的某个位置，这个位置对应一个内存地址。而指针是一个持有内存地址的值，可以通过解引用（dereference）来访问它指向的内存地址，理论上可以解引用到任意数据类型。\n引用（reference）和指针非常类似，不同的是，引用的解引用访问是受限的，它只能解引用到它引用数据的类型，不能用作它用。比如，指向 42u8 这个值的一个引用，它解引用的时候只能使用 u8 数据类型。\n所以，指针的使用限制更少，但也会带来更多的危害。如果没有用正确的类型解引用一个指针，那么会引发各种各样的内存问题，造成系统崩溃或者潜在的安全漏洞。\n刚刚讲过，指针和引用是原生类型，它们可以分配在栈上。\n根据指向数据的不同，某些引用除了需要一个指针指向内存地址之外，还需要内存地址的长度和其它信息。\n如上一讲提到的指向 “hello world” 字符串的指针，还包含字符串长度和字符串的容量，一共使用了 3 个 word，在 64 位 CPU 下占用 24 个字节，这样比正常指针携带更多信息的指针，我们称之为胖指针（fat pointer）。很多数据结构的引用，内部都是由胖指针实现的。\n代码 数据是程序操作的对象，而代码是程序运行的主体，也是我们开发者把物理世界中的需求转换成数字世界中逻辑的载体。我们会讨论函数和闭包、接口和虚表。\n函数、方法和闭包 函数是编程语言的基本要素，它是对完成某个功能的一组相关语句和表达式的封装。函数也是对代码中重复行为的抽象。在现代编程语言中，函数往往是一等公民，这意味着函数可以作为参数传递，或者作为返回值返回，也可以作为复合类型中的一个组成部分。\n在面向对象的编程语言中，在类或者对象中定义的函数，被称为方法（method）。方法往往和对象的指针发生关系，比如 Python 对象的 self 引用，或者 Java 对象的 this 引用。\n而闭包是将函数或者说代码和其环境一起存储的一种数据结构。闭包引用的上下文中的自由变量，会被捕获到闭包的结构中，成为闭包类型的一部分。\n接口和虚表 接口是一个软件系统开发的核心部分，它反映了系统的设计者对系统的抽象理解。作为一个抽象层，接口将使用方和实现方隔离开来，使两者不直接有依赖关系，大大提高了复用性和扩展性。\n很多编程语言都有接口的概念，允许开发者面向接口设计，比如 Java 的 interface 和 Rust 的 trait 等。\n我们可以看一下如下场景：在 HTTP 中，Request/Response 的服务处理模型其实就是一个典型的接口，只需要按照服务接口定义出不同输入下，从 Request 到 Response 具体该如何映射，通过这个接口，系统就可以在合适的场景下，把符合要求的 Request 分派给对应的服务。\n面向接口的设计是软件开发中的重要能力，而 Rust 尤其重视接口的能力。当我们在运行期使用接口来引用具体类型的时候，代码就具备了运行时多态的能力。但是，在运行时，一旦使用了关于接口的引用，变量原本的类型被抹去，就无法单纯从一个指针分析出这个引用具备什么样的能力。\n因此，在生成这个引用的时候，我们需要构建胖指针，除了指向数据本身外，还需要指向一张覆盖了这个接口所支持方法的列表。这个列表，也就是所谓的虚表（virtual table）。\n由于虚表记录了数据能够执行的接口，所以在运行期，我们想对一个接口有不同实现，可以根据上下文动态分派。\n比如我想为一个编辑器的 Formatter 接口实现不同语言的格式化工具。我们可以在编辑器加载时，把所有支持的语言和其格式化工具放入一个哈希表中，哈希表的 key 为语言类型，value 为每种格式化工具 Formatter 接口的引用。这样，当用户在编辑器打开某个文件的时候，我们可以根据文件类型，找到对应 Formatter 的引用，来进行格式化操作。\n运行方式 程序在加载后，代码以何种方式运行，往往决定着程序的执行效率。所以我们接下来讨论并发、并行、同步、异步以及异步中的几个重要概念 Promise/async/await。\n并发（concurrency）和并行（parallel） 并发和并行是软件开发中经常遇到的概念。\n并发是同时与多件事情打交道的能力，比如系统可以在任务 A 做到一定程度后，保存该任务的上下文，挂起并切换到任务 B，然后过段时间再切换回任务 A。\n并行是同时处理多件事情的方式，也就是说，任务 A 和任务 B 可以在同一个时间下工作，无需上下文切换。\n并发是一种能力，而并行是一种手段。当系统拥有了并发的能力后，代码如果跑在多个 CPU core 上，就可以并行运行。所以我们平时都谈论高并发处理，而不会说高并行处理。\n同步和异步 同步是指一个任务开始执行后，后续的操作会阻塞，直到这个任务结束。在软件中，我们大部分的代码都是同步操作，比如 CPU，只有流水线中的前一条指令执行完成，才会执行下一条指令。一个函数 A 先后调用函数 B 和 C，也会执行完 B 之后才执行 C。同步执行保证了代码的因果关系（causality），是程序正确性的保证。然而在遭遇 I/O 处理时，高效 CPU 指令和低效 I/O 之间的巨大鸿沟，成为了软件的性能杀手。下图对比了 CPU、内存、I/O 设备、和网络的延迟：\n我们可以看到和内存访问相比，I/O 操作的访问速度低了两个数量级，一旦遇到 I/O 操作，CPU 就只能闲置来等待 I/O 设备运行完毕。因此，操作系统为应用程序提供了异步 I/O，让应用可以在当前 I/O 处理完毕之前，将 CPU 时间用作其它任务的处理。\n所以，异步是指一个任务开始执行后，与它没有因果关系的其它任务可以正常执行，不必等待前一个任务结束。\n在异步操作里，异步处理完成后的结果，一般用 Promise 来保存，它是一个对象，用来描述在未来的某个时刻才能获得的结果的值，一般存在三个状态：\n初始状态，Promise 还未运行； 等待（pending）状态，Promise 已运行，但还未结束； 结束状态， Promise 成功解析出一个值，或者执行失败。 如果你对 Promise 这个词不太熟悉，在很多支持异步的语言中，Promise 也叫 Future / Delay / Deferred 等。除了这个词以外，我们也经常看到 async/await 这对关键字。\n一般来说，async 定义了一个可以并发执行的任务，而 await 则触发了这个任务并发执行。大多数编程语言中，async/await 是一个语法糖（syntactic sugar），它使用状态机将 Promise 包装起来，让异步调用的使用感觉和同步调用非常类似，也让代码更容易阅读。\n编程范式 为了在不断迭代时，更好地维护代码，我们还会引入各种各样的编程范式，来提升代码的质量。所以最后来谈谈泛型编程。\n如果你来自于弱类型语言，如 C / Python / JavaScript，那泛型编程是你需要重点掌握的概念和技能。泛型编程包含两个层面，数据结构的泛型和使用泛型结构代码的泛型化。\n（强类型和弱类型的定义一直不太明确，wikipedia 上也没有一个标准的说法。。按照习惯一般是看类型在调用时是否会发生隐式转换，所以说 python 是弱类型。不过 wikipedia 在介绍 python 时确实说它是 strongly typed。但如果按照类型是否会隐式转换，Rust 是强类型，Python 和 C 是弱类型）\n数据结构的泛型 首先是数据结构的泛型，它也往往被称为参数类型或者参数多态，比如下面这个数据结构：\n1 2 3 4 struct Connection\u003cS\u003e { io: S. state: State, } 它有一个参数 S，其内部的域 io 的类型是 S，S 具体的类型只有在使用 Connection 的上下文中才得到绑定。\n可以把参数化数据结构理解成一个产生类型的函数，在“调用”时，它接受若干个使用了具体类型的参数，返回携带这些类型的类型。比如我们为 S 提供 TcpStream 这个类型，那么就产生 Connection这个类型，其中 io 的类型是 TcpStream。\n读到这里可能会产生疑惑，如果 S 可以是任意类型，那我们怎么知道 S 有什么行为？如果我们要调用 io.send() 发送数据，编译器怎么知道 S 包含这个方法？\n这是个好问题，我们需要用接口对 S 进行约束。所以我们经常看到，支持泛型编程的语言，会提供强大的接口编程能力，后续有时间可以聊聊 Rust 的 trait，再详细探讨这个问题。\n数据结构的泛型是一种高级抽象，就像我们人类用数字抽象具体事物的数量，又发明了代数来进一步抽象具体的数字一样。它带来的好处是我们可以延迟绑定，让数据结构的通用性更强，适用场合更广阔；也大大减少了代码的重复，提高了可维护性。\n代码的规范化 泛型编程的另一个层面是使用泛型结构后代码的泛型化。当我们使用泛型结构编写代码时，相关的代码也需要额外的抽象。\n这里用我们熟悉的二分查找的例子解释会比较清楚：\n左边用 C 撰写的二分查找，标记的几处操作隐含着和 int[] 有关，所以如果对不同的数据类型做二分查找，实现也要跟着改变。右边 C++ 的实现，对这些地方做了抽象，让我们可以用同一套代码二分查找迭代器（iterator）的数据类型。\n同样的，这样的代码可以在更广阔的场合使用，更简洁容易维护。\n小结 本节内容讨论了四类基本概念：数据、代码、运行方式和编程范式。\n值无法离开类型单独讨论，类型一般分为原生类型和组合类型。指针和引用都指向值的内存地址，只不过二者在解引用时的行为不一样。引用只能解引用到原来的数据类型，而指针没有这个限制，然而，不受约束的指针解引用，会带来内存安全方面的问题。\n函数是代码中重复行为的抽象，方法是对象内部定义的函数，而闭包是一种特殊的函数，它会捕获函数体内使用到的上下文中的自由变量，作为闭包成员的一部分。\n而接口将调用者和实现者隔离开，大大促进了代码的复用和扩展。面向接口编程可以让系统变得灵活，当使用接口去引用具体的类型时，就需要虚表来辅助运行时代码的执行。有了虚表，我们可以很方便地进行动态分派，它是运行时多态的基础。\n在代码的运行方式中，并发是并行的基础，是同时与多个任务打交道的能力；并行是并发的体现，是同时处理多个任务的手段。同步阻塞后续操作，异步允许后续操作。被广泛用于异步操作的 Promise 代表未来某个时刻会得到的结果，async/await 是 Promise 的封装，一般用状态机来实现。\n泛型编程通过参数化让数据结构像函数一样延迟绑定，提升其通用性，类型的参数可以用接口约束，使类型满足一定的行为，同时，在使用泛型结构时，我们的代码也需要更高的抽象度。\n","description":"","tags":null,"title":"Rust02——程序员的基本素养，编程必会的基础知识","uri":"/tech/rust/prepare/02_basic/"},{"categories":null,"content":"（电子）装备清单 本篇内容仅仅是从我个人的使用习惯以及日常的装备出发，来梳理一下各个装备分别起到什么作用。\n先简单过一遍有哪些电子设备：\niPad Air3 + Apple Pencil（ 入坑的产品） iPhone11（感觉还可以做几年钉子户） 联想小新 Pro13（Windows 主力本） MacBook Pro（M1 Pro 10+14 core，32 + 1T） Sony WF-1000XM4（降噪体验最好的耳机） Nintendo Switch OLED（能够捧在手里玩塞尔达还要啥自行车） 客制化键盘（哪个程序员还没折腾过键盘？？） 平板 从我的角度来说，iPad 可以说是果子最成功的电子产品。虽然最近几年国产的平板确实还不错，但总归来说还是有差距的。所以可以简单把平板归类为：iPad 和其他。\n谈谈当时为何选择 Air3。当时 19 年首发的时候，刚好大一下，凭借着自己的能力有一点点经济基础，作为计算机学生自然而然对电子设备比较感兴趣。那一年上半年，果子推出了 mini5 和 Air3 两款。一开始我比较想入的是 mini5，大小尺寸捧在手里刚刚好，可以当作 Kindle 来使用，而且看视频的话比手机屏幕大，理论上会更舒服。可一想到了 iPad 可以当生产力工具，如果再加上 pencil 平时上课出门就能够摆脱厚重的书本，岂不快哉。所以最好选择了 Air3。\n“买前生产力，买后爱奇艺“真的是这样吗？？其实不然。当时秉持着生产力的理念，不下任何一款游戏、任何一个娱乐视频播放器（B 站除外。。hh😅），比较好的一点就是这个习惯一直持续至今，包括手机也是。那么没有娱乐软件，都拿 iPad 做了些什么呢？\n19 年是自媒体行业相对而言比较火爆的一年，就想着能否使用 iPad 来尝试做图剪视频呢？当时 iPadOS 生态还不健全，Adobe 全家桶几乎就是不可用的状态，于是寻找平替产品，做图方面用的是 Affinity Photo 和 Affinity Design，虽然比不过 PhotoShop，但好在方便，基本的操作都能实现；视频的话就 LumaFusion，我愿称之为当时 iPad 上最强的视频剪辑软件。还有一些好用的软件例如 procreate 这类的，由于我天生手残，从小就讨厌上美术课，也画不出来什么东西，虽然软件很好用，但我太菜咯。。就没怎么用过。\n比较好的看书软件话，微信阅读倒是不错。19—20 年这两年，几乎都是以电子书为主的，很方便。其实一开始我不太想用这软件的，看这几年鹅厂作妖，无论是游戏还是产品做的都是什么垃圾，比较抵触的。后来使用下来的感觉就是“真香”！首先几乎白嫖就能有书读，这个对于中国的用户来说真的太友好了，谁愿意多花钱呢。。没啥广告，阅读页面比较整洁，可以结合自己的阅读习惯做一些相应的调整。而且还能画线标注重点。emmm，微信阅读也就成了我安利比较多的软件了 哈哈哈哈。\n上面提到了 B 站，是唯一一个视频软件，众所周知小破站是个学习软件 hhhh。平时看看纪录片、一些技术视频或者关注的 up 主都是不错的选择。B 站可以说是大学生获取信息的平台之一，很多第三方技能的学习都可以借此来完成。\n上面的这些内容，大部分操作没有 pencil 都可以完成，那多花六七百买的笔是不是智商税呢？？当然不是！！！Notablility 和 GoodNote5 就可以很好发挥 pencil 的作用。一开始重度使用的是 Notability，书写体验要好一点（个人主观感受）。可以选择直接新建一个文件，或者把课本导入再写写画画都是很方便的，还可以配合墨墨背单词来分屏使用。可它不做人，从买断制变成了按月付费，就无语。然后就果断弃坑转头入了 GoodNote5，后来习惯了，用起来区别也不是很大。\niPad 可以说是我最最喜欢的产品，可以说是大学时候的主力设备，也陪伴了我的成长，但当不再是学生的身份，iPad 变得似乎有些尴尬，所有码字的内容能放在电脑上，就不会放在 iPad 上，iPad 的输入体验是真的糟糕，在不外接键盘的情况下。pencil 能用到的地方也越来越少了。。现如今只能说变成了看论文，看视频的工具。这类内容放在手机上看太小，电脑又不够便携。iPad 也就成了“第三块屏幕”，看似没用，如果没有的话，会感觉少了点什么，仅仅是屏幕大小的不同，也就决定了产品定位。\n有想过换 iPad Pro，毕竟屏幕素质更好，而且还支持 ProMotion，但如果不再重度使用的话，Air3 就足够咯，那就这样吧。。\n手机 先如今，如果说最重要的电子设备肯定是手机，它是将用户和服务端连接起来的重要枢纽之一。\n之前我一直是重度安卓机用户，因为可以 root，能够随便倒腾。也可能是年纪大了，慢慢就折腾不动了，体验了 iPad 的优点之后，在下半年果子发新机的时候，就入了 iPhone11，其实如果再让我选的话，会直接入手 11Pro。11 拿在手里还是有点大了，后面出的 mini 机型续航跟不上，而且也只支持单卡，就不在考虑范围之内了。高刷也是挤牙膏到 13Pro 才有。所以手机对于我而言就是个工具，能用就行。\n换了 iPhone 之后最大的感觉就是不再在意各种参数了，因为够用。对，够用就行。很多时候是供应商强推一堆不必要的升级然后都去跟风生产，作为一名普通用户来说，并没有啥实质性的作用吧。所以如果现在这款机子电池续航能撑得住的话，会继续当钉子户。\n从我的使用来说，手机最大的作用无外乎以下几点：\n通信，这也是手机最原始的功能。但一般电脑在身边，方便的话像微信这类的就转到电脑上，解放了手机。（键盘打字更舒服，节约了手机拿起放下的时间成本）；\n购物，这一点手机还是比较方便的，涉及到安全性考虑，Web 端每次重新登录都要扫码重新验证，这一点就不如手机来的方便，而且包括物流查询等；\n支付手段，不知何时起开始习惯了移动端付款，又一次见了新版的人民币，下意识的认为这是不是假钱 哈哈哈，在国内还是很方便的，大环境在这摆着嘛，这也导致了花钱没感觉，就是个数字。。。包括出门坐地铁、公交之类的；\n听歌，出门的时候戴耳机，一般都是直接连接手机，因为方便嘛。\n拍照，emmm 不怎么拍照，但貌似所有的设备只有手机的拍照功能好一点，随手咔嚓一张咯，剩余靠自己做后期呗；\n碎片时间：大学的时候喜欢刷知乎，心里感觉要高级一点，后来发现与短视频都一样。现在的话，可能会看看公众号、掘金之类的吧，知乎、小红书需要查东西的会随手看一下啦。至于短视频、游戏这些，手机上是不会下这类软件的。\n所以说平时主要用到的这些功能，没必要换新机，再等等吧。只能说。。\nBTW，去年 14Pro 的“灵动岛”一开始使用挺惊艳，后来太突兀了，从产品来说就是用软件交互层面来掩盖硬件上的短板。等什么时候没有岛了再说吧。。。\n电脑 这毕竟是吃饭的家伙。\nWindows 本的话是联想的小新 Pro13，一般来说都是工模机，硬件方面动手能力强的话可以直接换，13 寸主打的就是便携。16G 运行内存，大部分开发都能做，甚至能跑三个小的虚拟机集群，知足吧。。\nmacOS 是 14 寸的 M1 Pro，32 + 1T，配置拉高一点，多撑几年吧，事实也的确如此，后续出的新机固然很牛掰，对于我这种非专业用户来说几乎没啥提升。无非就是用户体验上会好一丢丢？？\n为何搞两台？？emmmm...... 如果说 Windows 开发真的舒服的话，也不会折腾 macOS 了，还是类 unix 系统好用，之前一度想过把 Windows 本重新装个好看一点的 Linux，后来看了下各个软件的兼容性还是放弃了。。\n其实二者装的工具都差不太多，开发的话 IDEA、VSCode 都是必装的，其余的结合各个系统的特点来了。macOS 比较好的就是，高素质的屏幕支持高刷、出色的音效，最重要的是可以直接使用 cli，这对我来说是最方便的，需要一个可视化界面来使用 Chrome、微信以及音视频软件等，其余的操作例如服务的启动，文件管理这部分工作就可以使用 iTemr2 来完成。所以读到这的你如果有好看的壁纸请一定要推荐给我，用的还是默认的。。。有关 macOS 从开发的角度倒腾了哪些好玩的，等有时间单独分享一篇。至于 Windows 的话，就那回事，似乎没啥好说的。。\n之前上大学的时候，特别羡慕那些在星巴克喝着咖啡，用着 mac 的人，现如今看就是纯纯的社畜。。Windows 搞个主机用来打 3A 大作才是王道！\n耳机 耳机的话，还是推荐降噪，毕竟用过就回不去了。当时第一款降噪耳机是 AirPods Pro，不知是不是第一次戴降噪耳机，戴上之后整个世界都安静了！！！那种感觉是真的惊艳，无可替代！！！可惜的是，AirPods Pro 丢了。。。还是在图书馆丢的，给我难受了半个月。原以为图书馆里最起码都是有素质的人，看来并不是。。\n后来暑期首发入了 sony wf1000 xm4，价格有点小贵，谁知半年之后疯狂背刺，一点都不保值。。。但如果从综合的使用体验 xm4 绝对是最顶的，无论是降噪还是音质，大法毕竟是大法。有利就有弊，牺牲的用户的佩戴体验，耳塞戴上会胀满耳朵里，耳机的腔体偏大，长时间佩戴会有点不舒服，这一点不如苹果。\n后来入了 AirPods Pro2，但没有第一次佩戴 Pro 时候的感觉了。。\n游戏机 如果非要说在 PS5 和 Nintendo Switch OLED 选一个的话，我还是会选择 Switch，能够捧在手里玩游戏其他的还能说什么？工作或者学习一天，本来想打游戏解压一下，结果还需要正襟危坐是不是很难受！！所以嘛，虽然 ns 的性能不怎么好，但是能玩到一些高质量的游戏就可以呗。\n高中的时候喜欢打手游，高考结束之后突然顿悟感觉一点意思都没有，妥妥国内资本圈钱的手段罢了。后来上了大学四年，不能说一点游戏没玩过吧，加在一起不到一百个小时。由于 20 年初，疫情爆发，一款叫动森的游戏进入大众的视野，也就在那时突然觉得 switch 还挺有意思的，再加上想弥补小时候没有 PSP 的遗憾，就入了。\n在 ns 玩的第一款游戏是《怪物猎人：崛起》，第一次玩动作游戏，玩了几百个小时才明白这游戏是怎么玩的，太菜了😭。后面又入了野炊，可惜的是当时玩了五六个小时觉得无聊，就放下了。下一款投入时间玩的游戏应该就是《异度神剑 3》，Mio！！！也让我入了 JRPG 的坑。后面还有《P5R》（玩到现在还没通关，后期真的越玩越累，但又不想烂尾。。）今年春季赶上塞尔达季票打折，就入了大师模式，接触大师模式才感觉到乐趣。有限的资源，变强的怪物，还能回血，直接变成魂类游戏可还行 哈哈哈。《王国之泪》当然也首发入啦～～还有很多优秀的游戏，比如马里奥系列、宝可梦系列、《十三机兵》都是值得入的。\n玩 NS 的时候，然后感觉又回到了小时候，可以去做自己想做的事情，都说成年人的世界很累很糟糕，但如果有 switch 的陪伴呢？\n键盘 程序员的键盘一定要与众不同才叫帅！！但实际上没啥必要，平时码码字写写代码，搞个差不多的键盘就行，也可能是老了折腾不动了吧。小键的话 Box 白轴用起来还是挺舒服的，大键的话 看个人使用情况，键帽看见喜欢的或者打油了就换呗。。\n其实主力的电子设备就是电脑、手机、平板，决定它们实际用途除了系统不一样之后，更重要的是屏幕可交互的尺寸，今年 WWDC 看见有 Vision Pro 还是挺震撼的，期待“下一种”交互方式早点应用到生活之中。\n","description":"","tags":null,"title":"二夕的装备清单","uri":"/life/about_devices/"},{"categories":null,"content":"RUST--01 ｜ 内存：值，放在栈上还是堆上？？ 牢骚话 学习 Java、Python 或者 Scala 的时候，通常都会从最基本的语法讲起，为何谈起 Rust 却偏偏要从这些较为抽象的基础知识谈起呢？其实不然，从我自己的经历来说，吃过基础知识没学透，后期回来补课的痛苦。。。\n比如，以最基础的内存为例，很多人其实并没有搞懂什么时候数据应该放在栈上，什么时候应该在堆上，直到工作中实际出现问题了，才意识到数据的存放方式居然会严重影响并发安全，无奈回头重新补基础，时间精力的耗费都很大。\n作为一名开发者，会遇见很多工具、框架和语言，但这类东西无论怎么变，底层的逻辑都是通用的，正所谓“万变不离其宗”。\n在学习一门新的语言中，最基本的概念就是代码中的变量和值，而存放它们的地方是内存，那么你真的有了解过内存吗？？\n内存 从写代码开始，我们就无时无刻不和内存在打交道。比如下面这行代码：\n1 let s = \"hello world\".to_string(); 首先，“hello world” 作为一个字符串常量（string literal），在编译时被存入可执行文件的 .RODATA 段（GCC）或者 .RDATA 段（VC++），然后在程序加载时，获得一个固定的内存地址。当执行 “hello world”.to_string() 时，在堆上，一块新的内存被分配出来，并把 “hello world” 逐个字节拷贝过去。\n当我们把堆上的数据赋值给 s 时，s 作为分配在栈上的一个变量，它需要知道堆上内存的地址，另外由于堆上的数据大小不确定且可以增长，我们还需要知道它的长度以及它现在有多大。\n最终，为了表述这个字符串，我们使用了三个 word：\n第一个表示指针; 第二个表示字符串的当前长度（11）; 第三个表示这片内存的总容量（11）; 在 64 位系统下，三个 word 是 24 个字节。也可以看下图，更直观一些：\n刚才例子中的字符串的内容在堆上，而指向字符串的指针等信息在栈上，那么有个问题就是：数据什么时候可以放在栈上，什么时候需要放在堆上呢？\n这个问题也是比较考验程序员的基本功是否扎实的，很多使用自动内存管理语言比如 Java/Python 的开发者，可能有一些模糊的印象或者规则：\n基本类型（primitive type）存储在栈上，对象存储在堆上； 少量数据存储在栈上，大量的数据存储在堆上。 这么回答，虽然对，但并没有抓到实质。如果在工作中只背规则套公式，一遇到特殊情况就容易懵，但是如果明白公式背后的推导逻辑，即使忘了，也很快能通过简单思考找到答案，所以接下来我们深挖堆和栈的设计原理，看看它们到底是如何工作的。（btw 如果连公式都不会背的话 emmmm。。。。。dddd😁）\n栈 栈是程序运行的基础。每当一个函数被调用时，一块连续的内存就会在栈顶被分配出来，这块内存被称为帧（frame）。\n栈是自顶向下增长的，一个程序的调用栈最底部，除去入口帧（entry frame），就是 main() 函数对应的帧，而随着 main() 函数一层层调用，栈会一层层扩展；调用结束，栈又会一层层回溯，把内存释放回去。\n在调用的过程中，一个新的帧会分配足够的空间存储寄存器的上下文。在函数里使用到的通用寄存器会在栈保存一个副本，当这个函数调用结束，通过副本，可以恢复出原本的寄存器的上下文，就像什么都没有经历一样。此外，函数所需要使用到的局部变量，也都会在帧分配的时候被预留出来。\n整个过程可以再看看这张图辅助理解：\n那一个函数运行时，怎么确定究竟需要多大的帧呢？这要归功于编译器。在编译并优化代码的时候，一个函数就是一个最小的编译单元。\n在这个函数里，编译器得知道要用到哪些寄存器、栈上要放哪些局部变量，而这些都要在编译时确定。所以编译器就需要明确每个局部变量的大小，以便于预留空间。\n于是乎我们可以这么理解：在编译时，一切无法确定大小或者大小可以改变的数据，都无法安全地放在栈上，最好放在堆上。比如一个函数，参数是字符串：\n1 2 3 4 5 fn say_name(name: String) {} // 调用 say_name(\"Lindsey\".to_string()); say_name(\"Rosie\".to_string()); 字符串的数据结构，在编译时大小不确定，运行时执行到具体的代码才知道大小。比如上面的代码，“Lindsey” 和 “Rosie” 的长度不一样，say_name() 函数只有在运行的时候，才知道参数的具体的长度。所以，我们无法把字符串本身放在栈上，只能先将其放在堆上，然后在栈上分配对应的指针，引用堆上的内存。\n放在栈上的问题 从刚才的图中也可以直观看到，栈上的内存分配是非常高效的。只需要改动栈指针（stack pointer），就可以预留相应的空间；把栈指针改动回来，预留的空间又会被释放掉。预留和释放只是动动寄存器，不涉及额外计算、不涉及系统调用，因而效率很高。\n所以理论上说，只要可能，我们应该把变量分配到栈上，这样可以达到更好的运行速度。那为什么在实际工作中，我们又要避免把大量的数据分配在栈上呢？这主要是考虑到调用栈的大小，避免栈溢出（stack overflow）。\n一旦当前程序的调用栈超出了系统允许的最大栈空间，无法创建新的帧，来运行下一个要执行的函数，就会发生栈溢出，这时程序会被系统终止，产生崩溃信息。过大的栈内存分配是导致栈溢出的原因之一，更广为人知的原因是递归函数没有妥善终止。一个递归函数会不断调用自己，每次调用都会形成一个新的帧，如果递归函数无法终止，最终就会导致栈溢出。\n堆 栈虽然使用起来很高效，但它的局限也显而易见。当需要动态大小的内存时，只能使用堆，比如可变长度的数组、列表、哈希表、字典，它们都分配在堆上。\n堆上分配内存时，一般都会预留一些空间，这是最佳实践。比如你创建一个列表，并往里添加两个值：\n1 2 3 let mut arr = Vec::new(); arr.push(1); arr.push(2); 这个列表实际预留的大小是 4，并不等于其长度 2。这是因为堆上内存分配会使用 libc 提供的 malloc() 函数，其内部会请求操作系统的系统调用，来分配内存。系统调用的代价是昂贵的，所以要避免频繁地 malloc()。\n对上面的代码来说，如果说需要多少就分配多少，那列表每次新增值，都要新分配一大块的内存，先拷贝已有数据，再把新的值添加进去，最后释放旧的内存，这样效率很低。所以在堆内存分配时，预留的空间大小 4 会大于需要的实际大小 2 。\n除了动态大小的内存需要被分配到堆上外，动态生命周期的内存也需要分配到堆上。\n上文中我们讲到，栈上的内存在函数调用结束之后，所使用的帧被回收，相关变量对应的内存也都被回收待用。所以栈上内存的生命周期是不受开发者控制的，并且局限在当前调用栈。而堆上分配出来的每一块内存需要显式地释放，这就使堆上内存有更加灵活的生命周期，可以在不同的调用栈之间共享数据。\n放在堆上的问题 然而，堆内存的这种灵活性也给内存管理带来很多挑战。\n如果手工管理堆内存的话，堆上内存分配后忘记释放，就会造成内存泄漏。一旦有内存泄漏，程序运行得越久，就越吃内存，最终会因为占满内存而被操作系统终止运行。\n如果堆上内存被多个线程的调用栈引用，该内存的改动要特别小心，需要加锁以独占访问，来避免潜在的问题。比如说，一个线程在遍历列表，而另一个线程在释放列表中的某一项，就可能访问野指针，导致堆越界（heap out of bounds）。而堆越界是第一大内存安全问题。\n如果堆上内存被释放，但栈上指向堆上内存的相应指针没有被清空，就有可能发生使用已释放内存（use after free）的情况，程序轻则崩溃，重则隐含安全隐患。根据微软安全反应中心（MSRC）的研究，这是第二大内存安全问题。\n小结 对于存入栈上的值，它的大小在编译期就需要确定。栈上存储的变量生命周期在当前调用栈的作用域内，无法跨调用栈引用。\n堆可以存入大小未知或者动态伸缩的数据类型。堆上存储的变量，其生命周期从分配后开始，一直到释放时才结束，因此堆上的变量允许在多个调用栈之间引用。但也导致堆变量的管理非常复杂，手工管理会引发很多内存安全性问题，而自动管理，无论是 GC 还是 ARC，都有性能损耗和其它问题。\n一句话对比总结就是：栈上存放的数据是静态的，固定大小，固定生命周期；堆上存放的数据是动态的，不固定大小，不固定生命周期。\n","description":"","tags":null,"title":"Rust01——内存：栈与堆？？","uri":"/tech/rust/prepare/01_memory/"},{"categories":null,"content":"给姐姐，写在你出嫁之后 总想写些什么，但又不知该如何下笔，作为弟弟，本应该为你出嫁感到快乐、开心，结果却往往事与愿违。我也不知为何会这样，或许是不舍，或许是焦虑，更多的也许是说不清楚。\n不舍的是，这么多年，从我出生到现在，在家里就有你的陪伴，出嫁之后，家里只剩我和父母，总感觉少了一份温暖。你是否还记得，在我快要高考的时候，有一段时间各方面都很低落，不知该如何是好，面对父母的不理解，自己的迷茫不知所措，还好有你。当时我就说，咱爸妈做的最正确的事情，就是把你生在了我前面。。但有时候就会设想，如果咱俩换一下呢？？或许，关系可能会更糟糕吧。我可能会处处管着你，让你好好学习看书，还可能会强制给你灌输我的价值观，让你变得不像你自己。。但好在，这一切也都只是假如。对于姐姐这个身份，从我的角度来说看你是满分的，我时常和爸妈说，有个贴心的姐姐确实舒服，自己不用操心各种生活的琐事，无论什么事情都有你为我考虑在前。咱爸妈经常说，我俩上学属于比较省心的，那是因为你比我大，小时候每天上学放学能够和你在一起，因为你的不哭不闹，然后意识到作为一名学生这是最基本的也是应该的，一切都是在你影响下的模仿罢了。也正因为你比我早读了几年书，每当小学周末老师布置了大把的作业，因为贪玩而写不完的时候，总会缠着你帮我写 哈哈哈。可，随着时间的推移，我俩慢慢长大了，从中学到大学，渐行渐远，由于你理科不好，再也没人能够帮我偷懒了，慢慢的，我也只能靠自己。\n很多人都说咱爸妈这二十多年混得不太行，也没啥大出息，emmm 怎么说呢，从某一方面来说确实是的。那是因为除了我俩，他们也没啥好骄傲的了。由于出生在农村，周围很多家庭的父母，对于教育都不太注重，很多亲戚邻居家的孩子，都早早辍学打工，甚至有些思想比较极端的人认为，女孩子读那么多书干什么，最后不还是要嫁给人家。不能说这种人不对，在他们的眼光中，他们也只能活在这种环境中。也许是因为受到舅舅家各位哥哥姐姐的原因，小时候每次去姥姥家那边，都会给我俩进行一顿思想灌输，说谁谁谁怎么怎么样考上大学，由此来教育，让我们好好学习。说实话，当时的内心想的也就那回事，在我看来，那只不过是到了一定年龄段，做了该做的事情。后来实际会发现，学习如逆水行舟，不进则退。值得庆幸的是，你成为了家里第一个全日制的本科生。16 年，你高考，送你去考场，看着你走进考场，我的内心比我后来高考都紧张，因为不确定性太大了。怕你考不上大学，下一步该怎么走？？可能也正是因为你的“忽忽悠悠“，从出成绩，到填志愿，最后录取，都比我要顺利的多。这也许求而不得，往往不求而得吧。有时候我都羡慕甚至嫉妒你，我花了几倍的功夫做到的事情，你往往漫不经心的就完成了。\n当你上了大学，也算是第一步远离了生活长大的城市。当时我上高中，特别羡慕上大学的你。就会想自己啥时候才能熬到啊。高中的时候，可能由于是叛逆期吧，经常你回家就和你闹矛盾，不知道你还记不记得。其实，初中的时候也有好几次，现在回头想想还真是黑历史。。hhhh 但也许是出于对你的依赖，也知道你会无限的包容我才会这样。到后来，我上大学之后，慢慢体会到一个人在陌生环境的不容易，也读了很多书。那个阶段，脑子也逐渐开窍，开始慢慢承担起自己的责任，我俩之间也由你照顾我，变成我谦让着你。也好像是从那时候开始，在爸妈眼中，我似乎变得比你要懂事，更独立。如果可以的话，我不想这样。。一点都不想 真的。。近几年这样过度的由着你你任性，也造就了你的脾气比较大。但不在家人身边，又有谁会真心让着你呢\n焦虑的是，当你真正变成妻子的身份，在他们家过得到底是不是自己所期望的那样。大学毕业之后，赶上疫情，比较好的是，你当时找到了工作，不用像大部分应届生那样忙得焦头烂耳。有时候，我就觉得父母喜欢瞎操心，刚刚大学毕业就着急你以后的未来，很没必要。我之前对你说过，如果你不想结婚，过年回老家怕被所谓的亲戚说三道四，我直接给你钱出去旅游，别受这气。比较可惜的是，我这钱没花出去 hhhh。\n当时你说李双双也是写代码的，顿时我的好感度就上来了，最起码来说，写代码的人都比较单纯简单，除了追求技术，对于其余的事情都不大感兴趣，也就不会搞那些花里胡哨的。他追你时候的表现确实值得表扬，刚开始我还担心他和我一样是个钢铁直男，不会讨你欢心，纯粹是我多虑了。相处了快到一年的时候，你们订婚了，从我的角度来看，速度或许有些太快了，因为紧接着的就是结婚。如果不是因为疫情，去年你就是他的妻子。去年疫情刚解封你去了他那边，还是比较好的，因为谁也不知道之后上海还会搞成什么样子。可能是距离产生美吧，当你们异地的时候，不会感觉到他的不好，但两个人同居，都有了自己的工作，那么生活中的小事到底谁负责呢？他是个典型的大男子主义，家务活不知道做，不会烧饭，而且还比较懒。这么一弄，家务活自然而然就落到你头上了。但我看来是不应该的，最起码从我的角度来说，作为一个男人就应该多承担点，如果真心喜欢一个女生，是需要细心呵护，爱情是靠两个人共同经营，而不是单方面付出的。就这样对他的印象分，也就逐渐下降。甚至我和你说过好几次，如果两个人真的磨合不来，他还是那屌样子，就算了吧，没必要受他一辈子气。这个时候的他和当时追你完全是两个样子。每次和你联系，都觉得你在那边过得好累，没有那个时候在家自由。但也许这就是生活吧，总归是要和现实和解的。\n当然，也不能站在我的角度来片面地看待他，他也不是全都缺点，毕竟他自己都夸自己优秀嘛。让我感到比较欣慰的是，去年年底，由于疫情的全面放开，谁到抵挡不住会感染。你成为家里第一个阳的，而且还不在身边，对你的担忧也就多了。我愿意按他惜命的性格，有可能连家都不会回，事实证明他还是不错的，得知你阳了，放下手边的工作，急匆匆地赶了回家照顾你。从这一点可以看出，他还是很在乎你的，也值得把你托付给他。如果在生活中，他能够考虑的更周到一点，更能为你着想一点，能够自觉地承担起自己的责任和义务，那就更好了。希望婚后，他可以做到。他是有自己的想法，但却不能付诸实践，现如今的生活形形色色的诱惑太多，一不小心就会迷失自我，作为年轻人，要学会静下自己的心，去好好思考，去努力，去寻找自身的价值所在。也可能我本身就是做技术的，关于互联网的诱惑都会刻意屏蔽，所以对我来说也就是个工具，不会浪费太多时间在上面。现如今的社会，是一个即将崩坏的形态，虚拟和现实相碰撞，有的人追求华丽的形式，有的人为了名利迷失了自我，更多的人都是随波逐流，无法思考。希望你俩以后也多投入时间在现实生活中，尽量过得简单一点，多读书！\n为何会说不清楚呢？？我想谈谈现如今的你。作为弟弟，我一直都认为对你很熟悉，但当你在那边过了快一年，恍惚变了一个人似的，我不知为何你会变成这样，身上的戾气有点重。。。\n生活，平平淡淡是常态，有不顺心的时候，也总有好的时候。不要因为暂时的不如意而感到烦恼，也不要想着为了未来怎么样怎么样而陷入精神内耗，要学会和自己和解，和周围的一切和解，但看待生活的心态变了，生活也会随之而改变。至少目前来看，我是一个挺”佛“的人，不为世事所动，也没啥太大的兴趣，自然就少了很多烦恼，但也不会有开心的感觉，所以也好也不好。你可别学我。我还是想让你开心一点的。在那边，嫁給他，就是他家人了。话语权方面，我也希望你能够做到独当一面，要沉得住气，不要因为一点小事而哭鼻子。最好是，也不要计较那么多，为了一群傻缺把自己气到不值得。当你把自己的认知提升到一定的高度，看他们做的很多事都很无聊，所以真的没必要。人总是复杂的，不能说某一个时间段对你好，他就是好人，反之他就不好。如果能处得来就更好不过，处不来也别强求自己委屈求全。我还是希望你在那边能开开心心、快快乐乐的。\n最后，如果说最近的开心事的话，那就是你说我快要当舅舅了。看到这个消息，我先是一愣，没反应过来，脑子差点宕机，总觉得有些突然。如果说对他/她 有什么期待的话，最好是能够像他/她舅舅，也就是我。哈哈哈哈~~也希望我能够以身作则，起到一个好的榜样的作用。希望他/她出生之后， 你们别给太大的压力，能够养成自己的思想，有独立的人格，不要把父母的期望和遗憾过度的强加给孩子。至于功名利禄放一边吧。这一点，我相信你能够做到的，而且做的比我好。\n罗里吧嗦，写了一堆废话，简单来说，我希望你俩有时间的话，多回家看看，仅此而已。\n","description":"","tags":null,"title":"给姐姐，写在你出嫁之后","uri":"/life/to_my_sister/"},{"categories":null,"content":"工作去死 劣币驱逐良币罢了～～\n","description":"","tags":null,"title":"Hello LQ","uri":"/life/work001/"},{"categories":null,"content":"遇见问题？？ 这两天在折腾一个数仓测试环境的迁移，MySQL 自然是必不可少缺少的咯，因为是测试环境，配置都是按最方便的来做，配置过程可参考：MySQL 安装\n前一天使用都是正常的，结果第二天不知什么原因，在使用 Maxwell 进行增量同步业务数据到 HDFS 过程中，爆出以下错误：java.sql.SQLException: Access denied for user 'root'@'aliyun001' (using password: YES) 这是一个常见的错误，遇到好几次，所以记录以下。\n解决？？？ 遇到该问题，立刻就尝试使用mysql -u root -p来登录数据库看看，结果仍然报错，同上。这时意识到数据库是进不去了。。。\n于是乎，可以先设置跳过密码：\n1 2 vim /etc/my.cnf skip-grant-tables #在[mysqld]下面添加这一行，忽略权限表 重启 MySQL：sudo systemctl restart mysqld.service\n进入之后选择 use mysql，然后 select user, host from user; 出现的结果令人惊讶！！！没有 root 用户了？？？没有就自己造一个！！！\n养成好习惯先刷新一下：flush privileges;\n创建create user 'root'@'localhost' identified by '123456';，然后报错：ERROR 1396 (HY000): Operation CREATE USER failed for 'root'@'localhost'，估计应该是没删干净？？再删一下：drop user root@'localhost';，刷新一下；这个时候再创建就 ok 了~~\n有了 root 用户之后，再给权限：mysql\u003e GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' WITH GRANT OPTION; #赋予所有库所有表操作权限；刷新一下~~\n再回到 /etc/my.cnf 删除 skip-grant-tables。重启数据库，这个时候就可以正常使用了~~\n如果为了方便还可以再设置一下 host 为 %：update user set host=\"%\" where user=\"root\";\n","description":"","tags":null,"title":"MySQL——Access denied for user 'root'@'localhost' (using password: YES) 问题解决","uri":"/tech/mysql_access_problem/"},{"categories":null,"content":"Windows 配置 Scala 开发环境 零、前言 谈起现如今的大数据开发框架，那么 Spark 想必是众所周知的。而 Spark 就是使用 Scala 语言编写的。所以问题来了，该如何配置一套 Scala 的环境呢？\n其实，有了 Java 的底子之后，配置一套 Scala 开发环境并不是很难，因为 Scala 一门以 JVM 为运行环境并将面向对象和函数式编程的最佳特性结合在一起的 静态类型编程语言，支持面向对象和函数式编程。\n一、Scala 环境搭建 前文提到，Scala 是运行在 JVM 上的，所以首先先保证开发环境已经配置了 JDK，这里不做过多赘述。（我使用的 JDK1.8）\n1.下载所需要的 Scala 版本，download；\n2.将下载好的 zip 文件压解至无中文的目录下，最好也不要有空格；\n3.打开 Windows 的系统属性中的环境变量，配置 Scala 的环境变量：SCALA_HOME 以及所属目录：D:\\DevelopmentTool\\scala-2.12.11\n配置 path 路径，将 bin 目录添加至系统环境 %SCALA_HOME%\\bin\n4.测试\n打开 terminal 终端，输入 scala 出现如下图所示表示配置好环境~~\n二、在 IDEA 中配置 Scala 开发环境 IDEA 懂的都懂 好用就完事了！！！下面将演示如何在 IDEA 集成 Scala 开发环境。\n1.在 Setting 的 plugins 中搜素 Scala -\u003e点击 Install-\u003e点击 ok-\u003e点击 apply，重启 IDEA；\n2.创建一个 projet，默认是不支持 Scala 的开发。需要手动引入 Scala 框架，在项目上，点击右键-\u003e Add Framework Support... -\u003e选择 Scala-\u003e点击 OK。\n注意：如果是第一次引入框架，Use libary 看不到，需要选择你的 Scala 安装目录，然后工具就会自动识别，就会显示 user libary。\n3.测试\n以上我们已经完成了 Scala 的开发环境，可以完成一些基础的相关。\n三、配置 Spark 开发环境 1.创建 Spark 项目，添加相关依赖：\n\u003cdependency\u003e \u003cgroupId\u003eorg.apache.spark\u003c/groupId\u003e \u003cartifactId\u003espark-core_2.12\u003c/artifactId\u003e \u003cversion\u003e3.0.0\u003c/version\u003e \u003c/dependency\u003e 添加依赖之后，就可以使用 Spark 相关的 API，但是在运行过程中，控制台可以会出现一些神奇的错误，如下所示：\nERROR Shell: Failed to locate the winutils binary in the hadoop binary path java.io.IOException: Could not locate executable null\\bin\\winutils.exe in the Hadoop binaries. at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:382) at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:397) at org.apache.hadoop.util.Shell.\u003cclinit\u003e(Shell.java:390) at org.apache.hadoop.util.StringUtils.\u003cclinit\u003e(StringUtils.java:80) at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:611) at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:274) at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:262) at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:807) at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:777) at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:650) at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2412) at scala.Option.getOrElse(Option.scala:189) at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2412) at org.apache.spark.SparkContext.\u003cinit\u003e(SparkContext.scala:303) at org.erxi.spark.core.rdd.operator.transform.AdClickCount$.main(AdClickCount.scala:8) at org.erxi.spark.core.rdd.operator.transform.AdClickCount.main(AdClickCount.scala) 这是因为在程序中使用了 Hadoop 相关的内容，比如写入文件到 HDFS。出现这个问题并不是程序的错误，而是windows 系统用到了 hadoop 相关的服务，解决办法是通过配置关联到 windows 的系统依赖就可以了。\n2.解决异常 安装 Spark：到官网 https://spark.apache.org/downloads.html 选择合适的版本下载，注意 Spark 与Hadoop 版本选择要相对应，建议下载预编译（Pre-built）好的版本，省得麻烦。解压文件，然后与配置 Scala 环境类似配置对应的 SPARK_HOME 与 path 变量 %SPARK_HOME%\\bin;\n安装 Hadoop：到官网 https://hadoop.apache.org/releases.html 下载与上边的 Spark 对应的版本。后与配置 Scala 环境类似配置对应的 HADOOP_HOME 与 path 变量 %HADOOP_HOME%\\bin。\n除此之外，还需要到这里 https://github.com/cdarlint/winutils 下载对应版本的 bin 目录中的 hadoop.dll 和 winutils.exe，复制到 hadoop 目录的 bin 目录下。\n完成上述操作之后，已经在 Windows 环境下搭建了可用于测试的 Spark 环境和 Hadoop 环境。最后还需要再 IDEA 中导入一下 HADOOP_HOME，这样运行程序就不会报错啦~~\n在 IDEA 中配置 Run Configuration，添加 HADOOP_HOME 变量：\n","description":"","tags":null,"title":"Windows 配置 Scala 开发环境","uri":"/tech/bigdata/scala/"},{"categories":null,"content":"标题写在变“羊”之前 占个坑 按照目前国内的这个趋势 躲得过初一 能躲得过十五嘛？？？？？？？？？\n","description":"","tags":null,"title":"标题写在我变“🐑”之前","uri":"/life/covid-19/"},{"categories":null,"content":"单例模式 为什么使用单例模式？ 单例设计模式：一个类只允许创建一个对象（或者实例），那么这个类就是一个单例类，这种设计模式就叫做单例设计模式，简称单例模式。\n单例模式的概念并不是很难，一看就能明白。接下来我们思考一下，为什么需要单例这种设计模式？它能解决哪些问题？\n实战案例：处理资源访问冲突 咱们先来看第一个例子。该例子中，我们自定义实现了一个往文件中打印日志的 Logger 类。具体的实现代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 public class Logger { private FileWriter writer; public Logger() { File file = new File(\"/Users/zhangsan/log.txt\"); writer = new FileWriter(file, true); // true表示追加写入 } public void log(String message) { writer.write(message); } } // Logger类的应用示例： public class UserController { private Logger logger = new Logger(); public void login(String username, String password) { // ...省略业务逻辑代码... logger.log(username + \" logined!\"); } } public class OrderController { private Logger logger = new Logger(); public void create(OrderVo order) { // ...省略业务逻辑代码... logger.log(\"Created an order: \" + order.toString()); } } 上述代码的功能并不是很复杂，但请停下来思考一下，这段代码存在什么问题。\n细心的同学可能已经注意到了，所有的日子都写入到同一个文件 /Users/zhangsan/log.txt 中。在 UserController 和 OrderController 中，分别创建了两个 Logger 对象。在 Web 容器的 Servlet 多线程环境下，如果两个 Servlet 线程同时分别执行 login() 和 create() 两个函数，并且同时写日子到 log.txt 文件中，那么就有可能存在日子信息相互覆盖的情况。\n为什么会出现相互覆盖呢？可以这样类比着理解。在多线程环境下，如果两个线程同时给同一个共享变量加 1，因为共享变量是竞争资源，所以，共享变量最后的结果有可能并不是加 2，而是只加了 1。同理，这里的 log.txt 文件也是竞争资源，两个线程同时往里面写数据，就有可能会存在相互覆盖的情况。\n那么该如何来解决和这个问题呢？通常的思路应该是加锁：给 log() 函数加互斥锁（Java 中可以通过 synchronized 的关键字），同一时刻只允许一个线程调用 log() 函数。具体的代码实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Logger { private FileWriter writer; public Logger() { File file = new File(\"/Users/zhangsan/log.txt\"); writer = new FileWriter(file, true); // true表示追加写入 } public void log(String message) { synchronized(this) { writer.write(mesasge); } } } 不过，仔细思考一下，这真的能解决多线程写入日志时相互覆盖的问题吗？答案是否定的！这是因为这种锁是一个对象级别的锁，一个对象在不同的线程下同时调用 log() 函数，会被强制要求顺序执行。但是，不同的对象之间并不能共享同一把锁。在不同的线程下，通过不同的对象调用执行 log() 函数，锁并不会起作用，任然有可能存在写入日志相互覆盖的问题。\n这里稍微补充一下，在刚刚的讲解和给出代码的中，故意“隐藏”了一个事实：我们给 log() 函数加不加对象级别的锁，其实都没有关系。因为 FileWriter 本身就是现场安全的，它的内部实现中本身就假了对象级别的锁，因此，在外层调用 write() 函数的时候，再加对象级别的锁实际上是多此一举。因为不同的 Logger 对象不共享 FileWriter 对象，所以 FileWriter 对象级别的锁也解决不了数据写入相互覆盖的问题。\n那么问题来了，该如何解决呢？实际上，要解决这个问题并不是很难。我们只需要吧对象级别的锁换成类级别的锁就可以了。让所有的对象都共享同一把锁。这样就避免了不同对象之间同时调用 log() 函数，而导致的日志覆盖的问题。具体的代码实现如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class Logger { private FileWriter writer; public Logger() { File file = new File(\"/Users/zhangsan/log.txt\"); writer = new FileWriter(file, true); // true表示追加写入 } public void log(String message) { synchronized(Logger.class) { // 类级别的锁 writer.write(mesasge); } } } 除了使用类级别锁之外，实际上，解决资源竞争问题的办法还有很多，分布式锁是最常听到的一种解决方案。不过，实现一个安全可靠、无 bug、高性能的分布式锁，并不是件容易的事情。除此之外，并发队列（比如 Java 中的 BlockingQueue）也可以解决这个问题：多个线程同时往并发队列里写日志，一个单独的线程负责将并发队列中的数据，写入到日志文件。这种方式实现起来也稍微有点复杂。\n相对于这两种解决方案，单例模式的解决思路就简单一些了。单例模式相对于之前类级别锁的好处是，不用创建那么多 Logger 对象，一方面节省内存空间，另一方面节省系统文件句柄（对于操作系统来说，文件句柄也是一种资源，不能随便浪费）。\n我们将 Logger 设计成一个单例类，程序中只允许创建一个 Logger 对象，所有的线程共享使用的这一个 Logger 对象，共享一个 FileWriter 对象，而 FileWriter 本身是对象级别线程安全的，也就避免了多线程情况下写日志会互相覆盖的问题。\n按照这个设计思路，我们实现了 Logger 单例类。具体代码如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class Logger { private FileWriter writer; private static final Logger instance = new Logger(); private Logger() { File file = new File(\"/Users/shangsan/log.txt\"); writer = new FileWriter(file, true); // true表示追加写入 } public static Logger getInstance() { return instance; } public void log(String message) { writer.write(mesasge); } } // Logger类的应用示例： public class UserController { public void login(String username, String password) { // ...省略业务逻辑代码... Logger.getInstance().log(username + \" logined!\"); } } public class OrderController { public void create(OrderVo order) { // ...省略业务逻辑代码... Logger.getInstance().log(\"Created a order: \" + order.toString()); } } 实战案例二：表示全局唯一类 从业务概念上，如果有些数据在系统中只应保持一份，那就适合设计为单例类。\n比如，配置信息类。在系统中，我们只有一个配置文件，当配置文件被加载到内存后，以对象的形式存在，也理所应当只有一份。\n再比如，唯一递增 ID 号码生成器，如果程序中有两个对象，就会存在生成重复 ID 的情况，所以我们应该将 ID 生成器类设计为单例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import java.util.concurrent.atomic.AtomicLong; public class IdGenerator { // AtomicLong 是一个 Java 并发库中提供的一个原子变量类型, // 它将一些线程不安全需要加锁的复合操作封装为了线程安全的原子操作， // 比如下面会用到的 incrementAndGet(). private AtomicLong id = new AtomicLong(0); private static final IdGenerator instance = new IdGenerator(); private IdGenerator() {} public static IdGenerator getInstance() { return instance; } public long getId() { return id.incrementAndGet(); } } // IdGenerator 使用举例 long id = IdGenerator.getInstance().getId(); 如何实现一个单例？ 概括起来，要实现一个单例，我们需要关注的无外乎下面几个：\n构造函数需要是 private 访问权限的，这样才能避免外部通过 new 创建实例； 考虑对象创建时的线程安全问题； 考虑是否支持延迟加载； 考虑 getInstance() 是否加锁（性能是否高）。 1. 饿汉式 饿汉式的实现方式比较简单。在类加载的时候，instance 静态实例就已经创建并初始化好了，所以 instance 实例的创建过程是线程安全的。不过，这样的实现方式不支持延迟加载（在真正用到 IdGenerator 的时候，再创建实例），从名字中我们也可以看出这一点。具体的代码实现如下所示：\n1 2 3 4 5 6 7 8 9 10 11 public class IdGenerator { private AtomicLong id = new AtomicLong(0); private static final IdGenerator instance = new IdGenerator(); private IdGenerator() {} public static IdGenerator getInstance() { return instance; } public long getId() { return id.incrementAndGet(); } } 有人觉得这种实现方式不好，因为不支持延迟加载，如果实例占用资源多（比如占用内存多）或初始化耗时长（比如需要加载各种配置文件），提前初始化实例是一种浪费资源的行为。最好的方法应该在用到的时候再去初始化。不过，从我的角度来说，并不是很认同这种观点。\n如果初始化耗时长，那我们最好不要等到真正要用它的时候，才去执行这个耗时长的初始化过程，这会影响到系统的性能（比如，在响应客户端接口请求的时候，做这个初始化操作，会导致此请求的响应时间变长，甚至超时）。采用饿汉式实现方式，将耗时的初始化操作，提前到程序启动的时候完成，这样就能避免在程序运行的时候，再去初始化导致的性能问题。\n如果实例占用资源多，按照 fail-fast 的设计原则（有问题及早暴露），那我们也希望在程序启动时就将这个实例初始化好。如果资源不够，就会在程序启动的时候触发报错（比如 Java 中的 PermGen Space OOM），我们可以立即去修复。这样也能避免在程序运行一段时间后，突然因为初始化这个实例占用资源过多，导致系统崩溃，影响系统的可用性。\n2. 懒汉式 有饿汉式，对应的，就有懒汉式。懒汉式相对于饿汉式的优势是支持延迟加载。具体的代码实现如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class IdGenerator { private AtomicLong id = new AtomicLong(0); private static IdGenerator instance; private IdGenerator() {} public static synchronized IdGenerator getInstance() { if (instance == null) { instance = new IdGenerator(); } return instance; } public long getId() { return id.incrementAndGet(); } } 不过懒汉式的缺点也很明显，我们给 getInstance() 这个方法加了一把大锁（synchronzed），导致这个函数的并发度很低。量化一下的话，并发度是 1，也就相当于串行操作了。而这个函数是在单例使用期间，一直会被调用。如果这个单例类偶尔会被用到，那这种实现方式还可以接受。但是，如果频繁地用到，那频繁加锁、释放锁及并发度低等问题，会导致性能瓶颈，这种实现方式就不可取了。\n3. 双重检测 饿汉式不支持延迟加载，懒汉式有性能问题，不支持高并发。那我们再来看一种既支持延迟加载、又支持高并发的单例实现方式，也就是双重检测实现方式。\n在这种实现方式中，只要 instance 被创建之后，即便再调用 getInstance() 函数也不会再进入到加锁逻辑中了。所以，这种实现方式解决了懒汉式并发度低的问题。具体的代码实现如下所示：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 public class IdGenerator { private AtomicLong id = new AtomicLong(0); private static IdGenerator instance; private IdGenerator() {} public static IdGenerator getInstance() { if (instance == null) { synchronized(IdGenerator.class) { // 此处为类级别的锁 if (instance == null) { instance = new IdGenerator(); } } } return instance; } public long getId() { return id.incrementAndGet(); } } 网上有人说，这种实现方式有些问题。因为指令重排序，可能会导致 IdGenerator 对象被 new 出来，并且赋值给 instance 之后，还没来得及初始化（执行构造函数中的代码逻辑），就被另一个线程使用了。\n要解决这个问题，我们需要给 instance 成员变量加上 volatile 关键字，禁止指令重排序才行。实际上，只有很低版本的 Java 才会有这个问题。我们现在用的高版本的 Java 已经在 JDK 内部实现中解决了这个问题（解决的方法很简单，只要把对象 new 操作和初始化操作设计为原子操作，就自然能禁止重排序）。关于这点的详细解释，跟特定语言有关，我就不展开讲了，感兴趣的同学可以自行研究一下。\n4. 静态内部类 我们再来看一种比双重检测更加简单的实现方法，那就是利用 Java 的静态内部类。它有点类似饿汉式，但又能做到了延迟加载。具体是怎么做到的呢？我们先来看它的代码实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 public class IdGenerator { private AtomicLong id = new AtomicLong(0); private IdGenerator() {} private static class SingletonHolder{ private static final IdGenerator instance = new IdGenerator(); } public static IdGenerator getInstance() { return SingletonHolder.instance; } public long getId() { return id.incrementAndGet(); } } SingletonHolder 是一个静态内部类，当外部类 IdGenerator 被加载的时候，并不会创建 SingletonHolder 实例对象。只有当调用 getInstance() 方法时，SingletonHolder 才会被加载，这个时候才会创建 instance。instance 的唯一性、创建过程的线程安全性，都由 JVM 来保证。所以，这种实现方法既保证了线程安全，又能做到延迟加载。\n5. 枚举 最后，我们介绍一种最简单的实现方式，基于枚举类型的单例实现。这种实现方式通过 Java 枚举类型本身的特性，保证了实例创建的线程安全性和实例的唯一性。具体的代码如下所示：\n1 2 3 4 5 6 7 8 public enum IdGenerator { INSTANCE; private AtomicLong id = new AtomicLong(0); public long getId() { return id.incrementAndGet(); } } 重点回顾 1. 单例的定义 单例设计模式（Singleton Design Pattern）理解起来非常简单。一个类只允许创建一个对象（或者叫实例），那这个类就是一个单例类，这种设计模式就叫作单例设计模式，简称单例模式。\n2. 单例的用处 从业务概念上，有些数据在系统中只应该保存一份，就比较适合设计为单例类。比如，系统的配置信息类。除此之外，我们还可以使用单例解决资源访问冲突的问题。\n3. 单例的实现 单例有下面几种经典的实现方式。\n饿汉式 饿汉式的实现方式，在类加载的期间，就已经将 instance 静态实例初始化好了，所以，instance 实例的创建是线程安全的。不过，这样的实现方式不支持延迟加载实例。\n懒汉式 懒汉式相对于饿汉式的优势是支持延迟加载。这种实现方式会导致频繁加锁、释放锁，以及并发度低等问题，频繁的调用会产生性能瓶颈。\n双重检测 双重检测实现方式既支持延迟加载、又支持高并发的单例实现方式。只要 instance 被创建之后，再调用 getInstance() 函数都不会进入到加锁逻辑中。所以，这种实现方式解决了懒汉式并发度低的问题。\n静态内部类 利用 Java 的静态内部类来实现单例。这种实现方式，既支持延迟加载，也支持高并发，实现起来也比双重检测简单。\n枚举 最简单的实现方式，基于枚举类型的单例实现。这种实现方式通过 Java 枚举类型本身的特性，保证了实例创建的线程安全性和实例的唯一性。\n","description":"","tags":null,"title":"设计模式（一）-- 单例模式 001","uri":"/tech/designpattern/001_signle%E4%B8%80/"},{"categories":null,"content":"Blog010 —— 考研系列完结篇，但是还有生活 零、写在前面 说实在的，我不想去回忆关于考研的任何内容，备考过程也好，考试当天的过程也罢，都不愿意去提起，真的太折磨了。所有 APP 中推荐的关于考研的内容，都刻意的去点了 X，但有可能就是应为刻意而为之，反而越想去逃避，不想去面对这一切。似乎就好像不去主动面对，这一切就还没结束，结果也就不会到来。但时间是一直往前走，不会止步的。除了麻痹、自我安慰、欺骗自己，真的不知道该做些什么。考研结束的这几天，过得也特别颓废。什么都不想做，吃了睡，睡了吃，报复性的“糟蹋”自己，来“补偿”这一年的付出。。。\n每到深夜，闭上眼，脑中回想的都是这一年的点点滴滴，又回头看看备考期间所写下的博客。就像是开篇中所写下的写在之后所提到，我想用文字记录下这一切。当看到这段话的时候，说明我坚持下来了，我也做到去突破自己的壁垒，勇敢的去面对自己这一年的汗水与泪水。既然之前的都写了，为何不写完这最后一篇呢？\n一、回到起点 是的，就像这篇的标题一样，考研终于结束了。这一年来的备考过程也总算是画上了个句号。这一年回想起来，过得也还是挺快的。一步一步也就这样走向了终点。但，真正的生活也才刚刚开始而已。\n这一路走来的点点滴滴，宛如就在昨夜，仍然历历在目，甚至还以为现在真的是结束了吗？？或许，再给我点时间，我还能坚持坚持，还能再努力努力，还能做的更好一点呢。。\n但当专业课交完试卷，走出考场的那一刻起，都已成为过往。很感谢这一年每月的记录，才有现在的最终篇。\n走出考场，整个人都好像失去了目标、失去方向、失去走下去的动力。我好像回到了一年前的自己，又好像看见了三年前的自己。\n一年前的自己，刚刚开始准备考研，还在吃着上一届学长学姐考研的瓜，跟风吐槽着数学出的简单、英语有多难、政治肖大爷有多神。但作为这届刚刚结束这一切的考研人，我不愿去讨论，甚至不想与这个世界存在任何联系，我怕一点点的风吹草动会影响接下来的心情。去年这个时候面对的是不知该如何复习的迷茫感，现在是不知该做些什么的困惑，甚至不知道该向什么方向去努力。那时的自己，你不了解你所处的位置，也无法判断自己真正的能力与实力。但是，却有着极大的野心和孤独一掷的决心与勇气。你说，你要考个牛掰的学校，想体验一下去大城市读书的感觉。同时，你对自己的学习方法也有时摸不着头脑，有时又蜜汁自信。最后，你说不管结果如何，你会坦然去面对这一切的后果，因为你相信，只要坚持到底总不会太差，如果不是，那就是还没到最后。那么值得吗？？？我觉得值！！！这是一段极为难得的专注时光，得以有机会深入地去探求最真实的自我，也是一场与自己的比赛，与自己对话的机会。\n是啊，你现在走完了这一路，为什么不敢去面对当时的自己了呢？？没达到自己预期的样子。。。对，确实没达到。原以为的自己能够在考场上意气风发、洋洋洒洒地写完试卷，走出考场时，还不忘给自己一个微笑。考前，我曾一遍一遍地想象自己在考场上的自己，想着这一年的付出终于能发挥出来，所有的付出都能看得到回报，这一路的坚持也是值得的。但事与愿违，四场下来，一场比一场难受，但我不能表现出来，我怕会影响下一场考试，怕自己会崩溃，怕自己没有踏进下一场考试的勇气。可能，这也就是现实了吧。\n三年前的自己，那时的你带着高考的不甘，极其不情愿的来到现在的学校，都还不知考研对你意味着是什么，就把考研定为自己的目标，大一的时候还不怎么逃课，上课也很积极坐在最前排，对大学里的一切即充满新鲜感，同时也很迷茫。迷茫的是大学和高中完全是两个样子，没有统一的标准，不知道到底怎么做是对的，哪样是错的。那时的你，眼界还仅仅局限于校园内，似乎就感觉世界好大，但与我无关，老老实实的做个普普通通的学生就好了，不是吗？你也更不会想到现如今的自己，不会真正参与到这个更大的世界。但现在，我又好想逃离这个错综复杂的世界。。。\n二、倒计时的煎熬 进入十二月 进入十二月，代表着不足一个月，就得走进考场，那时候政治啥都没背，只把肖八的选择题给做完，其他的老师的模拟题也不愿意去做，对政治这门课，就有点摆烂。英语开始最后一遍过真题，虽然记住大部分的答案，能要求自己的就是读懂文章，并分析答案的选项，正确选项是如何选出来的，错误选项是如何设置干扰的。每天保持一篇作文的量。数学也结束了真题，可能太过于急于求成，做完之后，没有进行详细的、系统的复盘，就去模拟题中挣扎了。现在看来是极其不明智的做法，数学说到底，还是应该以真题为主，模拟题是在全部掌握真题的情况下来开拓眼界、拓展思路，见见新的题型和技巧用的。看周围的同学都在做模拟题，自己也就忍不住去跟风，不免有点本末倒置。\n突然就觉得时间不够用了，每天都对自己说，起的早一点、学得晚一点、多坚持一点。硬生生的压迫自己去学习，效率也就不会太高。但是我不敢对自己有丝毫懈怠，因为真的快到头了，留给自己的时间也不多了。加油，踏踏实实的走下去。\n倒计时两周 这个时候，突然人就崩溃了。感觉好像啥都会，但再仔细想想又觉得自己哪里都不太会。肖四已经到手，根本背不动，学校这边还有一堆恶心的人和事来搞人状态，就想着我只是考个研究生，为什么觉得全世界都和我为敌，到底做错了什么？？英语也被 21 年的真题给打击到。。数学更是被各种模拟题做的我怀疑人生。专业课由于只有参考数目，并不知道实际上复习的咋样，一直都是玄学状态。\n我不止一次想过，要不就这样了吧。实在是坚持不动了。考研，真的是太痛苦了，比我原本的预期要难受的多的多的多。但回过头来再想想，再苦再累也就还剩两周，走完吧，别给自己留有遗憾。考场都没踏上，咋就自己知道自己就一定做不到呢？\n倒计时五天 距离考试还剩一周，真的是过一天少一天。现在也不做新题了，每天翻翻看自己做过的试卷，从错题找原因，再回归到讲义，查缺补漏。也就是在这个时候，回归真题，才意识到真题和模拟题的作用是不等价的。肖四也把当时可能考到的点都背了背，反正每天都在坚持嘛，虽然是不可能背完的了，奇迹也创造不出来。英语单词逐渐开始慢慢减少记忆量，腾出更多的时间来给作文。专业课就根据考纲和之前的真题回忆，每天睡前不断回忆专业课的内容。\n到了这个时间点，反而没有前两周那么慌张，更从容，更平静了。开始慢慢调整自己的状态，虽然不能回到巅峰，但最起码别太差就好。到了临考前两天，晚上从图书馆回宿舍的时候，开始收拾资料，逐渐往宿舍搬，收到一半的时候，突然好舍不得，不禁就呆住去回忆这一年的点点滴滴，眼泪止不住的在眼角里打转，强忍不让其落下来。回宿舍的路上，望着天上的星星，我就在想，所坚持的这一切真的值得吗？？为了考研所放弃的太多太多，真的不会后悔吗？？\n还记得，在十月份的博客中写到：我还在等一场雪，来见证这场考试。周五看好去考场的路线回到酒店，晚上真的飘起了小雪。从唯心主义来说，真的就有很大信心去踏上明天的战场。\n三、但是还有生活 是的，现在距离考研结束已经快过去一周了。这一年就好像做了一场梦，考试结束，梦也就醒了。\n还记得高考结束之后，留下的最多的是疲惫感，现在也是。还有一种无力感，颓废感。从踏进大学校门的那一刻起，就把考研当做自己的最终目标，完成之后，不知道自己下一步该怎么走，该走向哪？？一时间，又好似觉得自己的努力有些可笑，有些一文不值，开始不断的否定自己。\n现在考研都在默认奇数年简单、偶数年简单，虽然事实的确如此，但难与不难，往往更取决于个人的主观感受，而不是你我说了算，我们要做的就是坦然去面对这一切，在考场上做到发挥出最好的自己。回答前面的问题，值得！！！如果再给我一次机会，我还会选择考研，因为只有历经了真正意义上身心的折磨，才能算得上是成长，遇见困难，要硬着头皮冲，而不只想着做逃兵，一直在退缩。有的时候，不逼自己一把，都不知道自己是什么样的。最重要的是，这场考试，虽然发挥的不是太好（巅峰状态的百分之七十），但没有留下太大的遗憾，我尽我所能，做到了最好的自己。\n除了这一切，但是还有生活。\n想想之前所规划的，考试结束之后，想做的事情，好像也没啥了。脱离开源社区半年，突然回去，既熟悉又陌生。熟悉的是那种来自开源人带来的感觉是不会变的，陌生的是又有了许多新的小伙伴、新的代码，还需自己花时间去了解一下。这半年来，没有时间去积累新的技术栈，现在也有时间去探索新的领域，做新的尝试。这半年来，由于备考而落下的书籍，也有时间去阅读了。btw 可以的话，我还想把大学期间读过对我影响比较大的书买纸质版的再来一遍。还有就是，当时想着去健身，现在也有了大把的时间去锻炼自己，让自己朝着更好的方向去发展。\n若干年后，你会怎样回想这一年？人生海海，这一年，我们记得肆虐的洪水，反反复复的疫情，更记得那些逆行的无畏身影，爱与善汇成浩荡星河，在奉献，在永不言弃的精神。这一年，我们记得巨星，灿烂而不朽的陨落，记得他们走过一地荒芜，留下生生不息。记得那些顽强和汗水写下的闪耀时刻。每一个巨浪都成就于微澜，每一个普通的灵魂里都有江河。这一年，我们记得，勇立潮头的你，披荆斩棘前行的你，每一天都努力让自己和周边世界好一点点的你，记得一路千山万壑，希望就是我们自己，都在路上！\n附：考研歌单\n《平凡之路》-- 朴树 《一群无知少年的梦想》-- 杨赛 《稻香》-- 周杰伦 《拼个世界给自己》 -- 姜云升 《没有理想的人不伤心》-- 新裤子 《Iridescent》-- Linkin Park 《Beautiful》-- Eminem 《猛犸》-- 后海大鲨鱼 《幸存者》-- 林俊杰 《孤勇者》-- 陈奕迅 最后，有的人说，奇数年的坚持，都是为了在偶数年迎来好运，希望下一年会好一点~~\n还有就是，去 TM 的 2021，终于结束了。。。。。\n","description":"","tags":null,"title":"大政的考研 Blog010 —— 但是还有生活","uri":"/life/kaoyan010/"},{"categories":null,"content":"Blog009 —— 幸存者，十一月复盘 一、再坚持一下 1.1 彻底崩溃 是的，就像标题所说的那样，随着距离考研时间的越来越近，心里也就越来越着急，紧张感、压迫感都在无形的逼近。总想着，还有好多好多没有复习，到底该怎么办啊！就这样想着想着，心态崩了，严格意义上来说，是考研这将近一年的时间中第一次崩溃。\n进入考研倒计时 100 天的时候，我在想，还不着急，还有三个多月呢，时间在一定程度上还是很充裕的，就想着是不是背诵记忆类的内容可以往后放一放，况且专业课复习的不咋滴，数学才是重点。慢慢的到了快倒计时 60 天 的时候，突然的有一种压迫感袭来。马上就剩下两个月了，两个月需要背那么多，你能做到么？？但问题是，其实数学和专业课复习的也不是很好啊。。要知道，我高三的时候都没这样过，有的时候还经常逃课，上课睡觉，考研给我整成什么样子了。我也想去外面玩，好好的睡个懒觉，这学期更是进山窝里到目前为止三个月的时间没有出去过！就算是高考在我眼前，五一假期的时候，我还是该浪浪该玩玩。也许，这就应了那句话：出来混，迟早是要还的。。。\n就这样，到了倒计时 50 天的时候，彻底崩溃，下一步不知该如何是好，整个人都充满了无力感。总想着剩下的时间，英语作文、新题型、翻译、完型都没开始；高数的一些边边角角小的知识点、几何应用、物理应用都不会；线性代数掌握的也不是好牢固，知识点都串不起来，做题的时候都是磕磕巴巴，甚至还做不出来；专业课，笼统的感觉好像全部都掌握的还行，每个点都能说出个一二三出来，但是到具体的题目，又不太行；至于政治，更别提了只听了马原部分，经济学部分掌握的还不好，史纲也知道个点点，其余的压根没看。下一步到底该怎么走。考四门，结果没有一门是能让我安心的。\n下一步该怎么办？是放弃吗？还是做无谓的坚持？？\n很多的崩溃可能往往就是那么一瞬间。（但是学过马哲之后，就要说这句话是错的了，这不明显忽略了量变对于质变的影响嘛）。\n1.2 还剩 50 天 对啊，你还剩 50 天，又不是下周就要考研了，干嘛这么着急呢？焦虑有用吗？也许只会有反作用吧。就像之前暑假时候的状态，想玩但是又不敢玩，只能硬着头皮学，反而没有怎么玩，学的也不咋滴。你现在的问题不是不想学，而是不知道该如何去学，既然是有学习的心，剩余的就是学什么的问题了。\n这一路走来，很多时候我们都习惯于放大自己的缺点，和强调自己的特殊性，认为好像只有自己会遇见这种问题，甚至会觉得，我只是想考个研，怎么全世界都在和我作对！其实不然，我们也只是百万考生中的一员，其实往大了说，大家的问题也都差不多。不排除肯定有复习的特别好的大佬，也肯定有氛围组的炮灰，但是我想说的是绝大多数人都一样。都会感觉到焦虑。在没出成绩之前，谁敢说自己就一定能考上呢？坚持到这个时间段，我们当下需要做的就是走好自己的每一步，过好自己的每一天。但是如果太刻意去强调每天都要学的扎扎实实的，在很大程度上也会有副作用。人是特别容易受主观因素影响的动物，没有人能够保证自己学的特别棒，真的没有，偶尔出现情绪波动都是再正常不过的事情了，我们要学会接受自己的不足，欣赏自己的不完美，只有这样才能把自己的心态给端平，也能够给自己一个喘一口气的机会。\n1.3 30 天倒计时 就这样，不算太顺，但也不能说是太差，进入了三十天倒计时。有的时候，我就会想，为什么通常把三十天左右当做一个结点呢？仅仅是因为一个月的时间在这个范围左右嘛。也许吧。但也有可能是接下来的每一天离自己即会更近一步，又会渐行渐远。。每每这个时候，我就会想起高三对自己说的话：我不去想是否能够成功，既然选择了远方，便只能风雨兼程。其实吧，事情远没有自己想的那么严重。如果不考研的话，我就是一个不起眼的二本院校普普通通的毕业生，再说直白点，本身就没啥好失去的。考研，考上了等于赚了，考不上就问问自己这一年的坚持对自己而言值得吗？？有收获吗？？现在的自己是当时自己所想的样子嘛？？\n和之前的博客里面所写的一样，从选择考研的那一刻起，我就在问自己，为什么要考研，或者说读研对于我来说意味着什么。我能够感觉到，就算是我读研毕业之后，工作能力也许并不会比现在的自己高出多少。这个答案，直到今天，我还在寻找。。。\n二、十一月复盘 ① 数学 数学分值 150，自然而然是重中之重。但是数学的学习真的很枯燥无味，到现在这个阶段才感觉到在复习前期对数学真的是低估了。从而导致数学的整体进度到中后期开始慢慢落了下了来。从辩证法的角度来看，这一点也不是一点好处没有的，就把高数和线代的强化部分又抽重点给过了一遍，也是因为之前暑假的时候为了赶进度而导致的原因吧。由此可见，学习是真的要学的扎扎实实，不能囫囵吞枣！\n这个月主要就是把武神的 17 堂课给看的差不多，但是后面的几个专题因为时间的原因只是结合课程把里面的一些掌握不太好的题型给做了，并没有全部完成，而且整个课程还剩物理应用没有复习。进入十二月的第一天给它啃了吧。不得不说，武神终究是武神， 17 堂课听得很痛苦，因为全是重难点，几乎没有太多的垃圾题目，刷起来难度就真的大很多。但是对于解决问题的角度，都提供了很好的解法，尤其是微分中值定理的证明，之前看见这种题目从心理上来说是比较畏惧的，无法充分利用题目的已知条件，不会正确的构造函数，但这些经过系统地训练之后，会发现都是有迹可循的。所以考研给我的感觉，后期的付出比天赋重要的多。再有就是二重积分的求解问题，这段时间真题刷下来，二重积分几乎是必考的，往往还会更倾向于大题目的考察，解决此类问题的时候，首先看区间是否是对称区间，以及是否能够通过平移利用函数的奇偶性来适当的简化计算量，以及对于直角坐标和极坐标之间的转化适用于什么样的题目，还有就是像星形线、摆线之类的比较特殊的曲线图像，心里要有个大概的了解，这样的话遇见题目才不会出现无从下手的情况。课程的质量还是可以保证的，干货满满，就是听起来很费精力！！！\n其次，就是从这个月下半旬开始，真题的套卷终于开始刷了，虽然半个月的时间只消化了八张真题试卷。以下是对从 11——18 年真题的简单小结：\n11 年：难度一般，由于是第一次以套卷的形式开始做数学，出现很多知识点串不起来，像填空题中出现的弧长公式、以及对于微分方程的综合应用掌握的一般，整张试卷下来计算上的细节容易出现丢分情况，物理应用是丢分点之一，二重积分的出题方式比较特殊，但是结合一元的情况还是应该要解出来的； 12 年：难度一般，曲率没有掌握，还有就是对于行列式的计算要学会灵活处理，旋转体的体积的处理、二重积分考察的是心形线，整个试卷我感觉最难的题目是数列极限的题目：用零点定理证明至少有一个零点，再用单调有界准则证明最多有一个零点，在第二问求极限的时候，还要充分利用第一问给的信息；线代大题要注意同解方程的应用； 13 年：难度一般：反常积分的敛散性掌握不熟；以及变上限积分的连续性判定这些小的知识点都不能忽视，实对称矩阵等价=具有相同的特征多项式，伴随矩阵与其代数余子式之间的关系，大题目则比较中规中矩，除了一个考察形心，这是个什么鬼？？还有最后的线代大题，利用技巧来处理问题要引起注意，傻乎乎的展开几乎不太可能实现； 14 年：难度有所上升，函数的性态（单调性、凹凸性等）与导数之间的关系，质心坐标？？微分方程解的形式，以及特征根需要注意。证明题其中数列极限，是个好题。还有多元微分学以及积分的应用来求体积都是要引起关注的点。证明矩阵相似，通常要用一个中间的矩阵作为过渡； 15 年：难度一般，高阶导数的求法，二重积分的计算要想到对称区间——奇偶性，微分方程的物理应用，题目不是很难，要耐下心来读题，以及后面的证明题，比较综合，也是不错的题目； 16 年：难，计算量大！选择填空都还行，主要是计算量真的大！题目思路都比较常规，几乎都能想到，就是算不完。在求定积分的时候遇见绝对值要分区间讨论，以及对于可导性的判断也不能少！微分方程的求解，关于常数 C 如何确定的问题，旋转体的侧面积计算（积分区间的上下限要注意），以及最后线代的大题，求高次幂要想到利用对角矩阵，但是计算量也是令人匪夷所思； 17 年：比较简单，求解极限的时候，分母是含有 x 的变上限积分，不能直接使用洛必达，要想到换元，后面的题目没啥可说的点。。。； 18 年，难，但是计算量我感觉并没有 16 年大，反而选填题的难度有所上升，大题中考到了求不定积分，这玩意的难度是个无底洞，需要注意冲刺时候的训练；还有求拉格朗日最值，计算量比较大；二重积分考的是摆线，画出图形，利用对称区间可以简化计算量。 从 15 年开始，偶数年的题目是真的难，计算量还大，我了个天，谁知道今年会怎么样呢。。\n在当前状态下，模拟卷没有时间就不做，务必要把真题吃透，做好！\n② 英语 英语这个月，算是复习的比较理想的一科了。先是过完了翻译的课程，随后新题型和完型填空又紧随其上。目前还在准备作文阶段，小作文已经初步形成，大作文希望在一周之内可以完成，毕竟留给的时间真的真的不多了。\n这个月则把真题又过了一遍，因为属于多刷了已经，里面的大部分答案都能记住，所以要做的就是通读阅读文章，扫清生词和长难句，以及弄清楚题目与选项之间的关系。要养成良好的做题思维。接下来的日子，真题再过最后一遍，我也希望是我人生中最后一遍过考研英语的历年真题！！\n③ 专业课 专业课怎么说呢。。笼统的看好像全部都掌握的差不多了，但是放到具体的问题来看，还是掌握的不太牢固，就比如排序的算法，对于考纲中给出的内容都能手动模拟出来，但是要是说全部手写代码的话，还是存在一定的困难的，（根据前两年的回忆版真题，只出现了个快速排序的代码要求，而且还有文字提示），对于 BST、AVL 和 B 之类的插入和删除都算是掌握了吧，画图过程都会，但是容易忘，所以在接下的时间要反复巩固。但对于链表、栈和队列只知道这些数据结构的增加结点和删除结点的方式，并没有往下深究，看着之前的回忆版真题，感觉这部分考的不是很深。还有就是时间和空间复杂度的计算要掌握，图比较侧重于迪杰斯特拉，前两年都考到了。还有各种数据结构的存储方式。\n数据库方面的话，难点还是在第三范式和 BCNF 的分解，无损连接和保持函数依赖性掌握的还行，求闭包之类的也可以，求最小依赖集比较生疏，还有就是求候选码容易漏。。写 SQL 的话，经过了一定量的练习，应该不会丢太多分，考得太难了也就无了呗。至于关系代数，回头还需要看看，至于元组演算的话，战略性选择放弃吧。还有重点就是事务和故障恢复，这部分既需要理解，又需要一定量的背诵。难度的话倒不是很难，剩余的我感觉更多的都是偏向于记忆类的知识点，后期需要回归教材，多看看书，把书变薄再变厚。\n加油！\n④ 政治 政治这个是我最不想提起的，因为真的很无聊。马原和史纲部分还能接受，到了毛中特的部分，那就是开始无脑吹。唉。\n里面的 keywords 看着都很熟悉，就是记不清，而且还没有花时间开始背诵。还剩三周多几天的时间，能够背的完么？选择方面，肖八快全部刷完了，前面两套做的是真的惨不忍睹，错的稀里哗啦。。。但好处是之前马原和史纲过了一遍，这块的错误率是比较低的，因为毛中特和思修对于我来说等于啥都不知，只能结合错题回归背诵手册来勾画知识点，反复记忆。到了第四套开始慢慢有了起色，最起码不是做的太难看了。\n说真的，政治我不想花太多时间，毕竟拉不开多大的分，我想的就是在最短的时间内，冲到 60 分以上，最起码证明自己的政治觉悟没有问题是吧，虽然上海还是旱区。。。\n三、幸存者 天，快亮了！是啊，终于快了，我等了好久，内心是期待的，是渴望这一天早点到来，这样身上的担子就能卸下来了，就能做点自己想做的事情。每当看不下去书的时候，我就在想考研结束的生活，我想看自己喜欢的书籍，睡个懒觉，继续为开源项目做贡献，阅读源码，增加查克拉，再玩玩悠悠球。还有二十几天，就能过上了，一定一定要调整好自己的状态，最起码在面临考试的时候不是恐惧的心理。\n但在期待着她到来的同时，又不愿早点到。因为没有复习好，还是会觉得如果再给我多一个月的时间，我肯定能把哪里哪里给补回来，把什么什么给学的好好的，但是时间对于每个人都是公平的，过去了就是过去了，在剩下的日子里要做的就是在现有的基础上，不断巩固加强，查缺补漏。还有就是，我不知道下一次这么为了自己的目标去奋斗，坚持是什么时候，在选定考研目标的时候，这是我读书以来第一次有机会自主选择自己的院校，所以从根本上来说，我是很喜欢这个为之努力，为之付出的过程的，因为我知道，随着时间的推移，我在慢慢的、一点一点的靠近她。但是我还怕就差一点点，原以为只是踮起脚尖够月亮，没想到回过头来已经是万丈深渊。这段煎熬的时光纵然不舍，但我还是想说享受这一次就好，今年一定要冲上岸！！\n其实在和对大多数的考研人比，我算是比较幸运的，在别人还在焦虑选择院校的时候，我的目标已定；因为是自主命题，所以很感谢导师和实验室的师哥师姐给予的帮助。如果没有你们的帮助，我的心态早就崩了。也正是由于你们的帮助，我敢于去搏一把，去挑战自己心里的那个最高点，去勇于做别人想做但又不敢做的。还有就是离不开家人的支持，家永远是最后的防线。所以从这些角度来说，我是考研大军中，为数不多的幸存者！\n背负伤的幸存者 争夺着有限名额\n想要闪烁就对自己更严格\n加油！冲！\n","description":"","tags":null,"title":"大政的考研 Blog009 —— 幸存者","uri":"/life/kaoyan009/"},{"categories":null,"content":"Blog008 —— 莫问终点，十月复盘 一、煎熬 ? 终点 : 放弃 1、10.24 十月份，10.24 程序员节~~ 打心底来说，我还是很喜欢这个职业的，至少从目前为止，也许以后毕业了从事“劳动密集型工作”面对资本家的压榨，会产生厌恶的心情呢，but who cares？以后的事情以后再说咯。\n软件工程，这个专业名字确实听起来确实很高大上，但是临近毕业大四的自己，有掌握软件工程的思想吗？？似乎差的很远吧。但是我喜欢编程所给我带来的东西。在现在这样一个信息化的时代，几乎人人都离不开互联网带来的便利。所以我们将来所从事的职业是一个可以改变世界的，这一点也是挺值得自豪的。还有就是在掌握一些技术栈之后，会慢慢发现这个在互联网影响下，现实和虚拟相互交织的世界到底是如何运转的，我们每天使用电子设备所产生的的数据是如何存储的，又以何种方式被利用等等，这些在我看来都是很有意思，也是值得思考和探索的。所以我很感谢当初的自己选择了这个专业，能给现在的自己一个机会，以程序员的视角去感受这个世界。\n回想去年的 10.24 可谓是真的极限运动，周四晚上连夜做着绿皮小火车，轰隆轰隆吵得头皮发麻，周五到达上海，上午睡一觉，晚上赶往年会会场--微软 Reactor，到晚上回家的时候地铁停运，只能打车，洗漱完成已经是两点多，第二天还得早起，接连两天，然后周天晚上再次连夜赶回合肥。有的同学问我，这么赶时间折腾自己，就是去做志愿者，有必要吗？我想或许不是很有必要，但是有意义，信仰充值。在去年的开源年会，是我第一次得到被肯定的感觉。让我发现世界上有很多和我一样的人，普通却并不平凡为开源输出自己的力量，也更让我找到了考研的目标。（具体的详细感受看 我与开源的那些事儿）其实最好的体验是在于回来之后，写了这篇博客，得到认可的“满足感”和“虚荣心”是无可替代的！\n2、越来越近了… 是的，十月份的结束，代表着距离考研也越来越近了。这个阶段的自己心情是十分矛盾的，一方面想着完了还有好多东西没看没复习还来得及嚒？？另一方面却想赶快结束这一切吧，真的是熬不动了。我想无忧无虑的熬一次夜，更想无所顾虑的睡一次懒觉。但是对于目前这个阶段来说，这无疑是一种奢侈。\n就带着这矛盾的心情，一面是厌学，不想看书；另一面又是逼着自己学习，因为我太渴望考研上岸。就总觉得是这是证明我自己的一次机会，证明自己大学这几年混得还不差，证明自己还是有能力的，证明我能做得到。更想让那些之前看不起我的人，对我刮目相看。似乎从中考失利，就被贴上差等生的标签，从高中到大学，所以当再一次站在选择的路口，我不想再窝窝囊囊只是为了有学上来逃避自己啥都不会的现实，这一次我想选个牛 X 的，更何况机会就摆在我面前，我真的舍不得放弃。嗯，是的。\n但是选择了好的学校，就代表着你需要承受踏上终点的一切负重。其中压力部分是最大的，竞争力也要强上很多，在往年三百七左右的平均分作为参考，以及近年来报考人数的持续增长，很多次很多次很多次有不断地想过问自己，要不要换一个学校，或者说要不就这样了吧？？\n但是我熬了这么久，不是想证明自己临场退缩，我所期待的的是“拟录取”这三个字，是明年的录取通知书。是明年可以骄傲地说：我从做得到，到现在已经做到了！！！\n说实话，这一段不知为何，写得戾气有点重。但我实在是不知道该怎么给自己调整心态，我不相信什么“心灵鸡汤”、“励志成功学”等等之类的，那都是强者拿来安慰或者忽悠弱者的。我想说的是：我能做的就是逼自己认清现实，意识到现在自己的处境。时间是不等人的，今天过去，是不会再回来的。只能尽自己最大的能力，调整好自己的心态，哪怕这心态已经“畸形”了。。。\n二、十月复盘 ① 数学 数学可谓是整个考研过程中最耗费精力和时间的科目，现在回想起来从去年大约这个时候开始过高数的课本教材到现在已经一年了，但是距离自己最初所期待或者说是所要求的目标还离的有不小的一段距离，离考研也越来越快了，到底怎么样，心里似乎也不是很有底。\n我从来没没有想过数学的强化阶段会持续这么长！！原以为暑假的时候听完强化课，做好讲义上的例题就算是强化结束了。但工作量远比我想的要大得多。满打满算高数部分到上周末才算是强化结束。线代预计还要三天以后。十月份数学的重心大部分都是强化收尾工作。把之前漏看的、掌握不牢固的以及某个知识点题目做得比较少，都拿出来重新过了一遍。\n先具体说一下高数吧，要是论对考点的熟悉程度的话，掌握最好的应该是求极限，函数求极限只要不是太偏太怪太难理论上是没问题的了，数列求极限有待加强（原因很简单，求极限放在第一章，每一次重新过的时候，前半部分的时间花的最多，就好比是英语单词书最熟悉的是第一页的词汇一样）；其次就像是求导求积分之类的题目，不能说是掌握的太好，但是在做此类题目的时候，进入状态的时间有点长；而且求积分这块，尤其是不定积分就像是个无底洞，它有些常见的套路和题型，但却没有那么容易想到，这块的还有个难点是微分中值定理的证明题，从我现在的水平来说，是有希望啃下的，毕竟在暑期的时候就特地有投入时间在这部分，（昨晚在听 17 堂课中该专题的时候，看见题目能自然而然的想到如何构造辅助函数）但我怕的是，由于这部分确实比较难，出题比较灵活，万一出现课下模拟都会做，但是一到考试看见真题的时候傻眼了，这是及其恶心、难受的一件事，不花时间吧，我似乎又不太放心。。\n在不定积分和定积分还有两个盲点：第一个是变上限积分的比阶之类的，第二就是定积分的应用，包括几何应用和物理应用。比较明显的特点就是不是很难，但缺乏训练导致掌握的比较差，之前想的就是跟着武神的 17 堂课，再集合真题和模拟题巩固练习，但有的时候看见此类题目，容易产生抵触的心理。\n高数的下半部分也就是上面的特点，不是很难，但是掌握程度却不太理想。。在这次重新强化的过程中，加强了对于微分方程、多元函数微分学、二重积分的练习，当时想的就是这啥玩意哈，之前都学了个啥！！！由此可见之前学的有多差，现在回头来看要的多了，但是在做题之前还是需要先看一下知识点。。加强练习啊！！！发现问题之后，要学会解决它，不能放任不管。微分方程的话，技巧性不是很强，计算量略微有点点大，套模板记公式。多元函数微分，难度有一点点，特别是定义那块，给我感觉是整个高数部分考定义最难的点了。。。计算的话，需要细心，特别容易绕晕。二重积分，计算量有！根据定义域画出函数图像，这一块要仔细点，我觉得是难点所在，最后剩下的就是计算问题，如果在部分再考难一点，直接放弃吗？？\n线代的话，整体就是比较玄学，说不会吧，多少会一点，但是看见题目的时候，很多时候都无从下手，知识点全部都搅合在一起，能做的也只能是多花时间、多思考、多练习。所以我又把线代的强化课听了一遍，听李老讲题的时候，哎确实是这个道理，只要注意力集中也都听得懂，但是到自己做题目，就是另一回事了，关键原因还是无法利用题目所给的已知条件，甚至有的时候看完答案还得想好久，离考研不到六十天，有的时候，我就在想线代要不给放弃了？？但是放弃的话就代表着数学最多最多考到一百算是不错的了，李老还出了个综合提醒课，下个月抽时间看看吧。加油！\n② 英语 英语的话，阅读能感觉到已经没有问题了，但是问题是除了阅读其他的好像都有问题，准确来说是都还没开始，作文等进入十一月份，就可以准备起来了，新题型的话，我想的是等到十一月中旬再开始，翻译的话，有时间就开始吧。至于完型填空，我的预期目标是最少要及格，不拉后腿就好，可以适当的战略性放弃点。\n但是在做完英语二之后的阅读，再看英一的阅读，对比下来，英一要难好多，也许是自己阅读根本就没掌握好呢。。做英一阅读的时候，题目与文章的定位点大部分都能准确找到，但是英一的文章对于词汇和长难句要求真的是高很多，解题技巧会了，还是基础不牢，地动山摇？？这个阶段给我来这一出，我是真的怕啊！！！\n③ 专业课 专业课这部分我真的很感谢给我提供过帮助的学长学姐，要不然我真的是一脸懵逼。\n数据库：拉了许多的数据库终于补救回来了，呃，应该是抢救。。整个考纲里面所要求的知识点都有所掌握，常见的题目也都掌握的还行，盲点还在于关系代数和 SQL，这部分要抽时间集中练习，然后坚持到考前，至于关系演算，实在是看不懂，是不是可以放弃。。对了，还剩一章数据库设计没有看。。\n数据结构：这部分总体来说是比较熟悉的。但是具体到考点是比较迷茫的，因为数据结构的出题形式真的太多了，可以是只考理论也是可以写代码，甚至是画图。这就很恶心。十月份的重点都花在对于数据结构的查缺补漏上面，下个月计划再花半个月时间在二叉树、图、排序和查找，这部分知识点牵涉比较多，也是难点所在。一定要克服！！\n④ 政治 政治的话，我感觉是不是有点晚了，到现在才把马原看完，题目还没看完。政治这个科目，我已经开始迷了，完全不知道下一步该怎么走，该学什么。不对，是要学的太多，不知该怎么学。。。\n初步打算，跟完腿姐的技巧课。《肖 1000》的马原和史纲部分正确率要提到百分之九十，至于毛中特和思修的话，跟着模拟卷走吧，政治不求多，但是要及格啊。最起码证明自己的思想觉悟没问题，更何况自己还是党的一份子呢。。。。\n三、莫问终点 是鹰就不留恋地平线，云层上见～\n对了，我还在等。等一场大雪，来迎接这个冬季的到来，来从容地踏上考场，来记录我这一年的坚持与付出。\n至于终点是哪儿？其实，已经不是太重要了，这大半年的备考，让我自己的心又静下来许多。有的时候看不下去书，就会胡思乱想，其实我本身是一个比较喜欢发呆式思考的。在这断断续续的思想火花中，我也渐渐地更明白自己是一个怎样的人，想成为什么样的人。之前就听很多人说，考研的结果固然重要，但是真正值得回味的是这其中的过程，是一次次勇于挑战自己，敢于知难而上，不满足于目前的现状。\n之前，我总想着，等考上研究生就怎么怎么样，可以给自己放个假。但也许，考研只是这些年给自己的一个奋斗目标，督促自己要努力前进；也许自己并不喜欢读书专研，从而可能导致自己读研的时候会放纵自己；也许自己就是个差生，不是读书的那块料呢？？\n是的，也许吧。但是不坚持怎么会知道结果呢。不去尝试，又怎么能体会到这其中的酸甜苦辣呢。不逼自己一把，又怎么会确认自己就做不到呢？\n距离考研的日子越来越近了，就像前面所说的我已经在尽我最大的努力调整自己的心态，最后的冲刺阶段任务只会越来越重，心态上的煎熬也会加倍。当之前自己付出，到冲刺的白热化阶段慢慢感受到回报的时候，这一切都是值得的。\n考研，只是一场考试，是我所选择踏上的一条路，没必要把自己折磨的那么累，陷入极度的内卷，但这并不意味着是放纵自己的理由。还是要努力的啊！加油吧！\n感谢这个世界还有音乐~~\n","description":"","tags":null,"title":"大政的考研 Blog008 —— 莫问终点","uri":"/life/kaoyan008/"},{"categories":null,"content":"Blog007 —— 再出发，九月复盘 一、开始倒数 1.1 大四开学 时间过得真快，一眨眼，开学就是大四的老学长了。。这三年过来的一点一滴，就宛如刚发生一样，历历在目。现在回头想想，这几年经历了好多，但在学校中又似乎没有太大的收获。\n还记得三年前，这个时候还嚷嚷着想复读，现在看来其实都一样。也许复读顺利考得要稍微好一点，也可能不太幸运，甚至还不如现在呢。但当现在再一次为了一场考试而努力的时候，那种感觉又回来了。很多人都拿考研和高三比较，我感觉吧，相对而言考研要容易一点。因为考研能考个好学校的可能性要大一点，但是反过来看，高考的报录比是要好一点的，但是想读好的学校门槛是不一样的。于是也就有了，选择大于努力这一说话，考研真的是一场信息战！如果让我再选择一次的话，也许我仍然回想复习，但是现在也挺好的。遇见了很多意想不到的事情，遇见了很多有意思的灵魂。\n仔细算一下，正儿八经当时高中所憧憬的大学生活，也只能到大二上。 其余的时间，虽说还在学校，但是学习的内容和处理的事情都逐渐和学校的事情脱节，甚至在一定程度上反感学校许许多多杂七杂八的事情。大一，上课坐前排，参加社团活动，还想着找个对象吧啦吧啦的。。对待各种事情都特别认真。（大一的时候给自己定的目标就是拿到奖学金，认为奖学金就是最高的荣誉，现在看看，呃 不能说一点用都没有吧，反正就是没有之前想的那么重要，也就那么一回事罢了）对于大学的上课方式，社交方面还是很新鲜的，但是慢慢发现，和实际想的还差的很远，特别是遇见很多恶心的事情之后，就感觉天呐，一个学校怎么能是这个样子的，就离谱！！按照当时的脾气还会想着吐槽，但当看得多了，经历的多了，也就认了、不对是佛了。。当时大一特别想创建悠悠球社团，果不其然大二的时候，最折磨我的就是这个社团，每天想的都是怎么推广悠悠球，怎么把悠悠球传播出去，怎么教社员，怎么…… 就这样，心思也不放在学习了。就很难受，说句我不太喜欢的话，“不忘初心”，那么问题来了，初心是啥呢？？我怎么做的意义又在哪呢？？社团是我自己要创的，甩不掉的。。。（现在看看，如果说大学期间最值得纪念的事情，也只剩下这个社团了）再就是大二寒假，发生疫情，也就是在这个时间段发生的事情足以影响到我的大学生活，甚至是整个人生。由于疫情，线上开发协作，从而接触到了开源，也就有了现在的我，一个完全脱离于大学眼界的我。。感谢相遇~~（这也是我为什么说我的校园生活只到大二上的原因，之后的生活等有时间可以细说）。\n还记得去年这个时候，我还在犹豫，我到底要不要考研，或者说为什么决定去考研。我回来了??\n1.2 返校生活 是的，回学校之后，我的状态慢慢在恢复。这一点是我自己都感觉到比较惊喜和意外的，连我自己都没想到回到学校之后，状态真的在好转。七八两月暑假，说实话，离自己所要的复习预期，差的太多太多，都出现厌学心理，已经是在弃考的边缘徘徊的人了。。\n也许是因为暑假在自习室没有参照物来对比，整个网上的言论都是“我很努力”的这种，就很搞人心态。回到学校之后，发现大家都差不多嘛，（也许是我的学习太差 bushi）哈哈哈哈\n想通问题，恢复状态我想还是放在最后来说。\n但是最让我无语的事情是大四的课竟然还如此之多，那就逃呗，只要不挂科，就啥都好说，是吧。\n还有一点就是，自己还不够自律，要懂得拒绝，不能受别人影响、\n二、九月复盘 ① 数学 回到学校的时候，高数和线代已经全部听完强化课了，就想着是不是已经无敌了，结果就是被题目恶狠狠的给教训了一顿，我还是依旧的菜鸡。。。\n起初，刷《考研数学真题大全解·上册》的时候，因为是之前较早的题目，难度不是很大，所以一口气能刷五六十道，还是很嘚瑟的，而且正确率也有一定的保证。但是刷着刷着就变味了，做着前面的章节忘着后面的，于是在刷题之前，还是得巩固一下知识点，《高数辅导讲义》算是三刷了吧，知识点必须要看，边看边在草稿纸上写写画画，好记性不如烂笔头，况且我还没有好记性，再把之前做标记的题目再给做一遍，但是我发现问题的是，之前会做的题目，现在反而不太会做了，之前不会的还是不会，害。。。对了，《严选题》的质量也是很高的，虽然做的比较慢，十月份结束之前一定要二刷，一定！！加油~~\n但这也是比较好的事情，最起码知道自己的不足，是吧（也只能这么想了）\n线代的话，就是一遍一遍的过讲义，把知识点給串起来。效果也就一遍比一遍要好，有意识的去逼自己思考某个知识点可能会关联的东西。然后再做《李林880》的线代部分，习题线代题目给我的感觉还是比较中规中矩的，不像高数的证明题那么让我感觉无奈，有时候给的感觉就是恰到好处想到那一步。就很爽！\n其实在看线代的时候，心里还是比较没底的，因为分值不是很大，所以投入的时间不是很多，就导致过了一段时间就会有部分知识点遗忘，再加上暑假的时候，看线代的强化课有点太追求进度，听得就有点囫囵吞枣，效果自然也就不咋地，特别是二次型那部分，基于以上原因，就决定重新听一边线代的强化课，带着脑子学习，而不是一味的接受知识。类似的情况还出现在高数的后半部分，多元函数微分学以及二重积分都是理解的不太透彻，所以决定重听一下，这些得在国庆假期完成，又回到了没有课的日子，一定要把握住啊！！\n② 英语 英语，怎么说呢，阅读做起来有点感觉了，但我怕的是因为之前刷过的试卷，所以二刷起来效果还行，就导致一种盲目自信的状态。因为是二刷，阅读在做起来，就在一定程度扫清了生词和长难句，所以读起来没有太磕磕巴巴，做题目也能找到定位点，或者是排除干扰选项，较好的还能分清错误选项是怎么设计出来的。\n但是效果太好，反而有点让我不太适应，我怕这一切都是因为是二刷，是因为我下意识的知道这篇文章是关于什么的，讨论的问题是啥。。。\n至于作文和新题型也还没开始，也不知道该何时开始，也不知该准备哪些资料，头大\n单词肯定是每天必不可少的一个环节，有的时候，不想做阅读，就想着今天我背单词了，所以等于我看英语了，来安慰自己。。。\n③ 专业课 这个月专业课算是正式开始了，目标院校的大纲也更新了，与往年相比变化不是很大，考得范围有的还缩小了，所以在复习层面来说，更具体了。但是具体到某些知识点该考哪些题型的时候，还是比较懵的，不知所云。\n这个怎么说呢，有利有弊，因为从我自己来说并不属于刷题类的学生，也不喜欢刷题，没有历年真题的透漏，等于在一定程度上弥补了这一劣势。但是坏处是，我自己也不知该如何复习。能做的就是一遍一遍的根据考纲过知识点，争取做到没有太大的漏洞。\n数据结构：开始算是二刷了吧，第一边只是侧重于知识点的学习，并没有做太多的题目，这一次看一章，死磕一章的课后习题，选择题做到全部拿下，算法大题目前只做历年 408 真题，有的较怪较难的算法题会考虑直接放弃，进度到二叉树。另外听说学院喜欢考对于知识点的理解，而不是代码本身，所以尽可能要做到掌握理解，用图形来表达其中的逻辑关系。\n数据库：这个算是比较头疼的，首先 SQL 写得就不多，而且还比较烂，看课后习题也只是能看懂答案，让我自己徒手写的话，有很大难度，所以之后的两个月要加强对于 SQL 的练习，这一部分可不能丢分啊！查询优化看的比较懵，就是稀里糊涂的。。。依赖与范式那章就直接差点”要了我的命“，国庆集中处理。至于数据库事务和恢复反而比预期学的要好。\n后期需要根据当前的盲点，不断“扫盲”。\n④ 政治 可算是开始政治了，但是也是九月中下旬才开始的，而且花的时间也不是很多，整体进度是比较拉的。说不着急是假的，但是不能慌。要稳住阵脚，一步一个脚印地往前走。\n因为之前对于哲学比较感兴趣，所以读了一些相关的书籍。学马原的时候，虽然是偏重于理解，反而是比较容易找到共鸣的，能在现实生活中找到投影。刷《肖 1000》正确率也还行。\nBtw，蹲坑的时候，政治刷题小程序效果还是不错的。哈哈哈哈。\n进度得加快，投入时间得多加点，加油！\n三、再出发 为什么说是“再出发”呢？？倒数 100 天，算是比较有仪式感的日子，也预示着距离考研的日子从三位数变成两位数了，时间留给自己的时间不是很多了，得有点紧张感，所以说接下来的每一天如果状态不是很好，都是对这一天的浪费。\n如果把考研分阶段的话，今年三月之前的日子算作“0”，“0”代表着有想考研的想法，也做了一些努力，搜集了一些信息，但是距离真正开始行动，还是有一定的转变的；三月开始到暑假之前属于“1“，在这期间，慢慢开始投入时间和精力准备考研，会觉得考研还早呢，我还有一定的自由时间，复习状态也就还没拉满，整体上是比较放松的，有时候还会啥都抓，导致啥都学了点，但没完全学的尴尬情况；再往后就是暑假”2“，大家都说暑假是至关重要的两个月，因为这段时间完全是自己掌握的，这一点是真的，但没想到的是，在家复习没有学校的学习氛围，每天更要面对许许多多的日常琐事，眼看着自己的进度达不到所想的预期，心烦；九月开学——”3“，状态恢复，更想通了许多问题，所以是在解决了上面”012”的迷茫与不解之后的再出发！\n在预报名成功的那一刻，我不由的说了一句，我等这一刻，等了三年。对，为了考研，我鞭策自己三年。眼看着就要到终点了，不更应该是期待的嘛。而不是焦虑不安，原因是感觉复习的不好，但是还没走进考场，就代表着全部都是未知的，去努力啊！！别停下来！！\n所以说，把心态从焦虑调整到期待之后，每天都会有收获。有的时候还会看一下鸡汤，虽然很俗，但是有用，这段阶段的自己神经是比较敏感脆弱的，需要的是鼓励。\n希望会有好的结果，一定一定一定！！！\n","description":"","tags":null,"title":"大政的考研 Blog007 —— 再出发","uri":"/life/kaoyan007/"},{"categories":null,"content":"Blog006 —— Iridescent，八月复盘 Il n'ya qu'un héroïsme au monde : c'est de voir le monde tel qu'il est et de l'aimer.\n一、暑期生活 1.1 一次又一次被自己打败 过得好快啊，感觉什么都没做，暑假就过去了。。。\n每次在放假之前都会高估自己的能力，常常给自己布置一堆任务，而往往完成的也就两三件，甚至一件都做不好。。。是的，这种状态从中学时期就开始出现，但到现在还依然没有改掉。为什么会给自己选择充电呢，从根本来说，我不想成为一个碌碌无为的人，还是有一颗上进的心的，要不然为什么会选择考研呢。。但事实是，完不成任务还是因为自己太懒，自己不够聪明，一个知识点别人学一遍就能记住掌握，自己却只能听个大概，为了不愿承认自己的能力不够，还硬着头皮往下走，结果到头来发现，欺骗的也只有自己。说白了，就是虚荣心作祟。。\n最要命的是，意识到自己的错误，却改不了！！\n之前上半年在学校临近放假的时候，就一直在想，到了暑假就好了，每天的时间都是自己的了，就能有大把时间用于考研复习，从而可以达到一个由量变到质变的过程。可也就停留在了“想”，与实际付出行动来说还是有很大的差距。\n最主要的体现就是心静不下来，明明知道这是一个难熬的过程，却想着可以早点结束，想着这块内容是不是不太可能会考，我是不是就没必要花太多时间在这儿，总想着投机取巧。不肯脚踏实地，一步一个脚印地慢慢走。也许是高估了自己的行动能力，整个暑假给数学的时间最长，以为自己数学学的还行，到了强化阶段，越复习面对一堆难题无从下手，更是一种逃避的态度，久而久之，对数学是越来越讨厌；其实不止数学，英语和专业课不也是的嘛，英语除了背单词，阅读题更是不想做，硬着头皮啃下一篇之后，就匆匆忙忙去对答案，很多题目都不找原因，为什么错，不去弄明白其逻辑关系；专业课更是三天打鱼两天晒网，不知道该看些什么，看着考纲，无能为力；至于政治，更是可笑至极，说着为了空出时间给其余科目，连碰都没碰，连考些啥内容都不知道……\n所以说整个暑假是什么都没做吗？？也不是吧，虽然状态不是很好，每天的学习时间也不是很长，没有达到自己所预期的目标，但完成了其中的一小半吧，具体的复习情况放在复盘内容。\n很多人说，最大的对手是自己本身。克服自己的懒惰，浇灭自己的虚荣心，改掉不良的习惯，加油啊！！要学会独自去面对风风雨雨，独自在知识的苦海中摸索。\n1.2 我在努力 虽然有很多坏习惯，但是我一直在努力改变自己，不求能够有多好，但保证不会越来越差。\n自习室八点半开门，知道晚起毁一上午，但明白早起毁一天，所以一般来说选择七点多起床。尝试过五六点起来背单词，困得不行；也有过睡到八点多再起来，但是到自习室都将近九点半，从而导致一上午背完单词，再做几题高数就中午了，效率太差。慢慢调整选择一个比较适合自己的时间。一开始刚放假，可能是在学校“憋”了太久，看书回来家就比较晚。吃完饭，洗好澡，十点多，就导致家里人的作息都被我打乱。考研是我自己所决定的，虽然说爸爸妈妈都很支持我，但是不能影响他们第二天工作，（主要还是爸妈比较心疼我，）所以就适当的回家早一点，这样一家人可以一起吃一口热乎的饭。\n看书看不下去，想着想哪，一会刷一下朋友圈，一会又看一下小破站。只能硬逼着自己改变，手机屏幕使用时间限时，朋友圈关闭，B 站换成青少年模式，取关不太有意义的博主。不想做题，就看着题目想思路，想不出就看答案，再自己在稿纸上演算一遍，还能怎么办呢？又不能真的不做，做不到主动，只能改变自己从被动的层面吸取知识。英语阅读啃不下来，先翻译，扫清生词和长难句，最起码做到能读懂再说，再根据阅读方法论慢慢梳理题目以及段落之间的逻辑关系，最后再看看讲解视频。没办法，学不下去啊，只能这样了，我也真的无能为力了，我甚至开始怀疑自己并不适合学习，才到这个点就耐不住性子了，开始急了。我也不知到底怎么做是对的，只能敷衍着走，最起码不愿意承认自己停下！\n1.3 折磨？调整？ 说起自己状态开始变差还得从六月底 AirPods Pro 丢了开始说起。说不心疼吧，是假的。至今我还能记起第一次带上降噪耳机的感觉，整个世界都安静了。原来自己每天生活的环境噪声这么大，这么小的机身是如何做到这么强的功能的…… 特别新奇和不可思议是当时的感觉。但随着慢慢习惯降噪之后，那种一开始的新鲜感也早已见，也许是耳机麦克风堵住了，降噪就变菜了。。作为苹果生态的一环，在手机和 iPad 切换也早已习惯。在丢了的那几天，就好像是少了好多东西，哪哪都不舒服，就这样开始不想学习。起初也想过买个华强北的。但是吧，买山寨不是我的习惯，再买个全新的？？感觉不值。暑期教育优惠，换个 MacBook 或者换个 iPad Pro 送耳机？？但是更期待 M2 芯片，自己的 iPad Air3 用起来也不差，就很烦。对这种状态一直环绕着初期。到七月底。每天被这些事情闹心。。。\n后来，慢慢想开了，其实自己或许也不依赖一副耳机，也或许并不一定要用苹果生态下的产品？？为了整个生态，舍弃了自己客制化的习惯，开始对于处理器、芯片、刷新率等不再讲究，音质也不再挑剔，似乎就感觉苹果的生态是最屌的，舍弃点有啥关系呢。就这样变成了韭菜。也就这样，我看上了 Sony WF 1000 XM4，体积不大，续航强，佩戴舒适度属于能接受的范围，没有生态。。。。但这又有啥呢，一再犹豫之后，在 AirPods Pro 丢了两个月之后，还是入手了 XM4。降噪的天花板，也让相信了蓝牙耳机也可以有音质。时隔两个月重新又有了降噪，虽然各方面能力都比 AirPods Pro 好得多，但第一次带上降噪的感觉再也回不来了。\n但我的状态回来了……\n在快对自己失去信心的时候，找回了之前的状态，虽然还没满血复习，但是足够了！！\n对了，顺便提一下，暑假期间我又迷上了变形金刚。这个算是我从小喜欢到大的 IP 了吧。虽然每天看柱子哥模型的评测浪费了不少时间，害……等上岸奖励自己一个，一定。（当时纠结要不要买柱子哥，买了 XM4 之后，就说等等吧，该有的都会有）\n最后再补上，还有奥运会。马龙太帅了，今年好像是在 08 年之后，再一次这么关注奥运会了，看见五星红旗在东京升起，国歌奏响的那一刻，民族自豪感油然而生。我们生活在一个这么好的时代，国家提供了安稳的环境，作为新时代的我们也应该奋发努力，想想再过十年左右社会的中流砥柱就是咱们这代人了！\n二、八月复盘 很遗憾，暑假的计划并没有完成。。\n① 数学 分别听完了高数和线代的强化课程，但也仅仅是听完了而已。距离消化里面的知识还有一段路需要走。看讲义，做例题，还需要克服自己好高骛远的尿性，不能不懂装懂，还要勤动手，答案是算出来的，而不是看出来的。\n原以为八月能够把高数讲义重新过一遍，但是很遗憾，一遍看讲义然后做严选题和 08 年以前的考研真题，效率是真跟不上，才到第二章结束。但好处是前两章的知识点很牢固，从基本的定义题目（这类题目我感觉是很恶心的）到计算，再往后是压轴的证明题，都可以应付的来，也并不是像自己所想的那样啥思路都没有。坏处是后面的又给忘了，特别是常微分方程和多元微分学，一看就会，会了就忘。还得努力啊！！\n起初，做严选题太难，就转去做宇哥的真题大全解上册，给自己找点求生欲吧。后来一想，考研不会考简单的，要学会迎难而上。啃严选题的时候，给我最大的感受就是，这题我应该会做，但不是那么好做，最后往往会停留在应该上。。给题目做好标记分类。一遍一遍来，反复磨，总会完成的。\n线代的话，因为之前看完基础课的时候，就顺带把讲义过了一遍，这次的复习感觉比听基础课要好得多。但到了后面的章节之后，越来越综合，知识点稍有不牢，就不知这个为什么是这样，这一步是哪来的。课程内容不是很多 5 天，但我花了将近 15 天才全部看完。中间真的不能耽搁，一落下，很难追上。再刷讲义，也比之前有了更多思考，也想的更多，牵涉到的知识点，也算是一种巩固的过程。\n今晚听了武神的直播答疑，说强化阶段是到 10 月底，这无疑是一针强心针，可以告诉自己不要慌，进度并没有落太远。慢慢来，比较快，加油！\n② 英语 英语就有点玄学，除了背单词能记住（其实也不一定记住了）。阅读还是很难有底。做完了之后，站在上帝视角来分析，会觉得确实是那么一回事，但自己做题的时候为什么就想不到呢。知行合一？？只是知道方法论，做不对题目的知道，算是知道吗？\n在月底的时候梳理这两个月做过的阅读，还是挺有成就感的。看着原来白纸黑字的被一片片红笔的注释不成样子（错的不成样子）也确实有点难受的。不能说没有掌握阅读方法论，但就是还缺点什么，不像做数学题目那样，只要是我自己做出的就不会出错。\n小三门之类的也快要提上日程了，英语的时间要要延长点了。\n③ 专业课 七月说专业课每天 1.5 小时起步，还是没做到。\n数据结构结合考纲把知识点提出来了，但问题是不知道考试题目会考到哪种程度，是只考一些定义性质，还是会考代码呢，考这些又会怎么考呢？？\n数据结构就是感觉零碎的知识点好多，做题之前过一遍的话，题目都是会做的但是时间一长就容易忘记。。而且对于数据数据结构考纲比较迷，像栈牵涉到的中缀表达式、图涉及到的求关键路径之类的，王道的书上有，但是考纲上写得比较迷糊的不知道该不该看，以及题目的形式都好迷。。\n数据库，很碎很杂很多，有点像文科但它又不是。。其中像关系代数、元组演算之类的自我感觉不会考（蜜汁自信），因为掌握的不太好。。但是像 SQL 感觉理论上属于必考的，数据库不写 SQL 说不过去吧，至于考得有多难，掌握到什么程度又不知该如何。\n④ 政治 看不下书的时候，看政治打发时间必备~~\n九月份马原\n三、Iridescent 世界上只有一种真正的英雄主义，就是认清了生活的真相后还依然热爱它。\n我知道考研难熬，但我没想到是如此煎熬。暑假的复习状态几乎一直处于复习的低谷。好几次出现了弃考的想法，总想着也许自己就这样了吧，不是块学习的料，不适合学习。起初想考研更多是对高考遗憾的一种弥补，也是怕自己到时候啥都不会找不到工作。\n但现在看来这两样似乎也就那么一回事，那么我考研的意义又在哪里呢？研究生的生活又会想是自己所期望的那样吗？或者说，自己真的有想过读研的生活是哪样的嘛？也许我就是单纯的不知自己该干嘛所做出的一种逃避呢？？\n忽然想起自己以前的博客说过，我也想成为一个闪闪发光的人。\n考研与其说是孤独朝圣，倒不如说是与自己的对话。学习如逆水行舟，学海无涯。面对知识的敬畏，自己的内心到底会怎么做。走下去，卷入无尽深渊，退出，接受自己的平庸无能？？有时候还会想读书有什么用？人活着的目的又在哪？人该追求些什么呢？当今社会的价值观如此畸形，自己的价值观又该如何评判呢？\n好吧，我承认，考研真的很容易胡思乱想。人均哲学家。。。。\n说到底，我想成为一个有能力的人。进一步的话，成为一个有能力影响他人的人。\nDo you feel cold and lost in desperation\nYou build up hope but failure's all you've known\nRemember all the sadness and frustration\nAnd let it go\nLet it go\n","description":"","tags":null,"title":"大政的考研 Blog006 —— Iridescent","uri":"/life/kaoyan006/"},{"categories":null,"content":"Hadoop 极简入门 零、前言 在 2021 年初的时候，Apache 退休了一些 Hadoop 生态圈的子项目。再加上其 MapReduce 思想最为人诟病，因为不太友好的编写代码方式，需要高昂的维护成本以及较低的运行效率，唱衰 Hadoop 的声音（甚至对于整个大数据生态的质疑声）日益高涨。。\n然而，MapReduce 作为一种编程范式，恐怕并没有那么容易被淘汰。纵使很多人说：你看 Spark 速度又快又稳定，这不是可以淘汰掉 Hadoop 的 MapReduce 吗？但是真的是这样吗？？\n所谓的快和慢都是相对而言的。某些互联网公司每天的离线调度任务动辄数十万起，这么庞大的基于 MapReduce 的离线计算如果要是用 Spark 来替代，与之相对应的是高昂的服务器成本。\n因此，我们可以说原来用 Hadoop MapReduce 能做的事情被更好更快的其他计算引擎来替代了，而不是 MapReduce 被淘汰了。而且后来的计算引擎也大都有借鉴 Map、Reduce 这类的概念！\n一、长话短说 1.1 Hadoop 是什么？？ Hadoop 是 Apache Software Foundation 开源的，根据 Google 开源的三篇大数据论文设计的，一个能够允许大量数据在计算机集群中，通过使用简单的编程模型进行分布式处理的框架。其设计的规模可从单一的服务器到数千台服务器，每一个均可提供局部运算和存储功能。Hadoop 并不依赖昂贵的硬件以支持高可用性。Hadoop 可以检测并处理应用层上的错误，并可以把错误转移到其他服务器上(让它错误，我在用别的服务器顶上就可以了)，所以 Hadoop 提供一个基于计算机集群的、高效性的服务。\n1.2 主要优势 主要拥有以下优势：\n高可靠性：Hadoop 底层维护多个数据副本，所以即使 Hadoop 某个计算元素或存储出现故障，也不会导致数据丢失； 高扩展性：在集群间分配任务数据，可方便地扩展数以千计的结点； 高效性：在 MapReduce 的思想下，Hadoop 是并行工作的，以加快任务处理的速度； 高容错性：能够自动将失败任务重新分配。 1.3 发展 经过多年的发展，Hadoop 这个单词的意思也随之发生改变，由之前一个具体项目的名称，到现在提到 Hadoop 大多是指大数据的生态圈，包括许多现在火的一腿的项目，例如 Spark、Hive、HBase 等等。\n如同 Spring 框架有着最基础的几个模块 Context、Bean 和 Core。其余的模块和项目都是基于这些模块构建的。Hadoop 与之大体一样，也有最基础的几个模块：\nCommon：支持其它模块的公用工具包； HDFS：一个可高吞吐访问应用数据的分布式文件系统； Yarn：一个管理集群服务资源和任务调度的框架； MapReduce：基于 Yarn 对于大数据集群进行并行计算的系统。 其他的，像 Hbase、Hive 等等都是在这几个模块基础上的高级抽象。Common 模块是 Hadoop 最为基础的模块，负责为其余模块提供了像 I/O、操作文件系统、序列化和远程方法调用等最为基础的实现。（如果想深入了解 Hadoop 具体实现的小朋友，可以挑战自己阅读一下 Common 的源码~~）\n二、HDFS 基础概念 HDFS 是 “Hadoop Distributed File System”的首字母缩写，是一个分布式文件系统，说简单点就是为了存储文件。但是和其他的文件系统的不同之处是 HDFS 设计为运行在低成本的硬件上（因此在学习 Hadoop 入门的时候，可以使用 Linux 虚拟机搭建一套集群出来玩玩），且提供高可靠性的服务器。HDFS 设计满足大数据量，高吞吐的应用情况。\n为了更好地理解分布式文件系统，咱们先看看下面的这些概念：\n2.1 文件 咦？谈起文件，想必大家都很熟悉，在不同的行业中，文件也有着不同的意思。在计算机科学领域，文件是在存储设备中是 N 个字节序列。而从计算机使用者的角度而言，文件是对所有 I/O 设备的抽象。每个 I/O 设备都可以视为文件，包括磁盘、键盘和网络等等。文件这个简单而精致的概念其内涵是十分丰富的，它向应用程序提供了一个统一的视角，来看待系统中可能含有的各式各样的 I/O 设备。\n2.2 文件系统 那么一台计算机上肯定不止一个文件，成千上万的文件怎么管理呢？因此需要我们需要一种对文件进行管理的东西，即文件系统。文件系统是一种在计算机上存储和组织数据的方法，它使得对其访问和查找变得容易，文件系统使用文件和树形目录的抽象逻辑概念代替了硬盘和光盘等物理设备使用数据块的概念，用户使用文件系统来保存数据而不必关心数据实际保存在硬盘的地址为多少的数据块上，只需要记住这个文件的所属目录和文件名。在写入新数据之前，用户不必关心硬盘上的那个块地址没有被使用，硬盘上的存储空间管理(分配和释放)功能由文件系统自动完成，用户只需要记住数据被写入到了哪个文件中即可。\n2.3 分布式文件系统 相对于单机的文件系统而言，分布式文件系统（Distributed file system）。是一种允许文件通过网络在多台主机上分享的文件系统，可让多计算机上的多用户分享文件和存储空间。\n在这样的文件系统中，客户端并非直接访问底层的数据存储区块和磁盘。而是通过网络，基于单机文件系统并借由特定的通信协议的帮助，来实现对于文件系统的读写。\n分布式文件系统需要拥有的最基本的能力是通过畅通网络 I/O 来实现数据的复制与容错。也就是说，一方面一个文件是分为多个数据块分布在多个设备中。另一方面，数据块有多个副本分布在不同的设备上。即使有一小部分的设备出现离线和宕机等情况，整体来说文件系统仍然可以持续运作而不会有数据损失。\n注意：分布式文件系统和分布式数据存储的界线是模糊的，但一般来说，分布式文件系统是被设计用在局域网，比较强调的是传统文件系统概念的延伸，并通过软件方法来达成容错的目的。而分布式数据存储，则是泛指应用分布式运算技术的文件和数据库等提供数据存储服务的系统。\n2.4 HDFS HDFS 正是 Hadoop 中负责分布式文件系统的。HDFS 采用master/slave 架构。一个 HDFS 集群是由一个Namenode（可以理解为资本家老板） 和一定数目的 Datanodes（打工人） 组成。Namenode 是一个中心服务器，负责管理文件系统的命名空间以及文件的访问控制。集群中的 Datanode 一般是一个设备上部署一个，负责管理它所在节点上的存储。HDFS 暴露了文件系统的命名空间，用户能够以文件的形式在上面存储数据。\n实际上，一个文件会被分成一个或多个数据块，这些块存储在一组 Datanode 上。Namenode 执行文件系统的命名空间操作，比如打开、关闭、重命名文件或目录。它也负责确定数据块到具体 Datanode 设备的映射。Datanode 负责处理文件系统客户端的读写请求。在 Namenode 的统一调度下进行数据块的创建、删除和复制。为了保证文件系统的高可靠，往往需要另一个 Standby 的 Namenode 在 Actived Namenode 出现问题后，立刻接管文件系统。\nHDFS 架构概述 NameNode（nn）：存储文件的 元数据，如文件名、文件目录结构、文件属性（生成时间、副本数、文件权限），以及每个文件的 块列表 和 块所在的 DataNode 等等； DataNode（dn）：在本地文件系统 存储文件块数据。以及 块数据的校验和； SecondaryNameNode（2nn）：每隔一段时间对 NameNode 元数据备份（把 NameNode 当做老板的话，SecondaryNameNode 就相当于小秘，但小秘毕竟是小秘备份的数据肯定没有老板完全，所以在掌握 Zookeeper 之后可以配置 HA，也就是说两个 NameNode 互相备份）。 三、MapReduce 基础概念 MapReduce 是一个使用简单的软件框架，基于它写出来的应用程序能够运行在由上千个商用机器组成的大型集群上，并以一种可靠容错的方式并行处理上 T 级别的数据集。\n一个 MapReduce 作业(job)通常会把输入的数据集切分为若干独立的数据块，由 map 任务(task)以完全并行的方式处理它们。框架会对 map 的输出先进行排序， 然后把结果输入给 reduce 任务。通常作业的输入和输出都会被存储在文件系统中。 整个框架负责任务的调度和监控，以及重新执行已经失败的任务。\n通常，MapReduce 框架和 HDFS 是运行在一相同的设备集群上的，也就是说，计算设备和存储设备通常在一起。这种配置允许框架在那些已经存好数据的设备上高效地调度任务，这可以使整个集群的网络带宽被非常高效地利用。\nMapReduce 框架由一个单独的 master JobTracker 和每个集群设备一个 slave TaskTracker 共同组成。master 负责调度构成一个作业的所有任务，这些任务分布在不同的 slave 上，master 监控它们的执行，重新执行已经失败的任务。而 slave 仅负责执行由 master 指派的任务。\n用户编写的 MapReduce 应用程序应该指明输入/输出的文件位置(路径)，并通过实现合适的接口或抽象类提供 map 和 reduce 函数。再加上其他作业的参数，就构成了作业配置(job configuration)。然后，job client 提交作业(jar 包/可执行程序等)和配置信息给 JobTracker，后者负责分发这些软件和配置信息给 slave、调度任务并监控它们的执行，同时提供状态和诊断信息给 job-client。\n简单来说，MapReduce 将计算过程分为两个阶段：Map 和 Reduce；\nMap 阶段并行处理数据； Reduce 阶段对 Map 结果进行汇总。 一个 Map 函数就是对一些独立元素组成的概念上的列表的每一个元素进行指定的操作。事实上，每个元素都是被独立操作的，而原始列表没有被更改，因为这里创建了一个新的列表来保存操作结果。这就是说，Map操作是可以高度并行的。而 Reduce 函数指的是对 Map 函数的结果（中间经过洗牌的过程，会把 map 的结果进行分组）分组后多个列表的元素进行适当的归并。\n四、Yarn 基础概念 YARN(Yet Another Resource Negotiator)是 Hadoop 的设备资源管理器，它是一个通用资源管理系统，MapReduce 和其他上层应用提供统一的资源管理和调度，它为集群在利用率、资源统一管理和数据共享等方面提供了巨大的帮助。\nYarn由ResourceManager、NodeManager、ApplicationMaster 和 Containe 四个概念构成。\nResourceManager（RM）：整个集群资源（内存、CPU 等）的老大； NodeManager（NM）：单个结点服务器资源老大； ApplicationMaster（AM）：单个任务运行的老大； Container：容器，相当于一台独立的服务器，里面封装了任务运行任务所需要的资源，如内存、CPU、磁盘、网络等。 了解了上面的大致概念之后，再细细分析一下：\n4.1 ResourceManager ResourceManager 是一个全局的资源管理器，负责整个系统的资源管理和分配。它主要由两个组件构成：调度器(Scheduler)和应用程序管理器(Applications Manager)。\n调度器根据容量、队列等限制条件，将系统中的资源分配给各个正在运行的 MapReduce 程序。应用程序管理器负责管理整个系统中所有 MapReduce程序，包括提交、与调度器协商资源以启动 ApplicationMaster、监控 ApplicationMaster 运行状态并在失败时重新启动它等。\n4.2 NodeManager NodeManager 是每个设备上的资源和任务管理器，一方面，它会定时地向 ResourceManager 汇报本设备上的资源使用情况和各个Container 的运行状态；另一方面，它接收并处理来自ApplicationMaster 的 Container 启动/停止等各种请求。\n4.3 ApplicationMaster 用户提交的每个 MapReduce 程序均包含一个 ApplicationMaster，主要功能包括：与 ResourceManager 调度器协商以获取资源(用 Container 表示)；将得到的任务进一步分配给内部的任务(资源的二次分配)；与 NodeManager 通信以启动/停止任务；监控所有任务运行状态，并在任务运行失败时重新为任务申请资源以重启任务。\n4.4 Container Container 是 YARN 中的资源抽象，它封装了某个设备上的多维度资源，如内存、CPU、磁盘、网络等，当 AM 向 RM 申请资源时，RM 为AM 返回的资源便是用 Container 表示。\n五、结束语 本文走马观花的介绍了 Hadoop 相关内容。主要目的是给大家一个对大数据的分布式解决方案的感官印象，为后面的大数据相关文章提供一个基础的理解。\n最后要强调的是，思考大数据方向的问题是一定要记住分布式的概念，因为你的数据并不在一个设备中甚至不再一个集群中，而且计算也是分布的。所以在设计大数据应用程序时，要花时间思考程序和算法在单机应用和分布式应用所产生的不同(e.g. 加权平均值)。\n","description":"","tags":null,"title":"Hadoop001——入门篇","uri":"/tech/bigdata/bigdata_hadoop001/"},{"categories":null,"content":"Blog005 —— 事上炼，七月复盘 一、恍惚 1.1 怂了？？ 这才到哪了呢，就怂了！！明明每天给自己布置的任务量不是很大，却还是一次又一次高估自己的执行能力，整个七月份下来，没有几天实际上完成目标的。但是，平均下来给自己每天的任务量确实不是很大啊，但为什么就完成不了呢？？一身的小毛病却不能克服自己，总给自己找各种各样的理由，来推脱学习。大政啊，你现在的思想和态度都很危险知不知道！！！当你的行动能力和效率无法满足自身的野心的时候，除了抱怨，怨天尤人还能做些什么呢？？\n以上，大概是这段时间，反反复复对自己说的话。虽然想放弃是真的，但认怂是不可能认怂的！！！\n考研过程中的备考压力远远超出我心里的预期，比我想的要难受的多。这也是为什么想要放弃的原因，似乎放弃了，就退出备考的赛道，可以好好的缓一口气，也就不会面对煎熬，不会面对失败，但也意味着辜负了父母的期望，前期的准备都是为了见证这一刻的放弃，承认自己的软弱。如果放弃，每次遇到点啥磕磕绊绊的象征性的坚持一两下，就会怀疑自己做不到，想逃避，下意识的想退缩。也就这样成为一个懦夫……\n所以说，认怂是不可能认怂的。当时做出准备考研的决定，并不是头脑一热，更多的是因为有自己想做的事情，寻找自己的闪光点，努力成为一个能够影响别人的！！！如果这时候选择了低头，这不就成了别人口中的反面教材了嘛。。多丢人啊，是不！！想放弃也许是多个坚持不下来的瞬间累计导致的，但选择站起来勇敢的直面这些瞬间，是自己能到做出的回应。认怂的话，自己心里说说就好，可别真的怂了哈~~ 坚持下去，一步一个脚印。\n1.2 长跑心态 7 月份，过得是真的快。当时想着放暑假了，没有学校那么多杂七杂八且无意义的事情，总算可以“闭关修炼”了。事实却是，整体上和学校的学习效率差不太多，又一次没达到预期，高估了自己。这也是为啥想放弃的原因，开始质疑自己，甚至有时候感慨自己真的不是学习的料。中高考考得都不咋地，还想考着考研翻身，这是有点痴心妄想嘛，别坚持五六年的努力，你一年就能跟得上？？但是，就这样认输，会有点不甘心。\n现在的世界好处是信息多而广，且好获得。但坏处是干扰信息太多。往往也是这些干扰信息最搞人心态！！！无论是知乎，还是 B 站、公众号之类的平台，凡是可以传播信息的地方都会出现标题党。最让我恶心的就是“考研人一天学习 XX 小时”、“如何保证一天有效学习 XX 小时”之类的文章或视频。给你一种感觉就是：反正我学能学到这么长时间，早上 6 点就能背单词，晚上 11 点还在复盘。如果你达不到这种程度，你自己看着办吧。WDNMD，您可真能学习啊！！！我自己是一个极其懒的人，能早上八点起来绝不起点起来看书的那种，而且注意力也很难集中。每当做一件事的时候，总会控制不住自己想另外一件事情。仔细想想，每天花在考研上的有效时间不超过四个小时每天。但就是在这种情况下，进度还能跟得上。所以我特别想知道那些每天做到学习八小时以上的是学到了什么程度。这也是我之前所提到的 考研在没有上考场的情况下，所有的参照物都是无用的。\n上面扯了那么多，不是想说我摸鱼都能学到这种程度，也不是想吐槽那些“卷王”，只是想说，我天天那么混都觉得好累！！！更何况现在才到备考中期强化阶段，距离考研还有五个月左右的时间该怎么熬啊！！考研不是短距离冲刺，不是说这段时间坚持坚持突击搞一下就行。更像是一场马拉松，虽然知道终点线，但一路上的磕磕绊绊，遇到哪些荆棘都是未知的。一路上没人能够帮你走下去，只有你自己。这也就有了“孤独朝圣”这一说话。更像是一场与自己的修行。但与马拉松不同的是，你还不知道你的对手如何。\n之前总是听考研的过来人说，别开始那么早，战线别拉太长。当时自己想的是，我能坚持，我要变强。也许按照当时的心态是可以坚持的，但随着距离考研越来越近，焦虑感、压迫感就会慢慢左右心态。所以能做到的只能是，调整好自己，给自己足够的弹性空间，在不那么长的学习时间内，保持自己最高的效率来学习。说白了，没有人说学多长时间就一定能够上岸的。干嘛那么折腾自己呢。。。\n1.3 当 代 毕 业 生 生 存 现 状 一个普通青年毕业后的生存故事。虽然距离毕业还有一年，但从小金身上或多或少看到了点自己的影子：从怀着赤子之心，想着要成为一个对社会有用的人，到慢慢遇到很多不情愿的事情，渐渐地磨平自己的棱角，但好在我还是我。正如罗曼·罗兰所说：世界上只有一种真正的英雄主义，就是认清了生活的真相后还依然热爱它 。当看到这个视频中小金将视频通话转成语音的时候，破防了。。。似乎，这半年来的心酸、难受都在那一刻哭了出来。就想到自己，这半年来有好几次我妈给我开视频，都被我给转成语音，也不知道是什么原因，至少不想让家里人看到我丧的那一面。成长，也许就是从小时候有什么委屈哇的一声在母亲的怀抱里就能哭出来，到习惯了报喜不报忧，让爸妈少为自己操点心，告诉他们自己过得还不错，我没有止步，还在努力。\n我不要在孤独失败中死去\n我不要一直活在地下里\n物质的骗局\n匆匆的蚂蚁\n没有文化的人不伤心\n二、七月复盘 这个月的复盘要严格批评自己，学习效率太差！！！\n① 数学 7.23 完成高数强化阶段的全部课程。本预计还空出一周时间留出来查缺补漏，但事与愿违，可能是真的学倦了，然后台风暴雨刚好给自己一个偷懒的理由，最后一周没有认真学习。八月加油吧！！\n总体上武神的强化课干货上是没得说的，但不幸的是听起来太痛苦，有的章节要是死磕的话需要听好几遍才有点效果。没有听宇哥的课有那么多快乐。强化阶段确实是比较过瘾的，没有基础阶段的苦恼，不用扣定义，更倾向于做题，属于学会即用，所见即所得的感觉，说直白点就是过瘾，当看见讲义上一道道被自己画 pass 的题号越来越多，成就感也是满满。但有时候题目做不出来的挫败感也是十分闹心的……\n高数整个强化下来，对于考试的侧重点有了个了解，题型以及考点之类的啊，不像之前那样啥都抓，往往是哪都不熟悉。高数的盲点少了点吧，难点无非还是证明不太会，盲点的话是定义类的选择题。不熟悉的地方就是定积分的物理应用吧，也不能说是不会只是不熟悉，需要点题目来积累信心。对于基本知识的应用理论来说没什么问题，具体的掌握的好与不好，还得靠之后的题目来检测。\n《严选题》还没开工，之前看有些同学说这本习题册的难度是有的，看来又是一段煎熬时光。\n预计八月十号之后开始线性代数的强化。十五天之内务必完成。这样一来，八月就完成了所有的强化课程。接下来就是刷题。千题百炼，加油吧！！！\n② 英语 英语这个月进度有点拉。除了每天坚持背 45 分钟单词，阅读有点三天打鱼两天晒网，八月需要调整过来，至少两天一篇。\n课程上，重新听了一遍唐叔的阅读方法论和长难句，阅读方面确实有提升，但是长难句越听越混，总体来说阅读能力有所提升。错误率控制在每篇一到两个，能够分别出不同的题目怎么解题，解题不到位的情况大部分还是文章读不太懂，少许是解题方法的错误，易错点：猜测题，无法联系上下文逻辑。比较擅长例证题、作者态度、中心思想之类的题目。实践出真知，好事多磨。\n③ 专业课 专业课则是放慢了脚步，结合考纲（害 终于想起来我们是有考纲的，而不是 408 的 DS）把数据结构的知识点做了个梳理，这一轮下来，对于专业课上，心更静了。不会有种飘飘然的感觉。花了一个月时间都是数据结构，数据库方面还是前三章。对于后面的内容就交给八月份吧。\n底线：每天 1.5 个小时起步，再不花时间，等后期只会干着急，等着哭吧！！！\n④ 政治 这玩意怎么说呢，我书都没带。但是说不着急，心里还是慌的。所以把徐涛的强化课当下饭视频看着玩，给到点心里安慰吧~~\n三、可以的！ 写到这的时候，我又回头看了看之前的博客，似乎给人的感觉是怨气有点重，就好比是深处深渊，却不甘于此，于是一步一步地前进。用努力去创造属于自己的那一份荣耀。更多是挣扎之后的倔强。虽然好像连续的这几个月都说着好难啊，好累啊的话，但如果我自己都不给自己点鼓励，那么谁还会相信我可以呢？？\n事上炼，谈何容易？？考研与其说是一段备考的经历，更像是一次寻找自己的过程，每当遇到困难的时候，每一次迷茫绝望都是和自己对话的过程。唯有练就强大的内心，才能坚定的向上走，迈向更高的台阶。\n光阴里的每一步都是修行，不知之间早已 自渡''。\n","description":"","tags":null,"title":"大政的考研 Blog005 —— 事上炼","uri":"/life/kaoyan005/"},{"categories":null,"content":"Maven 常见问题处理方法 一、'npm install node-sass --unsafe-perm' failed 报错信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [INFO] BUILD FAILURE [INFO] ------------------------------------------------------------------------ [INFO] Total time: 02:01 min [INFO] Finished at: 2021-07-10 [INFO] ------------------------------------------------------------------------ [ERROR] Failed to execute goal com.github.eirslett:frontend-maven-plugin:1.6:npm (npm install node-sass --unsafe-perm) on project dolphinscheduler-ui: Failed to run task: 'npm install node-sass --unsafe-perm' failed. java.io.IOException: Cannot run program \"dolphinscheduler-dev\\dolphinscheduler-ui\\node\\node.exe\" (in directory \"dolphinscheduler-dev\\dolphinscheduler-ui\"): CreateProcess error=193, %1 不是有效的 Win32 应用程序。 -\u003e [Help 1] [ERROR] [ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch. [ERROR] Re-run Maven using the -X switch to enable full debug logging. [ERROR] [ERROR] For more information about the errors and possible solutions, please read the following articles: [ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException [ERROR] [ERROR] After correcting the problems, you can resume the build with the command [ERROR] mvn \u003cargs\u003e -rf :dolphinscheduler-ui 错误分析：\n当执行 mvn -U install package -Prelease -Dmaven.test.skip=true 的时候，由于前端 Module 的 pom.xml 对于 NodeJs 没有配置对应的镜像，并且有某堵墙的存在，懂的都懂不多说哈，从而导致无法能够成功的拉去对应的资源，因此需要在对应的 pom.xml 文件中添加相关配置即可。\n解决方法：\n1 2 3 4 5 6 7 8 9 10 11 12 \u003cexecution\u003e \u003cid\u003einstall node and npm\u003c/id\u003e \u003cgoals\u003e \u003cgoal\u003einstall-node-and-npm\u003c/goal\u003e \u003c/goals\u003e \u003cconfiguration\u003e \u003cnodeVersion\u003e${node.version}\u003c/nodeVersion\u003e \u003cnpmVersion\u003e${npm.version}\u003c/npmVersion\u003e \u003cnodeDownloadRoot\u003ehttps://npm.taobao.org/mirrors/node/\u003c/nodeDownloadRoot\u003e \u003cnpmDownloadRoot\u003ehttps://registry.npm.taobao.org/npm/-/\u003c/npmDownloadRoot\u003e \u003c/configuration\u003e \u003c/execution\u003e 注： 其中 nodeDownloadRoot 和 npmDownloadRoot 为添加的淘宝镜像，如果添加该配置还无法解决问题，可以尝试把 node 和 npm 的 version 置换成本机所安装的版本即可。\n二、Could not transfer artifact org.springframework.boot:spring-boot-starter-parent:pom:2.1.18.RELEASE from/to central 报错信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Caused by: org.apache.maven.project.ProjectBuildingException: Some problems were encountered while processing the POMs: [ERROR] Non-resolvable import POM: Could not transfer artifact org.springframework.boot:spring-boot-starter-parent:pom:2.1.18.RELEASE from/to central (http://repo.maven.apache.org/maven2): Failed to transfer http://repo.maven.apache.org/maven2/org/springframework/boot/spring-boot-starter-parent/2.1.18.RELEASE/spring-boot-starter-parent-2.1.18.RELEASE.pom. Error code 501, HTTPS Required @ org.apache.dolphinscheduler:dolphinscheduler:1.3.6-SNAPSHOT, D:\\ideaProjects\\dolphinscheduler-dev\\pom.xml, line 165, column 25 at org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:176) at org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:102) at io.airlift.resolver.ArtifactResolver.getMavenProject(ArtifactResolver.java:177) ... 44 more Caused by: org.apache.maven.model.building.ModelBuildingException: 1 problem was encountered while building the effective model for org.apache.dolphinscheduler:dolphinscheduler-registry-zookeeper:1.3.6-SNAPSHOT [ERROR] Non-resolvable import POM: Could not transfer artifact org.springframework.boot:spring-boot-starter-parent:pom:2.1.18.RELEASE from/to central (http://repo.maven.apache.org/maven2): Failed to transfer http://repo.maven.apache.org/maven2/org/springframework/boot/spring-boot-starter-parent/2.1.18.RELEASE/spring-boot-starter-parent-2.1.18.RELEASE.pom. Error code 501, HTTPS Required @ org.apache.dolphinscheduler:dolphinscheduler:1.3.6-SNAPSHOT, D:\\ideaProjects\\dolphinscheduler-dev\\pom.xml, line 165, column 25 at org.apache.maven.model.building.DefaultModelProblemCollector.newModelBuildingException(DefaultModelProblemCollector.java:195) at org.apache.maven.model.building.DefaultModelBuilder.build(DefaultModelBuilder.java:419) at org.apache.maven.model.building.DefaultModelBuilder.build(DefaultModelBuilder.java:371) at org.apache.maven.model.building.DefaultModelBuilder.build(DefaultModelBuilder.java:362) at org.apache.maven.model.building.DefaultModelBuilder.build(DefaultModelBuilder.java:232) at org.apache.maven.project.DefaultProjectBuilder.build(DefaultProjectBuilder.java:142) ... 46 more Process finished with exit code 1 错误分析：\n在网上拷贝的所有阿里云镜像比如：\n1 2 3 4 5 6 \u003cmirror\u003e \u003cid\u003enexus-aliyun\u003c/id\u003e \u003cmirrorOf\u003ecentral\u003c/mirrorOf\u003e \u003cname\u003eNexus aliyun\u003c/name\u003e \u003curl\u003ehttp://maven.aliyun.com/nexus/content/groups/public\u003c/url\u003e \u003c/mirror\u003e 查看官网之后发现：阿里不再支持http下载，只支持https。\n因此，先将maven镜像配置如下：\n1 2 3 4 5 6 \u003cmirror\u003e \u003cid\u003ealiyunmaven\u003c/id\u003e \u003cmirrorOf\u003e*\u003c/mirrorOf\u003e \u003cname\u003e阿里云公共仓库\u003c/name\u003e \u003curl\u003ehttps://maven.aliyun.com/repository/public\u003c/url\u003e \u003c/mirror\u003e 然后还出现了一个问题，由于使用了HTTPS，存在着 SSL 证书验证的问题，因此需要在 IDEA 中添加了一行配置 Maven —\u003e Importing —\u003e VM options for importer:\n-Dmaven.wagon.http.ssl.allowall=true\n一般到这里问题理论上是可以正常解决了，但是由于 Windows 的环境会出现许多神奇的问题，如果项目还依然报错，可以尝试删除本地包，重新构建。\n","description":"","tags":null,"title":"Maven 配置问题汇总","uri":"/tech/datastructes/question001/"},{"categories":null,"content":"Blog004 —— 拼个世界给自己，六月复盘 一、瓶颈期 1、一条路走到黑 考研就像是在黑屋子里洗衣服，看不见洗到什么程度，也不知道自己和别人差在哪里，自己低头拼命的洗，只有打开灯的时候，拿出自己的衣服，才能知道结果如何，但在这一过程中难免也会有感觉洗不动的时候。\n不知不觉半年过去了，这半年宛如一个人走一条只知道目的地，但是却不知该怎么走的黑路，很多时候感到迷茫，感到困惑，明知道某个点该歇一歇，但就是不敢停下脚步，生怕自己一旦停下，被别人超越，就再也追不回了。考研和高考相比，不清楚自己的竞争对手，也就没有有效的对比，不知道该做到什么程度才算是好，才能达到了某个时间点该有的样子。毫无头绪。\n其实这半年来，每个月总有几天学不下去的时候，还记得当时三月底，怀着急功近利的目的，开始肝《十天搞定考研词汇》，每天一睁眼一闭眼都是单词，甚至有一种看见字母有头晕的感觉。但还好我坚持了下来，说一句鸡汤的话，付出总有回报，啃完单词，再开始刷真题的时候，大部分单词都认识，至少心理上不会太排斥。四月份五月份的时候，专业课还没有正儿八经的开始，就隐隐约约总有一种紧张感，怕时间来不及，怕学不会。现在回头来看，虽然专业课没有认真的看，但把教材和课后习题，在无聊的时候过了一遍，对照考纲，大部分的知识点还是比较熟悉的。再到六月，这个月真的是各种倒霉，倒霉，倒霉！！！这个月估算了一下，只看了二十二天的书，先是知道暑假学校不给留校，然后 AirPods Pro 在图书馆无故丢了，再到期末考试，最后学院还给安排个校内实习？？有意义嘛，唉。所以到现在开始复盘的时候，心里还是五味杂陈，这个世界怎么了嘛，呃，简单来说，阻碍你考研的只有你的学校！！！\n再往后，因为学校不给留校，把之前所有的规划都给打乱，好几天都在愁，暑假，都说是考研过程中，最关键的一个阶段，到底该怎么办？？怕暑假两个月之后，达不到自己所预期的效果，怕因为没有学习环境而学不下去，怕两个月之后，我还在继续怀疑我自己，怀疑自己或许根本不适合读书。在提出这些问题，自己心里也许是有答案的，至于答案具体是什么，得靠自己去探索。别人的回答，在某种程度上也只是想要得到内心的肯定罢了。\n既然知道自己想要的未来是光明的，一路走到黑，又何妨？？\n2、音乐复盘 音乐真的世界上最好的治愈。当无处发泄的时候，音乐便是最好的良药。\n《平凡之路》，是属于三月份的。大学三年下来，熬过了很多黑夜，经历了许多风风雨雨，自己的能力慢慢得到肯定之后，在工作和提升自己之间，经过内心的挣扎之后，还是选择了考研。似乎就好像，冥冥中这是我唯一要走的路。也就这样踏上了一条平凡的勇者之路。\n《一群无知少年的梦想》，四月份有幸在 2050 遇见了许多有梦想有朝气的年青人。带着自己的理想，有梦就去追。梦想在哪里呀？\n《稻香》，五月份的那一天会觉得吃的米也是不容易的。周杰伦的歌可谓是从小听到大的，每当听起这首歌的时候总有一种回到小时候的感觉。但是童年的纸飞机，再也不回来了，农村的稻草人也越来越少了。小时候的梦，早就记不清是什么了。回家吧，回到最初的美好。\n《拼个世界给自己》，六月份的新歌。大一的时候，听见僵尸的《网易云》，似乎找到了共鸣，慢慢他越来越火了，但他的歌还是依旧。黑夜中，看星空，飘着一个个的梦。在最无助的时候，能遇到一首走进内心的歌，是一次不可多得的机会。我都懂，我都懂，我都懂……\n二、半学期复盘 ①数学 因为数二考得内容比较少，对于数学整体的把握要好得多，学习的知识点也要少一点，从而学习量也就好一点。因为高数开始的比较早，在三月份结束的时候，就差不多结束了，四五月份查缺补漏以及刷题，基础上几乎没有大的盲点。五月份的同时把线代也过了一遍。\n五月中下旬开始高数部分的强化，不得不说，武神是真的强。本以为自己对于高数的知识点已经掌握的炉火陈青，但是听过武神的强化之后，对于考试的整体更通透了。到六月结束，本预计能强化到定积分结束，可是事与愿违，定积分只是开了个头，（如果最后十天能够稳下心来，好好学，估计是能达到预期的）。\n由于基础部分开始的早，结束的早，问题也就来了，像多元函数微分学、二重积分之类的就有些遗忘。本来还打算六月份抽时间再过一遍的，结果也耽误了。愁呀！！\n线代，在五月份整体过完一遍之后，六月份对照着笔记把《线性代数辅导讲义》的内容过了一遍。满分是 10 分的话，刷《线代讲义》的时候给自己打 7 分吧，确实有很多地方缺点思路。而且有些知识点掌握的不牢固。\n暑期目标：\n跟完强化课程 认真对待《讲义》以及《严选题》 完成以上两点，继续把《880》给整完 ②英语 英语基础部分的长难句和单词，怎么说呢，就属于边看题边巩固的过程，二者之间相互反馈。\n在过完 05 —— 15 年的真题之后，没有着急往下做。先是复盘了一遍，然后闲着无聊把唐迟的《阅读的逻辑》书和课程过了一遍。听课听起来挺舒服的，感觉做英语真题好像也就是那么一回事。但当自己实践的过程中，和方法论存在着不小的差距。\n最后一段时间，因为闲着无聊，把唐叔的《美国历史文化》给看了，下饭必备！！\n暑期目标：\n回顾阅读方法论以及长难句分析 重做考研真题 背单词是每天必备的 ③专业课 如果说数学和英语有点迷惑，但好歹知道迷惑的点，至于专业课，有点找不着北的感觉，没有真题，考纲也只是罗列出一些简单的标题，虽然问了学长学姐，但心里还是有点不太踏实。\n而且之前看书的时候，大部分都只是在书上勾勾画画，没有做太多笔记，（还是因为找不到重点）。数据结构王道的课后习题过了百分之八十，总体难度是可以接手的。数据库，就很迷，感觉比数据结构要更细一点，从而就导致边边角角都要复习到位。\n暑期目标：\n再过一遍专业课课本（做思维导图） 对于掌握不透的知识点单独拎出来 刷题？？ ④政治 呃，犹豫了很久，本来打算八月份开始的，但是由于学校不给留校，而我又懒得带那么多书，在纠结之后，九月份开始吧，希望还来得及。\n三、关于感谢 这半年来，首先感谢我自己选择了这条路。人这一辈子，总要努力一次到两次，那一次是什么时候，我不知道，但是考研肯定算一次。不管能不能上岸，路途中的额外收获都是自己不可多得的一次经历。每当晚上从图书馆回寝室的路上，看着天上的星星，就会想自己也再一次成为了披星戴月的人。有时候反复问自己，我会不会坚持，我会不会坚持，我会不会坚持。会！！！\n这个月来，我慢慢（暂时）退出了开源社，也很感谢伙伴们的理解，因为我自己是个完美主义，每件事必须全部到位，这样就会很多事挂在心上，没办法全身心的投入学习。想了很久，最终还是决定暂时退出一段时间。很感谢居居，当时找到她的时候，对她说了，直接回复 OK，来接我这个烂摊子，说起来确实有点惭愧。各位小朋友，等我回来。\n再有就是，给予我帮助的各位学长学姐们，可能一次又一次的打扰到你们，问一些确实很无聊的问题，真的很感谢你们能抽出时间为我解答疑惑，也就不至于让我无从下手。也是你们，看见你们上岸之后，或者读研的经历，让我有了走下去的动力，我也想一年之后和你们一样！\n还有就是我的爸爸妈妈。像我爸妈虽然学历不太高，但却一直鼓励姐姐和我能够多学点知识，多读点书，以后不至于因为自己的知识面匮乏而感到不足。像我们老家周围的同龄人，几乎早早的都辍学打工，很多家里人都认为挣钱比学习重要，在这么个氛围中，也很感谢老王和老袁支持我继续读书。在学习方面，他俩就没说过一次“不”字，哈哈哈哈。。对了，还有大园，也在一直鼓励着我。\n最后，对坚持下来的自己说一声不容易。感谢去年怀着一腔热血想抗击疫情，为社会做点事的自己；感谢那个遇见开源，并勇于探索的自己；感谢那个因为疫情耽误，在家自己啃 JDK 源码的自己，感谢一直坚持下来的我。\n有时候，很多情况下，不经意做出的决定往往会带来意想不到的结果。也许这就是生活吧。加油啊，冲吧大政！\n怀感恩之心，行正义之事\n","description":"","tags":null,"title":"大政的考研 Blog004 —— 拼个世界给自己","uri":"/life/kaoyan004/"},{"categories":null,"content":"Blog003 —— 五月天，五月复盘 一、逆水行舟 1.1 疲倦期 好快啊！三个月过去了。五月份，没有三月时的不知所措，四月时的激情也慢慢消散，剩下的更多的是不知为啥的坚持。。。\n起初一直感觉自己的进度都是有条不紊的走在前面，整个复习进度也就比较佛系，在闲暇时间还去学学玩玩新的技术，因为比起正儿八经的学习，我更喜欢“瞎倒腾”着玩儿。但是慢慢一个月又一个月的时间过去了，紧迫感也就随之而来。如果说之前的一段时间是兴奋期的话，现在应该可以定义为疲倦期。整个人就有点学不下的感觉，但也不是学不下，而是不知道下一步该学些什么。\n把所有的课（包含专业课，除去政治）基础知识都过了一遍之后，忽然感觉就不想看书了，这种感觉很难受，忽然间就失去了目标。。。到现在写这篇博客的时候，整个人都是佛的。这样一折腾，和之前相比，每天的任务量也减轻了很多。停止是不可能停止的，现在每天能做到的也只能是在保持一定的题目量的过程中，查缺补漏吧。我怕自己一旦决定休息一天，就会在第二天想着：昨天没看书，今天天气那么热，明天再好好看书。说白了，给自己找退路有各种各样的借口，但是走下去的理由也只有那一个！！！\n我很讨厌去逼着自己做一些不情愿的事情，在自己有了一定的选择能力之后，能够去选择做某一件事的时候，都会给自己找到合适的理由，但我没想到的是这条路，这么难熬啊！！！就算不情愿也得走啊，因为还有许多事情没有做没有能力去实现呢。我也一定能够成为我想成为的那个人。一定！！！\n1.2 悟学习 在备考过程中，不仅仅是学习或者说是巩固知识的过程，让我获得比较多的应该是多给自己留几个问号？ 学这个有什么用？为什么要学这个知识？？这个点和之前学的或者之后要学的有什么关联？这种思考方式放在其它学科能用么？？为什么要……？？为什么……？为什……？？？\n这大概我这三个月来，在脑子里反复的最多的几句话。我们学习往往的不是一个一个零碎的知识点，而是一个整体，一个生态。就好比：在学高数的时候，牵涉到微分中值定理的证明题时，往往需要构造函数，这个时候除了用一些常见的套路之外，还可用后面章节的微分方程来构造；原函数、导数和积分之间的关系又可以建立起彼此之间的联系。还有在数据结构中会有求时间复杂度，就又可以和求极限作类比。所以从我自身学习的角度来看待备考过程的话：与其说是为了考试而去学知识，倒不如说是为了教会我们学习而学习。\n忽然想到，还没几天就要高考了，三年，多美的一个字眼，而三年前现在的我，或许还在犹豫，在焦虑。中学时候，各科老师都喜欢按照他们自己的经验来做题，从而稀里糊涂的就给出一套方法来，用心听课、认真学习的同学再课后刷题就能取得高分。但是很遗憾我不属于这类的人。但我也不会为此而感到惋惜，也正是因为这样，才有了现在的我。有些时候，一个人的状态或者说是机遇，很可能是 求而不得，往往不求而得。\n在这段学习过程中，比较让我头疼的应该就是线性代数。就是比较玄乎。第一次听永乐爷爷的课时，一个头有三个头大；咬着牙一遍过下来，对于里面很多的知识点有了大致的印象，具体要是让我像高数那样说出个一二三来，是做不到的。。拿到题目也能摸索着做出来，就是为什么这么做，还是不太懂，只能说我知道这样做就是对的。。。。呃，就是差了点火候，对于学习来说还点再悟，给我的整体感觉就是隔层纱，没有戳破。\n二、五月复盘 五月天气逐渐热了起来，晚上可以听见青蛙叫，天上的星星也更亮了些。\n①数学 都说偶数年数学难，而高数更是难中之最？？所以在四月的基础上，进一步查缺补漏，把之前写得笔记、做的题目又拉出来过了一遍，对于各个章节的知识点，做到纲举目张，从而再统一串起来。\n到此，自我感觉良好，于是去做《李林880》，基础篇还是能手撕的，当做的综合篇的时候，直呼好家伙，题目有点意思哈，再啃啃，我自闭了了了。。。对不起，是我不配了，我迷了，不应该，我咋那么菜呢？？？我高数复习了个 der啊？？带着这种心情，我又低下头去刷《1800》了，也意识到是时候进入强化阶段了。\n然后就线代，由于四月份就已经前四章过了一遍，但是总体感觉是模模糊糊的，就又重新过了一遍，学习还得要做到温故知新的嘛！带着疑惑去学习，确实要比一开始好好得多，但是在完整学完之后，就像前面所提到的，还是很迷的。。\n我也说不清为啥，题目会做，很多定理却不知所云。如果再让我安排一次的话，我会选择把线代的复习进度再往后放一放，不开始那么早，直接就基础过完开始强化。可能吧。\n在复习线代的时候，对于高数花的时间自然而然就少了，从而就导致一些题目做起来有些生疏。\n②英语 单词！！！单词！！！单词！！！\n由于使用的是墨墨背单词，每天 220+，看了下每天背单词的总时长大概在 100 分钟左右。再加上中间有可能做点其它的时间，综合下来，每天背单词大约需要两个小时左右的时间。感觉有点多了吧！！！但好在这些时间没有白费，其最之间的体现就是在做真题上。\n阅读进度：每天一篇阅读：看题干、做题目、翻译、再看题目、对答案，最后找原因。一天的时间在一个小时十分钟到一个半小时之间，这个还是可以接受的。做完一张试卷之后，复盘，做总结下一张。然后就刷到了 2013 年了。在做阅读的时候，就好像把自己又带回了之前的那个年代，也算是一种额外的收获吧。\n每天干饭的时候，看了唐叔的《美国背景文化》，确实挺下饭的，哈哈哈哈！\n③专业课 上个月立的 flag，也算做到了，最起码勾勾画画把书本过了一遍。但是吧，在看完之后，我就感觉看得有点太早了，以后肯定会忘。。。。。。（不愧是我，23333）\n再来吐槽一下数据结构，问了下师哥师姐大部分都在夸王道的书好，好吗？？好？？吗？？？或许从应付考试来说还不错，但是从剖析数据结构来说，无论是知识点的讲解，还是给的代码，从我来看都是不合格的。就是有点浅显，在看王道的书的时候，我还把之前《大话数据结构》和《算法4》，无论是从通俗易懂还是硬核知识来说，都被吊打，而且吧，课后习题给的方法，先抛出代码质量来说，有时候边界值都没考虑到。。。。 吐槽结束。\n数据库，根据考纲把知识点过了一遍，也列了个思维导图。在看关系演算的时候，我又迷了。。。其余的还行，整体上保持在预期之内。后期还得花时间啊！！！\n三、低欲望 其实说实在的，最近才发现自己是属于低欲望却有着野心的那类人。这就导致很多人，拼命去奋斗、去争取的东西，比如成绩排名、个人荣誉、证书啊之类的，我往往都是不屑一顾的。就是感觉很没必要这样做的吧，或者说是很搞笑。就这样，慢慢的，慢慢的，逐渐对周围很多的事情失去了兴趣，生活也就过得越来越简单。也可能是因为我比较懒吧，懒到所有的事情，在无关紧要的情况下，能离远一点就远一点。就像前面所说的，我找不到去做这类事情的理由，对我来说就是在浪费时间。\n再接着就是有时候甚至会对生活失去兴趣，读书学习到底是为了什么呢？？追求学历文凭，只是为了找一份工作，然后结婚生子、养家糊口？？？我对我现在所坚持的事情产生了怀疑，就好比感觉自己所做的努力只是为了像一个普通人一样，仅仅是为了活着而已！！也许读书也就是为了让我们能够变成一个普通人，但是我总感觉，作为当代青年，一个知识分子，能够做的事情有很多，人应该是有理想。自幼读书开始，就想着上了大学就自由了，但后面的挑战也是接踵而至，反观现在无聊的时候，玩玩悠悠球，睡前听歌也只是消磨时光，每天过得生活就像是一个带着情感的机器人。有的时候想要逃离又不敢逃，怕一退缩，迎面而来的是各种咒骂与唾弃。\n人活着的意义是什么呢？？在大部分情况下，我们的明天和今天并没有什么太大的区别。活在当下，也许是最优解。但那是饿了找东西吃，困了就睡的的动物才会做的事情，人之所以为人，那是因为人会幻想未来。那么我想追求的是什么呢？？我的野心又想体现在哪呢？？技术与文明 ，这或许也是我喜欢开源文化、黑客文化的原因之一，只有看过更广阔的对的世界，接触到更前沿的技术，才会感叹自己的渺小与无知，才会明白自己还有很长的路要走，还有梦和理想值得自己为之去努力，去流汗，去坚持，并心甘情愿的为之而受尽煎熬！！！\n最后想用当时曾国藩的一句话送给走在路上的朋友们：千秋邈矣独留我，百战归来再读书 ！！！\n加油！！！\n","description":"","tags":null,"title":"大政的考研 Blog003 —— 五月天","uri":"/life/kaoyan003/"},{"categories":null,"content":"Blog002 —— 阳光正好，四月复盘 一、要命！！！ 经过三月份的折磨，似乎更能明白与花时间熬学习相比，调整好自己，适当的减压，注重学习效率是更重要的。于是我就做减法，做到了什么程度呢？？貌似减得有点多，就导致有点飘，完全有点静不下心来，踏踏实实地学习！！！\n要命！！！\n其实说实话，如果这个月抛去学习不谈，过得还是挺开心的。就先简单聊点这个月我到底干了啥吧。\n1.1 浪潮之巅 看完了吴军博士写得《浪潮之巅》，（都说考研期间不要看课外书，但是考研的课本真的太无聊了了了了。。。。）之前或许是自己，或许是周围的同学总能听到些抱怨：我们出生晚了，最好的时代已经离我们而去了 。但是在看《浪潮之巅》的时候，给我更多的感受是我们现在的时代正是处于互联网的“浪潮之巅”，云原生、5G 时代的到来，将会对于过去的网络再次产生翻天覆地的改变。当下的我们要做的是不怨天尤人，而是把握自己，逆风奔跑，向阳而生！\n生在这个时代最大的幸运就是可以看到商业和科学技术完美结合不断的改变这个世界的面貌，不断的改变我们的生活方式。 吴军博士不断的说能赶上科技发展的浪潮便不枉此生。因此生活在这个时代的我们是幸运的，因为年青，就有资本去学习自己想学的，去追求自己所想追求的。\n1.2 参与 DolphinScheduler 在三月的复盘中有提到，开始转型学习大数据，于是在一次偶然的机会接触到 DS 这个项目。有人说：万物始于 Hello World，但对于我来说参与开源的第一步应该是从 Markdown 开始。首先文档类的任务，与代码层面相比要简单的多，不至于像代码那样牵一发而动全身，而且提交 PR 之后，通过检测的机会也要大的多，可以说门槛是要小一点的。于是参与 DS 的第一份 PR 就是写文档，哈哈哈哈。当自己的 PR 被 merge 的时候，那份满足感是任何事情都替代不了的，特别还是参与 Apache 的顶级项目。\n感受到社区的友好之后，按照我的习惯肯定要撸源码玩玩，徒手撕源码才是真男人嘛！在阅读源码的时候，看看测试案例对于理解和使用来说都是不可缺少的。当时看见了有些类的测试案例还没写，就尝试自己写了一份，结果是显而易见的，PR 没通过检测，然后就导致周末去杭州得背电脑了。。。。。起初最初的问题是代码规范，这个还是比较好改的（与后面遇见的问题相比确实啥都不算），但问题是解决了一个问题，随之而来的是下一个问题，虽然社区的导师给予帮助，但还是很头大。在遇见问题的过程中，最重要的是学会自己动手去解决问题，这个时候就要吹爆 StackOverflow ，以及慢慢体验到 issue 和邮件列表的好处，因为可以从之前的记录中找到类似的问题，解决起来就要好得多。最后看见 LGTM 的时候，感觉一切都值了，所以说还是热爱开源的，还是想写代码的。\n1.3 2050 如果你问我年青人做什么最酷？？ 那一定是参与 2050 大会（也就是因为这个，决定去参加的时候，每天肾上腺激素分泌过多，肯定静不下心学习）。三天下来，有遗憾，有欢笑，也有收获。\n周五到杭州的时候，因为有点晚，遗憾的是错过了“开源人团聚”，但是从博悟馆出来的时候，看见了王坚博士，这何尝不是一种收获呢。这也是我的一种态度：求而不得，往往不求而得。起初见到博士的时候，是先听见他的声音（之前了解到2050是王坚博士以个人名义发起的时候，就临时补课看了很多博士的视频~~），这声音好熟悉，抬头一看，我天呐！！！那穿格子衫的可不就是博士嘛！！！这也是我第一次在现实生活中，见到互联网中大神级别的人物。但说到底，还是有点亏的吧。。。。\n第二天，比较开心的应该是遇见了道哥——吴翰清！！！对，没错，就是段子中传说黑进阿里的大神。只不过感觉有点可惜的是道哥再回到阿里之后，不再做开发，而是产品经理。在听完分享之后，不得不承认，到阅历或者说是知识体系到达一定高度之后，看世界的角度真的会发生改变。我们还在为了生活而感到焦虑的时候，有的人都已经在尝试模拟甚至创造生活。然后还有比较开心的就是看见了赵生宇学长，上次见面还是 2020 开源年会，一别就是几个月。当和学长谈到开源的时候，眼里是有光的。能够更深入的探讨一些问题，也是弥补了昨天的遗憾吧。\n五点半的闹钟，早起，六公里的约定 —— 逐日晨跑。还有什么比这更酷的事情吗？？ 虽然说一开始参与晨跑是为了获得 T 恤，但当一路坚持下来的时候，再想想还有什么是自己不敢挑战的呢？路途中，拿起奠基石，为 2050 添砖加瓦；还看见了一路一直坚持下来的小朋友，他们都未停止脚步，二十出头的我们，不更应该起到带头作用嚒。当回到终点，收到奖牌的时候，感觉这一切都足了！\n快乐的时光总是短暂的，奋斗的路还很长，杭州这座城市去的次数，虽然不是很多，但却是去一次爱一次。（回到合肥之后的感觉，就好比用惯了 IDEA 回到了 Eclipse。。。。）\n四月复盘 说真的，四月给我的感受就好像是什么都没做。。。。\n①数学 四月初，把三月份高数的盲点又花了一周左右的时间整理了一下。这应该可说是零死角了吧。哈哈哈。原本准备这个月把线性代数看完，但是实现往往是高估了我自己的能力和自觉性。\n线代怎么说呢，给我的感觉不像是高数那样，学完一个章节，就能做对应的题目，它更多是对于整个知识体系的融会贯通。再加上李永乐爷爷年级大了，听起来确实不太清楚，还不知汤汤的南京话有个性呢。。。。然后就磕磕巴巴把线代的前四章啃完了。\n高数方面开始二刷 1800，不得不说确实有必要二刷，第一遍做的时候，可能更偏向于基础知识的应用。到了二刷，在之前的基础上再加上一定的技巧，不管是做题速度、正确率方面，还是对于题目对的理解方面，都有了质的飞越。再想起之前还在为选哪本习题册而感到困惑的时候，现在感觉更多的是市场上主流的习题册都各有优缺点，认真啃透一本，再加以补充，我相信问题应该不大。\n②英语 英语重要的就是单词不能停！！说实话，背单词是真的那个痛苦啊，苦不堪言中，还有无聊。。。但哪又能咋办，硬着头皮走下去。长难句方面，看了唐叔的（主要是因为时间较短，一开始是当段子看的）发现，按他那么来玩确实有点意思，就认真又听了一遍，结合真题来，走向正轨。\n搜英语的经验贴，都说上真题，于是这个月把从 2005~2009 所有真题中的阅读精翻了一遍，做前两套试卷的时候，还有比较痛苦的，积累的越多，就稍微好点，每做完一套就复盘一套，会发现从一开始满是红笔的标注慢慢过渡到只标注难点的句子和不认识的单词，红色越少，进步越多，哈哈哈！五月再接再厉！！！\n③专业课 emmmmmmm。。。。从五月开始一定好好准备专业课。我感觉我把准备专业的时间，都用来学习新的知识去了，惭愧！！！\n数据结构，我感觉考得也不是很难嘛、、、、\n三、谈谈愧疚感 人在不努力或者说觉得自己还不够努力的时候，总会感觉到自己有点愧疚感，甚至是罪恶感。这到底是为什么呢？？每天为了努力而去努力，不是我想要的，也不是我所追求的。带着这样的情绪强迫自己去学习、去工作，是比较难受的。\n明知道这种状态不对、这种状态不好，为何不能及时调整自己呢？？可能是因为贪心太大，我们追求的有太多太多了，这个世界也是太丰富多彩了，以至于给人一种错觉，我不努力，就没资格去享受这个世界所给的一切，于是就陷入了这种状态。\n接受自己的不足，接受自己的不完美。对的，在继续往下走之前，应该先想想自己的能力，所处的环境以及自身的状态等客观因素，因为这些种种都是会影响一个人的主观感受。在图书馆中经常能看见有些同学早上七点之前就在图书馆背单词，晚上也一直到十点多。从我的角度来说，我这种状态我做不到，就算做到了也坚持不了多久，甚至可能会把自己的身体搞垮。\n记得之前问过自己一个问题：是逼自己一把，还是放自己一马？ 一开始想的是逼自己一把，因为一直在给自己找更高的任务，说白了就是和自己杠到底。但更多的时候却发现，具体在执行的时候反而变得更佛，更像是在逼自己一把的同时，在有限的空间给自己偷个懒。\n有的时候接受自己的不足，往往不是为了向生活妥协，反而是为了跑得更远，跳得更高！！就像开头所说的这个月如果不谈学习，我们还是好朋友。\n","description":"","tags":null,"title":"大政的考研 Blog002 —— 阳光正好","uri":"/life/kaoyan002/"},{"categories":null,"content":"Blog001——在路上,三月复盘 一、浮躁 我们生活在一个贩卖焦虑的时代，“小镇做题家”、“读书无用论”、“内卷”等等言论充斥这我们的生活。而这个社会中也往往有些人喜欢制造焦虑，什么你已经被你的同龄人所抛弃，你已经被你所处的社会所抛弃等等。我们时常会感叹道：我才二十刚出头，为何活着的这么累啊！！\n是啊，我们为何会这样想呢？？遵循自己的内心，按照自己喜欢的方式走下去不好嘛？？但是真的好难，在这个信息爆炸的时代，几乎无一人能幸免，一方面在享受科技带给我们的便利，另一方面却又被信息所左右，这个时代的我们太浮躁，心也很难静下来，也就很难能坐得住冷板凳，一天能做到、两天能做到那不叫坚持，真正的坚持往往是带着一种煎熬！！\n考研路上，怎一个“卷”字了得！！看看 2021 的考研成绩，出现四百分似乎一点都不觉得稀奇，往年比较好考的院校，也都成了热门，计算机专业更是把内卷体现到了极致。考研就是一座黑暗森林，每个考研人都是带枪的猎人，像幽灵般潜行于林间，轻轻拨开挡路的树枝，竭力不让脚步发出一点儿声音，连呼吸都必须小心翼翼：他必须小心，因为林中到处都有与他一样潜行的考研人，如果他发现了别的考研人，能做的只有一件事：开枪消灭之。在这片森林中，他人就是地狱，就是永恒的威胁，任何暴露自己目前选择的稍微好考的院校都将很快被无数考研人群起冲之，这就是考研的常态？？\n二、心情状态 三月份回到学校，考研的路途也算是真正的拉开序幕，一开始的时候，充满干劲，却也一脸茫然，找不到方向，不知该如何是好。然后慢慢的找到适合自己的方法，说实话还是挺享受这种过程的，苦吗累吗？？有点吧，但是真的很舒服，每天的付出的都能看得见，能得到正向的反馈就很舒服。而且每天晚上带着一点点疲倦感回到宿舍之后，简单洗漱之后，还有点自己的时间，写写代码，看看杂书，练练球，这也是我当时所理想的状态，我原以为能一直这样下去，结果人绷紧了，还是会出问题的\n在这个月快结束的时候，突然间，整个人不知怎么的就不好了。。。。可能是累了，也可能是倦了。当时几乎是把高数基础又重新过了一遍，汤汤 1800 的基础部分 也做了百分之八十左右，专业课的书本也过了一遍，然后突然间就失去了目标，书不想看，题也只能是机械式的刷，当感觉到的时候，也就意识到自己的状态需要调整。这也是第一次出现心情上的波动，因为离目标太远，不知道到底能否做得到！！怕付出到最后不是自己想要的结果！！！\n忽然想起了高三激励自己的一句话：我不去想能否成功，既然选择了远方便只能风雨兼程！ 现在回过头来看，不免是有点中二的，但也就是这股劲，push 着一步一步走啊，走啊。那到底什么是成功呢？？考上大学算是成功吧，也许在当时看来是的，从宏观角度上看，我们往往把成功定义的太狭隘、太片面。所谓的成功，也许是就是一道坎，跨过去一个，下一个更高。简单来说，慢慢走吧，也许漫无目的，也许有目标，但是请别停下！！\n三、三月份学习复盘 ①数学 因为之前数学书本已经过了一遍，在看了一些经验贴之后，意识到基础的重要性，所以又花了半个月的时间，结合汤汤的复习全书、基础三十讲以及课本，整理了一份高数基础笔记，把其中的定理能证的都证明了一遍，一些经典例题也都有添加，当看见打印出来的时候，心里还是有点小激动的，哈哈哈。\n因为之前《基础 30 讲》降价，就入手了一本，总结完基础之后，就开始配合宇哥的课程，开始刷 1800。从我的个人角度来说，宇哥的课如果基础不牢固的话，听起来真的有点飘，全程很难 get 到他想表达的点，而且笔记还不太好记。如果基础还行，跟下来，做题技巧确实能学到不少，然后就去 1800 虐菜。再简单说说 1800，题量是真的大！！！ 虽然题目不是很难，还记得当时第一次翻开习题册，第一面极限，磕磕巴巴只能做五六题，从课本过渡到考研的基础阶段，还是要磨的，还好过渡的比较平滑，到现在二刷前面的基础题，极限也几乎可以做到口算，提高篇的内容暂且不谈，因为还没做。\n如果说高数部分哪里还有盲点的话，大概是 多元微分学 以及 常微分方程部分，因为是最后复习的部分，花的时间没有前几章那么多，所以还得抽时间再看看，知识体系不能出现漏洞嘛。\n②英语 英语咋说呢，有一种不太踏实的感觉，起初可能我高估英语的难度了，觉得考研真题就一定很难，不看语法长难句就一定读不懂文章，带着这种想法，看了刘晓燕的长难句课程，再看真题的感受，大概是我好像不看长难句的课程也能把文章的大意读懂，翻译句子我还是喜欢按照自己的语感来，也不怎么分析句子成分，做题效果比自己当时想的要好。但是吧，我不能说长难句的课程就没必要看，因为自己是看了之后才做题目的，虽然这课程真的有点鸡肋的感觉，不看总觉得少了点什么，不太放心，看的话又有点浪费时间。。。。\n单词方面，尝试了一下“作死”的行为，可能是有点急功近利，就开始肝《十天搞定考研词汇》，到了第五天第六天的时候，整个人都快被单词折磨疯了，哦对，这或许也是我考研状态出现波动的原因吧。真的很折磨人，仅仅是背单词几乎占用了一天大部分时间，感觉有点不值得吧。。。。还好肝完了，单词不能说全到熟稔于心吧，但是看真题是够的了。所以我感觉单词还是很重要的吧。\n真题的话，目前只做了阅读部分，进度为 一天一篇：做题、翻译、分析题目。不知是我飘了，还是做的题目有点老（从 05 年开始做的），感觉考研阅读的难度似乎和六级差不多？？？？在有了上面的基础，大约是从 18 号开始正式做真题的，比预期要好！\n③专业课 如果有最不受程序员欢迎的编程语言排行榜的话，我一定给 C\\C++ 投上一票，甚至在开始学 C++ 的时候，我就在想为啥考研还指定编程语言啊，23333~ 大一初学编程的时候，就是因为 C语言 给我一种我不配写代码的感觉，玄学指针！！！当时被支配的恐惧，现在也是时候和它正面刚了，再逃下去就真的没路咯。。。\n数据结构方面，不算太难吧？？ （人言否。。）也可能是之前看过 JDK 源码以及经常刷题的缘故吧，只不过是换了一种语言实现罢了。所以上手还是比较快的。当让静下心来学 C++ 的时候，还是有点收获的，也让我感觉到为何 C++ 更适合刷题。\n但是中国的应试给我的感觉就是，一样东西变成了考试的内容，与实际使用来说，就变味了。。。。\n四、谈谈备考的生活 整体的感觉是疲惫且充实，启动备考的一个月也在忙碌中结束了。在这期间，对于编程方面做出了一个决定，从后端跨到大数据，目前抽空学完了 Hadoop。问我原因的话，大概是寒假的时候玩了玩 Flink，真的太有意思了，并且看了一些前沿的技术框架，想想还是转吧，哈哈。\n因为当时心情的波动，有想过好久没买悠悠球了，逛了一圈闲鱼，没有太想收的，就把准备买球的钱，买书了，现在我想说，亲 咱能退款不？？。。。。。 有一点点后悔吧。但是多看点书还是好的。\n开源组织这边，也转移到了以开源社为主，毕竟当了组长，还是要干活的呀，带头作用要有。也从一开始几乎把任务都揽到一个人头人，到慢慢学会分配出去，再到招募新的小朋友加入进来，再想想去年自己似乎也是在这个时候接触到开源的吧，真好！\n有人说，你不是准备考研吗，怎么天天还做这些，不怕耽误你自己么？？ ，先说句谢谢您哈！可是我想说，如果把这十个月左右的时间全部用在考研上，就算到时候上岸了，我会开心吗，也许吧。但我更想在这有限的时间里做点自己喜欢的事情，不做一个只读“死书”的考研狗。\n五、写在之后 之前一直在想，要不要把自己的考研历程给录下来，但是又嫌后期处理麻烦，索性就用博客来记录吧。而且在写之前，还在想，如果到时候没有上岸，是不是太丢人了吧，是啊，那可真拉胯，但我还是想把这一段时间用文字给记录下啦。\n考研的基础阶段，就好比是编程语言的基本语法，算作基本功；一些常用的结论、定理 有点想数据结构和设计模式，可以定义为内功了吧；再看看做题技巧，对应的是常用的框架？？也就是某种定义上的武功秘籍了吧，哈哈。所以说学习是有相通性的，作为一名学生，不能为了学习而学习，而是要学会学习而学习。\n与学习编程相比，考研学的内容可能真的不算太多，但是考研是有一个时间界限的，比的是在规定时间内，谁玩得好。这就很烦。在准备考研之前，我还在问我自己，到底为什么要考研，现在的答案是 我有我所想追求的，现在的身份、圈子，无法得到我想要的状态 ，所以要走下去！\n最后，从我个人的角度来说，还是想读书的，但我并不喜欢学校要求实践、学分、发论文的这种教育，我还没到 21 岁，我还有时间按照我所想的去“浪费”！\n","description":"","tags":null,"title":"大政的考研 Blog001 —— 在路上","uri":"/life/kaoyan001/"},{"categories":null,"content":" 如果可以的话，我想看看明年这个时候的自己是什么状态，或者 回到三年前，对那个时候的自己说一声：其实也没啥大不了，你一定可以成为你想成为的那个人。\n疫情还没结束，但 2020 就要过去了，似乎这一年过得有点无语、有点匪夷所思，一种说不清道不明的感觉。记得小学的时候，老师让写作文，关于未来，就想着 2020 年的生活怎么样，记得当时有一点是：可以在家上学，没想到的是，我们在这样一种环境实现了在家上学。\n今年过的好嘛？？还行吧，虽然和自己想的完全是两个样子，但是做了一些值得去做的事，认识了一些有趣的人，这就够了。\n如果说 2019 年是我沉淀的一年，那么我想用厚积薄发来形容今年的自己。19 年八月底，发了一个朋友圈。给我三年，\n现在回过头来想想，不免觉得有点中二，哈哈哈哈。但也正是这股中二的动力，一直 push 着我向前走。但其实事实是：说这句话，当时所想的奋斗目标，和自己的现在的样子完全是两个样子。 当时的目标，无外乎就是学习啊、证书啊、名次啊…… 这些世俗的东西，但同样是避免不了的。如果不世俗，又怎么能真正做到不世俗呢？？幸好，在寻找的过程中，找到了目前的自己想做的事情，也是我想真正坚持下去的事情。\n絮絮叨叨说了一堆没啥用的，而且还是关于 2019 的事情，其实关于今年，没啥好说的。就像是一场梦，还没醒来，就结束了。那就说说，今年对我影响比较大的三本书吧。\n《百年独孤》看完这本书是四月份。可能也是和当时自己的处境有关，感觉自己一个人总是孤立的、没人懂我。这本书也是我硬着头皮看完的，里面的人名可以说直接就劝退。为什么这本书对我的影响比较大呢？？当一个人能感受到孤独的时候，才能做到静下心来。就像马尔克斯在书中所写的一样：所有人都显得很寂寞，用自己的方式想尽办法排遣寂寞，事实上仍是延续自己的寂寞。寂寞是造化对群居者的诅咒，孤独才是寂寞的唯一出口。 刚好那个时候，对于Java特别感兴趣，也就是在这种孤独感的环境下，能够让我有足够的耐心去读 JDK 和 JVM 源码，从而可以有效的提高自己的编程水平和技巧，随着越深入的了解和学习，也就对写代码越来越着迷。（其实源码并未完全读完，着迷之后，就在各地找项目练手，刚好那个时候接触到开源，也就有了读一些顶级项目源码的机会，增加查克拉，哈哈哈哈）\n第二本书，我想说的是《人间简史：从动物到上帝》，这本书在书架上已经有一年多了，但是因为标题写得太大，我一向不是不喜欢读这类书籍的，总感觉有点空洞。当时看了一段作者 尤瓦尔·赫拉利的一期关于如何看待疫情的视频，便开始下手准备读下去。这本书，可谓不读不知道，从一个绝对想不到的宏观角度来阐述人类的发展。也正是受到这种宏观角度的影响，从而培养出了我一个良好的思考问题的习惯，可以出圈的来想问题，也就这样，使得我的思维能够超脱出现在的处境，能够找到自己，找到自己想要的时候，找到如何在自己有限的能力之下，做一些有意义的事情。\n最后我想说的是大刘的《三体》，这本书高中的时候就听说过，但一直拖到今年暑期才看完，《三体》除了是一部科幻作品之外，更重要的是关于人性的描绘，有人说，大刘在里面是不是过分的把人类描述的太丑陋了，但脱离人类的身份来思考这个问题，相信每个人都会得到一份属于自己的答案。也是这本书，让我找到活着的意义所在：人，在能够解决自身的基本需求之后，更重要的是要留下些东西。\n这些书都是上半年读的，至于下半年，读得更多的都是一些文言文，我绝对不会想到现在的自己，会“佛”到这种程度，哈哈哈哈哈。\n今年最大的收获就是接触到了开源，这是从我接触的悠悠球之后，重新找到能让我为之付出努力的事情，而且还和我的专业有关，如果说今年有啥值得吹得事情，那就是把自己的第一份 pr，提交给了 Apache 项目。\n最后，我想说，从做得到，到今天已经做到了。\n","description":"","tags":null,"title":"关于 2020_我想说","uri":"/life/about_2020/"},{"categories":null,"content":"第二章：面向对象 面向对象是学习编程过程中一个非常重要的思想，但是它却被很多人理解成了一个比较难，比较深奥的问题，其实不然。其实面向对象在理解之后还是很简单的，简而言之就是程序之中所有的操作都需要通过对象来完成。\n举例来说： 操作浏览器要使用window对象 操作网页要使用document对象 操作控制台要使用console对象 一切操作都要通过对象，也就是所谓的面向对象，那么对象到底是什么呢？这就要先说到程序是什么，计算机程序的本质就是对现实事物的抽象，抽象的反义词是具体，比如：照片是对一个具体的人的抽象，汽车模型是对具体汽车的抽象等等。程序也是对事物的抽象，在程序中我们可以表示一个人、一条狗、一把枪、一颗子弹等等所有的事物。一个事物到了程序中就变成了一个对象。\n在程序中所有的对象都被分成了两个部分数据和功能，以人为例，人的姓名、性别、年龄、身高、体重等属于数据，人可以说话、走路、吃饭、睡觉这些属于人的功能。数据在对象中被成为属性，而功能就被称为方法。所以简而言之，在程序中一切皆是对象。\n1、类（class） 要想面向对象，操作对象，首先便要拥有对象，那么下一个问题就是如何创建对象。要创建对象，必须要先定义类，所谓的类可以理解为对象的模型，程序中可以根据类创建指定类型的对象，举例来说：可以通过Person类来创建人的对象，通过Dog类创建狗的对象，通过Car类来创建汽车的对象，不同的类可以用来创建不同的对象。\n定义类：\n1 2 3 4 5 6 7 8 9 10 11 12 class 类名 { 属性名: 类型; constructor(参数: 类型){ this.属性名 = 参数; } 方法名(){ .... } } 示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 class Person{ name: string; age: number; constructor(name: string, age: number){ this.name = name; this.age = age; } sayHello(){ console.log(`大家好，我是${this.name}`); } } 使用类：\n1 2 const p = new Person('孙悟空', 18); p.sayHello(); 2、面向对象的特点 封装\n对象实质上就是属性和方法的容器，它的主要作用就是存储属性和方法，这就是所谓的封装\n默认情况下，对象的属性是可以任意的修改的，为了确保数据的安全性，在TS中可以对属性的权限进行设置\n只读属性（readonly）：\n如果在声明属性时添加一个readonly，则属性便成了只读属性无法修改 TS中属性具有三种修饰符：\npublic（默认值），可以在类、子类和对象中修改 protected ，可以在类、子类中修改 private ，可以在类中修改 示例：\npublic\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class Person{ public name: string; // 写或什么都不写都是public public age: number; constructor(name: string, age: number){ this.name = name; // 可以在类中修改 this.age = age; } sayHello(){ console.log(`大家好，我是${this.name}`); } } class Employee extends Person{ constructor(name: string, age: number){ super(name, age); this.name = name; //子类中可以修改 } } const p = new Person('孙悟空', 18); p.name = '猪八戒';// 可以通过对象修改 protected\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Person{ protected name: string; protected age: number; constructor(name: string, age: number){ this.name = name; // 可以修改 this.age = age; } sayHello(){ console.log(`大家好，我是${this.name}`); } } class Employee extends Person{ constructor(name: string, age: number){ super(name, age); this.name = name; //子类中可以修改 } } const p = new Person('孙悟空', 18); p.name = '猪八戒';// 不能修改 private\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Person{ private name: string; private age: number; constructor(name: string, age: number){ this.name = name; // 可以修改 this.age = age; } sayHello(){ console.log(`大家好，我是${this.name}`); } } class Employee extends Person{ constructor(name: string, age: number){ super(name, age); this.name = name; //子类中不能修改 } } const p = new Person('孙悟空', 18); p.name = '猪八戒';// 不能修改 属性存取器\n对于一些不希望被任意修改的属性，可以将其设置为private\n直接将其设置为private将导致无法再通过对象修改其中的属性\n我们可以在类中定义一组读取、设置属性的方法，这种对属性读取或设置的属性被称为属性的存取器\n读取属性的方法叫做setter方法，设置属性的方法叫做getter方法\n示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Person{ private _name: string; constructor(name: string){ this._name = name; } get name(){ return this._name; } set name(name: string){ this._name = name; } } const p1 = new Person('孙悟空'); console.log(p1.name); // 通过getter读取name属性 p1.name = '猪八戒'; // 通过setter修改name属性 静态属性\n静态属性（方法），也称为类属性。使用静态属性无需创建实例，通过类即可直接使用\n静态属性（方法）使用static开头\n示例：\n1 2 3 4 5 6 7 8 9 10 class Tools{ static PI = 3.1415926; static sum(num1: number, num2: number){ return num1 + num2 } } console.log(Tools.PI); console.log(Tools.sum(123, 456)); this\n在类中，使用this表示当前对象 继承\n继承时面向对象中的又一个特性\n通过继承可以将其他类中的属性和方法引入到当前类中\n示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Animal{ name: string; age: number; constructor(name: string, age: number){ this.name = name; this.age = age; } } class Dog extends Animal{ bark(){ console.log(`${this.name}在汪汪叫！`); } } const dog = new Dog('旺财', 4); dog.bark(); 通过继承可以在不修改类的情况下完成对类的扩展\n重写\n发生继承时，如果子类中的方法会替换掉父类中的同名方法，这就称为方法的重写\n示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 class Animal{ name: string; age: number; constructor(name: string, age: number){ this.name = name; this.age = age; } run(){ console.log(`父类中的run方法！`); } } class Dog extends Animal{ bark(){ console.log(`${this.name}在汪汪叫！`); } run(){ console.log(`子类中的run方法，会重写父类中的run方法！`); } } const dog = new Dog('旺财', 4); dog.bark(); 在子类中可以使用super来完成对父类的引用\n抽象类（abstract class）\n抽象类是专门用来被其他类所继承的类，它只能被其他类所继承不能用来创建实例\n1 2 3 4 5 6 7 8 9 10 11 12 abstract class Animal{ abstract run(): void; bark(){ console.log('动物在叫~'); } } class Dog extends Animals{ run(){ console.log('狗在跑~'); } } 使用abstract开头的方法叫做抽象方法，抽象方法没有方法体只能定义在抽象类中，继承抽象类时抽象方法必须要实现\n3、接口（Interface） 接口的作用类似于抽象类，不同点在于接口中的所有方法和属性都是没有实值的，换句话说接口中的所有方法都是抽象方法。接口主要负责定义一个类的结构，接口可以去限制一个对象的接口，对象只有包含接口中定义的所有属性和方法时才能匹配接口。同时，可以让一个类去实现接口，实现接口时类中要保护接口中的所有属性。\n示例（检查对象类型）：\n1 2 3 4 5 6 7 8 9 10 interface Person{ name: string; sayHello():void; } function fn(per: Person){ per.sayHello(); } fn({name:'孙悟空', sayHello() {console.log(`Hello, 我是 ${this.name}`)}}); 示例（实现）\n1 2 3 4 5 6 7 8 9 10 11 12 13 interface Person{ name: string; sayHello():void; } class Student implements Person{ constructor(public name: string) { } sayHello() { console.log('大家好，我是'+this.name); } } 4、泛型（Generic） 定义一个函数或类时，有些情况下无法确定其中要使用的具体类型（返回值、参数、属性的类型不能确定），此时泛型便能够发挥作用。\n举个例子：\n1 2 3 function test(arg: any): any{ return arg; } 上例中，test函数有一个参数类型不确定，但是能确定的时其返回值的类型和参数的类型是相同的，由于类型不确定所以参数和返回值均使用了any，但是很明显这样做是不合适的，首先使用any会关闭TS的类型检查，其次这样设置也不能体现出参数和返回值是相同的类型\n使用泛型：\n1 2 3 function test\u003cT\u003e(arg: T): T{ return arg; } 这里的\u003cT\u003e就是泛型，T是我们给这个类型起的名字（不一定非叫T），设置泛型后即可在函数中使用T来表示该类型。所以泛型其实很好理解，就表示某个类型。\n那么如何使用上边的函数呢？\n方式一（直接使用）：\n1 test(10) 使用时可以直接传递参数使用，类型会由TS自动推断出来，但有时编译器无法自动推断时还需要使用下面的方式\n方式二（指定类型）：\n1 test\u003cnumber\u003e(10) 也可以在函数后手动指定泛型\n可以同时指定多个泛型，泛型间使用逗号隔开：\n1 2 3 4 5 function test\u003cT, K\u003e(a: T, b: K): K{ return b; } test\u003cnumber, string\u003e(10, \"hello\"); 使用泛型时，完全可以将泛型当成是一个普通的类去使用\n类中同样可以使用泛型：\n1 2 3 4 5 6 7 class MyClass\u003cT\u003e{ prop: T; constructor(prop: T){ this.prop = prop; } } 除此之外，也可以对泛型的范围进行约束\n1 2 3 4 5 6 7 interface MyInter{ length: number; } function test\u003cT extends MyInter\u003e(arg: T): number{ return arg.length; } 使用T extends MyInter表示泛型T必须是MyInter的子类，不一定非要使用接口类和抽象类同样适用。\n","description":"","tags":null,"title":"TypeScript学习笔记02","uri":"/tech/typescript02/"},{"categories":null,"content":"第一章 快速入门 0、TypeScript简介 TypeScript是JavaScript的超集。 它对JS进行了扩展，向JS中引入了类型的概念，并添加了许多新的特性。 TS代码需要通过编译器编译为JS，然后再交由JS解析器执行。 TS完全兼容JS，换言之，任何的TS代码都可以直接当成JS使用。 相较于JS而言，TS拥有了静态类型，更加严格的语法，更强大的功能；TS可以在代码执行前就完成代码的检查，减小了运行时异常的出现的几率；TS代码可以编译为任意版本的JS代码，可有效解决不同JS运行环境的兼容问题；同样的功能，TS的代码量要大于JS，但由于TS的代码结构更加清晰，变量类型更加明确，在后期代码的维护中TS却远远胜于JS。 1、TypeScript 开发环境搭建 下载Node.js\n64位：https://nodejs.org/dist/v14.15.1/node-v14.15.1-x64.msi 32位：https://nodejs.org/dist/v14.15.1/node-v14.15.1-x86.msi 安装Node.js\n使用npm全局安装typescript\n进入命令行 输入：npm i -g typescript 创建一个ts文件\n使用tsc对ts文件进行编译\n进入命令行\n进入ts文件所在目录\n执行命令：tsc xxx.ts\n2、基本类型 类型声明\n类型声明是TS非常重要的一个特点\n通过类型声明可以指定TS中变量（参数、形参）的类型\n指定类型后，当为变量赋值时，TS编译器会自动检查值是否符合类型声明，符合则赋值，否则报错\n简而言之，类型声明给变量设置了类型，使得变量只能存储某种类型的值\n语法：\n1 2 3 4 5 6 7 let 变量: 类型; let 变量: 类型 = 值; function fn(参数: 类型, 参数: 类型): 类型{ ... } 自动类型判断\nTS拥有自动的类型判断机制 当对变量的声明和赋值是同时进行的，TS编译器会自动判断变量的类型 所以如果你的变量的声明和赋值时同时进行的，可以省略掉类型声明 类型：\n类型 例子 描述 number 1, -33, 2.5 任意数字 string 'hi', \"hi\", hi 任意字符串 boolean true、false 布尔值true或false 字面量 其本身 限制变量的值就是该字面量的值 any * 任意类型 unknown * 类型安全的any void 空值（undefined） 没有值（或undefined） never 没有值 不能是任何值 object {name:'孙悟空'} 任意的JS对象 array [1,2,3] 任意JS数组 tuple [4,5] 元素，TS新增类型，固定长度数组 enum enum{A, B} 枚举，TS中新增类型 number\n1 2 3 4 5 let decimal: number = 6; let hex: number = 0xf00d; let binary: number = 0b1010; let octal: number = 0o744; let big: bigint = 100n; boolean\n1 let isDone: boolean = false; string\n1 2 3 4 5 6 7 8 let color: string = \"blue\"; color = 'red'; let fullName: string = `Bob Bobbington`; let age: number = 37; let sentence: string = `Hello, my name is ${fullName}. I'll be ${age + 1} years old next month.`; 字面量\n也可以使用字面量去指定变量的类型，通过字面量可以确定变量的取值范围\n1 2 let color: 'red' | 'blue' | 'black'; let num: 1 | 2 | 3 | 4 | 5; any\n1 2 3 let d: any = 4; d = 'hello'; d = true; unknown\n1 2 let notSure: unknown = 4; notSure = 'hello'; void\n1 let unusable: void = undefined; never\n1 2 3 function error(message: string): never { throw new Error(message); } object（没啥用）\n1 let obj: object = {}; array\n1 2 let list: number[] = [1, 2, 3]; let list: Array\u003cnumber\u003e = [1, 2, 3]; tuple\n1 2 let x: [string, number]; x = [\"hello\", 10]; enum\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 enum Color { Red, Green, Blue, } let c: Color = Color.Green; enum Color { Red = 1, Green, Blue, } let c: Color = Color.Green; enum Color { Red = 1, Green = 2, Blue = 4, } let c: Color = Color.Green; 类型断言\n有些情况下，变量的类型对于我们来说是很明确，但是TS编译器却并不清楚，此时，可以通过类型断言来告诉编译器变量的类型，断言有两种形式：\n第一种\n1 2 let someValue: unknown = \"this is a string\"; let strLength: number = (someValue as string).length; 第二种\n1 2 let someValue: unknown = \"this is a string\"; let strLength: number = (\u003cstring\u003esomeValue).length; 3、编译选项 自动编译文件\n编译文件时，使用 -w 指令后，TS编译器会自动监视文件的变化，并在文件发生变化时对文件进行重新编译。\n示例：\n1 tsc xxx.ts -w 自动编译整个项目\n如果直接使用tsc指令，则可以自动将当前项目下的所有ts文件编译为js文件。\n但是能直接使用tsc命令的前提时，要先在项目根目录下创建一个ts的配置文件 tsconfig.json\ntsconfig.json是一个JSON文件，添加配置文件后，只需只需 tsc 命令即可完成对整个项目的编译\n配置选项：\ninclude\n定义希望被编译文件所在的目录\n默认值：[\"**/*\"]\n示例：\n1 \"include\":[\"src/**/*\", \"tests/**/*\"] 上述示例中，所有src目录和tests目录下的文件都会被编译\nexclude\n定义需要排除在外的目录\n默认值：[\"node_modules\", \"bower_components\", \"jspm_packages\"]\n示例：\n1 \"exclude\": [\"./src/hello/**/*\"] 上述示例中，src下hello目录下的文件都不会被编译\nextends\n定义被继承的配置文件\n示例：\n1 \"extends\": \"./configs/base\" 上述示例中，当前配置文件中会自动包含config目录下base.json中的所有配置信息\nfiles\n指定被编译文件的列表，只有需要编译的文件少时才会用到\n示例：\n1 2 3 4 5 6 7 8 9 10 11 \"files\": [ \"core.ts\", \"sys.ts\", \"types.ts\", \"scanner.ts\", \"parser.ts\", \"utilities.ts\", \"binder.ts\", \"checker.ts\", \"tsc.ts\" ] 列表中的文件都会被TS编译器所编译\ncompilerOptions\n编译选项是配置文件中非常重要也比较复杂的配置选项\n在compilerOptions中包含多个子选项，用来完成对编译的配置\n项目选项\ntarget\n设置ts代码编译的目标版本\n可选值：\nES3（默认）、ES5、ES6/ES2015、ES7/ES2016、ES2017、ES2018、ES2019、ES2020、ESNext 示例：\n1 2 3 \"compilerOptions\": { \"target\": \"ES6\" } 如上设置，我们所编写的ts代码将会被编译为ES6版本的js代码\nlib\n指定代码运行时所包含的库（宿主环境）\n可选值：\nES5、ES6/ES2015、ES7/ES2016、ES2017、ES2018、ES2019、ES2020、ESNext、DOM、WebWorker、ScriptHost ...... 示例：\n1 2 3 4 5 6 \"compilerOptions\": { \"target\": \"ES6\", \"lib\": [\"ES6\", \"DOM\"], \"outDir\": \"dist\", \"outFile\": \"dist/aa.js\" } module\n设置编译后代码使用的模块化系统\n可选值：\nCommonJS、UMD、AMD、System、ES2020、ESNext、None 示例：\n1 2 3 \"compilerOptions\": { \"module\": \"CommonJS\" } outDir\n编译后文件的所在目录\n默认情况下，编译后的js文件会和ts文件位于相同的目录，设置outDir后可以改变编译后文件的位置\n示例：\n1 2 3 \"compilerOptions\": { \"outDir\": \"dist\" } 设置后编译后的js文件将会生成到dist目录\noutFile\n将所有的文件编译为一个js文件\n默认会将所有的编写在全局作用域中的代码合并为一个js文件，如果module制定了None、System或AMD则会将模块一起合并到文件之中\n示例：\n1 2 3 \"compilerOptions\": { \"outFile\": \"dist/app.js\" } rootDir\n指定代码的根目录，默认情况下编译后文件的目录结构会以最长的公共目录为根目录，通过rootDir可以手动指定根目录\n示例：\n1 2 3 \"compilerOptions\": { \"rootDir\": \"./src\" } allowJs\n是否对js文件编译 checkJs\n是否对js文件进行检查\n示例：\n1 2 3 4 \"compilerOptions\": { \"allowJs\": true, \"checkJs\": true } removeComments\n是否删除注释 默认值：false noEmit\n不对代码进行编译 默认值：false sourceMap\n是否生成sourceMap 默认值：false 严格检查\nstrict 启用所有的严格检查，默认值为true，设置后相当于开启了所有的严格检查 alwaysStrict 总是以严格模式对代码进行编译 noImplicitAny 禁止隐式的any类型 noImplicitThis 禁止类型不明确的this strictBindCallApply 严格检查bind、call和apply的参数列表 strictFunctionTypes 严格检查函数的类型 strictNullChecks 严格的空值检查 strictPropertyInitialization 严格检查属性是否初始化 额外检查\nnoFallthroughCasesInSwitch 检查switch语句包含正确的break noImplicitReturns 检查函数没有隐式的返回值 noUnusedLocals 检查未使用的局部变量 noUnusedParameters 检查未使用的参数 高级\nallowUnreachableCode 检查不可达代码 可选值： true，忽略不可达代码 false，不可达代码将引起错误 noEmitOnError 有错误的情况下不进行编译 默认值：false 4、webpack 通常情况下，实际开发中我们都需要使用构建工具对代码进行打包，TS同样也可以结合构建工具一起使用，下边以webpack为例介绍一下如何结合构建工具使用TS。\n步骤：\n初始化项目\n进入项目根目录，执行命令 npm init -y 主要作用：创建package.json文件 下载构建工具\nnpm i -D webpack webpack-cli webpack-dev-server typescript ts-loader clean-webpack-plugin 共安装了7个包 webpack 构建工具webpack webpack-cli webpack的命令行工具 webpack-dev-server webpack的开发服务器 typescript ts编译器 ts-loader ts加载器，用于在webpack中编译ts文件 html-webpack-plugin webpack中html插件，用来自动创建html文件 clean-webpack-plugin webpack中的清除插件，每次构建都会先清除目录 根目录下创建webpack的配置文件webpack.config.js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 const path = require(\"path\"); const HtmlWebpackPlugin = require(\"html-webpack-plugin\"); const { CleanWebpackPlugin } = require(\"clean-webpack-plugin\"); module.exports = { optimization:{ minimize: false // 关闭代码压缩，可选 }, entry: \"./src/index.ts\", devtool: \"inline-source-map\", devServer: { contentBase: './dist' }, output: { path: path.resolve(__dirname, \"dist\"), filename: \"bundle.js\", environment: { arrowFunction: false // 关闭webpack的箭头函数，可选 } }, resolve: { extensions: [\".ts\", \".js\"] }, module: { rules: [ { test: /\\.ts$/, use: { loader: \"ts-loader\" }, exclude: /node_modules/ } ] }, plugins: [ new CleanWebpackPlugin(), new HtmlWebpackPlugin({ title:'TS测试' }), ] } 根目录下创建tsconfig.json，配置可以根据自己需要\n1 2 3 4 5 6 7 { \"compilerOptions\": { \"target\": \"ES2015\", \"module\": \"ES2015\", \"strict\": true } } 修改package.json添加如下配置\n1 2 3 4 5 6 7 8 9 { ...略... \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" \u0026\u0026 exit 1\", \"build\": \"webpack\", \"start\": \"webpack serve --open chrome.exe\" }, ...略... } 在src下创建ts文件，并在并命令行执行npm run build对代码进行编译，或者执行npm start来启动开发服务器\n5、Babel 经过一系列的配置，使得TS和webpack已经结合到了一起，除了webpack，开发中还经常需要结合babel来对代码进行转换以使其可以兼容到更多的浏览器，在上述步骤的基础上，通过以下步骤再将babel引入到项目中。\n安装依赖包：\nnpm i -D @babel/core @babel/preset-env babel-loader core-js 共安装了4个包，分别是： @babel/core babel的核心工具 @babel/preset-env babel的预定义环境 @babel-loader babel在webpack中的加载器 core-js core-js用来使老版本的浏览器支持新版ES语法 修改webpack.config.js配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ...略... module: { rules: [ { test: /\\.ts$/, use: [ { loader: \"babel-loader\", options:{ presets: [ [ \"@babel/preset-env\", { \"targets\":{ \"chrome\": \"58\", \"ie\": \"11\" }, \"corejs\":\"3\", \"useBuiltIns\": \"usage\" } ] ] } }, { loader: \"ts-loader\", } ], exclude: /node_modules/ } ] } ...略... 如此一来，使用ts编译后的文件将会再次被babel处理，使得代码可以在大部分浏览器中直接使用，可以在配置选项的targets中指定要兼容的浏览器版本。\n","description":"","tags":null,"title":"Typescript 学习笔记01","uri":"/tech/typescript01/"},{"categories":null,"content":"我与开源的那些事儿。 很幸运！！！是的，很幸运，除了幸运，我不知道该怎么形容我和 开源 的缘分。感觉就好像在冥冥之中，肯定会走上这条道路一样。\n缘起 2020注定是特别的一年，年初，谁也没想到，一场疫情把我们牢牢的困在家里，哪也去不了。。说实话，或多或少有点抱怨吧。但伴随而来的，是一场灾难。那个时候每天一早醒来，看见手机屏幕刷新的数据，冰冷的可怕，红线一直在升。。。当时就在想，为什么我不是学医的，待在家里什么都做不了，似乎捐钱变成了最可悲的方式。\n偶然一次，在知乎上看见关于开发者抗疫的活动——“Wuhan2020”。本身就是学计算机专业的我，对于技术方面的文章也比较感兴趣，就随手点了进去。（ 其实当时内心所想的是，可能有是一个营销号在做文章 ）。在大致了解了Wuhan2020整个项目之后，便开始搜集更多的与之相关的信息。最后偶然在一个公众号中，看见了“黑客松活动”。就水群，进去了，，哈哈哈哈。但当时还是个技术小白，啥都不懂，可以理解成比会写“hello world“强那么一点点。在那之后，也找到了Wuhan2020的官方公众号。那时，想着尽自己的一份力，但是无论是对于开源文化上还是技术上都感到了很大的局限性，说俗点，大概就是心有余而力不足吧。随后大约在四月份（ 精确点是4月4号，因为那一天整个世界都是灰色的 ），看见了Wuhan2020公众号招人，我想了想自己对于做图剪视频之类的，还算是比较擅长的，就去试试水。进入了设计组。这也算是我第一次真正接触到开源吧。\n幸运 说实话，除了幸运我不知道该怎么来形容这段经历。当时在设计组群里，几乎什么都没做，就发了一份作品＋自我介绍，然后有一位华师大的学姐，就加我为好友，说是带我一起和一位大佬做Apache相关的推广。哈？？Apache是什么？？当时的我是一脸问号。。。。然后就抱着试一试的心态跟着去了。。。（ 现在想想当时真的是有趣，如果我说我什么都不了解，甚至拒绝的话还会有现在的我么。。而且群里那么多人咋就单单选中了我呢，哈哈哈哈）然后和Apache的姜宁老师简单聊了一下，说到hugo啥的。我心里想hugo？？雨果还搞开源？？随后查了一下，是一款搭建静态博客的框架，这也是我正式使用github的起点吧，更新博客。学了点东西总要找点事情做的，要不然时间一长，不就那也记不住了，哈哈哈。\n慢慢的跟着学姐运营ALC-Beijing和Wuhan2020的公众号，也一起了解到更多有关开源的文化。习惯也由之前的天天逛CSDN、知乎变成Github、掘金之类的。成功搭建博客，给我学习新的知识也树立了信心。似乎一切都好了起来，那个时候武汉已经宣布解封。\n当时接触开源之前，总感觉自己怀才不遇，明明会的不少，懂得知识也挺多的，为什么就还只是一个普普通通的大学生呢？？还是做不到出圈，每天混学分，做着毫无疑义的事情。但当皓月姐姐加我好友的那一刻开始，就感觉那份属于我的运气该来了，还撞的特别准。\n随后也加入了开源社，慢慢认识了更多的小伙伴，一群人不认识也不了解，分布在各个地方，做着一件共同的事情，可能这就是我当时所理解的开源吧。\n受阻 当时想着为一些顶级的开源项目做贡献，就开始学会主动去吸取知识，那种学习给我的感觉是由心而发的，主动的。如果问我那时为什么想参与开源，大概是开源本身就具有向善的属性，也认为那是一种体现自己价值的方式。\n当五月份学校宣布返校的时候，回头学校之后，就开始感觉自己有出圈的能力了，也有出圈的想法，可能是技术层面，学校没有需要学习的，也可能是真正意识到现在的自己可以做一些更有意义的事情了。就逐渐向周围的同学唠叨着自己接触开源的事情，很多人的情况和我一样，一开始都是一脸懵圈，但遗憾的是懵圈之后，就什么都没了。这就好比一个主动跳入坑里的人，很难再拉下一个人主动入坑。其实准确点来说，都感觉开源离自身太远。从学生角度来思考，学好文化课，在课余时间参加活动、比赛之类的，赚学分，才是本职工作。至于开源，第一是不了解（不直接和自己的利益挂钩），第二是技术层面达不到。可以发现github上面的顶级项目几乎大多数都不适合学生来做，而且更多的是面向求职者或者说是已经工作了的，这样一来，即使有一腔热血，但是也被挡在门外。（回头想想自己，能想到把blog部署到github上，这样一来，几乎就和github捆绑在一起了，也就是这样能有更多的机会接触更多的项目。）带着这样的问题，我就在思考如何才能让身边的人参与开源，其实参与开源也不一定是技术层面，是不是？？\nCOSCon‘20 期盼已久的开源年会终于来了，尤其是今年年会的主题——“开源向善“ 。这可能也是我接触到开源的初衷。当时去之前，就在脑子里构想了很多有关开源的问题，在自身深入了解开源之后，总感觉没有自己想的那么简单，说大点可以是一种哲学，甚至是一种信仰。这是开源带给我最直观的感受。\n年会现场，也可谓是大型的网友见面会，虽然每个人都不一样，学着不同的专业、不同的城市、不同的年龄段，但是却都可以在彼此身上找到各自的影子，有时候有些事确实挺奇妙的。在第二天，无论是和庄表伟老师的聊天学习，还是和王伟老师的沟通交流，都刷新了我对于开源的认识，就好像是打破之前的定义，更深入的思考，对，这次是思考，不再是了解。如果说皓月姐姐是我接触开源的引路人，这大概就是遇见了自己的伯乐。\n天下没有不散的宴席，虽然很不舍，但是离别是必然的，愿下次再遇见，那个时候的自己更优秀。\n","description":"","tags":null,"title":"我与开源的那些事儿","uri":"/life/coscon/"},{"categories":null,"content":"大三了，二夕回来了？？ 转眼间，大学生活已经过去两年了，一切总感觉一切都还早，一切都不用那么着急，反正很多事情也不是着急的事。这学期临近开学，忽然不知怎么就有了一种无形的压迫感。这种压迫感似乎在怒斥着自己，你前两年都学了些什么？？ 仔细想想，好像什么都没有。。。。\n是的，什么都没有！代码写得还是一如既往的差劲，缺少能够独立思考的能力、做不到举一反三，一切的一切都只会按部就班。在台上依旧会紧张，更少了刚踏入大学门时的斗志。失败吧？？确实挺失败的。\n一开始一直想着考研，感觉打着考研的口号，就能贴上好学生的标签，就不会变得浑浑噩噩，但是环境的影响是必然的，因为自身所处的氛围，从而间接的决定了你所看到的上限。很多人，在大学阶段都在乎名利、奖学金啊之类的，说实话，当时我的也是。恨不得把所有的荣誉都贴在身上。随着时间的推移，慢慢接触了更多的大佬，了解到上一个层面，才知道这一切是多么可笑的事情。从我现在的自己看着两年前的自己，说成降维打击也不为过。当时忙来忙去的，说好听点叫做锻炼自己，实际上谁还不是为了那点可笑的学分呢？？学分有用嘛？？也许有吧，没用怎么才能拿奖学金呢？？那么问题来了，奖学金有用吗？？似乎没吧，能写到简历上吗？？搞笑的嘛？？所以现在回头来看，似乎才知道当时的自己做了许多毫无意义还徒添烦恼的事情。上了大学，很少有人为了学习烦心过，更多的在于这些组织关系的一些杂七杂八的事情，毫无意义且浪费时间。所以从大三开始，我要撕去前两年亲手为自己贴上的标签，做个简简单单的普通大学生。\n但是想撕标签，说的简单，做的时候还是顶着很大的压力，等于摧毁以前苦心营造出来的一个人设，再树立一个与之不同甚至相反的，周围人怎么看？？重新树立的我 还是我吗？？谁知道呢？？往下走就完事了。这也算是对于两年的自己一个交代。\n高三的高考失利，就注定在心里埋下考研的萌芽。当时看着各个高校的专业排名，最中意的是华东师范大学，其次是我喜欢上海这个城市。但是呢，上了大学之后，周围的人都在告诉你，像文达这种学校能考个安大就不错了。。。是呀，安大还是211呢，你稀罕嘛？？反正我可不想。随着最近的忧虑，我恍惚和当时的自己进行了一次对话。大政笑二夕多么的颓废，而二夕却在感叹当时的大政多么心高气傲。如果可以，我更想做回以前的自己。那个做出一点点成绩，就引以为傲的大政。那个血气方刚的中二少年。\n现在，我 回 来 了！！！先从目标开始，考研目标： 华东师范大学 ，说难听点，窝窝囊囊从中学到大学上的都是垃圾学校，考研再不翻身更待何时！！！ 我想把高三时候陪伴大政的一句话，送给现在的二夕： 我不去想是否能够成功，既然选择了远方，便只能风雨兼程。\n现在回答开头提出的问题：我回来了吗？？是的，一个全新的我回来了。\n","description":"","tags":null,"title":"我回来了？？","uri":"/life/%E6%88%91%E5%9B%9E%E6%9D%A5%E4%BA%86/"},{"categories":null,"content":"可能自己就是天生比较丧的原因，当第一次僵尸的《网易云》就入了坑，这几天，听见了他的《淹没》，就开始单曲循环。\n其实，说到底，rapper也好，yoer也罢，都是小众文化，想要的到大众的认可，谈何容易。但往往就是这种小众的圈子，入圈的人更能找到共鸣，因为有些话，只有小众人才能明白。\n以下内容是根据歌词所想所写：\n想去冒险，结果一直没有真正的去实践过。我也曾一个人做地铁坐公交到底站，带上耳机的惆怅感只有自己能懂。喝酒吗？？我不喝酒，喝酒伤身体，多喝点奶。有时自己的抑郁的时候，通常是手机开飞行模式，不想遭到任何事情打扰，关上房门，带上耳机，拿起悠悠，就进入另外一个世界了。\n你高考了没？？学习成绩怎么样啊？？对于自己的未来有想法嘛？？考不上大学是不是打算直接就去打工啊？？ 反正谁知道呢，走一步看一步就好。\n我是个yoer，但不是火力少年王那种，电视上面的都是基础招，都是垃圾，哎哟、好吧，其实大家玩的都差不多吧。反正你们也不懂，只是看看热闹罢了。玩的也就一般嘛 在圈子算低端吧。从来没指望这玩意能够赚钱，还不是因为自己喜欢啊。家里啊、家里人一开始最多认为我是三天的新鲜劲，过去就没了，支持嘛？？说不上吧，你想想你儿子整天玩个悠悠球，难不成你还供着他啊……至于现在，不反对就好。\n有时候，就很烦，玩悠悠球毕竟不是未来，鸡汤现在都烂大街咯，成功一定会来，就**放屁。我会不会坚持？？不知道，反正我没想过放弃。\n凌晨的卧室它会变成汪洋 在每晚一点半准时的重逢\n手机屏散发出微弱的光芒 抵抗这无形中巨浪的重重\n连秒针都变得肆意而猖狂 嘲弄他理想的荒唐\n苦笑的祭奠那逝去的张扬 还有他已不知去向的从容\n我想做到给他们看见 我想成为他们口中特例\n我想做到给他们看见 吐出这口憋了无数年的恶气\n失魂落魄的那个人啊，这个世界又何曾让他选\n一开始就只有这一条路给他走，死不悔改的丧家犬\n暴风雨并不会让人绝望，杀人的不是狂风\n遍体鳞伤的人 绝不会倒在最艰苦的长征\n积压的情绪爆发后 突入其来的平静让人惊讶\n生的了结最可能出现在某个无限美的黄昏\n嘴里说我知道我明白我会照做，心里说死也不要\n他们总逼着你喝下去有一种名字叫为了你好的毒药\n成功竟然比存在本身还重要 他们指着那些伟人\n时至今日我发现哪里有人群 入眼处尽是鬼魂\n愿世界没有歧视，小众文化forever！\n","description":"","tags":null,"title":"听姜云升——《反抗》","uri":"/life/%E5%90%AC%E5%A7%9C%E4%BA%91%E5%8D%87%E5%8F%8D%E6%8A%97/"},{"categories":null,"content":"致RIOT悠悠球协会全体成员的一封信、 社团名以及LOGO的由来 时间返回到一年前，也大约在这个时候，我可以确信我们的悠悠球社团能够成立，也大约在这个时候，想好了社团的名字，以及设计出社团的LOGO。\n还是想说说名字的来历吧，主要来源于我比较喜欢的一颗悠悠球 “start the riot” ；还有就是RIOT可以简单分成两部分来看：“RI” 其中R的词根的有再一次的意思，而”OT“呢？？这个可不是打游戏里面的OT，而是圈子里面提倡的一个概念”Original Throw“。因为大多数人，或多或少再小时候都接触过悠悠球，所以我希望的是当再一次接触到悠悠球，请不要再放下她。（ 还好学校里面的领导没文化，不知道riot其实是暴动、暴乱的意思，要不然说不定给我ban了，哈哈哈哈 ）\n至于社团的LOGO呢？？更偏向于街头涂鸦的那种感觉，给人的整体感觉也是比较青春有活力的。与传统的圆形或者中规中矩的方形所不同，甚至可以感觉到一点叛逆的味道在里面。。。\n为何创立？？ 为何创立社团？？以及有没有必要创立一个悠悠球社团？？ 其实这两个问题困惑了我许久。先谈谈第一个：悠悠球作为小众运动，对于绝大多数人而言，甚至还停留在儿时的玩具，只能够普普通通一上一下的简单操作，对于电视上出现的各种操作，更以为是特效。。。。。这个原因也是能说是其中的一点。想打破大家对于悠悠球的认识也是创立的一个主要原因。在刚上大学的时候，我就开始尝试着让更多人了解悠悠球，或者说入坑悠悠球，但是悠悠球相比于其他的玩物，上手难度比较大，因为是小众，文化基础不是很好。再加上需要付出时间和精力去练习等等诸多因素，从而导致更多的人都只是愿意看看。但是正是由于她的小众以及上手难度，这也是使得悠悠球更显得与众不同。在当时尝试推广之下，已经有了一定的群众基础，刚好赶上要举办元旦晚会，因此便和几位小伙伴上台表演了一番，虽然玩得都是基础招，对于许多没有真正了解过的人来说，这已经amazing了！！！是的，表演效果还是可以的。这也让我有了创办的信心。在2019年三月份，华东高校悠悠球联赛正式举办，当时因为一些原因，并没有去现场学习。但通过直播，仍然可以看见有许许多多的大学生对于悠悠球的热爱与执着，特别看见新手组的时候，对我而言感觉是最多的。在五一假期的时候，来到上海，参加了上海悠悠球聚会，起初我以为我是最差的，，但是看见很多意想不到的，有小朋友也有大叔，都是因为对于悠悠球的喜欢与热爱，我们得以相聚。玩悠悠球，玩得开心不就可以了，为什么想那么多呢？、如果创立社团可以让这份快乐延续和传播下去，岂不是更好？？从那时起，我就在心中埋下一颗种子，并尽力让其生根发芽。\n有必要吗？？或许正确的答案是没必要吧。创立社团对我自己而言更多的是徒增了许多烦恼（在实际的过程中也是如此）。但既然能够成立一个社团，又何必去管它有没有必要呢、、 干就完了！！\n为期一年？？ 实际上，在协会会长这个职位上，并没有满一年就下来了。。。\n起初，在刚成立的时候，还在幻想着，纳新能招多少多少人，以后举办什么什么活动之类的，理想总是美好的，实际证明这一切的幻想都是基于我自己对于悠悠球的喜欢，对于一个不冷不热的路人来说，我们更应该思考的是如何让他们对此感兴趣。。 所以说，不管是纳新还是举办活动，都比我预想的要差的很多，甚至在有一段时间，我就在想，社团还有必要继续运营下去吗？？这时，我想起《曾国藩》中的一句话：\n打破牙和血吞！！！\n哈哈哈，现在回头看来也没有那么严重，只不过是与心里的预期相差太多，有点接受不了，所以难免有点颓废。颓废过去，社团还是要经营的，最重要的每周的训练是必不可少的，只有在保证训练量的基础上，部员才能有所成长。就这样，新的一年即将到来，随之而来的还有元旦晚会，这也算是社团的一个隐藏起点吧。但是身份却发生了改变，相比较一年前，想在舞台上秀操作，那时更多的是想让协会的部员能够上台展示自己，这是社团的收获，也是你们的收获。和当时不变的还是，舞台肯定要炸，玩悠悠球不蹦迪，那不是在土嗨嘛？？（ 开个玩笑 ） 就这样，经过为期三个月的努力，社团可以呈现一个完整的舞台，足够了，是的。这既是对于社团部员的考核，也是对于我自己的一次检验，还好，不算太差。\n到了2020年，因为疫情原因，没能及时返校，部员的训练量也就落下了。回校之后，就在想，要不就这样吧？？反正接力棒就要交到下一届，到时候就与我无关了了了了、、、 内心还是挺纠结的。最后想了想，活动还是要办的，毕竟要为留下来的部员最大化的谋取福利，顺便可以培养下一届会长的办事能力。也算是对自己交个差吧。\n以上大概差不多就是这一年来经营社团方面的心态变化。接下来简单说一下个人的经验：\n做好牺牲自己（时间和金钱），当选择成立一个社团或者留任的时候，那就代表着你要担负起属于自己的那一份责任； 要有适当的计划，可以是长远性的，也可以是目前的，比如说在纳新结束后，可以根据部员的时间合理安排每周的训练，再具体点就是每周训练的内容； 调动部员的积极性，相比较参与社团活动，可能大部分部员都会选择做自己的事情，因为在他们看来参与社团活动是为了社团的发展之类的，而往往牺牲的是他们自己的时间，长而久之，就慢慢会退出社团活动，这时作为会长就要结合实际情况，调动部员的积极性； 在比较活跃或者说表现比较积极的部员，要培养他们的归属感，从而可以他们有参与社团活动、留在社团之类的想法，产生良性循环； 认真重视自己的社团，比如在每次训练的时候，可以逐一私给部员私发信息，让部员意识到其重要性，如果作为会长自己都不重视，凭什么要求部员积极呢？？ 谈谈收获。。 好像读到现在，整体给人的感觉是有点不太乐观的、甚至还是比较颓废的。但事情都是有两面性的。\n给我收获最大的莫过于看见部员的成长。从什么都不会，到可以玩出点东西；从内向腼腆，到敢于上台表演；从遭受别人的冷眼嘲笑，到慢慢有了掌声……\n记得当时纳新结束，有一个小部员，来找我练球，教他的时候，问他什么都不说，发球手还抖的噼里啪啦的，整个人就是特别内向，更别说在人群面前展示自己了，但是逐渐慢慢的，有了变化，在元旦晚会的时候，上台表演，听见来自台下观众的掌声，也可以肯定自己。这一切的变化，不能说都是来自于悠悠球，但是悠悠球在其中有不可或缺的因素。还有的部员说，我从小就双手不协调，不可能玩好的。但是我想说，只要你相信自己，并且听我的愿意花时间去练习，没有什么做不到的。是的， 只要坚持，结果总不会太差 。\n再说说我自己吧，因为把自己大部分时间都放在社团上，也就没了过多的时间抄招想招，每周都在想着教什么基础招，想必圈子里面很多的老前辈都知道基础招的重要性，从而就有了我现在的手感，这与教授部员基础招有着密不可分的关系。还有就是，心态被磨平了，做事情可以从更多的方面去思考问题，这些也全都是收获。\n那么现在再想有必要创立社团嘛？？我的回答是：有的。我把社团的定位是传播悠悠球的正确玩法，而不是培养比赛型选手，如果可以向圈子里面输送新人也是更好。但就说传播悠悠球的玩法，我想我尽我自己的能力，做的还行吧。\n如果说社团最大的难题在哪？？莫过于 传承 。\n我的故事到此为止\n没做好的 你来帮我完成\n永远保持热爱\n","description":"","tags":null,"title":"关于RIOT悠悠球协会","uri":"/life/%E5%85%B3%E4%BA%8Eriot%E6%82%A0%E6%82%A0%E7%90%83%E5%8D%8F%E4%BC%9A/"},{"categories":null,"content":"说起 《三体》 ，想必大家并不陌生，大约从初中就听说过这套书，但很遗憾的是，当时的我并不喜欢读书，直到现在，也就是大二的时候才读完。但庆幸的是，有些书幸好没有那么早的草草地过一遍，要不书中想表达的含义，在当时的经历与心境来说是无法理解和体会的。\n地球生命真的是宇宙中偶然里的偶然，宇宙是个空荡荡的大宫殿，人类是这宫殿中唯一的一只小蚂蚁。这想法让我的后半辈子有一种很矛盾的心态：有时觉得生命真珍贵，一切都重如泰山；有时又觉得人是那么渺小，什么都不值一提。反正日子就在这种奇怪的感觉中一天天过去，不知不觉人就老了……\n这是《三体1》当中叶文洁，对伪主人公汪淼所说的一段话，也是全书中我比较喜欢的一段话。读完书之后，在翻阅之前做的笔记的时候，看到这段。不得不佩服大刘的思维，在读第一本的时候，可能会觉得这只是叶文洁的感叹。但通读全书之后，何尝又不是每个读者心里发出的一声叹息呢。。从宏观的角度来看，与浩渺的宇宙相比，人类确实只是一粒尘埃。但同时，人类是幸运的，生活在地球上。可悲的是，人类本身却不知道爱惜这块土地。\n反观叶文洁，为何要给三体人发信息呢？？甚至不惜犯了反人类罪。当从汪淼的视角，第一次看见叶文洁的时候，不免觉得这样一位老太太有点可怜，失去了自己的女儿，看着她那照看小区里邻居家小孩的样子，哪能想得到是ETO的统帅。。 但结合叶文洁的遭遇，也不难发现，她之所以决定把三体人引来都是有原因的，甚至不惜牺牲丈夫的生命，是人类一次又一次的做出违反道德底线的事情，在文革那个特殊时期，国将不国，人成非人。从而给叶文洁的心中埋下不相信人类的种子，当来到红岸基地之后，凭借自己的技术和手段，在收到三体人的警告：“不要回答！不要回答！不要回答！” 但她还是毫不犹豫地发送信息，暴露出地球的坐标，也就有了三体以后的故事。\n全书中，我最喜欢的角色是：章北海 ；最欣赏的应该是： 维德 。一个是要多想，一个是前进，不择手段的前进！之前，在还没读《三体》之前，隐隐约约看了点书评之类的，知道章北海是一个坚定的失败主义者，那时候就在想，既然是一个失败主义者，为何还有那么多人粉他呢？？不是应该被批评的嘛？？所以一开始对于章北海并没有什么太好的印象，甚至还有点反感。。。。在读到的《黑暗森林》的时候，面对三体人的来临，几乎所有人都慌张失措的时候，联合国更因此，制定了反人类的面壁计划。在这个条件下，反观章北海，没有面壁者的权利有义务，却成为了一个合格的民间面壁者。当大刘写到他问自己的父亲，下一步该怎么做的时候，父亲告诉他：“北海，我只能告诉你那以前要多想”。设想一下，如果我们自己在当时的环境下，我们该如何去做？？更多的可能是崩溃，但他没有。知道人类的特性都明白，逃亡主义是不可能实现的，但面对敌我实力的悬殊，也唯有逃亡，才能为人类文明的延续留下火种，尽管流浪在宇宙中的新人类，已经成为非人。但是毫无疑问，他是成功的，也完成了自己的任务。再来看看看维德，第一反应是这个人未免有点太讨厌了，喜欢欣赏人绝望的时候，就凭这一点就很恶心，是不是。。但是慢慢读下去，发现他是一个彻底的功利主义者，更说出了很多金句，比如： 失去人性，失去很多，失去兽性，失去一切 。但是欣赏归欣赏，要是在现实生活中，要这么一个人，肯定是不愿意和他做朋友的，太危险了，得绕的远远的，哈哈哈~\n简单的说一下阅读感受，在读第一部的时候，能感觉到这本书的格局之大，也被大刘的一些科幻创意点子所惊呆，尤其是在说冯诺依曼用大量的士兵给秦始皇展示计算机模型的时候，绝对的是一大亮点，还有就是从工具人汪淼的视角，来揭开三体人，让人感觉不太像是科幻小说，更有点的侦探悬疑的感觉。再看第二部，主人公罗辑从一个混日子的大学教授，被指定为面壁者，从而慢慢经历在书的末尾与三体人正面对决，可谓惊叹，对于罗辑的心路历程，再看看年少时候到我们。反观第三部，程心被喷圣母biao，但是她做错了什么嘛、是人类选择了程心，在那个时代的人类，可怜更可笑，盲目地自大，所以选择程心是理所当然。在读到书的结尾的时候，被大刘一个接着一个抛出的科幻点子所惊艳，有一种喘不过气的感觉。但又有点急急促促的感觉。\n读科幻小说给我的最大感受，就是每次读的时候都把自己的思想扩展到宏观层面，感觉眼前的所有烦心事，在整个人类文明面前都是不值一提的，可以把问题思考的更深入点，就想到既然文明可以一直延续下去，那么该如何让自己更有意义，成为文明的一部分呢？？我得出的答案是，那就是做些有意义的事情，什么事情是有意义的呢？？放下小了说，就是活好当下。。。\n","description":"","tags":null,"title":"读后感——《三体》","uri":"/life/threebody/"},{"categories":null,"content":"今天想说说 关于知足 、 大家经常说“知足常乐”，但对于知足却没有一个明确的定义。\n语出《道德经》。认为“祸莫大于不知足”，不知满足，进而追求，定招灾祸。知其足，不追求，安于所得，无为无德，反而常常满足。知足才能避免灾祸，才能全生保身。\n今天我为数不多的一位朋友，遇到了点烦心事，和我唠嗑。然后我对她说“知足就好。” 她说：“ 我太喜欢这个词了，知足常乐”\n但怎么说呢、知足是个好词，每个人都渴望知足，但是从我的角度来说：其实我想要的是比知足多一丢丢，这样才能因为知不足，而保持学习。 知足确实是挺好的，但是人在成长的过程中，往往会由于自己的贪婪或者说是欲望，而不断提高对于自己的要求。当自己的要求更高、更严，从而可以在一定程度上促使自己变得更好、站得更高，那么在那个时候的自己，可能就会变得不那么知足，甚至有点贪得无厌。其实我感觉这些都是人之常情，如果所有人都安于泛泛而谈的知足，那么又有谁来推动社会的进步呢？？\n其实这种想法也是不对的，把贪婪说成知足，把知足说成安逸。我所理解的知足，是一种享受状态，是在于知道自己想得到什么之后，不用多想其他的什么，是完成目标之后的，有点小小的满足，甚至是骄傲的感觉，似乎整个世界都没有烦心事了，又好似整个世界的事情都与自己无关，可以安安稳稳地去做自己想做的事情，没有为了目标而去努力的劳累感。就这样，一切都安静了。。\n事实证明，知足状态下的我，可能会变得一塌糊涂，如果再这种状态下去，甚至会变得一无是处。在暑期，当忙完了所有要紧的事情的时候，当时的我已经精力交瘁，也有一种“知足”的感觉。因为感觉所有的事情都结束了，似乎可以让自己好好休息一段时间咯。当时理想的状态就是：每天写写代码，看看书，练练球，再学点额外的技能之类的。但是这几样，几乎没有一件事情是完成了的。这就是因为人的惰性，人只会着急与眼前的事情，很难去保证或者说坚持一些有意义的事情，让自己可以变得更优秀。\n等等，写到这里，我不由得想到，前面所说的我想要的是比知足多一丢丢 。这似乎就进入了一个死循环当中，每当处理完一些事情（￥%#\u0026噼里啪啦、乱七八糟之类的事），就会进入短暂的休息期，这个期间的自己是不想做任何事的，或者说不想做任何要动脑、动体力的事情，在这个状态下去，就会想是不是因为自己最近的不努力、懈怠，从而导致自己没有进步，与别人的差距又拉开了？？然后就感觉自己不再知足…… 长此以往下去，似乎会让自己变得更累，总感觉自己没有丝毫喘气的机会。。。\n那么问题来了？？究竟什么样的状态才是知足呢？？就如同五月天在歌词中写到：\n天上的星星笑地上的人，总是不能懂不能觉得足够。\n","description":"","tags":null,"title":"谈谈知足","uri":"/life/%E7%9F%A5%E8%B6%B3/"},{"categories":null,"content":"两年前的这个时候，高考也已经告一段落。一直以来，都太强调学习，满脑子里想的都是”知识改变命运“这种空而大的口号。其实这一点，直到今天，还依然未变。要不看了这么多年的书，岂不是白看了嘛？？哈哈哈哈哈……\n在高三的时候，总想着，只要再努力一点，再多背一个单词，多做一道题目，就离考了大学更进一步，但其实不然。当拿到报考指南的那一刻，还是傻眼了。似乎有一种无力感，高考查完分之后的那种兴奋再也找不到了，就在想：当时熬的夜，还值得吗？？都说付出就会有回报，但结果呢？？这大概就是灰色而幽默的现实，当头一棒，给我敲醒。我只是个蝼蚁，还有很长的路要走！！\n在大一的时候，大部分的同学的共同语言，还是关于“高三”。似乎，之前的所有经历和高三相比都不值一提，还是当时眼界太低，能看见的只有高考呢？？上了大学，懵懵懂懂，总想着，摆脱了高中的条条框框的拘束，也有个平台可以展示自己了。其实现在反过来，想想当时自己为什么要加哪些组织、社团呢？？是真的喜欢吗？？还是单纯的为了学分呢？？还是利益相关呢？？大一刚入学的时候，感觉那些当着学生组织负责人的学长学姐好了不起，如果自己到了那个时候，会变得和他们一样优秀吗？？大一，也许在悔恨高中为什么不努力好好学习，也许是刚刚告别高三，还把看书、刷题当做一种习惯，但慢慢的，随着时间的推移，当时的屠龙少年，现在也变成了一条恶龙。（前段时间在整理书柜的时候，发现了大一时候学高数，演算的稿纸，还真的挺佩服那时候的自己）\n到了大二，渐渐的在学校里有了自己的圈子，创立了自己的社团，原以为会变成自己想要的样子，迎来的却是各种毒打，其实也算不上毒打，准确来说是劝退。当热情被慢慢消磨殆尽，坚持下来的可能就是责任了吧。那如果连责任心都没了呢？？我还有什么坚持下去的理由呢？？\n到现在，回过头来，看看高三时候的自己，可能会对他说：把一切都看淡一点，没什么大不了的。是的，没什么大不了的。说句鸡汤的话：只要你努力，总不会变得太差劲。\n其实这篇文章，在好久之前就想写，但一直找不到带入点，也不知该如何去说起。可能是最近的烦心事多了，又变得消极了点，心里有情绪，总归要抒发出来的嘛。\n","description":"","tags":null,"title":"写个两年前的自己","uri":"/life/%E5%86%99%E4%B8%AA%E4%B8%A4%E5%B9%B4%E5%89%8D%E7%9A%84%E8%87%AA%E5%B7%B1/"},{"categories":null,"content":"关于我？ 叫我二夕就好，可能看到这里，你会好奇，为啥起一个这么怪的名字呢？？\n当时在想昵称的时候一直找不到合适的，打算叫“无名”，但总感觉有点落了俗套。还好，中文是比较有意思的，把“无”和“名”下面的部分拿了，不就是“二夕”了嘛。。。。。哈哈哈哈哈哈\n玩什么？？ 常常会感慨自己是个老年人了，过了打游戏的年龄。在大学生活中，不打游戏，时间就多了起来。无聊的时候，总想找些东西打发时间。慢慢的，找到新的伙伴——悠悠球。停停停！！！我知道你想说：刚刚还感慨自己是老年人，现在又玩起小孩子的东西。\n大多数人对于悠悠球的印象可能还停留在儿时的玩具，是的，重新开始接触的时候，我也是那么认为的。但随着技术的提升，认识的玩家越来越多，会发现一个全新的世界。你会发现，有很多人都在为之而共同努力。只想把悠悠球，一种玩具，小众文化，推向大众。想得到大众的认可。\n除了玩？？ 除了玩，那肯定就是吃和睡咯……呸呸呸，这不是我！！！\n学的专业是软件工程，所以平时最多打交道的就是代码，哪还有时间吃吃睡睡的，捋了捋自己的头发。作为一个日常摸鱼的当代大学生，平时无非就是看看书，写写代码，听听歌。就这？？\n","description":"","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"前言 大政的Blog就这样稀里糊涂的开通了。\n有时候闲着无聊，总想着写点什么，可能是乱七八糟的想法，可能是一段书评，也有可能是一段歌词。因为相对于话语的直白，文字能表达的情感是更加细腻的，它也可以将有些事情一直保存下去。\n也有可能是我天生就有点内向，甚至比较丧，不太喜欢说话。\n当时之所以想开通Blog最主要是想督促自己保持学习的习惯，并且可以在这里记录一些关于学习的笔记。也有一部分原因是在这段时间接触了许多之前没有接触过的人和事，总想着这些美好的事和可爱的人更应该被文字所记录，而不是埋藏在我的心里。\n所以博客的内容可能是一串代码，一行文字，一条书评，一段歌词，或许是一句心里话。\n我既做不上神明，那当个野兽也好。\n","description":"","tags":null,"title":"Hello World ! Hello Blog !","uri":"/life/hello/"}]