---
title: "Redis04——主从数据同步"
date: 2024-05-23T13:35:33+08:00
draft: false
---

# Redis——数据同步：主从库实现数据一致

## 前言

在前面两篇博客，我们了解了 AOF 和 RDB，如果 Redis 发生了宕机，它们可以分别通过回放日志和重新读入 RDB 文件的方式恢复数据，从而尽可能地减少数据丢失，提升可靠性。

不过，之前讨论的范围都是在单机 Redis 的场景下，如果 Redis 集群中存在多个节点，如果某个实例宕机了，它在恢复期间是无法服务新来的数据请求，那么该如何处理呢？

我们经常会听到 Redis 具有**高可靠性**，这里指的主要是：**数据尽量少丢失**和**服务尽量少中断**。AOF 和 RDB 保证了前者，而对于后者，Redis 的做法是**增加副本冗余量**，说简单点就是，将一份数据同时保存在多个实例上。这样一来，即使有一个实例出现了故障，需要过一段时间才能恢复，其他实例也可以对外提供服务，不会影响业务使用。

但这会引发出一个新的问题：这么多的副本，它们之间的数据如何保持一致呢？数据的读写操作可以发送给所有的实例吗？

## 主从模式

Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。

- **读操作**：主库、从库都可以接收；
- **写操作**：首先到主库执行，然后，主库将同步写操作给从库。

![master-slave](https://raw.githubusercontent.com/QuakeWang/quakewang.github.io/22073d5a33bc440f222174790c6934e7cb64c31e/content/imag/tech/redis/04_Master_Slave.svg)

那么，为什么要这样设计呢？

道理很简单，如果在上图中，不管是主库还是从库，都能接收客户端的写操作，就会带来这样一个问题：如果客户端对同一个数据（例如 k1）前后修改了三次，每一次的修改请求都发送到不同的节点上执行，那么，这个数据在这三个节点上的副本就不一致了（分别是 v1、v2 和 v3）。在读取这个数据的时候，就可能读取到旧的值。

如果我们非要保持数据在这三个节点上是一致的，就要涉及到加锁、实例间协商是否完成修改等一系列操作，但这会带来巨额的开销，对于整个集群来说是较大的负担。

而主从模式如果采用了读写分离，所有数据的修改只会在主库上进行，不用协调三个节点。主库有了最新的数据后，会同步给从库，这样主从库的数据就是一致的。

那么，主从库同步是如何完成的呢？主库数据是一次性传给从库，还是分批同步？要是主从库间的网络断连了，数据还能保持一致吗？带着这些思考，继续看下去吧。

## 第一次同步

首先，我们来看主从模式下的第一次同步是如何进行的，这也是 Redis 实例建立主从模式后的规定动作。

当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof 命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。

例如，现在有实例 1（IP：192.168.10.102）和实例 2（IP：192.168.10.103），在实例 2 上执行 `replicaof 192.168.10.102 6379` 命令，实例 2 就会变成实例 1 的从库，并从实例 1 上复制数据。

关于主从数据第一次同步的三个阶段，具体可以看下图：

![first-sync-process](https://raw.githubusercontent.com/QuakeWang/quakewang.github.io/22073d5a33bc440f222174790c6934e7cb64c31e/content/imag/tech/redis/04_First_Sync.svg)

第一阶段是主从之间建立连接、协商同步的过程，主要是为全量复制做准备。在这一步，**从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从之间就可以开始同步了**。

具体来说，从库给主库发送 `psync` 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。`psync` 命令包括了**主库的 runID** 和**复制进度的 offset**两个参数。

- **runID**：每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实力。当从库和主库第一次复制时，因为不知主库的 runID，所以将 runID 设为“?”。
- **offset**：此时设为 -1，表示第一次复制。

主库收到 `psync` 命令后，会用 FULLRESYNC 响应命令并带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。从库接收到响应后，会记录下这两个参数。

这里有个需要注意的地方，**FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库**。

在第二阶段，**主库将所有数据同步给从库。从库接收到数据后，在本地完成数据加载**。在这个过程依赖于内存快照生成的 RDB 文件。

具体来说，主库执行完 `bgsave` 命令，生成 RDB 文件，接着将文件发给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 `replicaof` 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。

在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，就会把此时 replication buffer 中的修改操作发送给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。

## 主从级联模式

通过分析主从库间第一次数据同步的过程，可以看到，一次全量复制中，对于主库来说，需要完成两个好事的操作：生成 RDB 文件和传输 RDB 文件。

如果从库数据很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量同步。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。

针对上述产生的问题，我们就可以选用“主 - 从 - 从”模式来解决。

在刚才介绍的主从模式中，所有的从库都是和主库连接，所有的全量复制也都是和主库进行的。现在，我们可以通过“主 - 从 - 从”模式将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上。

简单来说，在部署主从集群的时候，可以手动选择一个从库，比如内存资源配置较高的从库，用于级联其他的从库。然后，可以再选择一些从库，在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。

```bash
replicaof 所选从库的 IP 6379
```

这样一来，这些从库就会知道，在进行同步时，不用再和主库进行交互了，只要和级联的从库进行写操作同步就行，从而减轻了主库上的压力。

![m-s-s](https://raw.githubusercontent.com/QuakeWang/quakewang.github.io/22073d5a33bc440f222174790c6934e7cb64c31e/content/imag/tech/redis/04_Master_Slave_Slave.svg)

到这里，我们了解了主从库间通过全量复制实现数据同步的过程，以及通过“主 - 从 -从”模式分担主库压力的方式。一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续收到的命令再同步给从库，这个过程也称为**基于长连接的命令传播**，可以避免频繁建立连接的开销。

## 网络断连

上面的过程看似一切顺利，但却有这不可忽视的风险点，那就是**网络断连或阻塞**。如果网络断连，主从库之间就无法进行命令传播了，从库的数据自然也就没办法和主库保持一致，客户端就可能在从库中读取到旧数据，

Redis 提供的解决办法是，网络断了之后，主从库会采用增量复制的方式继续同步，增量复制只会把主从库网络断连期间主库收到的命令同步给从库。

那么，增量复制时，主从库之间是怎么保持同步的呢？原因是 repl_backlog_buff 这个缓冲区。我们先来看看它是如何用于增量命令的同步的。

当主从库断连后，主库会把断连期间收到的写操作命令，写入 replication buffer，同时也会把这些操作命令也写入 repl_backlog_buffer 这个缓冲区。repl_backlog_buffer 是一个环形缓冲区，**主库会记录自己写到的位置，从库则会记录自己已经读到的位置**。

刚开始的时候，主库和从库的写读位置在一起，这算是它们的起始位置。随着主库不断接收新的写操作，它在缓冲区中的写位置会逐步偏离起始位置，我们通常用偏移量来衡量这个偏移距离的大小，对主库来说，对应的偏移量就是 master_repl_offset。主库接收的新写操作越多，这个值就会越大。

同样，从库在复制完写操作命令后，它在缓冲区中的读位置也开始逐步偏移刚才的起始位置，此时，从库已复制的偏移量 slave_repl_offset 也在不断增加。正常情况下，这两个偏移量基本相等。

![repl-backlog-buffer](https://raw.githubusercontent.com/QuakeWang/quakewang.github.io/22073d5a33bc440f222174790c6934e7cb64c31e/content/imag/tech/redis/04_Repl_Backlog_Buffer.svg)

主从库的连接恢复之后，从库首先会给主库发送 psync 命令，并把自己当前的 slave_repl_offset 发给主库，主库会判断自己的 master_repl_offset 和 slave_repl_offset 之间的差距。

在网络断连阶段，主库可能会收到新的写操作命令，所以，一般来说，master_repl_offset 会大于 slave_repl_offset。此时，主库只用把 master_repl_offset 和 slave_repl_offset 之间的命令操作同步给从库就行。

就像刚刚示意图的中间部分，主库和从库之间相差了 `put d e` 和 `put d f` 两个操作，在增量复制时，主库只需要把它们同步给从库，就行了。

![network-error](https://raw.githubusercontent.com/QuakeWang/quakewang.github.io/22073d5a33bc440f222174790c6934e7cb64c31e/content/imag/tech/redis/04_Network_Error.svg)

不过，这里还有一个地方需要注意一下，因为 repl_backlog_buffer 是一个环形缓冲区，所以在缓冲区写满后，主库会继续写入，此时，就会覆盖了之前写入的操作。**如果从库的读取速度比较慢，就有可能导致从库还未读取的操作被主库新写的操作覆盖了，这会导致主从库间的数据不一致**。

因此，就需要想办法避免这一情况，通常来说，可以调整 **repl_backlog_size** 这个参数。这个参数和所需的缓冲空间大小有关。缓冲空间的计算公式是：缓冲空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度 * 操作大小。在实际应用中，考虑到可能存在一些突发的请求压力，我们通常需要把这个缓冲空间扩大一倍，即 repl_backlog_size = 缓冲空间大小 * 2，这也就是 repl_backlog_size 的最终值。

举个例子，如果主库每秒写入 2000 个操作，每个操作的大小为 2KB，网络每秒能传输 1000 个操作，那么，有 1000 个操作需要缓冲起来，这就至少需要 2MB 的缓冲空间。否则，新写的命令就会覆盖掉旧操作了。为了应对可能的突发压力，我们最终把 repl_backlog_size 设为 4MB。

这样一来，增量复制时主从库的数据不一致风险就降低了。不过，如果并发请求量非常大，连两倍的缓冲空间都存不下新操作请求的话，此时，主从库仍然可能会不一致。针对这种情况，就可以根据 Redis 所在服务器的内存资源继续增加 repl_backlog_size 的值。或者使用**切片集群**来分担单个主库的请求压力（关于切片集群留个坑）。

## 总结

在这篇博客中，主要概括了 Redis 主从库同步的基本原理，总结起来，有三种模式：全量复制、基于长连接的命令传播，以及增量复制。

全量复制虽然耗时，但对于从库来说，如果是第一次同步，全量复制是无法避免的，所以尽可能保证一个 Redis 实例的数据库不要太大，一个实例大小在几 GB 比较合适，这样可以减少 RDB 文件生成、传输和重新加载的开销。另外，为了避免多个从库同时和主库进行全量复制，给主库过大的同步压力，也可以采用“主 - 从 - 从”级联模式。来缓解主库的压力。

长连接复制是主从库正常运行后的常规同步阶段。在这个阶段中，主从库之间通过命令传播实现同步。不过，这期间如果遇到了网络断连，增量复制就派上用场了。其中需要注意的点事 repl_backlog_size 这个配置参数。如果它配置得过小，在增量复制阶段，可能会导致从库的复制进度赶不上主库，进而导致从库重新进行全量复制。所以，通过调大这个参数，可以减少从库在网络断连时全量复制的风险。


## 延伸

AOF 记录的操作命令更全，相比于 RDB 丢失的数据更少。那么，为什么主从库间的复制不使用 AOF 呢？

- RDB 文件是二进制文件，无论是要把 RDB 写入磁盘，还是要通过网络传输 RDB，IO 效率都比记录和传输 AOF 的高；
- 在从库进行恢复时，用 RDB 的恢复效率要高于 AOF。
